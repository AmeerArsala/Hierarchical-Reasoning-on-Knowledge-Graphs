{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1776e602-293c-4caa-a4ba-33ea9bc2fbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fab36db-24ea-4096-9b6c-a5f5c0385016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I hate python\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(\"qagnn\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "faca6092-f661-41cb-a708-90955800235f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ent_emb': ['tzw'], 'dataset': 'csqa', 'inhouse': True, 'inhouse_train_qids': 'qagnn/data/csqa/inhouse_split_qids.txt', 'train_statements': 'qagnn/data/csqa/statement/train.statement.jsonl', 'dev_statements': 'qagnn/data/csqa/statement/dev.statement.jsonl', 'test_statements': 'qagnn/data/csqa/statement/test.statement.jsonl', 'max_seq_len': 100, 'encoder': 'FacebookAI/roberta-large', 'encoder_layer': -1, 'encoder_lr': 1e-05, 'loss': 'cross_entropy', 'optim': 'radam', 'lr_schedule': 'fixed', 'batch_size': 64, 'warmup_steps': 150, 'max_grad_norm': 1.0, 'weight_decay': 0.01, 'n_epochs': 15, 'max_epochs_before_stop': 10, 'log_interval': 10, 'cuda': True, 'seed': 0, 'debug': False, 'mode': 'train', 'save_dir': 'qagnn/saved_models/csqa/enc-FacebookAI/roberta-large__k5__gnndim200__bs64__seed0__20240320_173213', 'save_model': True, 'load_model_path': None, 'num_relation': 38, 'train_adj': 'qagnn/data/csqa/graph/train.graph.adj.pk', 'dev_adj': 'qagnn/data/csqa/graph/dev.graph.adj.pk', 'test_adj': 'qagnn/data/csqa/graph/test.graph.adj.pk', 'use_cache': True, 'k': 5, 'att_head_num': 2, 'gnn_dim': 200, 'fc_dim': 200, 'fc_layer_num': 0, 'freeze_ent_emb': True, 'max_node_num': 200, 'simple': False, 'subsample': 1.0, 'init_range': 0.02, 'dropouti': 0.2, 'dropoutg': 0.2, 'dropoutf': 0.2, 'decoder_lr': 0.001, 'mini_batch_size': 2, 'eval_batch_size': 2, 'unfreeze_epoch': 4, 'refreeze_epoch': 10000, 'fp16': True, 'drop_partial_batch': False, 'fill_partial_batch': False, 'ent_emb_paths': ['data/cpnet/tzw.ent.npy']}\n",
      "| num_concepts: 799273 |\n",
      "train_statement_path qagnn/data/csqa/statement/train.statement.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9741/9741 [00:06<00:00, 1455.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1221/1221 [00:00<00:00, 1423.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_choice 5\n",
      "| ori_adj_len: mu 121.54 sigma 94.04 | adj_len: 107.96 | prune_rate： 0.17 | qc_num: 7.43 | ac_num: 2.07 |\n",
      "| ori_adj_len: mu 118.44 sigma 90.55 | adj_len: 106.55 | prune_rate： 0.15 | qc_num: 7.20 | ac_num: 2.05 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1140/1140 [00:00<00:00, 2022.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| ori_adj_len: mu 119.20 sigma 93.49 | adj_len: 106.22 | prune_rate： 0.16 | qc_num: 7.38 | ac_num: 2.05 |\n",
      "args.num_relation 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at FacebookAI/roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LM_QAGNN(\n",
       "  (encoder): TextEncoder(\n",
       "    (module): RobertaModel(\n",
       "      (embeddings): RobertaEmbeddings(\n",
       "        (word_embeddings): Embedding(50265, 1024, padding_idx=1)\n",
       "        (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
       "        (token_type_embeddings): Embedding(1, 1024)\n",
       "        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): RobertaEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-23): 24 x RobertaLayer(\n",
       "            (attention): RobertaAttention(\n",
       "              (self): RobertaSelfAttention(\n",
       "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): RobertaSelfOutput(\n",
       "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): RobertaIntermediate(\n",
       "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): RobertaOutput(\n",
       "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): RobertaPooler(\n",
       "        (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): QAGNN(\n",
       "    (concept_emb): CustomizedEmbedding(\n",
       "      (emb): Embedding(799273, 1024)\n",
       "      (cpt_transform): Linear(in_features=1024, out_features=200, bias=True)\n",
       "      (activation): GELU()\n",
       "    )\n",
       "    (svec2nvec): Linear(in_features=1024, out_features=200, bias=True)\n",
       "    (activation): GELU()\n",
       "    (gnn): QAGNN_Message_Passing(\n",
       "      (emb_node_type): Linear(in_features=4, out_features=100, bias=True)\n",
       "      (emb_score): Linear(in_features=100, out_features=100, bias=True)\n",
       "      (edge_encoder): Sequential(\n",
       "        (0): Linear(in_features=47, out_features=200, bias=True)\n",
       "        (1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Linear(in_features=200, out_features=200, bias=True)\n",
       "      )\n",
       "      (gnn_layers): ModuleList(\n",
       "        (0-4): 5 x GATConvE()\n",
       "      )\n",
       "      (Vh): Linear(in_features=200, out_features=200, bias=True)\n",
       "      (Vx): Linear(in_features=200, out_features=200, bias=True)\n",
       "      (activation): GELU()\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (pooler): MultiheadAttPoolLayer(\n",
       "      (w_qs): Linear(in_features=1024, out_features=200, bias=True)\n",
       "      (w_ks): Linear(in_features=200, out_features=200, bias=True)\n",
       "      (w_vs): Linear(in_features=200, out_features=200, bias=True)\n",
       "      (attention): MatrixVectorScaledDotProductAttention(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (softmax): Softmax(dim=1)\n",
       "      )\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (fc): MLP(\n",
       "      (layers): Sequential(\n",
       "        (0-Linear): Linear(in_features=1424, out_features=1, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (dropout_e): Dropout(p=0.2, inplace=False)\n",
       "    (dropout_fc): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from munch import DefaultMunch\n",
    "from modeling.modeling_qagnn import LM_QAGNN, LM_QAGNN_DataLoader\n",
    "\n",
    "\n",
    "OUTPUT_DIR = \"qagnn/saved_models/csqa/enc-FacebookAI/roberta-large__k5__gnndim200__bs64__seed0__20240320_173213\"\n",
    "\n",
    "# Load the configuration from the JSON file\n",
    "with open(f'{OUTPUT_DIR}/config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Fix the paths (I hate python x2)\n",
    "paths_to_fix = [\"inhouse_train_qids\", \"train_statements\", \"dev_statements\", \"test_statements\", \"train_adj\", \"dev_adj\", \"test_adj\", \"save_dir\"]\n",
    "for path in paths_to_fix:\n",
    "    config[path] = f\"qagnn/{config[path]}\" \n",
    "\n",
    "print(config)\n",
    "\n",
    "relative_ent_emb_path: str = config[\"ent_emb_paths\"][0]\n",
    "config[\"ent_emb_paths\"][0] = f\"qagnn/{relative_ent_emb_path}\" \n",
    "\n",
    "# Convert dict to object (I hate python x3)\n",
    "args = DefaultMunch.fromDict(config)\n",
    "\n",
    "\n",
    "# Now that we've worked around Python's BS, we can finally play around with this\n",
    "# Now let's load it!\n",
    "cp_emb = [np.load(path) for path in args.ent_emb_paths]\n",
    "cp_emb = torch.tensor(np.concatenate(cp_emb, 1), dtype=torch.float)\n",
    "\n",
    "concept_num, concept_dim = cp_emb.size(0), cp_emb.size(1)\n",
    "print('| num_concepts: {} |'.format(concept_num))\n",
    "\n",
    "if torch.cuda.device_count() >= 2 and args.cuda:\n",
    "    device0 = torch.device(\"cuda:0\")\n",
    "    device1 = torch.device(\"cuda:1\")\n",
    "elif torch.cuda.device_count() == 1 and args.cuda:\n",
    "    device0 = torch.device(\"cuda:0\")\n",
    "    device1 = torch.device(\"cuda:0\")\n",
    "else:\n",
    "    device0 = torch.device(\"cpu\")\n",
    "    device1 = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "dataset = LM_QAGNN_DataLoader(args, args.train_statements, args.train_adj,\n",
    "                                               args.dev_statements, args.dev_adj,\n",
    "                                               args.test_statements, args.test_adj,\n",
    "                                               batch_size=args.batch_size, eval_batch_size=args.eval_batch_size,\n",
    "                                               device=(device0, device1),\n",
    "                                               model_name=args.encoder,\n",
    "                                               max_node_num=args.max_node_num, max_seq_length=args.max_seq_len,\n",
    "                                               is_inhouse=args.inhouse, inhouse_train_qids_path=args.inhouse_train_qids,\n",
    "                                               subsample=args.subsample, use_cache=args.use_cache)\n",
    "\n",
    "###################################################################################################\n",
    "#   Build model                                                                                   #\n",
    "###################################################################################################\n",
    "print('args.num_relation', args.num_relation)\n",
    "qa_gnn = LM_QAGNN(args, args.encoder, k=args.k, n_ntype=4, n_etype=args.num_relation, n_concept=concept_num,\n",
    "                                   concept_dim=args.gnn_dim,\n",
    "                                   concept_in_dim=concept_dim,\n",
    "                                   n_attention_head=args.att_head_num, fc_dim=args.fc_dim, n_fc_layer=args.fc_layer_num,\n",
    "                                   p_emb=args.dropouti, p_gnn=args.dropoutg, p_fc=args.dropoutf,\n",
    "                                   pretrained_concept_emb=cp_emb, freeze_ent_emb=args.freeze_ent_emb,\n",
    "                                   init_range=args.init_range,\n",
    "                                   encoder_config={})\n",
    "\n",
    "qa_gnn.encoder.to(device0)\n",
    "qa_gnn.decoder.to(device1)\n",
    "\n",
    "qa_gnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd622f54-0ea6-46b1-af7e-eb32dc2e1236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(qa_gnn, torch.nn.Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3604e18d-59ab-4957-b531-8161e13fc689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the checkpoint\n",
    "checkpoint = torch.load(f\"{OUTPUT_DIR}/model.pt.14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "95ec06fd-e2f1-48f5-9d31-45d9753a7a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OrderedDict([('encoder.module.embeddings.word_embeddings.weight',\n",
       "               tensor([[-0.1402, -0.0094,  0.0387,  ...,  0.0506, -0.0055, -0.0362],\n",
       "                       [ 0.0078, -0.0156,  0.0156,  ..., -0.0156,  0.0231,  0.0156],\n",
       "                       [-0.0830, -0.0004, -0.1170,  ...,  0.1088,  0.0691, -0.0357],\n",
       "                       ...,\n",
       "                       [ 0.0393,  0.0031,  0.0465,  ..., -0.0240, -0.0505,  0.0342],\n",
       "                       [ 0.0499,  0.0272,  0.0413,  ..., -0.0370, -0.0100,  0.0071],\n",
       "                       [-0.0149, -0.0114, -0.0222,  ...,  0.0441,  0.0116, -0.0330]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.embeddings.position_embeddings.weight',\n",
       "               tensor([[-0.0038,  0.0253, -0.0092,  ...,  0.0177,  0.0062, -0.0162],\n",
       "                       [ 0.0117, -0.0019, -0.0267,  ...,  0.0062, -0.0193,  0.0263],\n",
       "                       [ 0.0319,  0.0150, -0.0553,  ..., -0.0719, -0.0456,  0.0466],\n",
       "                       ...,\n",
       "                       [-0.0209, -0.0052,  0.0484,  ..., -0.0394,  0.0463,  0.0537],\n",
       "                       [-0.0274,  0.1172,  0.0470,  ...,  0.0169, -0.1204,  0.0525],\n",
       "                       [ 0.0969, -0.0729,  0.0558,  ..., -0.1204, -0.1075,  0.0489]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.embeddings.token_type_embeddings.weight',\n",
       "               tensor([[-1.0618e-05,  2.8758e-05, -3.0997e-04,  ..., -3.2288e-05,\n",
       "                        -9.2162e-05,  2.4317e-04]], device='cuda:0')),\n",
       "              ('encoder.module.embeddings.LayerNorm.weight',\n",
       "               tensor([0.9345, 0.9233, 0.9123,  ..., 0.9408, 0.9148, 0.9019], device='cuda:0')),\n",
       "              ('encoder.module.embeddings.LayerNorm.bias',\n",
       "               tensor([ 0.0314,  0.0421,  0.1922,  ..., -0.2254, -0.0895,  0.1252],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.0.attention.self.query.weight',\n",
       "               tensor([[-0.0035,  0.0343, -0.0013,  ...,  0.0033,  0.0593, -0.0433],\n",
       "                       [-0.0244,  0.0518, -0.0165,  ..., -0.0310, -0.0134,  0.0099],\n",
       "                       [ 0.0037,  0.0732, -0.0307,  ...,  0.0802,  0.0114, -0.0114],\n",
       "                       ...,\n",
       "                       [-0.0586,  0.0189, -0.0421,  ..., -0.0325,  0.0046,  0.0688],\n",
       "                       [ 0.0418,  0.0229, -0.0642,  ..., -0.0528, -0.0167,  0.0189],\n",
       "                       [-0.0199, -0.0427, -0.0099,  ...,  0.0460,  0.0245, -0.0176]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.0.attention.self.query.bias',\n",
       "               tensor([ 0.3103,  0.0555, -0.0737,  ..., -0.0701, -0.0528, -0.0658],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.0.attention.self.key.weight',\n",
       "               tensor([[-0.0045, -0.0172, -0.0130,  ..., -0.0044,  0.0072, -0.0139],\n",
       "                       [-0.0238, -0.0003,  0.0267,  ...,  0.0390,  0.0427, -0.0212],\n",
       "                       [-0.0287, -0.0528, -0.0136,  ..., -0.0341,  0.0068,  0.0191],\n",
       "                       ...,\n",
       "                       [-0.0704, -0.0227, -0.0193,  ..., -0.0186,  0.0133,  0.1045],\n",
       "                       [ 0.0148,  0.0054, -0.0194,  ..., -0.0014, -0.0083,  0.0437],\n",
       "                       [-0.0076, -0.0644,  0.0450,  ...,  0.0460,  0.0174, -0.0477]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.0.attention.self.key.bias',\n",
       "               tensor([-0.0039, -0.0033, -0.0011,  ...,  0.0014,  0.0016,  0.0019],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.0.attention.self.value.weight',\n",
       "               tensor([[ 0.0326,  0.0017, -0.0227,  ..., -0.0245,  0.0013,  0.0220],\n",
       "                       [ 0.0568,  0.0460,  0.0025,  ..., -0.0176,  0.0915, -0.0176],\n",
       "                       [-0.0168, -0.0435,  0.0110,  ..., -0.0510,  0.0006,  0.0638],\n",
       "                       ...,\n",
       "                       [-0.0100,  0.0080, -0.0122,  ...,  0.0355,  0.0262,  0.0146],\n",
       "                       [-0.0038, -0.0113, -0.0569,  ...,  0.0372, -0.0323,  0.0305],\n",
       "                       [ 0.0024, -0.0069, -0.0114,  ..., -0.0242,  0.0885, -0.0161]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.0.attention.self.value.bias',\n",
       "               tensor([-0.0015,  0.0012, -0.0092,  ..., -0.0235, -0.0204, -0.0351],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.0.attention.output.dense.weight',\n",
       "               tensor([[ 0.0037,  0.0409, -0.0174,  ..., -0.0164, -0.0334, -0.0146],\n",
       "                       [-0.0360,  0.0116, -0.0144,  ...,  0.0334, -0.0053,  0.0270],\n",
       "                       [ 0.0270, -0.0738,  0.0180,  ..., -0.0318, -0.0049,  0.0995],\n",
       "                       ...,\n",
       "                       [ 0.0258,  0.0024,  0.0231,  ...,  0.0139, -0.0109, -0.0401],\n",
       "                       [-0.0061,  0.0525, -0.0469,  ...,  0.0420,  0.0255, -0.0173],\n",
       "                       [ 0.0478,  0.0247,  0.0921,  ...,  0.0261,  0.0095,  0.0082]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.0.attention.output.dense.bias',\n",
       "               tensor([-0.0140,  0.0290,  0.0845,  ...,  0.0737, -0.0088,  0.0105],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.0.attention.output.LayerNorm.weight',\n",
       "               tensor([0.9801, 0.9888, 0.9740,  ..., 0.9834, 0.9908, 0.9955], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.0.attention.output.LayerNorm.bias',\n",
       "               tensor([-0.4313,  0.2762, -0.0082,  ...,  0.0119,  0.3295, -0.2980],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.0.intermediate.dense.weight',\n",
       "               tensor([[ 0.0577, -0.0650, -0.0921,  ...,  0.0056,  0.0177, -0.0157],\n",
       "                       [ 0.0162, -0.0287,  0.0204,  ...,  0.0148, -0.0403,  0.1210],\n",
       "                       [ 0.0370, -0.0655, -0.0023,  ...,  0.0306, -0.0267, -0.0214],\n",
       "                       ...,\n",
       "                       [ 0.0160, -0.0911,  0.0038,  ...,  0.0337, -0.0487,  0.0007],\n",
       "                       [ 0.1340,  0.0506, -0.1338,  ..., -0.1487, -0.0339,  0.0232],\n",
       "                       [ 0.0707, -0.0305, -0.0604,  ...,  0.0107, -0.0559, -0.0312]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.0.intermediate.dense.bias',\n",
       "               tensor([-0.0955, -0.0762, -0.0829,  ..., -0.1065, -0.0703, -0.0931],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.0.output.dense.weight',\n",
       "               tensor([[ 0.0440,  0.1033,  0.0296,  ..., -0.0544,  0.0583,  0.0658],\n",
       "                       [ 0.0181,  0.0091, -0.0102,  ..., -0.0043,  0.0201, -0.0115],\n",
       "                       [ 0.0274, -0.0708,  0.0514,  ..., -0.0398, -0.0097,  0.0031],\n",
       "                       ...,\n",
       "                       [-0.0144, -0.0045,  0.0531,  ...,  0.0100, -0.0610,  0.0133],\n",
       "                       [-0.0500,  0.0326, -0.0726,  ...,  0.0563, -0.0353, -0.0029],\n",
       "                       [-0.0944, -0.0434, -0.0970,  ..., -0.0545,  0.0548, -0.0317]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.0.output.dense.bias',\n",
       "               tensor([ 0.0637, -0.0392,  0.0423,  ...,  0.0081, -0.0957,  0.0558],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.0.output.LayerNorm.weight',\n",
       "               tensor([0.9693, 0.9603, 0.9665,  ..., 0.9714, 0.9695, 0.9492], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.0.output.LayerNorm.bias',\n",
       "               tensor([ 0.3963, -0.1877,  0.0424,  ..., -0.0483, -0.2742,  0.2006],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.1.attention.self.query.weight',\n",
       "               tensor([[ 0.0213, -0.1125,  0.0191,  ..., -0.0657, -0.0288, -0.0350],\n",
       "                       [ 0.0322, -0.0090,  0.0987,  ..., -0.0253,  0.0251,  0.1673],\n",
       "                       [ 0.0102, -0.0432,  0.0326,  ...,  0.0083,  0.0004, -0.0043],\n",
       "                       ...,\n",
       "                       [ 0.0163,  0.0324,  0.0658,  ...,  0.0452, -0.0525,  0.1040],\n",
       "                       [-0.1168,  0.0718,  0.0684,  ..., -0.0135, -0.0762,  0.0614],\n",
       "                       [ 0.0294, -0.0692,  0.0241,  ...,  0.0651,  0.0013,  0.0046]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.1.attention.self.query.bias',\n",
       "               tensor([ 0.0741,  0.0509, -0.0696,  ...,  0.0822,  0.0454, -0.0778],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.1.attention.self.key.weight',\n",
       "               tensor([[-0.0101,  0.0598, -0.0090,  ..., -0.0296,  0.0141, -0.0163],\n",
       "                       [-0.0195, -0.0880, -0.0577,  ...,  0.0531, -0.0386,  0.0150],\n",
       "                       [-0.0130,  0.0401,  0.0355,  ...,  0.0066,  0.0013, -0.0113],\n",
       "                       ...,\n",
       "                       [-0.0619, -0.0674,  0.0816,  ...,  0.0227,  0.0218,  0.0022],\n",
       "                       [ 0.0472, -0.0481,  0.0354,  ...,  0.0481,  0.0382, -0.0329],\n",
       "                       [ 0.0616,  0.0385,  0.0560,  ...,  0.0918,  0.0252,  0.0010]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.1.attention.self.key.bias',\n",
       "               tensor([ 1.5260e-03, -8.1243e-04, -7.9964e-04,  ...,  2.8900e-04,\n",
       "                       -5.8891e-05,  9.3044e-04], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.1.attention.self.value.weight',\n",
       "               tensor([[-0.0651,  0.0028, -0.0267,  ..., -0.0064,  0.0536,  0.0284],\n",
       "                       [-0.0196,  0.0350, -0.0340,  ..., -0.0098,  0.0327, -0.0211],\n",
       "                       [ 0.0019,  0.0369,  0.0038,  ...,  0.0248,  0.0853, -0.0175],\n",
       "                       ...,\n",
       "                       [-0.0039, -0.0807, -0.0334,  ..., -0.0223,  0.0369,  0.0237],\n",
       "                       [-0.0613,  0.0684, -0.0166,  ..., -0.0053,  0.0229, -0.0134],\n",
       "                       [ 0.0363,  0.0348,  0.0144,  ...,  0.0116,  0.0311, -0.0158]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.1.attention.self.value.bias',\n",
       "               tensor([ 0.0067,  0.0036,  0.0057,  ...,  0.0012, -0.0547, -0.0021],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.1.attention.output.dense.weight',\n",
       "               tensor([[-0.0384, -0.0116,  0.0060,  ..., -0.0720, -0.0308,  0.0185],\n",
       "                       [ 0.0016, -0.0531, -0.0047,  ..., -0.0744, -0.0386,  0.0060],\n",
       "                       [ 0.0435,  0.0116, -0.0226,  ..., -0.0307,  0.0177,  0.0337],\n",
       "                       ...,\n",
       "                       [-0.0066, -0.0177,  0.0368,  ...,  0.0223, -0.0257,  0.0481],\n",
       "                       [-0.0194,  0.0105,  0.0087,  ..., -0.0492, -0.0399, -0.0518],\n",
       "                       [ 0.0052, -0.0219,  0.0423,  ...,  0.0079, -0.0465,  0.0257]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.1.attention.output.dense.bias',\n",
       "               tensor([-0.2173,  0.0390, -0.0820,  ..., -0.0753,  0.2331,  0.0729],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.1.attention.output.LayerNorm.weight',\n",
       "               tensor([0.9831, 0.9999, 0.9579,  ..., 0.9794, 0.9882, 0.9729], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.1.attention.output.LayerNorm.bias',\n",
       "               tensor([-0.3297,  0.1810, -0.0329,  ..., -0.0727,  0.2494, -0.2292],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.1.intermediate.dense.weight',\n",
       "               tensor([[ 0.0285, -0.0341, -0.0020,  ..., -0.0203,  0.1008,  0.0514],\n",
       "                       [-0.0029, -0.0696, -0.0298,  ...,  0.0348, -0.0021, -0.0550],\n",
       "                       [-0.0044,  0.0846,  0.0727,  ...,  0.0144,  0.0216, -0.0072],\n",
       "                       ...,\n",
       "                       [-0.0392, -0.0434,  0.1242,  ...,  0.0005,  0.0130, -0.0307],\n",
       "                       [ 0.0744, -0.0583, -0.1045,  ..., -0.0316,  0.0243, -0.0830],\n",
       "                       [ 0.0011,  0.0746,  0.0947,  ..., -0.0187, -0.0265,  0.0313]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.1.intermediate.dense.bias',\n",
       "               tensor([ 0.0960, -0.0533, -0.0538,  ..., -0.0873, -0.0856, -0.0858],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.1.output.dense.weight',\n",
       "               tensor([[-0.0209, -0.0180,  0.0632,  ..., -0.0227, -0.0908,  0.0513],\n",
       "                       [ 0.0459, -0.0187, -0.0137,  ..., -0.0317, -0.0057, -0.0449],\n",
       "                       [ 0.0414,  0.0374,  0.0648,  ..., -0.0265, -0.0519,  0.0961],\n",
       "                       ...,\n",
       "                       [ 0.0416, -0.0619, -0.0756,  ..., -0.0404,  0.0235,  0.0344],\n",
       "                       [ 0.0095,  0.0857,  0.1109,  ...,  0.0651, -0.0422, -0.0220],\n",
       "                       [-0.0650,  0.0733,  0.0051,  ..., -0.0345,  0.0692,  0.0394]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.1.output.dense.bias',\n",
       "               tensor([ 0.0100,  0.0058,  0.0672,  ...,  0.0119, -0.0484,  0.0130],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.1.output.LayerNorm.weight',\n",
       "               tensor([0.9591, 0.9943, 0.9396,  ..., 0.9688, 0.9669, 0.9388], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.1.output.LayerNorm.bias',\n",
       "               tensor([ 0.1891, -0.1931, -0.0495,  ..., -0.0135, -0.2732,  0.1576],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.2.attention.self.query.weight',\n",
       "               tensor([[ 0.0039, -0.0496,  0.0445,  ..., -0.0288, -0.0679, -0.0151],\n",
       "                       [-0.0826, -0.0900,  0.0350,  ..., -0.0250,  0.0030,  0.0135],\n",
       "                       [-0.0214, -0.0071, -0.0401,  ..., -0.0336, -0.0133, -0.0217],\n",
       "                       ...,\n",
       "                       [ 0.0205, -0.0192, -0.0119,  ..., -0.0352,  0.0825, -0.0730],\n",
       "                       [ 0.0316, -0.0969, -0.0500,  ..., -0.0463, -0.0011,  0.0119],\n",
       "                       [ 0.0207, -0.0244, -0.0707,  ...,  0.0729, -0.0066,  0.0467]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.2.attention.self.query.bias',\n",
       "               tensor([-0.0627,  0.1263,  0.1138,  ..., -0.1519,  0.0648, -0.1616],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.2.attention.self.key.weight',\n",
       "               tensor([[ 0.0138,  0.1364,  0.0391,  ...,  0.0353,  0.0184, -0.0570],\n",
       "                       [-0.0002,  0.0156, -0.0160,  ..., -0.0302, -0.0384,  0.0428],\n",
       "                       [ 0.0658, -0.0082,  0.0020,  ..., -0.0537,  0.0267, -0.0464],\n",
       "                       ...,\n",
       "                       [-0.0028, -0.0351, -0.0346,  ..., -0.0019, -0.0546, -0.0682],\n",
       "                       [-0.0551, -0.0334,  0.0353,  ...,  0.0027, -0.0500,  0.0193],\n",
       "                       [ 0.0320,  0.0149, -0.0258,  ...,  0.0672,  0.0113,  0.0533]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.2.attention.self.key.bias',\n",
       "               tensor([-9.1236e-04, -2.6559e-03, -1.1033e-03,  ...,  4.9065e-05,\n",
       "                       -6.6379e-04, -9.1310e-04], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.2.attention.self.value.weight',\n",
       "               tensor([[-0.0059,  0.0502,  0.0218,  ...,  0.0288,  0.0287,  0.0007],\n",
       "                       [-0.0005,  0.0914, -0.0207,  ..., -0.0035, -0.0302, -0.0043],\n",
       "                       [ 0.0204,  0.0468,  0.0072,  ...,  0.0364,  0.0283, -0.0200],\n",
       "                       ...,\n",
       "                       [-0.0115,  0.0285, -0.0110,  ..., -0.0393, -0.0268,  0.0396],\n",
       "                       [ 0.0609,  0.0396, -0.0402,  ..., -0.0240,  0.0644,  0.0300],\n",
       "                       [-0.0240, -0.0091,  0.0009,  ..., -0.0115,  0.0123,  0.0530]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.2.attention.self.value.bias',\n",
       "               tensor([-0.0299,  0.0157,  0.0105,  ..., -0.0050,  0.0107, -0.0050],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.2.attention.output.dense.weight',\n",
       "               tensor([[-1.3482e-02, -1.6333e-02,  2.1289e-02,  ..., -5.4758e-03,\n",
       "                        -1.1926e-02,  2.3625e-02],\n",
       "                       [ 3.1707e-03,  1.6660e-02, -1.4398e-02,  ..., -4.6522e-02,\n",
       "                        -1.2077e-02, -2.8264e-03],\n",
       "                       [ 6.0994e-03,  4.0657e-02, -7.1024e-02,  ..., -1.2754e-02,\n",
       "                        -1.3767e-02, -1.5191e-02],\n",
       "                       ...,\n",
       "                       [-3.0070e-02, -7.1995e-03,  4.8884e-02,  ..., -3.0136e-03,\n",
       "                         9.1774e-03, -1.2675e-02],\n",
       "                       [-8.0736e-02, -2.0098e-05,  3.2670e-03,  ...,  4.3712e-02,\n",
       "                         1.9678e-02, -8.8421e-03],\n",
       "                       [ 5.4194e-02,  4.8298e-02,  6.4266e-05,  ...,  4.8767e-03,\n",
       "                         5.4590e-02,  2.6172e-02]], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.2.attention.output.dense.bias',\n",
       "               tensor([ 0.0609, -0.0594,  0.0323,  ...,  0.0803, -0.0397,  0.0737],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.2.attention.output.LayerNorm.weight',\n",
       "               tensor([0.9813, 0.9851, 0.9860,  ..., 0.9628, 0.9561, 0.9711], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.2.attention.output.LayerNorm.bias',\n",
       "               tensor([-0.0941, -0.0032, -0.3413,  ..., -0.0276, -0.0715,  0.2152],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.2.intermediate.dense.weight',\n",
       "               tensor([[ 0.0228,  0.0860,  0.0685,  ..., -0.0477, -0.0158, -0.0440],\n",
       "                       [-0.0248, -0.0678,  0.0926,  ..., -0.0752,  0.0543, -0.0043],\n",
       "                       [-0.0730,  0.0045,  0.0926,  ...,  0.0138,  0.0224,  0.0031],\n",
       "                       ...,\n",
       "                       [-0.0364, -0.0123,  0.0055,  ...,  0.0065, -0.0011,  0.0199],\n",
       "                       [-0.0674,  0.0101, -0.0131,  ..., -0.0002,  0.0338, -0.0952],\n",
       "                       [ 0.0008,  0.0221,  0.0189,  ..., -0.0159, -0.0528, -0.1006]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.2.intermediate.dense.bias',\n",
       "               tensor([-0.0233, -0.0801, -0.0688,  ...,  0.0582, -0.0866, -0.0891],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.2.output.dense.weight',\n",
       "               tensor([[-0.0241,  0.0824,  0.0166,  ..., -0.0397, -0.1089,  0.0008],\n",
       "                       [-0.0072,  0.0175, -0.0628,  ...,  0.0476, -0.0254, -0.0119],\n",
       "                       [ 0.0537, -0.0567,  0.0586,  ...,  0.0124, -0.0475, -0.0761],\n",
       "                       ...,\n",
       "                       [ 0.0061, -0.0443,  0.0690,  ...,  0.0143,  0.1029,  0.0017],\n",
       "                       [ 0.0487, -0.0090, -0.0308,  ...,  0.0113, -0.0955, -0.0088],\n",
       "                       [ 0.0311, -0.0490, -0.0231,  ..., -0.0424,  0.0165,  0.0011]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.2.output.dense.bias',\n",
       "               tensor([-0.0089, -0.0411,  0.0116,  ...,  0.0297,  0.0136,  0.0442],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.2.output.LayerNorm.weight',\n",
       "               tensor([0.9654, 0.9686, 0.9535,  ..., 0.9730, 0.9769, 0.9592], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.2.output.LayerNorm.bias',\n",
       "               tensor([-0.0324, -0.1077,  0.2081,  ..., -0.0504, -0.0277, -0.2035],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.3.attention.self.query.weight',\n",
       "               tensor([[-0.0715,  0.0100,  0.0374,  ...,  0.0288,  0.0525, -0.0108],\n",
       "                       [-0.0187, -0.0765, -0.0403,  ...,  0.0358, -0.0141,  0.0315],\n",
       "                       [-0.0206, -0.0179,  0.0800,  ...,  0.0355, -0.0197,  0.0060],\n",
       "                       ...,\n",
       "                       [-0.0568, -0.0124, -0.0112,  ...,  0.0377,  0.0884, -0.0206],\n",
       "                       [ 0.0692, -0.0346,  0.0424,  ..., -0.0892,  0.0267, -0.0357],\n",
       "                       [ 0.0320,  0.0647, -0.0204,  ..., -0.0421, -0.0323,  0.0206]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.3.attention.self.query.bias',\n",
       "               tensor([-0.0245, -0.0527,  0.0306,  ...,  0.0132,  0.1152, -0.0827],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.3.attention.self.key.weight',\n",
       "               tensor([[-0.1327, -0.0380,  0.0013,  ...,  0.0233,  0.0478, -0.0255],\n",
       "                       [ 0.0243,  0.1003,  0.0936,  ..., -0.0250,  0.0848, -0.0455],\n",
       "                       [ 0.0056, -0.0404,  0.0914,  ..., -0.0175,  0.0154, -0.0207],\n",
       "                       ...,\n",
       "                       [-0.0248, -0.0049, -0.0034,  ...,  0.0737, -0.0610, -0.0407],\n",
       "                       [ 0.0021, -0.0245, -0.0065,  ...,  0.0403, -0.0319,  0.0083],\n",
       "                       [ 0.0313,  0.0118,  0.0217,  ...,  0.0154, -0.0308, -0.0182]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.3.attention.self.key.bias',\n",
       "               tensor([ 2.7646e-05,  1.1264e-03,  1.7614e-04,  ...,  1.3361e-03,\n",
       "                       -8.6365e-04,  4.9541e-04], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.3.attention.self.value.weight',\n",
       "               tensor([[ 0.0118, -0.0319, -0.0748,  ...,  0.0303,  0.0971,  0.0226],\n",
       "                       [-0.0173,  0.0381,  0.0468,  ..., -0.0292,  0.0076, -0.0065],\n",
       "                       [ 0.0397,  0.0377, -0.0703,  ..., -0.0517,  0.0276,  0.0236],\n",
       "                       ...,\n",
       "                       [ 0.0722,  0.0009,  0.0130,  ...,  0.0227,  0.0312,  0.0434],\n",
       "                       [-0.0226,  0.0503, -0.0326,  ..., -0.0040, -0.1066, -0.0126],\n",
       "                       [ 0.0266, -0.0087, -0.0443,  ..., -0.0314, -0.0028, -0.0478]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.3.attention.self.value.bias',\n",
       "               tensor([-0.0183, -0.0084, -0.0073,  ...,  0.0066,  0.0060, -0.0011],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.3.attention.output.dense.weight',\n",
       "               tensor([[-0.0004,  0.0027,  0.0343,  ...,  0.0009, -0.0267, -0.0284],\n",
       "                       [ 0.0108, -0.0084,  0.0408,  ...,  0.0132, -0.0189,  0.0139],\n",
       "                       [-0.0789,  0.0120, -0.0064,  ..., -0.0124,  0.0572, -0.0048],\n",
       "                       ...,\n",
       "                       [ 0.0211, -0.0009, -0.0218,  ...,  0.0220, -0.0327,  0.0140],\n",
       "                       [ 0.0129,  0.0421,  0.0025,  ..., -0.0075, -0.0125, -0.0087],\n",
       "                       [-0.0284, -0.0182,  0.0179,  ..., -0.0088,  0.0168,  0.0359]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.3.attention.output.dense.bias',\n",
       "               tensor([ 0.0423, -0.0197, -0.0265,  ..., -0.0228,  0.0345, -0.0205],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.3.attention.output.LayerNorm.weight',\n",
       "               tensor([0.9866, 0.9823, 0.9769,  ..., 0.9864, 0.9784, 0.9661], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.3.attention.output.LayerNorm.bias',\n",
       "               tensor([-0.1803, -0.1192, -0.3015,  ..., -0.0454,  0.1130,  0.0350],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.3.intermediate.dense.weight',\n",
       "               tensor([[ 0.0116,  0.0397, -0.0336,  ..., -0.0524, -0.0227, -0.0354],\n",
       "                       [ 0.0370,  0.0314,  0.0163,  ...,  0.0232, -0.0439, -0.0148],\n",
       "                       [ 0.0341, -0.0616, -0.0168,  ...,  0.0668, -0.1823,  0.0079],\n",
       "                       ...,\n",
       "                       [-0.0285, -0.0329, -0.0361,  ...,  0.0337, -0.0248, -0.0534],\n",
       "                       [ 0.0301, -0.0594, -0.0384,  ..., -0.0018,  0.0214, -0.0295],\n",
       "                       [ 0.0002,  0.0048, -0.0462,  ...,  0.0120, -0.0645, -0.0449]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.3.intermediate.dense.bias',\n",
       "               tensor([-0.0912, -0.1102, -0.0566,  ..., -0.1007, -0.0188, -0.0873],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.3.output.dense.weight',\n",
       "               tensor([[-0.0193, -0.0332, -0.0233,  ...,  0.0202, -0.0676, -0.0083],\n",
       "                       [ 0.0242, -0.0141, -0.0245,  ..., -0.0045, -0.0456, -0.0677],\n",
       "                       [-0.0763, -0.0783,  0.0211,  ...,  0.0563, -0.0287, -0.0015],\n",
       "                       ...,\n",
       "                       [ 0.0082,  0.0291,  0.0779,  ..., -0.0534, -0.0733,  0.0006],\n",
       "                       [-0.0966, -0.0811, -0.0590,  ..., -0.0209, -0.0069, -0.1064],\n",
       "                       [ 0.1377,  0.0522, -0.0634,  ...,  0.0482, -0.0441,  0.0301]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.3.output.dense.bias',\n",
       "               tensor([-0.0872,  0.0331,  0.0637,  ...,  0.0406, -0.0829,  0.2712],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.3.output.LayerNorm.weight',\n",
       "               tensor([0.9753, 0.9917, 0.9679,  ..., 0.9714, 0.9672, 0.9497], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.3.output.LayerNorm.bias',\n",
       "               tensor([ 0.0134, -0.0074,  0.1964,  ..., -0.0254, -0.1183, -0.0805],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.4.attention.self.query.weight',\n",
       "               tensor([[-0.0063, -0.0137, -0.0589,  ..., -0.0077, -0.0344, -0.0073],\n",
       "                       [-0.0024,  0.0018,  0.0431,  ..., -0.0606, -0.0116,  0.0691],\n",
       "                       [-0.0847,  0.0070,  0.0155,  ..., -0.0648, -0.0117,  0.0285],\n",
       "                       ...,\n",
       "                       [ 0.0164,  0.0070, -0.0130,  ...,  0.0210,  0.0043,  0.0016],\n",
       "                       [ 0.0172, -0.0275,  0.0376,  ..., -0.0104, -0.0284,  0.0164],\n",
       "                       [ 0.0352, -0.1014, -0.0187,  ..., -0.0377, -0.0363, -0.1452]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.4.attention.self.query.bias',\n",
       "               tensor([ 0.2099,  0.0040,  0.2280,  ..., -0.2532, -0.1884,  0.2033],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.4.attention.self.key.weight',\n",
       "               tensor([[-0.0186, -0.0762, -0.0492,  ..., -0.0070, -0.0442,  0.0077],\n",
       "                       [-0.0532, -0.0106,  0.0206,  ...,  0.0042, -0.0242,  0.0125],\n",
       "                       [ 0.0139,  0.0292,  0.0413,  ...,  0.0327,  0.0659, -0.0061],\n",
       "                       ...,\n",
       "                       [ 0.0371,  0.0803,  0.0373,  ...,  0.0556,  0.0096,  0.0901],\n",
       "                       [-0.0151, -0.0257, -0.0283,  ..., -0.0180, -0.0420,  0.0626],\n",
       "                       [ 0.0043,  0.0279, -0.0063,  ...,  0.0267, -0.0332,  0.0235]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.4.attention.self.key.bias',\n",
       "               tensor([ 0.0006, -0.0002,  0.0003,  ..., -0.0005, -0.0002, -0.0002],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.4.attention.self.value.weight',\n",
       "               tensor([[-0.0094,  0.0010,  0.0084,  ...,  0.0207,  0.0029,  0.0478],\n",
       "                       [ 0.0199,  0.0609, -0.0225,  ...,  0.0637, -0.0176, -0.0740],\n",
       "                       [ 0.0368,  0.0162,  0.0247,  ...,  0.0519, -0.0345,  0.0642],\n",
       "                       ...,\n",
       "                       [ 0.0117,  0.0652,  0.0219,  ...,  0.0489, -0.0018,  0.0250],\n",
       "                       [ 0.0274,  0.0077,  0.0162,  ...,  0.0291, -0.0030,  0.0633],\n",
       "                       [ 0.0086, -0.1033, -0.0014,  ..., -0.0403,  0.0335,  0.0074]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.4.attention.self.value.bias',\n",
       "               tensor([-0.0094, -0.0033,  0.0089,  ..., -0.0075,  0.0025, -0.0005],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.4.attention.output.dense.weight',\n",
       "               tensor([[-0.0334, -0.0706, -0.0206,  ..., -0.0066, -0.0078,  0.0661],\n",
       "                       [-0.0453, -0.0165, -0.0117,  ...,  0.0457,  0.0283,  0.0089],\n",
       "                       [ 0.0060,  0.0090, -0.0099,  ..., -0.0415,  0.0451, -0.0116],\n",
       "                       ...,\n",
       "                       [ 0.0044,  0.0053,  0.0072,  ...,  0.0125,  0.0027, -0.0156],\n",
       "                       [-0.0023,  0.0141, -0.0295,  ...,  0.0535,  0.0048, -0.0254],\n",
       "                       [ 0.0173,  0.0456, -0.0143,  ..., -0.0102, -0.0274,  0.0094]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.4.attention.output.dense.bias',\n",
       "               tensor([-0.0073, -0.0125, -0.0086,  ...,  0.0167, -0.0641, -0.0042],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.4.attention.output.LayerNorm.weight',\n",
       "               tensor([0.9904, 0.9983, 0.9867,  ..., 0.9873, 0.9975, 0.9586], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.4.attention.output.LayerNorm.bias',\n",
       "               tensor([-0.1679,  0.0776, -0.2974,  ...,  0.0608,  0.0174,  0.2049],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.4.intermediate.dense.weight',\n",
       "               tensor([[ 0.0025,  0.0551, -0.0333,  ..., -0.0766,  0.0540,  0.0405],\n",
       "                       [-0.0144, -0.0164, -0.0074,  ..., -0.0157, -0.0173, -0.0903],\n",
       "                       [-0.0326,  0.0143,  0.0496,  ..., -0.0940,  0.0211, -0.0463],\n",
       "                       ...,\n",
       "                       [-0.0589, -0.0233,  0.0650,  ...,  0.1269,  0.0421, -0.0711],\n",
       "                       [-0.0040, -0.0810, -0.0883,  ..., -0.0558, -0.0258,  0.0620],\n",
       "                       [-0.0365, -0.0229,  0.0063,  ...,  0.0205,  0.0368, -0.0449]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.4.intermediate.dense.bias',\n",
       "               tensor([-0.0894, -0.0796, -0.0722,  ..., -0.0708, -0.0520, -0.0546],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.4.output.dense.weight',\n",
       "               tensor([[-0.0204,  0.0603,  0.0072,  ...,  0.0362, -0.0110, -0.0280],\n",
       "                       [-0.0465, -0.0276, -0.0511,  ...,  0.0357, -0.0569,  0.0018],\n",
       "                       [ 0.0150,  0.0825,  0.1045,  ...,  0.0022,  0.0528, -0.0289],\n",
       "                       ...,\n",
       "                       [-0.0351, -0.0456, -0.0653,  ...,  0.1405, -0.0656,  0.0144],\n",
       "                       [ 0.0388, -0.0213,  0.0319,  ...,  0.1022, -0.0142,  0.0146],\n",
       "                       [ 0.0074, -0.0455, -0.0988,  ..., -0.0382,  0.0641, -0.0394]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.4.output.dense.bias',\n",
       "               tensor([-0.0843, -0.0168,  0.1403,  ...,  0.0093, -0.1006,  0.1652],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.4.output.LayerNorm.weight',\n",
       "               tensor([0.9729, 0.9961, 0.9750,  ..., 0.9770, 0.9965, 0.9674], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.4.output.LayerNorm.bias',\n",
       "               tensor([ 0.0116, -0.1011,  0.2787,  ..., -0.1055, -0.1017, -0.1644],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.5.attention.self.query.weight',\n",
       "               tensor([[ 0.0700, -0.0118,  0.0258,  ..., -0.0179,  0.0206,  0.0343],\n",
       "                       [ 0.0536, -0.0120,  0.0065,  ...,  0.0029,  0.0462, -0.1405],\n",
       "                       [-0.0546, -0.0125, -0.0211,  ...,  0.0232, -0.0477, -0.0022],\n",
       "                       ...,\n",
       "                       [-0.0178, -0.0199, -0.0732,  ..., -0.0314,  0.0172,  0.0018],\n",
       "                       [ 0.0474, -0.0839,  0.0218,  ...,  0.0348,  0.0220, -0.0326],\n",
       "                       [-0.0076,  0.0275,  0.0586,  ...,  0.0085,  0.0673,  0.0537]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.5.attention.self.query.bias',\n",
       "               tensor([ 0.0330, -0.0289, -0.0239,  ...,  0.0297,  0.1256, -0.1331],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.5.attention.self.key.weight',\n",
       "               tensor([[ 2.0024e-03,  6.4798e-02, -9.3016e-03,  ..., -4.0371e-02,\n",
       "                         5.8995e-03, -1.4847e-02],\n",
       "                       [ 3.8978e-02, -2.1360e-02, -3.8421e-02,  ...,  3.6202e-02,\n",
       "                         3.1528e-02, -3.7590e-02],\n",
       "                       [ 3.5582e-02, -1.6480e-02, -3.2980e-02,  ..., -1.1358e-01,\n",
       "                         4.2403e-02,  3.2613e-02],\n",
       "                       ...,\n",
       "                       [ 2.7950e-02,  5.7143e-05, -4.7798e-03,  ...,  2.7696e-02,\n",
       "                         6.5372e-02,  4.1512e-02],\n",
       "                       [ 1.7674e-02,  7.0106e-03, -1.3185e-02,  ...,  1.6778e-02,\n",
       "                        -1.5144e-02,  1.0560e-02],\n",
       "                       [-7.3066e-02,  1.2416e-03,  5.9495e-02,  ..., -5.3007e-02,\n",
       "                         1.7157e-02,  3.3654e-03]], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.5.attention.self.key.bias',\n",
       "               tensor([ 0.0008, -0.0002, -0.0002,  ...,  0.0018,  0.0009,  0.0005],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.5.attention.self.value.weight',\n",
       "               tensor([[-0.0212,  0.0520,  0.0126,  ..., -0.0003, -0.0068,  0.0516],\n",
       "                       [-0.0671, -0.0655, -0.0130,  ...,  0.0227, -0.0432, -0.0596],\n",
       "                       [ 0.0387, -0.0426, -0.0291,  ..., -0.0003, -0.0125,  0.0323],\n",
       "                       ...,\n",
       "                       [ 0.0302, -0.0207, -0.0139,  ..., -0.0306, -0.0094, -0.0315],\n",
       "                       [ 0.0561,  0.0271, -0.0972,  ...,  0.0122, -0.0089,  0.0470],\n",
       "                       [-0.0355,  0.0701, -0.0230,  ..., -0.0224, -0.0215,  0.0236]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.5.attention.self.value.bias',\n",
       "               tensor([ 0.0020, -0.0050, -0.0023,  ...,  0.0085, -0.0056, -0.0094],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.5.attention.output.dense.weight',\n",
       "               tensor([[ 0.0298, -0.0095, -0.0192,  ...,  0.0245,  0.0241, -0.0229],\n",
       "                       [-0.0986,  0.0298,  0.0095,  ..., -0.0521, -0.0189,  0.0467],\n",
       "                       [ 0.0651, -0.0071,  0.0426,  ..., -0.0187, -0.0406, -0.0307],\n",
       "                       ...,\n",
       "                       [-0.0108, -0.0525, -0.0141,  ..., -0.0065,  0.0209, -0.0371],\n",
       "                       [ 0.0010,  0.0128,  0.0365,  ...,  0.0085, -0.0688, -0.0014],\n",
       "                       [ 0.0070,  0.0254,  0.0213,  ...,  0.0340, -0.0079, -0.0044]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.5.attention.output.dense.bias',\n",
       "               tensor([ 0.0058,  0.0078, -0.0753,  ..., -0.0274, -0.0630, -0.0143],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.5.attention.output.LayerNorm.weight',\n",
       "               tensor([0.9914, 0.9988, 0.9986,  ..., 0.9788, 0.9925, 0.9698], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.5.attention.output.LayerNorm.bias',\n",
       "               tensor([-0.1208,  0.0556, -0.2698,  ...,  0.0015, -0.0934,  0.0926],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.5.intermediate.dense.weight',\n",
       "               tensor([[-0.0017, -0.0376, -0.0314,  ..., -0.0090, -0.0048, -0.0247],\n",
       "                       [-0.0046, -0.0437, -0.0200,  ..., -0.0161,  0.0678, -0.0435],\n",
       "                       [ 0.0645,  0.0491,  0.0060,  ..., -0.0124, -0.0359,  0.0523],\n",
       "                       ...,\n",
       "                       [-0.0156, -0.0546, -0.0125,  ...,  0.0600,  0.0030, -0.0714],\n",
       "                       [-0.0238, -0.1218,  0.0010,  ...,  0.0287,  0.0660, -0.0308],\n",
       "                       [-0.0576,  0.0428,  0.0489,  ...,  0.0289, -0.0008,  0.0442]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.5.intermediate.dense.bias',\n",
       "               tensor([-0.0727, -0.1106, -0.1094,  ..., -0.0520, -0.1169, -0.1059],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.5.output.dense.weight',\n",
       "               tensor([[-0.0309,  0.0612,  0.0031,  ..., -0.0152, -0.0379,  0.0261],\n",
       "                       [ 0.0446, -0.0577,  0.0644,  ..., -0.0438, -0.0211, -0.0806],\n",
       "                       [ 0.0063,  0.0121, -0.0138,  ..., -0.0324, -0.0124, -0.0699],\n",
       "                       ...,\n",
       "                       [-0.0677, -0.0647, -0.0335,  ...,  0.0011,  0.1031, -0.0220],\n",
       "                       [-0.0118,  0.0196, -0.0772,  ..., -0.0258, -0.0109, -0.0043],\n",
       "                       [ 0.0015, -0.0225,  0.0842,  ..., -0.0507,  0.0294, -0.0353]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.5.output.dense.bias',\n",
       "               tensor([-0.1073,  0.0105,  0.1376,  ..., -0.0012, -0.0590,  0.1447],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.5.output.LayerNorm.weight',\n",
       "               tensor([0.9725, 0.9938, 0.9904,  ..., 0.9754, 0.9918, 0.9571], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.5.output.LayerNorm.bias',\n",
       "               tensor([-0.0165, -0.1135,  0.2715,  ..., -0.1173, -0.0456, -0.1471],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.6.attention.self.query.weight',\n",
       "               tensor([[ 0.0196, -0.0262,  0.0548,  ...,  0.0419,  0.0496,  0.0079],\n",
       "                       [-0.0054, -0.0329, -0.0064,  ..., -0.0063, -0.0499, -0.0331],\n",
       "                       [ 0.0380,  0.1499,  0.0873,  ...,  0.0484,  0.0453,  0.0364],\n",
       "                       ...,\n",
       "                       [ 0.0096, -0.0026, -0.1047,  ...,  0.0315,  0.0681,  0.0648],\n",
       "                       [ 0.0259,  0.0189,  0.0191,  ...,  0.0054,  0.0270,  0.0863],\n",
       "                       [-0.0396, -0.0008,  0.0403,  ..., -0.0430,  0.0341, -0.0310]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.6.attention.self.query.bias',\n",
       "               tensor([-0.3070,  0.0543, -0.3075,  ..., -0.0908,  0.0279,  0.0038],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.6.attention.self.key.weight',\n",
       "               tensor([[ 2.7794e-02, -3.0469e-02,  6.7685e-02,  ..., -1.1314e-02,\n",
       "                        -2.7330e-02, -6.8249e-04],\n",
       "                       [-1.6221e-02,  3.0847e-02,  1.9335e-02,  ...,  9.9139e-02,\n",
       "                         7.6029e-02,  1.5817e-02],\n",
       "                       [ 5.5143e-02,  6.2480e-05,  1.8972e-02,  ..., -1.4660e-02,\n",
       "                        -3.5012e-02, -4.0957e-02],\n",
       "                       ...,\n",
       "                       [-1.8491e-02,  1.6199e-02,  3.6844e-03,  ..., -3.3738e-02,\n",
       "                         1.3604e-02, -6.4020e-05],\n",
       "                       [-7.4941e-02, -6.2888e-02, -1.0905e-03,  ...,  4.5084e-02,\n",
       "                         3.7688e-02, -6.9551e-03],\n",
       "                       [ 9.9136e-03,  3.3959e-02,  9.2323e-05,  ...,  5.8859e-02,\n",
       "                         3.0609e-02, -9.0229e-03]], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.6.attention.self.key.bias',\n",
       "               tensor([ 7.7416e-04, -6.6255e-04,  1.7531e-04,  ..., -7.8539e-05,\n",
       "                        7.7771e-05,  3.3924e-04], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.6.attention.self.value.weight',\n",
       "               tensor([[ 0.0128,  0.0158, -0.0072,  ..., -0.0311, -0.0133, -0.0016],\n",
       "                       [-0.0024,  0.0396,  0.0185,  ..., -0.0564,  0.0383,  0.0133],\n",
       "                       [-0.0173, -0.0563,  0.0531,  ...,  0.0453, -0.0023,  0.0233],\n",
       "                       ...,\n",
       "                       [ 0.0149,  0.0407,  0.0010,  ...,  0.0473, -0.0586,  0.0014],\n",
       "                       [ 0.0094, -0.0157, -0.0046,  ..., -0.0296,  0.0175, -0.0146],\n",
       "                       [ 0.0117,  0.0239,  0.0226,  ..., -0.0345,  0.1073,  0.0264]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.6.attention.self.value.bias',\n",
       "               tensor([-0.0072, -0.0077, -0.0015,  ..., -0.0179, -0.0082, -0.0027],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.6.attention.output.dense.weight',\n",
       "               tensor([[-0.0386,  0.0046, -0.0161,  ...,  0.0405, -0.0315, -0.0049],\n",
       "                       [ 0.0188, -0.0355, -0.0399,  ...,  0.0210,  0.0384, -0.0200],\n",
       "                       [ 0.0493, -0.0577, -0.0384,  ...,  0.0265,  0.0671, -0.0364],\n",
       "                       ...,\n",
       "                       [-0.0168,  0.0494,  0.0012,  ..., -0.0426,  0.0060,  0.0211],\n",
       "                       [-0.0267,  0.0231,  0.0434,  ...,  0.0247, -0.0197, -0.0410],\n",
       "                       [-0.0220,  0.0472,  0.0231,  ...,  0.0603,  0.0046,  0.0188]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.6.attention.output.dense.bias',\n",
       "               tensor([ 7.2820e-03, -1.1136e-02,  3.1680e-02,  ...,  6.8015e-05,\n",
       "                       -6.6930e-02,  8.7634e-03], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.6.attention.output.LayerNorm.weight',\n",
       "               tensor([0.9850, 0.9996, 0.9997,  ..., 0.9824, 0.9801, 0.9517], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.6.attention.output.LayerNorm.bias',\n",
       "               tensor([-0.1210,  0.0572, -0.2836,  ..., -0.0225, -0.1026,  0.1006],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.6.intermediate.dense.weight',\n",
       "               tensor([[-0.0049, -0.0055, -0.0124,  ..., -0.0033,  0.0405,  0.0701],\n",
       "                       [ 0.0059,  0.0058, -0.0010,  ..., -0.0272,  0.0210, -0.0421],\n",
       "                       [-0.0606, -0.0774, -0.0482,  ...,  0.0749, -0.0169, -0.0796],\n",
       "                       ...,\n",
       "                       [-0.0475, -0.0407,  0.0061,  ..., -0.0117,  0.0809, -0.0509],\n",
       "                       [ 0.0039,  0.0025,  0.0085,  ...,  0.0126,  0.0112,  0.0075],\n",
       "                       [-0.0101, -0.0606,  0.0461,  ..., -0.0201,  0.0190, -0.1269]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.6.intermediate.dense.bias',\n",
       "               tensor([-0.0800, -0.0928, -0.1035,  ..., -0.0771, -0.0703, -0.1737],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.6.output.dense.weight',\n",
       "               tensor([[ 0.0272, -0.0351, -0.0201,  ...,  0.0352,  0.0233, -0.0080],\n",
       "                       [ 0.0100, -0.0430, -0.0086,  ..., -0.0072,  0.0349,  0.0114],\n",
       "                       [ 0.0245, -0.0135, -0.0904,  ...,  0.0430, -0.0433,  0.0378],\n",
       "                       ...,\n",
       "                       [ 0.0093, -0.0625,  0.0094,  ..., -0.0169,  0.0571, -0.0456],\n",
       "                       [ 0.0281,  0.0008, -0.1135,  ..., -0.0174, -0.0273,  0.0639],\n",
       "                       [ 0.0405,  0.0090,  0.0191,  ..., -0.0306,  0.0257, -0.0177]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.6.output.dense.bias',\n",
       "               tensor([-0.0681,  0.0310,  0.0668,  ..., -0.0088, -0.0556,  0.0709],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.6.output.LayerNorm.weight',\n",
       "               tensor([0.9826, 0.9898, 1.0000,  ..., 0.9792, 0.9755, 0.9611], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.6.output.LayerNorm.bias',\n",
       "               tensor([-0.0242, -0.1124,  0.1121,  ..., -0.0807, -0.0280, -0.1336],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.7.attention.self.query.weight',\n",
       "               tensor([[ 0.0189, -0.0202,  0.0036,  ...,  0.0258, -0.0392, -0.1074],\n",
       "                       [ 0.0567, -0.0802, -0.0153,  ...,  0.0166, -0.0427,  0.0196],\n",
       "                       [-0.1335,  0.0187,  0.0228,  ...,  0.0098,  0.0817,  0.0018],\n",
       "                       ...,\n",
       "                       [-0.0297,  0.1953,  0.0427,  ...,  0.0570,  0.0103,  0.1292],\n",
       "                       [ 0.0085,  0.0252, -0.0313,  ...,  0.0126,  0.0743,  0.1002],\n",
       "                       [ 0.0170,  0.0126,  0.0277,  ...,  0.0942,  0.1176,  0.0466]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.7.attention.self.query.bias',\n",
       "               tensor([ 0.0159,  0.0130, -0.0539,  ..., -0.2545,  0.1263, -0.2625],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.7.attention.self.key.weight',\n",
       "               tensor([[ 0.0044, -0.0022, -0.0544,  ..., -0.0081, -0.0031,  0.0631],\n",
       "                       [ 0.0124,  0.0054,  0.0236,  ...,  0.0236, -0.0455,  0.0065],\n",
       "                       [-0.0079, -0.0427, -0.0183,  ...,  0.0219, -0.0369,  0.0292],\n",
       "                       ...,\n",
       "                       [-0.0245,  0.0017,  0.0287,  ..., -0.0510, -0.0771, -0.0423],\n",
       "                       [-0.0697,  0.0383,  0.0179,  ..., -0.0069, -0.0242,  0.0808],\n",
       "                       [ 0.0222,  0.0233,  0.0276,  ...,  0.0108, -0.0107, -0.0332]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.7.attention.self.key.bias',\n",
       "               tensor([-3.1071e-04, -8.7827e-04, -9.8964e-05,  ...,  3.7811e-04,\n",
       "                        6.2051e-04,  3.3757e-04], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.7.attention.self.value.weight',\n",
       "               tensor([[ 0.0065, -0.0216,  0.0022,  ...,  0.0201, -0.0024, -0.0427],\n",
       "                       [-0.0115, -0.0296, -0.0225,  ..., -0.0176, -0.0343, -0.0479],\n",
       "                       [ 0.0236, -0.0200,  0.0250,  ..., -0.0146,  0.0223,  0.0083],\n",
       "                       ...,\n",
       "                       [-0.0020, -0.0426,  0.0138,  ...,  0.0235,  0.0379,  0.0100],\n",
       "                       [-0.0549, -0.0563, -0.0036,  ...,  0.0457,  0.0207,  0.0210],\n",
       "                       [ 0.0357, -0.0014, -0.0254,  ...,  0.0328, -0.0364, -0.0162]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.7.attention.self.value.bias',\n",
       "               tensor([ 0.0012,  0.0337, -0.0517,  ...,  0.0140,  0.0036,  0.0048],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.7.attention.output.dense.weight',\n",
       "               tensor([[ 0.0013, -0.0077,  0.0298,  ...,  0.0086,  0.0639, -0.0320],\n",
       "                       [-0.0392,  0.0027,  0.0162,  ...,  0.0410, -0.0791,  0.0256],\n",
       "                       [-0.0340, -0.0198,  0.0132,  ...,  0.0439,  0.0380,  0.0345],\n",
       "                       ...,\n",
       "                       [ 0.0448,  0.0032,  0.0524,  ...,  0.0072, -0.0658, -0.0062],\n",
       "                       [ 0.0110,  0.0139,  0.0117,  ..., -0.0084,  0.0159,  0.0333],\n",
       "                       [-0.0120, -0.0280, -0.0094,  ..., -0.0520, -0.0143,  0.0465]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.7.attention.output.dense.bias',\n",
       "               tensor([-0.0172,  0.0162, -0.0390,  ..., -0.0470, -0.0039,  0.0278],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.7.attention.output.LayerNorm.weight',\n",
       "               tensor([0.9910, 0.9864, 0.9999,  ..., 0.9805, 0.9598, 0.9747], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.7.attention.output.LayerNorm.bias',\n",
       "               tensor([-0.0919,  0.0109, -0.4246,  ..., -0.0742, -0.1016, -0.0008],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.7.intermediate.dense.weight',\n",
       "               tensor([[-0.0649,  0.0356,  0.0165,  ...,  0.0629,  0.0046,  0.0348],\n",
       "                       [ 0.0648,  0.0383, -0.0084,  ..., -0.0020, -0.0383, -0.0372],\n",
       "                       [-0.0375, -0.0248, -0.0008,  ...,  0.0163,  0.0164,  0.0334],\n",
       "                       ...,\n",
       "                       [ 0.0060,  0.0325,  0.0043,  ..., -0.0391, -0.0228,  0.0072],\n",
       "                       [-0.0333, -0.1084,  0.0162,  ..., -0.0868, -0.0081, -0.0115],\n",
       "                       [-0.0504, -0.0502,  0.0032,  ...,  0.0442, -0.0249,  0.0339]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.7.intermediate.dense.bias',\n",
       "               tensor([-0.0924, -0.0911, -0.0114,  ...,  0.0073, -0.0845, -0.0317],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.7.output.dense.weight',\n",
       "               tensor([[-0.0116,  0.0720, -0.0146,  ...,  0.0152, -0.1039, -0.0401],\n",
       "                       [ 0.0330,  0.0777,  0.0048,  ..., -0.0379, -0.0641,  0.0317],\n",
       "                       [-0.0133, -0.0086, -0.0086,  ...,  0.0290,  0.0141,  0.0066],\n",
       "                       ...,\n",
       "                       [-0.0593,  0.0384, -0.0252,  ...,  0.0267, -0.0118,  0.0272],\n",
       "                       [-0.0096, -0.0016, -0.0243,  ...,  0.0291,  0.0201,  0.0133],\n",
       "                       [ 0.0689, -0.0198,  0.0120,  ..., -0.0292,  0.0173, -0.0433]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.7.output.dense.bias',\n",
       "               tensor([-0.1937,  0.0498,  0.1158,  ..., -0.0160, -0.0424,  0.0587],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.7.output.LayerNorm.weight',\n",
       "               tensor([0.9892, 0.9893, 0.9990,  ..., 0.9805, 0.9774, 0.9516], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.7.output.LayerNorm.bias',\n",
       "               tensor([-0.0313, -0.0963, -0.0034,  ..., -0.0475, -0.0410, -0.1096],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.8.attention.self.query.weight',\n",
       "               tensor([[ 0.0358,  0.0331,  0.0311,  ...,  0.0218,  0.0173,  0.0115],\n",
       "                       [-0.0904, -0.0679,  0.0669,  ..., -0.0369,  0.0025,  0.0109],\n",
       "                       [-0.0667,  0.1055, -0.0310,  ...,  0.0427,  0.0672, -0.0033],\n",
       "                       ...,\n",
       "                       [ 0.0616,  0.0421, -0.0026,  ..., -0.0072,  0.0861, -0.0056],\n",
       "                       [ 0.0114,  0.0807, -0.0314,  ..., -0.1259,  0.0415,  0.0285],\n",
       "                       [-0.0275, -0.0795,  0.0003,  ...,  0.0057, -0.0169, -0.0442]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.8.attention.self.query.bias',\n",
       "               tensor([-0.0948,  0.1278,  0.0216,  ..., -0.1389, -0.0547,  0.0569],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.8.attention.self.key.weight',\n",
       "               tensor([[-0.0710,  0.0463,  0.0003,  ..., -0.1572,  0.0552, -0.0123],\n",
       "                       [-0.0544, -0.0026,  0.1166,  ...,  0.0146,  0.0182, -0.0305],\n",
       "                       [ 0.0419, -0.0373, -0.0595,  ..., -0.0314,  0.1134, -0.0309],\n",
       "                       ...,\n",
       "                       [-0.0084,  0.0541, -0.0413,  ...,  0.0566,  0.0012,  0.0333],\n",
       "                       [-0.0787,  0.0296, -0.0481,  ...,  0.0119,  0.0417, -0.0280],\n",
       "                       [-0.0111, -0.0857,  0.0332,  ...,  0.0145,  0.0086, -0.0653]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.8.attention.self.key.bias',\n",
       "               tensor([ 5.7599e-05,  2.1966e-04, -2.7304e-04,  ...,  3.6880e-05,\n",
       "                       -5.2950e-05,  1.5549e-04], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.8.attention.self.value.weight',\n",
       "               tensor([[ 0.0439,  0.0023, -0.0153,  ..., -0.0456,  0.0317,  0.0349],\n",
       "                       [-0.0498, -0.0349, -0.0010,  ...,  0.0655,  0.0012,  0.0494],\n",
       "                       [ 0.0018, -0.0060,  0.0048,  ..., -0.0010, -0.0085, -0.0674],\n",
       "                       ...,\n",
       "                       [ 0.0030,  0.0341,  0.0177,  ..., -0.0221, -0.0396, -0.0317],\n",
       "                       [ 0.0523, -0.0485,  0.0015,  ..., -0.0060, -0.0176, -0.0135],\n",
       "                       [-0.0276, -0.0153,  0.0039,  ...,  0.0417, -0.0164, -0.0403]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.8.attention.self.value.bias',\n",
       "               tensor([-0.0069, -0.0148,  0.0093,  ..., -0.0142, -0.0056, -0.0037],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.8.attention.output.dense.weight',\n",
       "               tensor([[ 0.0287, -0.0025, -0.0088,  ..., -0.0007,  0.0061, -0.0011],\n",
       "                       [ 0.0024, -0.0160,  0.0281,  ..., -0.0005,  0.0400,  0.0616],\n",
       "                       [ 0.0499, -0.0381,  0.0264,  ...,  0.0437, -0.0358,  0.0063],\n",
       "                       ...,\n",
       "                       [-0.0340,  0.0262, -0.0164,  ...,  0.0362, -0.0339, -0.0307],\n",
       "                       [-0.0473,  0.0049, -0.0263,  ...,  0.0026,  0.0016,  0.0064],\n",
       "                       [ 0.0270, -0.0116,  0.0306,  ...,  0.0233,  0.0035,  0.0472]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.8.attention.output.dense.bias',\n",
       "               tensor([-0.0504,  0.0051,  0.0043,  ...,  0.0091, -0.0962,  0.0549],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.8.attention.output.LayerNorm.weight',\n",
       "               tensor([0.9887, 0.9956, 1.0000,  ..., 0.9886, 0.9953, 0.9737], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.8.attention.output.LayerNorm.bias',\n",
       "               tensor([-0.1705,  0.0123, -0.4999,  ..., -0.0113, -0.1094, -0.0146],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.8.intermediate.dense.weight',\n",
       "               tensor([[-0.0093, -0.0013,  0.0191,  ..., -0.0639,  0.0098, -0.0767],\n",
       "                       [ 0.0293, -0.0720,  0.0390,  ..., -0.1106,  0.0509, -0.0231],\n",
       "                       [ 0.0318,  0.0975,  0.0396,  ...,  0.0278,  0.0105,  0.0159],\n",
       "                       ...,\n",
       "                       [ 0.0444, -0.0180,  0.0362,  ..., -0.0200, -0.0170,  0.0366],\n",
       "                       [ 0.0873,  0.0202,  0.0094,  ...,  0.0160,  0.0524, -0.0739],\n",
       "                       [ 0.0361,  0.0054,  0.0192,  ..., -0.0242, -0.0673, -0.0163]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.8.intermediate.dense.bias',\n",
       "               tensor([-0.0612, -0.0999, -0.0531,  ..., -0.0758, -0.0579, -0.0349],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.8.output.dense.weight',\n",
       "               tensor([[ 0.0065,  0.0090,  0.0101,  ..., -0.0303,  0.0685,  0.0162],\n",
       "                       [-0.0350,  0.0173,  0.0659,  ...,  0.0196,  0.0093,  0.0270],\n",
       "                       [ 0.0370, -0.0163,  0.0182,  ...,  0.0376, -0.0040, -0.0028],\n",
       "                       ...,\n",
       "                       [ 0.0695, -0.0602,  0.0319,  ...,  0.0520, -0.0109,  0.0215],\n",
       "                       [-0.0157, -0.0060,  0.0141,  ..., -0.0643, -0.0102, -0.0052],\n",
       "                       [ 0.0210,  0.0234,  0.0252,  ...,  0.0253,  0.0079,  0.0249]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.8.output.dense.bias',\n",
       "               tensor([-0.1677,  0.0009,  0.0616,  ..., -0.0411, -0.0503, -0.0571],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.8.output.LayerNorm.weight',\n",
       "               tensor([0.9752, 0.9947, 1.0002,  ..., 0.9768, 0.9800, 0.9543], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.8.output.LayerNorm.bias',\n",
       "               tensor([ 0.0215, -0.1106, -0.0194,  ..., -0.0839, -0.0250, -0.0838],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.9.attention.self.query.weight',\n",
       "               tensor([[ 0.0094, -0.0838, -0.0360,  ..., -0.0320,  0.0669, -0.0665],\n",
       "                       [ 0.0207, -0.0312, -0.0086,  ..., -0.0323,  0.0509,  0.0566],\n",
       "                       [ 0.0205,  0.0260,  0.0154,  ..., -0.0404,  0.0147, -0.0259],\n",
       "                       ...,\n",
       "                       [ 0.0584, -0.0264, -0.0013,  ..., -0.0135, -0.0661, -0.0124],\n",
       "                       [ 0.0454,  0.0059, -0.0797,  ...,  0.0384,  0.0273,  0.0223],\n",
       "                       [-0.0214, -0.0197, -0.0416,  ..., -0.0469, -0.0362, -0.0465]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.9.attention.self.query.bias',\n",
       "               tensor([-0.0133, -0.0314, -0.0593,  ...,  0.0044, -0.0582,  0.0745],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.9.attention.self.key.weight',\n",
       "               tensor([[-3.5470e-02,  5.0172e-02,  8.2295e-06,  ..., -1.2851e-02,\n",
       "                        -3.0647e-02, -3.7194e-02],\n",
       "                       [ 3.7715e-02, -7.4924e-03, -3.5996e-03,  ..., -3.5361e-02,\n",
       "                        -1.9228e-02, -4.1577e-02],\n",
       "                       [ 3.7180e-02, -5.0020e-02,  6.9988e-02,  ..., -6.7592e-02,\n",
       "                        -2.6847e-02,  1.3417e-02],\n",
       "                       ...,\n",
       "                       [-1.0913e-02,  1.1511e-02,  2.2165e-03,  ...,  8.2961e-03,\n",
       "                         5.4171e-02,  7.3049e-03],\n",
       "                       [ 4.3057e-02,  3.5284e-02, -1.0992e-02,  ...,  1.4433e-02,\n",
       "                         2.8832e-02,  1.0114e-02],\n",
       "                       [-4.1063e-02,  9.8135e-03, -3.0008e-02,  ...,  8.5773e-02,\n",
       "                        -3.2332e-03,  1.0221e-01]], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.9.attention.self.key.bias',\n",
       "               tensor([-1.0146e-04, -5.6505e-06,  2.3852e-04,  ...,  1.9571e-04,\n",
       "                        3.1929e-04,  1.5910e-04], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.9.attention.self.value.weight',\n",
       "               tensor([[-0.0242,  0.0028,  0.0105,  ..., -0.0260, -0.0557,  0.0287],\n",
       "                       [-0.0215, -0.0320, -0.0010,  ..., -0.0535, -0.0039,  0.0557],\n",
       "                       [ 0.0002,  0.0535,  0.0108,  ...,  0.0214,  0.0262,  0.0112],\n",
       "                       ...,\n",
       "                       [-0.0540,  0.0350,  0.0133,  ...,  0.0558,  0.0596, -0.0052],\n",
       "                       [ 0.0541,  0.0144, -0.0109,  ..., -0.0322, -0.0370, -0.0333],\n",
       "                       [-0.0349,  0.0136,  0.0082,  ...,  0.0209,  0.0060, -0.0190]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.9.attention.self.value.bias',\n",
       "               tensor([ 0.0012, -0.0072,  0.0014,  ...,  0.0322, -0.0014,  0.0013],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.9.attention.output.dense.weight',\n",
       "               tensor([[-0.0177, -0.0263,  0.0085,  ...,  0.0192, -0.0104, -0.0194],\n",
       "                       [ 0.0031, -0.0422,  0.0037,  ..., -0.0460,  0.0173,  0.0207],\n",
       "                       [ 0.0342, -0.0673, -0.0011,  ..., -0.0131,  0.0403,  0.0015],\n",
       "                       ...,\n",
       "                       [ 0.0023,  0.0129,  0.0324,  ..., -0.0186,  0.0040,  0.0018],\n",
       "                       [-0.0167, -0.0069, -0.0078,  ..., -0.0810, -0.0195,  0.0549],\n",
       "                       [ 0.0272,  0.0133,  0.0288,  ..., -0.0129, -0.0120, -0.0040]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.9.attention.output.dense.bias',\n",
       "               tensor([ 0.0464,  0.0031, -0.1743,  ...,  0.0535, -0.0486,  0.0044],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.9.attention.output.LayerNorm.weight',\n",
       "               tensor([0.9843, 0.9919, 0.9997,  ..., 0.9841, 0.9932, 0.9871], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.9.attention.output.LayerNorm.bias',\n",
       "               tensor([-0.1782, -0.0276, -0.4653,  ..., -0.0479, -0.1164, -0.0285],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.9.intermediate.dense.weight',\n",
       "               tensor([[ 0.0256,  0.0056, -0.0159,  ...,  0.0243,  0.0214,  0.0019],\n",
       "                       [ 0.0072, -0.0008,  0.0153,  ...,  0.0828,  0.0250,  0.0138],\n",
       "                       [ 0.0491, -0.0505,  0.0141,  ...,  0.0634, -0.0778,  0.0660],\n",
       "                       ...,\n",
       "                       [ 0.0073, -0.0351,  0.0135,  ...,  0.0732,  0.0060, -0.0192],\n",
       "                       [ 0.0139, -0.0574,  0.0069,  ...,  0.0001, -0.0117, -0.0104],\n",
       "                       [-0.0203, -0.0327,  0.0111,  ...,  0.0093,  0.0479,  0.0183]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.9.intermediate.dense.bias',\n",
       "               tensor([-0.0534, -0.0802, -0.0251,  ..., -0.0479, -0.0425, -0.1010],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.9.output.dense.weight',\n",
       "               tensor([[-0.0031,  0.0216, -0.0172,  ..., -0.0070,  0.0221,  0.0035],\n",
       "                       [ 0.0335,  0.0771, -0.0187,  ..., -0.0196, -0.0086, -0.0116],\n",
       "                       [ 0.0113,  0.0048,  0.0168,  ...,  0.0128, -0.0050, -0.0018],\n",
       "                       ...,\n",
       "                       [ 0.0139,  0.0928, -0.0512,  ..., -0.0506,  0.0201,  0.0168],\n",
       "                       [ 0.0313,  0.0484, -0.0488,  ...,  0.0433,  0.0332, -0.0015],\n",
       "                       [-0.0399, -0.0262, -0.0483,  ..., -0.0113,  0.0224,  0.0052]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.9.output.dense.bias',\n",
       "               tensor([-0.1372,  0.0675, -0.0874,  ..., -0.0444, -0.0780, -0.0239],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.9.output.LayerNorm.weight',\n",
       "               tensor([0.9759, 0.9884, 0.9987,  ..., 0.9716, 0.9816, 0.9732], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.9.output.LayerNorm.bias',\n",
       "               tensor([ 0.0327, -0.0622, -0.2096,  ..., -0.0588, -0.0126, -0.0454],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.10.attention.self.query.weight',\n",
       "               tensor([[ 0.0669,  0.0395, -0.0003,  ..., -0.1473,  0.0458,  0.0172],\n",
       "                       [ 0.0665, -0.1064, -0.0106,  ...,  0.0778,  0.0037, -0.0292],\n",
       "                       [-0.0308, -0.0115, -0.0377,  ...,  0.0798,  0.0949, -0.0405],\n",
       "                       ...,\n",
       "                       [ 0.0374,  0.0346,  0.2359,  ...,  0.0903, -0.0641,  0.0620],\n",
       "                       [ 0.0183,  0.0181,  0.0624,  ...,  0.1151,  0.0489, -0.0498],\n",
       "                       [ 0.0310, -0.0190,  0.0493,  ...,  0.0546,  0.0594, -0.0204]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.10.attention.self.query.bias',\n",
       "               tensor([ 0.0239,  0.0314, -0.0162,  ...,  0.0301,  0.0554,  0.0012],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.10.attention.self.key.weight',\n",
       "               tensor([[-0.0111,  0.0409,  0.0550,  ..., -0.0202, -0.0262, -0.0489],\n",
       "                       [-0.0969, -0.0963,  0.0256,  ..., -0.0674,  0.0010, -0.0060],\n",
       "                       [-0.0313,  0.0766, -0.0067,  ..., -0.1060,  0.0009, -0.0567],\n",
       "                       ...,\n",
       "                       [ 0.0190, -0.0087,  0.2555,  ..., -0.0731, -0.0286,  0.0291],\n",
       "                       [ 0.0112, -0.0092,  0.0811,  ..., -0.0077, -0.0020, -0.0161],\n",
       "                       [-0.0285, -0.0460,  0.0271,  ...,  0.0624, -0.0078, -0.0247]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.10.attention.self.key.bias',\n",
       "               tensor([-0.0006, -0.0009,  0.0005,  ...,  0.0004,  0.0004, -0.0005],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.10.attention.self.value.weight',\n",
       "               tensor([[ 0.0108,  0.0441,  0.0096,  ..., -0.0033, -0.0261, -0.0305],\n",
       "                       [ 0.0251, -0.0050, -0.0098,  ..., -0.0135, -0.0031, -0.0182],\n",
       "                       [ 0.0359,  0.0510,  0.0037,  ..., -0.0012,  0.0291, -0.0191],\n",
       "                       ...,\n",
       "                       [-0.0182,  0.0052, -0.0025,  ...,  0.0021,  0.0065, -0.0429],\n",
       "                       [ 0.0130,  0.0162, -0.0080,  ...,  0.0188, -0.0391,  0.0120],\n",
       "                       [-0.0269, -0.0149, -0.0153,  ..., -0.0253,  0.0117, -0.0155]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.10.attention.self.value.bias',\n",
       "               tensor([ 0.0219,  0.0104, -0.0333,  ...,  0.0204, -0.0136,  0.0498],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.10.attention.output.dense.weight',\n",
       "               tensor([[ 0.0085,  0.0544, -0.0078,  ...,  0.0126,  0.0358,  0.0216],\n",
       "                       [-0.0179, -0.0061, -0.0152,  ..., -0.0445,  0.0249, -0.0142],\n",
       "                       [ 0.0311,  0.0227, -0.1381,  ..., -0.0696, -0.0630, -0.0113],\n",
       "                       ...,\n",
       "                       [ 0.0055, -0.0079, -0.0362,  ..., -0.0076, -0.0065, -0.0199],\n",
       "                       [ 0.0296, -0.0010,  0.0470,  ..., -0.0180,  0.0013,  0.0158],\n",
       "                       [ 0.0530, -0.0038,  0.0056,  ..., -0.0050, -0.0115, -0.0268]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.10.attention.output.dense.bias',\n",
       "               tensor([-0.0046,  0.0635,  0.0535,  ...,  0.0353, -0.0607,  0.0743],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.10.attention.output.LayerNorm.weight',\n",
       "               tensor([0.9741, 0.9900, 1.0001,  ..., 0.9890, 0.9916, 0.9870], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.10.attention.output.LayerNorm.bias',\n",
       "               tensor([-0.1806, -0.0025, -0.4714,  ..., -0.0686, -0.1522, -0.0407],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.10.intermediate.dense.weight',\n",
       "               tensor([[-0.0175, -0.0042,  0.0075,  ..., -0.0173, -0.0134, -0.0763],\n",
       "                       [ 0.0041,  0.0207,  0.0338,  ...,  0.0525,  0.0372, -0.0061],\n",
       "                       [-0.0011, -0.0164,  0.0281,  ...,  0.0292,  0.0336,  0.0027],\n",
       "                       ...,\n",
       "                       [ 0.0204,  0.0229,  0.0230,  ...,  0.0715, -0.0365,  0.0041],\n",
       "                       [ 0.0517, -0.0171,  0.0032,  ...,  0.0350,  0.0612, -0.0301],\n",
       "                       [-0.0087, -0.0186, -0.0078,  ...,  0.0173,  0.0034, -0.0229]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.10.intermediate.dense.bias',\n",
       "               tensor([-0.0571, -0.0502, -0.0152,  ..., -0.0922, -0.0903, -0.0147],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.10.output.dense.weight',\n",
       "               tensor([[-0.0174,  0.0023, -0.0023,  ...,  0.0587,  0.0150, -0.0558],\n",
       "                       [-0.0336,  0.0102,  0.0008,  ...,  0.0141, -0.0239, -0.0470],\n",
       "                       [ 0.0063, -0.0063,  0.0108,  ..., -0.0007, -0.0114,  0.0006],\n",
       "                       ...,\n",
       "                       [ 0.0103, -0.0144, -0.0114,  ...,  0.0235, -0.0048, -0.0066],\n",
       "                       [-0.0193, -0.0944, -0.0459,  ...,  0.0258,  0.0092, -0.0486],\n",
       "                       [-0.0254, -0.0002, -0.0444,  ...,  0.0069,  0.0239,  0.0106]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.10.output.dense.bias',\n",
       "               tensor([-0.2128,  0.0545,  0.0879,  ..., -0.0425,  0.0073, -0.1136],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.10.output.LayerNorm.weight',\n",
       "               tensor([0.9779, 0.9874, 0.9999,  ..., 0.9785, 0.9776, 0.9861], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.10.output.LayerNorm.bias',\n",
       "               tensor([ 0.0441, -0.0730, -0.2016,  ..., -0.0414,  0.0385, -0.0470],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.11.attention.self.query.weight',\n",
       "               tensor([[ 0.0356, -0.0109,  0.0256,  ...,  0.0181,  0.0850,  0.0366],\n",
       "                       [ 0.0721, -0.0424, -0.0022,  ..., -0.0238,  0.0123,  0.0318],\n",
       "                       [ 0.0529, -0.0496, -0.2163,  ...,  0.0503,  0.0724, -0.0327],\n",
       "                       ...,\n",
       "                       [ 0.0940, -0.0229,  0.0825,  ..., -0.0424,  0.0633, -0.0683],\n",
       "                       [-0.0685, -0.0217, -0.0633,  ..., -0.0205, -0.0343, -0.0838],\n",
       "                       [ 0.0379,  0.0065, -0.0362,  ..., -0.0496, -0.0955, -0.0480]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.11.attention.self.query.bias',\n",
       "               tensor([0.0106, 0.0283, 0.0473,  ..., 0.1027, 0.0180, 0.0222], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.11.attention.self.key.weight',\n",
       "               tensor([[-0.0863, -0.0035,  0.0745,  ...,  0.0059, -0.0251, -0.0131],\n",
       "                       [-0.0621, -0.0168, -0.0321,  ...,  0.0193, -0.0277,  0.0740],\n",
       "                       [-0.1178,  0.0090, -0.2359,  ..., -0.0570, -0.0031,  0.0054],\n",
       "                       ...,\n",
       "                       [-0.0393, -0.0319,  0.1112,  ..., -0.0796, -0.0347, -0.0251],\n",
       "                       [-0.0140,  0.0091, -0.0642,  ..., -0.1068,  0.0082,  0.0109],\n",
       "                       [ 0.0100, -0.0780, -0.0353,  ..., -0.0435, -0.0185, -0.0165]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.11.attention.self.key.bias',\n",
       "               tensor([ 5.8434e-04, -2.9706e-05, -2.1220e-05,  ..., -1.6546e-04,\n",
       "                       -6.0570e-06,  5.2048e-05], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.11.attention.self.value.weight',\n",
       "               tensor([[ 0.0101, -0.0316,  0.0028,  ...,  0.0624,  0.0035, -0.0001],\n",
       "                       [ 0.0254, -0.0347, -0.0042,  ..., -0.0777, -0.0298,  0.0399],\n",
       "                       [-0.0457, -0.0106,  0.0268,  ..., -0.0849, -0.0282,  0.0196],\n",
       "                       ...,\n",
       "                       [-0.0057,  0.0450, -0.0015,  ...,  0.0015, -0.0457, -0.0011],\n",
       "                       [ 0.0418,  0.0283,  0.0013,  ...,  0.0478,  0.0339, -0.0786],\n",
       "                       [-0.0132,  0.0007,  0.0017,  ..., -0.0461,  0.0339, -0.0238]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.11.attention.self.value.bias',\n",
       "               tensor([-0.0098,  0.0112,  0.0058,  ..., -0.0280,  0.0112, -0.0346],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.11.attention.output.dense.weight',\n",
       "               tensor([[-0.0066, -0.0249,  0.0218,  ...,  0.0061,  0.0042, -0.0243],\n",
       "                       [ 0.0449,  0.0072,  0.0231,  ...,  0.0076, -0.0024,  0.0315],\n",
       "                       [-0.0249,  0.0068, -0.0320,  ...,  0.0077,  0.0179, -0.0202],\n",
       "                       ...,\n",
       "                       [-0.0110,  0.0026,  0.0653,  ...,  0.0226,  0.0247, -0.0174],\n",
       "                       [ 0.0071,  0.0193,  0.0347,  ...,  0.0112,  0.0299, -0.0063],\n",
       "                       [ 0.0245, -0.0564, -0.0037,  ..., -0.0197, -0.0256, -0.0252]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.11.attention.output.dense.bias',\n",
       "               tensor([-0.0511,  0.1448, -0.1547,  ...,  0.0590, -0.0474,  0.0369],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.11.attention.output.LayerNorm.weight',\n",
       "               tensor([0.9817, 0.9929, 0.9997,  ..., 0.9932, 0.9956, 0.9810], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.11.attention.output.LayerNorm.bias',\n",
       "               tensor([-0.2123,  0.0090, -0.3471,  ..., -0.0617, -0.0711, -0.0355],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.11.intermediate.dense.weight',\n",
       "               tensor([[ 0.0070, -0.0359, -0.0075,  ...,  0.0530,  0.0283,  0.0410],\n",
       "                       [ 0.1040,  0.0581,  0.0037,  ...,  0.0586,  0.0348, -0.0855],\n",
       "                       [ 0.0036,  0.0460, -0.0063,  ...,  0.0400,  0.0088, -0.0368],\n",
       "                       ...,\n",
       "                       [ 0.0613,  0.0114,  0.0082,  ..., -0.0027,  0.0500, -0.1040],\n",
       "                       [ 0.0511,  0.0047,  0.0145,  ...,  0.0647, -0.0277,  0.0378],\n",
       "                       [ 0.0696,  0.0207,  0.0362,  ...,  0.0150,  0.0020,  0.0121]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.11.intermediate.dense.bias',\n",
       "               tensor([ 0.0239, -0.0455, -0.0557,  ..., -0.0536, -0.0638,  0.0378],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.11.output.dense.weight',\n",
       "               tensor([[ 0.0086,  0.0324, -0.0032,  ...,  0.0088,  0.0267, -0.0502],\n",
       "                       [ 0.0177,  0.0425,  0.0047,  ..., -0.0198,  0.0452,  0.0061],\n",
       "                       [-0.0153,  0.0214, -0.0083,  ..., -0.0046, -0.0069, -0.0026],\n",
       "                       ...,\n",
       "                       [ 0.0509, -0.0554,  0.0636,  ..., -0.0223, -0.0164, -0.0122],\n",
       "                       [ 0.0130,  0.0297, -0.0422,  ...,  0.0131, -0.0343,  0.0144],\n",
       "                       [ 0.0262, -0.0403,  0.0013,  ..., -0.0314, -0.0599, -0.0132]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.11.output.dense.bias',\n",
       "               tensor([-0.1759, -0.0093, -0.0050,  ..., -0.0141, -0.0839, -0.1054],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.11.output.LayerNorm.weight',\n",
       "               tensor([0.9867, 0.9904, 0.9997,  ..., 0.9784, 0.9824, 0.9908], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.11.output.LayerNorm.bias',\n",
       "               tensor([ 0.0854, -0.0873,  0.1802,  ..., -0.0374, -0.0192, -0.0719],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.12.attention.self.query.weight',\n",
       "               tensor([[-4.8801e-02, -2.4072e-02,  8.8054e-02,  ...,  2.6472e-03,\n",
       "                         5.3192e-02,  5.9305e-02],\n",
       "                       [-2.3200e-02,  6.8120e-03,  1.3998e-02,  ..., -8.0420e-02,\n",
       "                        -6.4488e-02,  5.5517e-02],\n",
       "                       [-5.6253e-02,  3.9899e-02, -1.3430e-01,  ...,  5.5875e-02,\n",
       "                         3.0077e-02,  5.0069e-02],\n",
       "                       ...,\n",
       "                       [ 2.6300e-02,  2.1235e-02,  2.8901e-01,  ..., -1.4791e-02,\n",
       "                         9.4844e-02, -2.3197e-02],\n",
       "                       [-8.4691e-02,  1.3762e-02, -1.0885e-01,  ..., -3.3938e-02,\n",
       "                         1.3628e-02, -2.3983e-02],\n",
       "                       [-2.6341e-04, -4.2995e-03, -3.1212e-02,  ..., -9.0760e-02,\n",
       "                        -4.2664e-03, -7.9350e-02]], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.12.attention.self.query.bias',\n",
       "               tensor([ 0.0043, -0.0059,  0.0022,  ..., -0.2385, -0.0193, -0.0036],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.12.attention.self.key.weight',\n",
       "               tensor([[-2.5527e-02, -1.2586e-01,  7.4955e-02,  ...,  3.8491e-02,\n",
       "                        -1.8016e-02,  6.6667e-02],\n",
       "                       [ 1.2175e-01,  2.3826e-02, -7.6932e-02,  ...,  1.4100e-04,\n",
       "                        -2.6859e-02, -1.7448e-02],\n",
       "                       [-4.3746e-02,  3.1089e-02, -1.0856e-01,  ..., -7.8189e-02,\n",
       "                        -4.5242e-02,  3.4632e-03],\n",
       "                       ...,\n",
       "                       [-3.1230e-03,  1.6832e-02, -3.7097e-01,  ...,  5.7401e-02,\n",
       "                        -7.1693e-03, -9.3028e-03],\n",
       "                       [ 2.4365e-02, -5.5965e-03, -1.9452e-01,  ..., -3.5051e-02,\n",
       "                         8.0228e-03,  5.6383e-02],\n",
       "                       [ 3.5171e-03, -3.9062e-02, -9.6139e-02,  ...,  3.8449e-02,\n",
       "                         9.7325e-03,  9.7846e-03]], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.12.attention.self.key.bias',\n",
       "               tensor([ 4.7666e-05, -1.0270e-04,  1.3898e-05,  ..., -1.7913e-02,\n",
       "                        5.9356e-04, -1.9250e-04], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.12.attention.self.value.weight',\n",
       "               tensor([[-0.0893, -0.0027,  0.0088,  ...,  0.0459, -0.0019, -0.0060],\n",
       "                       [ 0.0316,  0.0998, -0.0115,  ..., -0.0075,  0.0305,  0.0838],\n",
       "                       [ 0.0155,  0.0042, -0.0011,  ..., -0.0360, -0.0432,  0.0351],\n",
       "                       ...,\n",
       "                       [-0.0187, -0.0378, -0.0148,  ..., -0.0055, -0.0146,  0.0627],\n",
       "                       [-0.0360, -0.0446,  0.0239,  ..., -0.0140, -0.0368,  0.0622],\n",
       "                       [ 0.0018, -0.0307,  0.0002,  ..., -0.0338,  0.0363,  0.0228]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.12.attention.self.value.bias',\n",
       "               tensor([ 0.0050, -0.0075,  0.0003,  ...,  0.0298,  0.0153,  0.0310],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.12.attention.output.dense.weight',\n",
       "               tensor([[-0.0449, -0.0198, -0.0211,  ...,  0.0201,  0.0005,  0.0008],\n",
       "                       [-0.0476,  0.0174, -0.0386,  ..., -0.0312,  0.0039,  0.0174],\n",
       "                       [-0.0411, -0.0196,  0.0288,  ...,  0.0136,  0.0363,  0.0014],\n",
       "                       ...,\n",
       "                       [ 0.0178, -0.0133, -0.0403,  ..., -0.0140,  0.0114,  0.0297],\n",
       "                       [ 0.0017, -0.0273,  0.0171,  ..., -0.0172,  0.0194, -0.0215],\n",
       "                       [ 0.0053,  0.0382,  0.0408,  ..., -0.0110, -0.0290, -0.0254]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.12.attention.output.dense.bias',\n",
       "               tensor([ 0.0293, -0.0018,  0.0631,  ..., -0.0135, -0.0418, -0.0079],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.12.attention.output.LayerNorm.weight',\n",
       "               tensor([0.9920, 0.9810, 1.0002,  ..., 0.9884, 0.9839, 0.9876], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.12.attention.output.LayerNorm.bias',\n",
       "               tensor([-0.1647,  0.0042, -0.3015,  ..., -0.0278, -0.1446, -0.0364],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.12.intermediate.dense.weight',\n",
       "               tensor([[ 0.0728, -0.0337,  0.0158,  ..., -0.0143, -0.0046,  0.0081],\n",
       "                       [-0.0168, -0.0274,  0.0180,  ..., -0.0484, -0.0393, -0.0167],\n",
       "                       [-0.0388, -0.0446,  0.0778,  ..., -0.0025, -0.0160, -0.0243],\n",
       "                       ...,\n",
       "                       [ 0.0209, -0.0464,  0.0278,  ..., -0.1238, -0.0197, -0.0035],\n",
       "                       [ 0.0128, -0.0499,  0.0155,  ..., -0.0497, -0.0163,  0.0440],\n",
       "                       [ 0.0182,  0.0055, -0.0061,  ...,  0.0152, -0.0276, -0.0090]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.12.intermediate.dense.bias',\n",
       "               tensor([-0.1074, -0.0404, -0.0113,  ..., -0.1226, -0.0860, -0.1047],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.12.output.dense.weight',\n",
       "               tensor([[ 0.0305, -0.0028, -0.0675,  ...,  0.0266,  0.0262, -0.0147],\n",
       "                       [-0.0146,  0.0205,  0.0110,  ..., -0.0289,  0.0097, -0.0360],\n",
       "                       [ 0.0003,  0.0010, -0.0148,  ..., -0.0016, -0.0285, -0.0023],\n",
       "                       ...,\n",
       "                       [-0.0097, -0.0116,  0.0155,  ..., -0.0420, -0.0118, -0.0244],\n",
       "                       [-0.0179, -0.0111, -0.0235,  ..., -0.0114, -0.0246,  0.0201],\n",
       "                       [-0.0544, -0.0361,  0.0324,  ...,  0.0057, -0.0026, -0.0106]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.12.output.dense.bias',\n",
       "               tensor([-0.2180,  0.1670, -0.0793,  ..., -0.0087, -0.0804, -0.1233],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.12.output.LayerNorm.weight',\n",
       "               tensor([0.9877, 0.9905, 0.9963,  ..., 0.9903, 0.9831, 0.9911], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.12.output.LayerNorm.bias',\n",
       "               tensor([ 0.0085, -0.0779,  0.0869,  ..., -0.0695, -0.0121, -0.0617],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.13.attention.self.query.weight',\n",
       "               tensor([[ 0.0448,  0.0473, -0.0504,  ..., -0.0472,  0.0426, -0.0586],\n",
       "                       [-0.0264, -0.0095,  0.0493,  ...,  0.0335,  0.0293,  0.0587],\n",
       "                       [-0.0053, -0.0268,  0.0018,  ..., -0.0378, -0.0804, -0.0144],\n",
       "                       ...,\n",
       "                       [ 0.0633, -0.0096,  0.0292,  ...,  0.0067, -0.0203, -0.0164],\n",
       "                       [-0.0053, -0.0269, -0.1436,  ...,  0.0454,  0.0224, -0.0244],\n",
       "                       [ 0.0501,  0.0561, -0.1591,  ...,  0.0247,  0.0381,  0.0658]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.13.attention.self.query.bias',\n",
       "               tensor([-0.0478,  0.0438,  0.0065,  ...,  0.0428,  0.1791,  0.0484],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.13.attention.self.key.weight',\n",
       "               tensor([[ 0.0267,  0.0612, -0.0415,  ..., -0.0176,  0.0262, -0.0715],\n",
       "                       [ 0.0543, -0.0048,  0.0743,  ..., -0.0335, -0.0022, -0.0320],\n",
       "                       [ 0.0189,  0.0648, -0.0433,  ...,  0.1567,  0.0242, -0.0780],\n",
       "                       ...,\n",
       "                       [-0.0468, -0.0479, -0.0111,  ..., -0.0245,  0.0126, -0.0224],\n",
       "                       [ 0.0217,  0.0325, -0.2133,  ..., -0.0188, -0.0205,  0.0022],\n",
       "                       [-0.0433,  0.0463, -0.1319,  ...,  0.0231,  0.0087,  0.0320]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.13.attention.self.key.bias',\n",
       "               tensor([-3.8081e-05, -6.7709e-05, -2.4498e-04,  ...,  1.8495e-04,\n",
       "                        5.4848e-04, -3.5835e-04], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.13.attention.self.value.weight',\n",
       "               tensor([[ 5.4093e-02,  6.5674e-02, -1.5529e-02,  ...,  3.9786e-02,\n",
       "                         5.9725e-03,  3.8671e-02],\n",
       "                       [ 1.4891e-02,  5.4602e-02,  6.9210e-03,  ..., -3.4420e-02,\n",
       "                        -2.1761e-02,  2.2652e-02],\n",
       "                       [-3.8045e-03,  5.0695e-02,  9.8608e-04,  ..., -2.2995e-02,\n",
       "                        -5.5622e-02,  3.9144e-02],\n",
       "                       ...,\n",
       "                       [ 4.1323e-02, -7.2542e-02,  1.9550e-02,  ..., -3.6455e-04,\n",
       "                        -1.5171e-02, -2.3390e-02],\n",
       "                       [-1.0871e-03,  8.9378e-04, -3.9205e-02,  ...,  7.6769e-03,\n",
       "                        -1.1067e-01, -9.2029e-03],\n",
       "                       [-4.1449e-02, -9.0341e-02,  2.5514e-02,  ..., -9.4621e-05,\n",
       "                        -7.6007e-03, -1.8495e-02]], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.13.attention.self.value.bias',\n",
       "               tensor([ 0.0120,  0.0079,  0.0063,  ..., -0.0072, -0.0073, -0.0008],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.13.attention.output.dense.weight',\n",
       "               tensor([[ 0.0018, -0.0391,  0.0306,  ..., -0.0514, -0.0004,  0.1053],\n",
       "                       [ 0.0090,  0.0064, -0.0079,  ...,  0.0097, -0.0632,  0.0405],\n",
       "                       [-0.0028, -0.0099, -0.0161,  ...,  0.0143, -0.0198, -0.0009],\n",
       "                       ...,\n",
       "                       [-0.0380, -0.0049, -0.0470,  ...,  0.0013, -0.0425,  0.0174],\n",
       "                       [-0.0428,  0.0573, -0.0023,  ...,  0.0163,  0.0800, -0.0292],\n",
       "                       [-0.0013,  0.0023,  0.0138,  ...,  0.0204,  0.0361,  0.0530]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.13.attention.output.dense.bias',\n",
       "               tensor([-0.0423,  0.0429, -0.0923,  ...,  0.0384, -0.0336,  0.0341],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.13.attention.output.LayerNorm.weight',\n",
       "               tensor([0.9803, 0.9892, 0.9997,  ..., 0.9911, 0.9855, 0.9798], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.13.attention.output.LayerNorm.bias',\n",
       "               tensor([-0.1781,  0.0721, -0.2694,  ..., -0.0585, -0.1191, -0.0615],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.13.intermediate.dense.weight',\n",
       "               tensor([[ 0.0205, -0.0218,  0.0199,  ..., -0.0340, -0.0568, -0.0415],\n",
       "                       [ 0.0354,  0.0090,  0.0101,  ...,  0.0516,  0.0217, -0.0007],\n",
       "                       [ 0.0594, -0.0431,  0.0545,  ...,  0.1132, -0.0105, -0.0641],\n",
       "                       ...,\n",
       "                       [ 0.0296, -0.0114, -0.0061,  ..., -0.0107,  0.0371,  0.0057],\n",
       "                       [ 0.0095,  0.0431,  0.0935,  ...,  0.0424,  0.0410, -0.0324],\n",
       "                       [ 0.0344, -0.1294,  0.0409,  ...,  0.0058,  0.0022, -0.0757]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.13.intermediate.dense.bias',\n",
       "               tensor([-0.1378, -0.0528, -0.0889,  ..., -0.1026, -0.0329, -0.0373],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.13.output.dense.weight',\n",
       "               tensor([[ 0.0634, -0.0330, -0.0446,  ..., -0.0347,  0.0098, -0.0065],\n",
       "                       [-0.0084,  0.0005, -0.0564,  ...,  0.0087,  0.0215, -0.0255],\n",
       "                       [ 0.0146,  0.0071,  0.0031,  ..., -0.0014,  0.0066, -0.0031],\n",
       "                       ...,\n",
       "                       [-0.0298,  0.0344,  0.0009,  ..., -0.0324,  0.0107,  0.0349],\n",
       "                       [-0.0873, -0.0238,  0.0315,  ..., -0.0197,  0.0595,  0.0162],\n",
       "                       [-0.0277, -0.0034, -0.0283,  ..., -0.0250, -0.0015, -0.0440]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.13.output.dense.bias',\n",
       "               tensor([-0.1067,  0.0574, -0.0723,  ..., -0.0241, -0.0499, -0.0874],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.13.output.LayerNorm.weight',\n",
       "               tensor([0.9857, 0.9919, 0.9975,  ..., 0.9896, 0.9884, 0.9940], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.13.output.LayerNorm.bias',\n",
       "               tensor([ 0.0679, -0.1159,  0.2406,  ..., -0.0530, -0.0041, -0.0440],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.14.attention.self.query.weight',\n",
       "               tensor([[-0.0415, -0.0574,  0.0110,  ..., -0.1231, -0.0240, -0.1601],\n",
       "                       [-0.0686,  0.0300, -0.0958,  ...,  0.0300, -0.0204, -0.0346],\n",
       "                       [-0.0060, -0.0323,  0.1081,  ..., -0.0077, -0.0609,  0.0326],\n",
       "                       ...,\n",
       "                       [ 0.0635,  0.0023,  0.0228,  ..., -0.0388, -0.0702,  0.0419],\n",
       "                       [-0.0177,  0.0402, -0.0162,  ..., -0.0931, -0.0313,  0.0583],\n",
       "                       [-0.0709,  0.0261,  0.0084,  ...,  0.0572,  0.0292,  0.0414]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.14.attention.self.query.bias',\n",
       "               tensor([ 0.1925,  0.1407, -0.1232,  ...,  0.2324, -0.1197,  0.0184],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.14.attention.self.key.weight',\n",
       "               tensor([[ 0.0361,  0.0813,  0.0729,  ...,  0.0074,  0.0034, -0.0071],\n",
       "                       [-0.0668, -0.0047, -0.1240,  ..., -0.0121,  0.0115,  0.0430],\n",
       "                       [-0.0207,  0.0271,  0.0475,  ...,  0.0238, -0.1161,  0.0600],\n",
       "                       ...,\n",
       "                       [ 0.0782, -0.0605,  0.0650,  ..., -0.0999, -0.0444, -0.0249],\n",
       "                       [ 0.0456,  0.0767,  0.0443,  ..., -0.0771,  0.0683,  0.0377],\n",
       "                       [-0.0682, -0.0025,  0.0571,  ..., -0.0072, -0.0541, -0.0274]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.14.attention.self.key.bias',\n",
       "               tensor([ 2.5960e-04, -6.5786e-05, -1.5482e-04,  ..., -1.6639e-04,\n",
       "                        6.5704e-05,  1.5342e-04], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.14.attention.self.value.weight',\n",
       "               tensor([[-0.0428,  0.0019,  0.0434,  ..., -0.0437, -0.0048, -0.0064],\n",
       "                       [-0.0023, -0.0698, -0.0089,  ...,  0.0601,  0.0618, -0.0541],\n",
       "                       [ 0.0274, -0.0341, -0.0241,  ..., -0.0638,  0.0103,  0.0177],\n",
       "                       ...,\n",
       "                       [ 0.0815,  0.0247, -0.0177,  ...,  0.0245, -0.0284, -0.0344],\n",
       "                       [ 0.0718,  0.0167, -0.0145,  ..., -0.0028, -0.0221,  0.0307],\n",
       "                       [-0.0726, -0.0347, -0.0240,  ..., -0.0011,  0.0484, -0.1314]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.14.attention.self.value.bias',\n",
       "               tensor([-6.7340e-05,  5.9770e-03, -1.2090e-02,  ...,  1.1727e-04,\n",
       "                        4.8451e-03,  1.3237e-02], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.14.attention.output.dense.weight',\n",
       "               tensor([[-0.0125, -0.0239,  0.0356,  ..., -0.0439, -0.0008,  0.0847],\n",
       "                       [ 0.0157, -0.0406,  0.0493,  ..., -0.0698, -0.0414, -0.0060],\n",
       "                       [ 0.0408, -0.0356,  0.0162,  ...,  0.0048,  0.0070, -0.0233],\n",
       "                       ...,\n",
       "                       [ 0.0661, -0.0342,  0.0695,  ...,  0.0084, -0.0049, -0.0084],\n",
       "                       [-0.0059, -0.0630, -0.0203,  ...,  0.0260,  0.0086, -0.0088],\n",
       "                       [-0.0120, -0.0312,  0.0251,  ...,  0.0648,  0.0188,  0.0692]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.14.attention.output.dense.bias',\n",
       "               tensor([-0.0237,  0.0020,  0.0311,  ...,  0.0651, -0.0414, -0.0050],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.14.attention.output.LayerNorm.weight',\n",
       "               tensor([0.9979, 0.9837, 0.9994,  ..., 0.9899, 0.9909, 0.9893], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.14.attention.output.LayerNorm.bias',\n",
       "               tensor([-0.0863, -0.0134, -0.1951,  ..., -0.0626, -0.1386, -0.0531],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.14.intermediate.dense.weight',\n",
       "               tensor([[-0.0087, -0.0012,  0.0394,  ...,  0.0003, -0.0169,  0.0385],\n",
       "                       [ 0.0129, -0.0519, -0.0091,  ...,  0.0624, -0.0237,  0.0486],\n",
       "                       [ 0.0453, -0.0666,  0.0101,  ...,  0.0640,  0.0665, -0.0525],\n",
       "                       ...,\n",
       "                       [ 0.0743, -0.0388,  0.0085,  ...,  0.0079, -0.0062, -0.0341],\n",
       "                       [-0.0352, -0.0586, -0.0118,  ...,  0.0300,  0.0121,  0.0184],\n",
       "                       [ 0.0354, -0.0426, -0.0663,  ...,  0.0372, -0.0153,  0.0054]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.14.intermediate.dense.bias',\n",
       "               tensor([-0.1081, -0.1092, -0.1115,  ..., -0.0580, -0.0804, -0.0826],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.14.output.dense.weight',\n",
       "               tensor([[-0.0196,  0.0288,  0.0082,  ...,  0.0272,  0.0085, -0.0655],\n",
       "                       [ 0.0077, -0.0103, -0.0870,  ..., -0.0096,  0.0156, -0.0647],\n",
       "                       [-0.0105, -0.0182,  0.0368,  ...,  0.0098,  0.0054,  0.0125],\n",
       "                       ...,\n",
       "                       [ 0.0606,  0.0087,  0.0067,  ..., -0.0465,  0.0367, -0.0312],\n",
       "                       [-0.0510,  0.0130,  0.0244,  ...,  0.0446,  0.0018, -0.0314],\n",
       "                       [ 0.0270,  0.0106, -0.0592,  ..., -0.0044, -0.0201, -0.0694]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.14.output.dense.bias',\n",
       "               tensor([-0.1094,  0.0496, -0.1960,  ..., -0.0112, -0.1291, -0.0688],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.14.output.LayerNorm.weight',\n",
       "               tensor([0.9907, 0.9935, 0.9980,  ..., 0.9915, 0.9905, 0.9935], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.14.output.LayerNorm.bias',\n",
       "               tensor([-0.0244, -0.1100,  0.2496,  ..., -0.0509, -0.0146, -0.0587],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.15.attention.self.query.weight',\n",
       "               tensor([[ 0.0602,  0.0549, -0.1355,  ..., -0.0178,  0.0381,  0.0186],\n",
       "                       [-0.0217,  0.0184,  0.0861,  ...,  0.0862, -0.0278, -0.0231],\n",
       "                       [-0.0031, -0.0200, -0.0308,  ..., -0.0582,  0.0586, -0.0830],\n",
       "                       ...,\n",
       "                       [ 0.0501,  0.1160, -0.0245,  ...,  0.0255, -0.0174,  0.0139],\n",
       "                       [-0.0178,  0.0906,  0.0348,  ..., -0.0046, -0.0625,  0.0392],\n",
       "                       [-0.0552, -0.0342,  0.0114,  ..., -0.0129,  0.0937, -0.0541]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.15.attention.self.query.bias',\n",
       "               tensor([-0.0122, -0.0729, -0.0247,  ..., -0.1174, -0.0878, -0.0033],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.15.attention.self.key.weight',\n",
       "               tensor([[-0.0437,  0.0160, -0.2183,  ..., -0.0841, -0.0103, -0.0082],\n",
       "                       [ 0.0627, -0.0182, -0.0566,  ..., -0.0116,  0.0013, -0.0230],\n",
       "                       [-0.0313,  0.0872, -0.0740,  ..., -0.0446, -0.0619, -0.0167],\n",
       "                       ...,\n",
       "                       [ 0.0160,  0.0140, -0.0534,  ..., -0.1037,  0.0359, -0.0165],\n",
       "                       [-0.0982, -0.0158, -0.0395,  ..., -0.0039,  0.0132,  0.0328],\n",
       "                       [ 0.0532, -0.0452,  0.0258,  ..., -0.0333,  0.0473,  0.0601]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.15.attention.self.key.bias',\n",
       "               tensor([ 1.2952e-04, -3.9652e-05,  2.7541e-04,  ...,  4.8910e-04,\n",
       "                        1.9019e-04, -2.0512e-04], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.15.attention.self.value.weight',\n",
       "               tensor([[-6.7444e-02,  4.6222e-02,  5.8268e-03,  ...,  1.0668e-03,\n",
       "                        -2.4784e-02,  6.5475e-02],\n",
       "                       [-1.3486e-02, -2.9810e-02, -3.1635e-02,  ..., -3.9141e-02,\n",
       "                         3.7655e-02, -6.6108e-02],\n",
       "                       [ 7.3940e-05, -9.1596e-03,  3.6369e-03,  ..., -1.0545e-01,\n",
       "                         1.0470e-01,  9.7701e-02],\n",
       "                       ...,\n",
       "                       [ 1.6463e-02, -5.8153e-02,  3.1320e-04,  ...,  3.6566e-02,\n",
       "                        -8.1827e-03,  7.6367e-02],\n",
       "                       [-4.7229e-02, -8.6532e-02,  5.1329e-03,  ...,  6.1005e-02,\n",
       "                         1.6789e-02,  1.3355e-02],\n",
       "                       [-6.3939e-02,  4.3613e-03, -1.3436e-02,  ..., -6.5099e-02,\n",
       "                        -1.0760e-01,  2.1085e-03]], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.15.attention.self.value.bias',\n",
       "               tensor([-0.0045,  0.0053,  0.0015,  ...,  0.0030, -0.0046, -0.0215],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.15.attention.output.dense.weight',\n",
       "               tensor([[ 0.0145,  0.0039, -0.0207,  ..., -0.0355, -0.0311,  0.0244],\n",
       "                       [ 0.0098,  0.0242, -0.0344,  ..., -0.0031,  0.0479, -0.0246],\n",
       "                       [-0.0272, -0.0384,  0.0716,  ..., -0.0159, -0.0166, -0.0120],\n",
       "                       ...,\n",
       "                       [-0.0027,  0.0526,  0.0168,  ..., -0.0369, -0.0088,  0.0223],\n",
       "                       [-0.0600,  0.0955,  0.0484,  ..., -0.0035,  0.0194,  0.0878],\n",
       "                       [ 0.0254, -0.0558,  0.0104,  ..., -0.0112, -0.0378, -0.0204]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.15.attention.output.dense.bias',\n",
       "               tensor([-0.0165,  0.0167,  0.0532,  ...,  0.0020, -0.0478, -0.0281],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.15.attention.output.LayerNorm.weight',\n",
       "               tensor([0.9910, 0.9904, 0.9995,  ..., 0.9915, 0.9915, 0.9859], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.15.attention.output.LayerNorm.bias',\n",
       "               tensor([-0.1105, -0.0167, -0.1705,  ..., -0.0920, -0.0813, -0.1239],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.15.intermediate.dense.weight',\n",
       "               tensor([[-0.0215, -0.0179,  0.0236,  ...,  0.0113,  0.0506, -0.0314],\n",
       "                       [ 0.0532, -0.0539,  0.0043,  ..., -0.0226, -0.0464, -0.0110],\n",
       "                       [-0.0259,  0.0529,  0.0247,  ...,  0.0951,  0.0065,  0.0232],\n",
       "                       ...,\n",
       "                       [-0.0404, -0.0329,  0.0204,  ...,  0.0804,  0.0416,  0.0258],\n",
       "                       [-0.0416,  0.0694,  0.0569,  ..., -0.0117,  0.0223, -0.0107],\n",
       "                       [ 0.0672,  0.0077,  0.0062,  ...,  0.0436,  0.0705,  0.0231]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.15.intermediate.dense.bias',\n",
       "               tensor([-0.0443, -0.1070, -0.0776,  ..., -0.0345,  0.0107, -0.0831],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.15.output.dense.weight',\n",
       "               tensor([[-0.0235,  0.0637, -0.0439,  ..., -0.0001,  0.0174, -0.0094],\n",
       "                       [-0.0220,  0.0113, -0.0343,  ..., -0.0554, -0.0027, -0.0036],\n",
       "                       [-0.0171, -0.0077, -0.0258,  ..., -0.0026,  0.0165,  0.0142],\n",
       "                       ...,\n",
       "                       [ 0.0047,  0.0237,  0.0552,  ..., -0.0088,  0.0034, -0.0013],\n",
       "                       [-0.0018, -0.0083,  0.0666,  ..., -0.0425, -0.0172,  0.0012],\n",
       "                       [-0.0458,  0.0186,  0.0200,  ...,  0.0322, -0.0091,  0.0380]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.15.output.dense.bias',\n",
       "               tensor([-0.1302,  0.0302, -0.2485,  ..., -0.0317, -0.0861, -0.0998],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.15.output.LayerNorm.weight',\n",
       "               tensor([0.9884, 0.9861, 0.9983,  ..., 0.9864, 0.9959, 0.9868], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.15.output.LayerNorm.bias',\n",
       "               tensor([-0.0083, -0.0669,  0.1742,  ..., -0.0156, -0.0312, -0.0161],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.16.attention.self.query.weight',\n",
       "               tensor([[-0.0178,  0.0010, -0.0399,  ..., -0.0123,  0.0901,  0.0356],\n",
       "                       [-0.0467, -0.0655, -0.0256,  ...,  0.0127, -0.0201, -0.0383],\n",
       "                       [ 0.0019, -0.0054,  0.0839,  ..., -0.0682, -0.0602, -0.0079],\n",
       "                       ...,\n",
       "                       [ 0.0706, -0.0923, -0.0288,  ..., -0.0144,  0.0361,  0.0214],\n",
       "                       [-0.0500,  0.0419,  0.0564,  ..., -0.0885,  0.0312, -0.1165],\n",
       "                       [ 0.0141,  0.0082,  0.0344,  ..., -0.0358, -0.0882, -0.0328]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.16.attention.self.query.bias',\n",
       "               tensor([-0.0090, -0.0675,  0.0129,  ..., -0.0052,  0.0856,  0.0127],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.16.attention.self.key.weight',\n",
       "               tensor([[-0.0549, -0.0115, -0.0310,  ...,  0.0776, -0.0133, -0.0555],\n",
       "                       [ 0.0520, -0.0135, -0.0301,  ...,  0.0747, -0.0465, -0.0283],\n",
       "                       [-0.0175,  0.0691,  0.0812,  ..., -0.0364, -0.0604,  0.0315],\n",
       "                       ...,\n",
       "                       [ 0.0493,  0.0355,  0.0024,  ..., -0.0698, -0.0159, -0.0027],\n",
       "                       [ 0.0018,  0.0830,  0.0184,  ..., -0.0272,  0.0515,  0.0041],\n",
       "                       [ 0.0490, -0.0263,  0.0753,  ..., -0.0916, -0.0372,  0.0445]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.16.attention.self.key.bias',\n",
       "               tensor([-0.0002, -0.0004,  0.0004,  ..., -0.0002, -0.0004,  0.0001],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.16.attention.self.value.weight',\n",
       "               tensor([[ 0.0402, -0.0019,  0.0107,  ...,  0.0371, -0.0579,  0.0565],\n",
       "                       [ 0.0256,  0.0590, -0.0328,  ...,  0.0014,  0.0237,  0.0849],\n",
       "                       [ 0.0106,  0.0055, -0.0078,  ..., -0.0432, -0.0562,  0.0284],\n",
       "                       ...,\n",
       "                       [-0.0578, -0.1274,  0.0225,  ..., -0.0893, -0.0107,  0.0547],\n",
       "                       [-0.0025, -0.0322, -0.0334,  ..., -0.0223,  0.0054,  0.1260],\n",
       "                       [ 0.0401,  0.1230, -0.0010,  ..., -0.0211,  0.0103, -0.0254]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.16.attention.self.value.bias',\n",
       "               tensor([-0.0094,  0.0054,  0.0030,  ..., -0.0103, -0.0152, -0.0091],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.16.attention.output.dense.weight',\n",
       "               tensor([[ 0.0401, -0.0426, -0.0121,  ..., -0.0008, -0.0207,  0.0090],\n",
       "                       [ 0.0032,  0.0201,  0.0106,  ...,  0.0354, -0.0656, -0.0212],\n",
       "                       [ 0.0537, -0.0718,  0.0200,  ..., -0.0151, -0.0269,  0.0380],\n",
       "                       ...,\n",
       "                       [ 0.0194,  0.0083, -0.0578,  ...,  0.0841,  0.0392,  0.0029],\n",
       "                       [-0.0482, -0.0360, -0.0249,  ...,  0.0191, -0.0723,  0.0361],\n",
       "                       [ 0.0031, -0.0149, -0.0031,  ..., -0.0693, -0.0658, -0.0380]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.16.attention.output.dense.bias',\n",
       "               tensor([-0.0022, -0.0225,  0.0808,  ..., -0.0592,  0.0308, -0.0680],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.16.attention.output.LayerNorm.weight',\n",
       "               tensor([0.9977, 0.9945, 0.9986,  ..., 0.9932, 0.9969, 0.9982], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.16.attention.output.LayerNorm.bias',\n",
       "               tensor([-0.0785, -0.0414, -0.2097,  ..., -0.0618, -0.0683, -0.0664],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.16.intermediate.dense.weight',\n",
       "               tensor([[ 0.0746, -0.0217,  0.0455,  ...,  0.0472,  0.0110, -0.0304],\n",
       "                       [ 0.0129,  0.0432,  0.0237,  ...,  0.0627, -0.0745, -0.0008],\n",
       "                       [ 0.0124,  0.0171, -0.0133,  ...,  0.1303, -0.0051, -0.0166],\n",
       "                       ...,\n",
       "                       [-0.0783, -0.0630,  0.0141,  ...,  0.0246,  0.0261, -0.0214],\n",
       "                       [-0.0371, -0.0232,  0.0402,  ...,  0.0068, -0.0493, -0.0476],\n",
       "                       [-0.0146, -0.0863,  0.0382,  ...,  0.0241, -0.0492,  0.0310]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.16.intermediate.dense.bias',\n",
       "               tensor([-0.0784, -0.0589, -0.0988,  ..., -0.0642, -0.0775, -0.0862],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.16.output.dense.weight',\n",
       "               tensor([[ 0.0125,  0.0352,  0.0682,  ..., -0.0133, -0.0018,  0.0059],\n",
       "                       [-0.0152, -0.0019,  0.0128,  ..., -0.0334, -0.0683, -0.0234],\n",
       "                       [ 0.0067, -0.0022, -0.0163,  ...,  0.0018,  0.0004,  0.0070],\n",
       "                       ...,\n",
       "                       [-0.0156,  0.0419,  0.0055,  ...,  0.0060, -0.0326, -0.0576],\n",
       "                       [-0.0546, -0.0406,  0.0455,  ..., -0.0061, -0.0310,  0.0173],\n",
       "                       [-0.0046,  0.0193, -0.0110,  ..., -0.0394,  0.0101,  0.0364]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.16.output.dense.bias',\n",
       "               tensor([-0.0816,  0.0123, -0.2006,  ..., -0.0394, -0.0640, -0.1035],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.16.output.LayerNorm.weight',\n",
       "               tensor([0.9805, 0.9965, 0.9975,  ..., 0.9756, 0.9913, 0.9874], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.16.output.LayerNorm.bias',\n",
       "               tensor([-0.0194, -0.0471,  0.1807,  ..., -0.0244, -0.0307, -0.0294],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.17.attention.self.query.weight',\n",
       "               tensor([[-0.0059, -0.0175,  0.0622,  ...,  0.0437, -0.0281,  0.0619],\n",
       "                       [ 0.0308,  0.0173, -0.0222,  ...,  0.0891, -0.0317,  0.0482],\n",
       "                       [ 0.1371,  0.0720,  0.0295,  ..., -0.0814, -0.0424, -0.0062],\n",
       "                       ...,\n",
       "                       [-0.0277, -0.0425,  0.0739,  ..., -0.1263,  0.0552, -0.0763],\n",
       "                       [ 0.0474, -0.0099,  0.0442,  ...,  0.0012, -0.0467,  0.0321],\n",
       "                       [ 0.0127,  0.0891, -0.0297,  ...,  0.0012,  0.0176, -0.0198]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.17.attention.self.query.bias',\n",
       "               tensor([-0.1753,  0.0583,  0.0230,  ..., -0.0484,  0.0412,  0.0124],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.17.attention.self.key.weight',\n",
       "               tensor([[ 0.0272, -0.0098,  0.0549,  ..., -0.0642,  0.0378,  0.0313],\n",
       "                       [ 0.0472,  0.0105,  0.0325,  ...,  0.0894, -0.0343,  0.0201],\n",
       "                       [ 0.0125,  0.0306, -0.0354,  ..., -0.0664,  0.0821,  0.0042],\n",
       "                       ...,\n",
       "                       [ 0.0195,  0.0560,  0.0246,  ...,  0.0182,  0.0391, -0.0757],\n",
       "                       [ 0.0324,  0.0487,  0.0486,  ...,  0.0555,  0.0231,  0.0185],\n",
       "                       [-0.0881, -0.0012, -0.0290,  ...,  0.0581,  0.0087,  0.0656]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.17.attention.self.key.bias',\n",
       "               tensor([ 2.4357e-03, -1.9340e-05,  8.2812e-05,  ..., -9.4199e-06,\n",
       "                        3.9316e-04,  2.2320e-04], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.17.attention.self.value.weight',\n",
       "               tensor([[-0.0168,  0.0040, -0.0070,  ...,  0.0123,  0.0022,  0.0050],\n",
       "                       [-0.0183,  0.0201, -0.0101,  ...,  0.0223,  0.0118,  0.0255],\n",
       "                       [ 0.0074,  0.0112, -0.0096,  ...,  0.0174, -0.0016, -0.0740],\n",
       "                       ...,\n",
       "                       [-0.0251,  0.0310,  0.0057,  ..., -0.0274, -0.0804, -0.1123],\n",
       "                       [ 0.0160, -0.0989, -0.0300,  ...,  0.0028, -0.0297,  0.0954],\n",
       "                       [ 0.0591, -0.0673,  0.0101,  ..., -0.1133,  0.0468, -0.0467]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.17.attention.self.value.bias',\n",
       "               tensor([ 0.0079, -0.0015, -0.0010,  ...,  0.0012,  0.0090,  0.0051],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.17.attention.output.dense.weight',\n",
       "               tensor([[ 0.0001, -0.0224, -0.0162,  ..., -0.0210, -0.0318,  0.0524],\n",
       "                       [ 0.0259,  0.0084,  0.0125,  ...,  0.0758, -0.0500,  0.0667],\n",
       "                       [ 0.0009,  0.0085, -0.0030,  ...,  0.0149, -0.0295, -0.0059],\n",
       "                       ...,\n",
       "                       [ 0.0318,  0.0098, -0.0394,  ...,  0.0292,  0.0297,  0.0220],\n",
       "                       [-0.0284,  0.0254, -0.0095,  ..., -0.0473,  0.0638, -0.0307],\n",
       "                       [ 0.0260, -0.0276, -0.0557,  ..., -0.0025, -0.0308,  0.0152]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.17.attention.output.dense.bias',\n",
       "               tensor([-0.0234,  0.0375,  0.0295,  ..., -0.0088, -0.0498, -0.0184],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.17.attention.output.LayerNorm.weight',\n",
       "               tensor([0.9903, 0.9981, 0.9986,  ..., 0.9852, 0.9885, 0.9865], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.17.attention.output.LayerNorm.bias',\n",
       "               tensor([-0.0950, -0.0614, -0.2155,  ..., -0.0824, -0.0679, -0.0850],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.17.intermediate.dense.weight',\n",
       "               tensor([[ 0.0056, -0.0428,  0.0231,  ..., -0.0517, -0.0381, -0.0282],\n",
       "                       [ 0.0824, -0.0310,  0.0201,  ...,  0.0233, -0.0604, -0.0038],\n",
       "                       [-0.0048,  0.0129,  0.0115,  ...,  0.0317,  0.0271,  0.0142],\n",
       "                       ...,\n",
       "                       [ 0.0736, -0.0577, -0.0373,  ..., -0.0065,  0.0344,  0.0078],\n",
       "                       [-0.0062,  0.0937,  0.0127,  ..., -0.0513, -0.0673,  0.0136],\n",
       "                       [-0.0542, -0.0242, -0.0050,  ..., -0.0253, -0.0026,  0.0256]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.17.intermediate.dense.bias',\n",
       "               tensor([-0.0443, -0.0903, -0.0246,  ...,  0.0193, -0.1121, -0.0450],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.17.output.dense.weight',\n",
       "               tensor([[ 0.0275,  0.0672, -0.0155,  ...,  0.0049, -0.0236, -0.0566],\n",
       "                       [ 0.0071, -0.0059,  0.0216,  ...,  0.0035,  0.0031, -0.0068],\n",
       "                       [-0.0173, -0.0251, -0.0005,  ...,  0.0136,  0.0318, -0.0158],\n",
       "                       ...,\n",
       "                       [ 0.0088,  0.0985, -0.0154,  ...,  0.0209, -0.0335,  0.0018],\n",
       "                       [ 0.0117,  0.0120, -0.0232,  ...,  0.0182,  0.0373, -0.0013],\n",
       "                       [-0.0269, -0.0364, -0.0153,  ...,  0.0102, -0.0190,  0.0144]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.17.output.dense.bias',\n",
       "               tensor([-0.0693,  0.0154, -0.1523,  ..., -0.0159, -0.0878, -0.0514],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.17.output.LayerNorm.weight',\n",
       "               tensor([0.9882, 0.9918, 0.9971,  ..., 0.9848, 0.9878, 0.9863], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.17.output.LayerNorm.bias',\n",
       "               tensor([-0.0038, -0.0266,  0.1263,  ..., -0.0133, -0.0372, -0.0074],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.18.attention.self.query.weight',\n",
       "               tensor([[ 3.6751e-02, -3.3289e-05,  1.3821e-01,  ...,  2.5397e-02,\n",
       "                         6.5598e-02, -2.4664e-02],\n",
       "                       [ 3.3232e-02,  1.9245e-02,  1.2652e-02,  ..., -1.4206e-01,\n",
       "                        -4.8007e-02, -3.9465e-02],\n",
       "                       [-5.0668e-02,  5.6206e-02,  1.8897e-01,  ...,  4.4060e-02,\n",
       "                        -2.4586e-02, -2.6627e-02],\n",
       "                       ...,\n",
       "                       [-5.1486e-02, -2.8011e-03, -2.8190e-02,  ...,  2.0182e-02,\n",
       "                        -1.5861e-02, -3.2911e-02],\n",
       "                       [-5.7257e-02,  4.2928e-02, -1.1736e-02,  ...,  1.1981e-02,\n",
       "                         5.1345e-02,  1.1053e-01],\n",
       "                       [-1.7415e-02,  4.0345e-02,  1.4265e-01,  ..., -3.0697e-02,\n",
       "                         1.2528e-02, -5.4152e-02]], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.18.attention.self.query.bias',\n",
       "               tensor([-0.2755, -0.0112, -0.1426,  ...,  0.0097, -0.0073,  0.0218],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.18.attention.self.key.weight',\n",
       "               tensor([[-0.0606, -0.0173,  0.0531,  ...,  0.0107, -0.0087,  0.0467],\n",
       "                       [-0.0250,  0.0826,  0.1168,  ..., -0.0194, -0.0075, -0.0566],\n",
       "                       [ 0.0664,  0.0492,  0.2589,  ..., -0.0252,  0.0011,  0.0091],\n",
       "                       ...,\n",
       "                       [-0.0554, -0.0358, -0.0143,  ..., -0.0323,  0.0620,  0.0246],\n",
       "                       [ 0.0641, -0.0268, -0.0223,  ..., -0.0104, -0.0416, -0.0051],\n",
       "                       [-0.0155, -0.0172,  0.1423,  ...,  0.0383, -0.0085,  0.0757]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.18.attention.self.key.bias',\n",
       "               tensor([-7.0144e-04,  1.4384e-04, -1.4243e-04,  ...,  4.6404e-06,\n",
       "                        1.2977e-05,  2.5628e-04], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.18.attention.self.value.weight',\n",
       "               tensor([[ 0.0269,  0.0191, -0.0016,  ...,  0.0166,  0.0020,  0.0064],\n",
       "                       [-0.0377,  0.0597,  0.0153,  ...,  0.0075,  0.0042,  0.0263],\n",
       "                       [ 0.0105, -0.0388, -0.0325,  ...,  0.1059, -0.0258,  0.0040],\n",
       "                       ...,\n",
       "                       [ 0.0076, -0.0008,  0.0203,  ...,  0.0249, -0.0216, -0.0367],\n",
       "                       [ 0.0381, -0.0024, -0.0427,  ...,  0.0069,  0.0326,  0.0053],\n",
       "                       [ 0.0254,  0.0679, -0.0172,  ..., -0.0476,  0.0170,  0.0042]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.18.attention.self.value.bias',\n",
       "               tensor([-0.0073,  0.0054, -0.0178,  ..., -0.0077,  0.0028, -0.0113],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.18.attention.output.dense.weight',\n",
       "               tensor([[-0.0349, -0.0207, -0.0622,  ..., -0.0273, -0.0066, -0.0412],\n",
       "                       [-0.0215,  0.0689, -0.0525,  ...,  0.0043, -0.0256,  0.0205],\n",
       "                       [-0.0428,  0.0151, -0.0095,  ...,  0.0121, -0.0245, -0.0008],\n",
       "                       ...,\n",
       "                       [ 0.0320,  0.0092,  0.0669,  ..., -0.0082,  0.0231,  0.0183],\n",
       "                       [-0.0066,  0.0198,  0.0187,  ..., -0.0183, -0.0009,  0.0152],\n",
       "                       [-0.0059,  0.0056, -0.0078,  ..., -0.0034,  0.0282,  0.0216]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.18.attention.output.dense.bias',\n",
       "               tensor([-0.0148,  0.0795,  0.0279,  ...,  0.0720,  0.0369,  0.0007],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.18.attention.output.LayerNorm.weight',\n",
       "               tensor([0.9885, 0.9853, 0.9983,  ..., 0.9906, 0.9804, 0.9896], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.18.attention.output.LayerNorm.bias',\n",
       "               tensor([-0.0946, -0.0219, -0.2505,  ..., -0.0717, -0.0624, -0.0678],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.18.intermediate.dense.weight',\n",
       "               tensor([[ 0.0497, -0.0259,  0.0311,  ...,  0.0203,  0.0042, -0.0250],\n",
       "                       [ 0.0612, -0.0435,  0.0091,  ..., -0.0145, -0.0016, -0.0470],\n",
       "                       [ 0.0256, -0.0304, -0.0301,  ..., -0.0364,  0.0078, -0.0315],\n",
       "                       ...,\n",
       "                       [ 0.0179,  0.0679,  0.0402,  ...,  0.0306,  0.0313,  0.0073],\n",
       "                       [-0.0307, -0.0509,  0.0054,  ...,  0.0419, -0.0238,  0.0076],\n",
       "                       [ 0.0402,  0.0605, -0.0644,  ...,  0.0037,  0.0113, -0.0084]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.18.intermediate.dense.bias',\n",
       "               tensor([-0.0716, -0.1016, -0.0044,  ..., -0.0477, -0.0969, -0.0804],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.18.output.dense.weight',\n",
       "               tensor([[-3.9529e-02,  3.2429e-05,  1.7672e-02,  ...,  2.1361e-02,\n",
       "                        -2.9729e-02, -3.2711e-02],\n",
       "                       [-3.6445e-02, -3.8090e-02, -1.8349e-02,  ...,  4.3578e-02,\n",
       "                        -2.9701e-02, -5.8972e-03],\n",
       "                       [ 1.6083e-02, -3.6531e-03, -5.4671e-03,  ..., -1.1584e-02,\n",
       "                        -6.1758e-03, -1.6010e-02],\n",
       "                       ...,\n",
       "                       [ 1.9981e-02,  1.7714e-02,  4.1006e-02,  ..., -3.1077e-03,\n",
       "                        -1.4521e-03, -8.1402e-03],\n",
       "                       [-9.2505e-03, -1.3867e-02,  4.3788e-04,  ..., -4.6812e-03,\n",
       "                         5.0823e-02,  1.2591e-02],\n",
       "                       [-2.7757e-02, -1.3849e-02,  4.4082e-02,  ...,  3.1692e-03,\n",
       "                        -5.6854e-02, -2.2744e-02]], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.18.output.dense.bias',\n",
       "               tensor([-0.0766,  0.0012, -0.1594,  ...,  0.0426, -0.0416, -0.0424],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.18.output.LayerNorm.weight',\n",
       "               tensor([0.9839, 0.9973, 0.9984,  ..., 0.9809, 0.9888, 0.9825], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.18.output.LayerNorm.bias',\n",
       "               tensor([-0.0068, -0.0484,  0.1254,  ..., -0.0183, -0.0274, -0.0289],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.19.attention.self.query.weight',\n",
       "               tensor([[-0.0485, -0.0313, -0.0166,  ..., -0.0709,  0.0614, -0.1430],\n",
       "                       [ 0.0287,  0.0149, -0.1316,  ...,  0.0347,  0.0423,  0.0795],\n",
       "                       [-0.0311, -0.0197,  0.0465,  ..., -0.0590, -0.0814,  0.0176],\n",
       "                       ...,\n",
       "                       [-0.0050, -0.0108, -0.1974,  ...,  0.0872, -0.0064, -0.0345],\n",
       "                       [-0.1271,  0.0599,  0.0545,  ..., -0.0125,  0.0566, -0.0852],\n",
       "                       [-0.0272,  0.0588,  0.0604,  ...,  0.0970,  0.0690, -0.0209]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.19.attention.self.query.bias',\n",
       "               tensor([-0.0139, -0.0616, -0.0124,  ..., -0.0221,  0.0376, -0.0224],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.19.attention.self.key.weight',\n",
       "               tensor([[-0.0189,  0.0068, -0.0008,  ...,  0.0456, -0.0926, -0.0129],\n",
       "                       [ 0.0638,  0.0658, -0.0974,  ...,  0.0578, -0.0419,  0.0628],\n",
       "                       [-0.0588, -0.0167,  0.0368,  ...,  0.0193,  0.1104, -0.0434],\n",
       "                       ...,\n",
       "                       [-0.0803, -0.0242, -0.2640,  ...,  0.0136,  0.0649,  0.0287],\n",
       "                       [-0.0139,  0.0079,  0.1634,  ...,  0.0251,  0.0857,  0.0182],\n",
       "                       [ 0.0186, -0.0762,  0.1227,  ..., -0.0472, -0.0180,  0.0720]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.19.attention.self.key.bias',\n",
       "               tensor([-8.2632e-05, -1.3315e-04,  1.7966e-04,  ..., -5.9897e-05,\n",
       "                        1.4607e-03, -1.3739e-05], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.19.attention.self.value.weight',\n",
       "               tensor([[ 0.0266,  0.0119,  0.0285,  ...,  0.0282,  0.0206,  0.0257],\n",
       "                       [-0.0065,  0.0101, -0.0031,  ...,  0.0341,  0.0252, -0.0187],\n",
       "                       [-0.0347, -0.0132,  0.0149,  ...,  0.0355, -0.0211, -0.0324],\n",
       "                       ...,\n",
       "                       [ 0.0186,  0.0173,  0.0135,  ..., -0.0196, -0.0152, -0.0179],\n",
       "                       [ 0.0231,  0.0260, -0.0368,  ...,  0.0291, -0.0189, -0.0462],\n",
       "                       [-0.0176,  0.0598, -0.0252,  ...,  0.0375,  0.0248, -0.0033]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.19.attention.self.value.bias',\n",
       "               tensor([ 0.0033,  0.0725, -0.0001,  ..., -0.0049,  0.0002, -0.0173],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.19.attention.output.dense.weight',\n",
       "               tensor([[ 0.0013,  0.0280, -0.0179,  ...,  0.0274,  0.0127, -0.0046],\n",
       "                       [ 0.0063, -0.0304, -0.0474,  ..., -0.0030,  0.0365,  0.0051],\n",
       "                       [ 0.0014, -0.0487, -0.0238,  ...,  0.0409, -0.0234,  0.0151],\n",
       "                       ...,\n",
       "                       [-0.0631, -0.0612, -0.0297,  ...,  0.0025, -0.0005,  0.0137],\n",
       "                       [-0.0164,  0.0463,  0.0093,  ...,  0.0112,  0.0181, -0.0089],\n",
       "                       [-0.0191, -0.0373,  0.0031,  ..., -0.0118, -0.0235, -0.0472]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.19.attention.output.dense.bias',\n",
       "               tensor([ 0.0043,  0.0610,  0.0789,  ..., -0.0016,  0.0254,  0.0067],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.19.attention.output.LayerNorm.weight',\n",
       "               tensor([0.9800, 0.9890, 0.9985,  ..., 0.9726, 0.9882, 0.9948], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.19.attention.output.LayerNorm.bias',\n",
       "               tensor([-0.0797, -0.0365, -0.2133,  ..., -0.0627, -0.0840, -0.0623],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.19.intermediate.dense.weight',\n",
       "               tensor([[ 0.0427, -0.0420,  0.0148,  ...,  0.0872,  0.0761,  0.1549],\n",
       "                       [ 0.0501, -0.0103,  0.0539,  ...,  0.0198,  0.0287,  0.0301],\n",
       "                       [ 0.0196,  0.0075,  0.0389,  ..., -0.0204, -0.0055,  0.0091],\n",
       "                       ...,\n",
       "                       [ 0.0753, -0.0251,  0.0214,  ..., -0.0025, -0.0522,  0.0382],\n",
       "                       [ 0.0289, -0.0084, -0.0386,  ..., -0.0151,  0.0328, -0.0840],\n",
       "                       [ 0.0146,  0.0445,  0.0356,  ..., -0.0370, -0.0110,  0.0347]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.19.intermediate.dense.bias',\n",
       "               tensor([-0.1024,  0.0125, -0.0424,  ..., -0.1168,  0.0036, -0.0176],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.19.output.dense.weight',\n",
       "               tensor([[ 0.0118, -0.0163, -0.0197,  ..., -0.0422, -0.0091,  0.0072],\n",
       "                       [-0.0581, -0.0388,  0.0081,  ...,  0.0529, -0.0177,  0.0203],\n",
       "                       [ 0.0136, -0.0144, -0.0004,  ..., -0.0156,  0.0088, -0.0013],\n",
       "                       ...,\n",
       "                       [ 0.0103, -0.0086,  0.0301,  ..., -0.0457,  0.0122,  0.0234],\n",
       "                       [ 0.0284, -0.0090, -0.0316,  ..., -0.0178, -0.0080, -0.0094],\n",
       "                       [ 0.0078,  0.0138, -0.0028,  ...,  0.0416,  0.0414,  0.0316]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.19.output.dense.bias',\n",
       "               tensor([-0.0388,  0.0273, -0.0501,  ...,  0.1111, -0.0572,  0.0031],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.19.output.LayerNorm.weight',\n",
       "               tensor([0.9639, 0.9944, 0.9965,  ..., 0.9763, 0.9912, 0.9857], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.19.output.LayerNorm.bias',\n",
       "               tensor([-0.0106, -0.0327,  0.0787,  ..., -0.0203, -0.0165, -0.0065],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.20.attention.self.query.weight',\n",
       "               tensor([[-0.0147,  0.0174, -0.0110,  ...,  0.0012, -0.0577,  0.0194],\n",
       "                       [-0.0724, -0.0724,  0.0294,  ..., -0.0305, -0.0394, -0.0035],\n",
       "                       [-0.0188, -0.0296, -0.0005,  ...,  0.0300,  0.0462, -0.0053],\n",
       "                       ...,\n",
       "                       [ 0.0955, -0.0104, -0.0276,  ...,  0.0713, -0.0226,  0.0173],\n",
       "                       [-0.0014, -0.0016,  0.1986,  ..., -0.0232,  0.0237,  0.0017],\n",
       "                       [-0.0252,  0.0132, -0.1223,  ..., -0.0457, -0.0356, -0.0504]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.20.attention.self.query.bias',\n",
       "               tensor([-0.0272,  0.0251,  0.0127,  ...,  0.0903, -0.0333,  0.0521],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.20.attention.self.key.weight',\n",
       "               tensor([[ 0.0151, -0.0673, -0.0259,  ..., -0.1064, -0.0147, -0.0858],\n",
       "                       [-0.0145, -0.0050,  0.0354,  ..., -0.0162, -0.0012, -0.0034],\n",
       "                       [ 0.0272,  0.0473, -0.0871,  ...,  0.1048,  0.0214,  0.0366],\n",
       "                       ...,\n",
       "                       [-0.0373, -0.0532, -0.1084,  ..., -0.0246, -0.0156,  0.0287],\n",
       "                       [-0.0327,  0.0546,  0.2247,  ...,  0.0259, -0.0634,  0.0284],\n",
       "                       [-0.0195,  0.0242, -0.0454,  ..., -0.0933, -0.0159,  0.0171]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.20.attention.self.key.bias',\n",
       "               tensor([ 3.1508e-04,  1.9668e-04,  3.1824e-04,  ...,  1.7927e-04,\n",
       "                       -2.9245e-05,  1.0939e-04], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.20.attention.self.value.weight',\n",
       "               tensor([[-0.0486, -0.0088,  0.0261,  ..., -0.0251, -0.0009,  0.0608],\n",
       "                       [-0.0186,  0.0013, -0.0165,  ..., -0.0243,  0.1045,  0.0206],\n",
       "                       [ 0.0051,  0.0316, -0.0122,  ..., -0.0674, -0.0781,  0.0165],\n",
       "                       ...,\n",
       "                       [-0.0650,  0.0293,  0.0203,  ...,  0.0661,  0.0087,  0.0175],\n",
       "                       [ 0.0918,  0.0099,  0.0630,  ..., -0.0055,  0.0164, -0.0505],\n",
       "                       [ 0.0217,  0.0426, -0.0116,  ..., -0.0255, -0.0091, -0.0743]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.20.attention.self.value.bias',\n",
       "               tensor([-0.0003,  0.0056,  0.0192,  ...,  0.0027,  0.0030, -0.0059],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.20.attention.output.dense.weight',\n",
       "               tensor([[ 0.0096, -0.0653, -0.0505,  ...,  0.0568, -0.0547, -0.0164],\n",
       "                       [ 0.0132,  0.0436,  0.0166,  ..., -0.0144, -0.0153, -0.0552],\n",
       "                       [ 0.0262,  0.0096,  0.0100,  ..., -0.0174, -0.0530, -0.0049],\n",
       "                       ...,\n",
       "                       [ 0.0437, -0.0266, -0.0440,  ..., -0.0725, -0.0224,  0.0398],\n",
       "                       [ 0.0205,  0.0002,  0.0085,  ..., -0.0204, -0.0123,  0.0301],\n",
       "                       [ 0.0086,  0.0065, -0.0167,  ...,  0.0238,  0.0123,  0.0371]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.20.attention.output.dense.bias',\n",
       "               tensor([-0.0102,  0.0781,  0.0602,  ...,  0.0719,  0.0868,  0.0220],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.20.attention.output.LayerNorm.weight',\n",
       "               tensor([0.9723, 0.9950, 0.9993,  ..., 0.9795, 0.9858, 0.9953], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.20.attention.output.LayerNorm.bias',\n",
       "               tensor([-0.0296, -0.0330, -0.1557,  ..., -0.0448, -0.0895, -0.0459],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.20.intermediate.dense.weight',\n",
       "               tensor([[ 0.0062, -0.0099,  0.0590,  ...,  0.0059,  0.0104,  0.0130],\n",
       "                       [ 0.0207, -0.0087,  0.0044,  ...,  0.0079, -0.0651,  0.0704],\n",
       "                       [-0.0160, -0.0145, -0.0554,  ..., -0.0223, -0.0313, -0.0315],\n",
       "                       ...,\n",
       "                       [ 0.0009, -0.0304,  0.0034,  ...,  0.0399,  0.0904,  0.0201],\n",
       "                       [ 0.0592,  0.0491,  0.0600,  ..., -0.0512, -0.0089, -0.0289],\n",
       "                       [-0.0175, -0.0421,  0.0497,  ..., -0.0107,  0.0012, -0.0069]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.20.intermediate.dense.bias',\n",
       "               tensor([-0.0226, -0.0381, -0.0478,  ..., -0.0260, -0.0179, -0.0257],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.20.output.dense.weight',\n",
       "               tensor([[-0.0169,  0.0672,  0.0131,  ...,  0.0582, -0.0088, -0.0173],\n",
       "                       [ 0.0103,  0.0308,  0.0499,  ...,  0.0042,  0.0151, -0.0400],\n",
       "                       [-0.0119, -0.0021, -0.0031,  ..., -0.0085, -0.0095, -0.0122],\n",
       "                       ...,\n",
       "                       [ 0.0138,  0.0070,  0.0452,  ..., -0.0166,  0.0146, -0.0031],\n",
       "                       [-0.0199, -0.0457,  0.0213,  ...,  0.0315,  0.0596,  0.0219],\n",
       "                       [-0.0337,  0.0024,  0.0384,  ...,  0.0212,  0.0382, -0.0062]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.20.output.dense.bias',\n",
       "               tensor([-0.0564,  0.0041, -0.0086,  ...,  0.0620, -0.0943,  0.0493],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.20.output.LayerNorm.weight',\n",
       "               tensor([0.9663, 0.9921, 0.9977,  ..., 0.9803, 0.9841, 0.9801], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.20.output.LayerNorm.bias',\n",
       "               tensor([-0.0310, -0.0306,  0.0812,  ..., -0.0303, -0.0235, -0.0134],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.21.attention.self.query.weight',\n",
       "               tensor([[ 0.0294, -0.0809, -0.2133,  ..., -0.0181, -0.0100, -0.0440],\n",
       "                       [-0.0245, -0.0810,  0.0545,  ..., -0.0246,  0.0212,  0.0030],\n",
       "                       [ 0.0550,  0.0398,  0.0605,  ...,  0.0321, -0.0400, -0.0779],\n",
       "                       ...,\n",
       "                       [ 0.0016,  0.0144, -0.1501,  ...,  0.0744,  0.0648,  0.0554],\n",
       "                       [-0.0580,  0.0106,  0.0361,  ...,  0.0062,  0.0064,  0.0055],\n",
       "                       [-0.0480, -0.0429,  0.0472,  ...,  0.0163, -0.0200,  0.0679]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.21.attention.self.query.bias',\n",
       "               tensor([ 0.1657, -0.0315, -0.0174,  ..., -0.0690,  0.0409, -0.0460],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.21.attention.self.key.weight',\n",
       "               tensor([[ 0.0106,  0.0486, -0.1590,  ...,  0.0698,  0.0304,  0.0119],\n",
       "                       [ 0.0435,  0.0443,  0.0703,  ...,  0.0068,  0.1318, -0.0435],\n",
       "                       [-0.0005,  0.0016, -0.0024,  ..., -0.0806,  0.0139, -0.0116],\n",
       "                       ...,\n",
       "                       [-0.0567, -0.0455, -0.1240,  ...,  0.0280, -0.0530,  0.0310],\n",
       "                       [ 0.0887, -0.0140,  0.0698,  ..., -0.0936,  0.0291, -0.0110],\n",
       "                       [-0.0311,  0.0130,  0.0787,  ..., -0.0392,  0.0150, -0.0053]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.21.attention.self.key.bias',\n",
       "               tensor([-5.0854e-02, -5.5043e-05,  7.1470e-04,  ...,  3.9272e-03,\n",
       "                       -3.3241e-04,  1.0085e-02], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.21.attention.self.value.weight',\n",
       "               tensor([[ 0.0289, -0.0319, -0.0536,  ..., -0.0363,  0.0161, -0.0274],\n",
       "                       [ 0.0426, -0.0498, -0.0003,  ...,  0.0232, -0.0507,  0.0682],\n",
       "                       [ 0.0166, -0.0406, -0.0112,  ...,  0.0032, -0.0379,  0.0264],\n",
       "                       ...,\n",
       "                       [ 0.0200, -0.0725, -0.0099,  ..., -0.0241, -0.0741, -0.0296],\n",
       "                       [ 0.0280, -0.0294, -0.0437,  ...,  0.0672, -0.0155,  0.0250],\n",
       "                       [-0.0202, -0.0031,  0.0946,  ..., -0.0343, -0.0219,  0.0221]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.21.attention.self.value.bias',\n",
       "               tensor([ 0.0075, -0.0017, -0.0012,  ..., -0.0112, -0.0260, -0.0125],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.21.attention.output.dense.weight',\n",
       "               tensor([[-0.0024,  0.0444, -0.0341,  ..., -0.0173,  0.0066,  0.0372],\n",
       "                       [ 0.0342,  0.0149, -0.0343,  ...,  0.0047,  0.0279, -0.0189],\n",
       "                       [ 0.0103, -0.0402, -0.0076,  ..., -0.0139,  0.0143, -0.0396],\n",
       "                       ...,\n",
       "                       [ 0.0197,  0.0446, -0.0042,  ...,  0.0199, -0.0221,  0.0489],\n",
       "                       [-0.0538,  0.0704, -0.0665,  ...,  0.0016, -0.0416, -0.0162],\n",
       "                       [ 0.0158,  0.0136, -0.0549,  ...,  0.0509, -0.0234, -0.0266]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.21.attention.output.dense.bias',\n",
       "               tensor([-0.0267,  0.0898,  0.0438,  ...,  0.0352,  0.1779,  0.0309],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.21.attention.output.LayerNorm.weight',\n",
       "               tensor([0.9710, 0.9920, 1.0003,  ..., 0.9794, 0.9911, 0.9923], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.21.attention.output.LayerNorm.bias',\n",
       "               tensor([-0.0457, -0.0584, -0.1334,  ..., -0.0504, -0.1017, -0.0347],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.21.intermediate.dense.weight',\n",
       "               tensor([[-0.0169, -0.0317,  0.0370,  ...,  0.0542,  0.0235, -0.0262],\n",
       "                       [ 0.0016,  0.0004, -0.0736,  ...,  0.0261,  0.0011,  0.0592],\n",
       "                       [ 0.0018,  0.0369, -0.0441,  ..., -0.0049,  0.0096,  0.0010],\n",
       "                       ...,\n",
       "                       [-0.0091, -0.0185,  0.0261,  ..., -0.0239, -0.0733, -0.0231],\n",
       "                       [ 0.0130, -0.0698,  0.0180,  ..., -0.0241,  0.0056, -0.0255],\n",
       "                       [ 0.0037,  0.0034,  0.0191,  ..., -0.0111,  0.0282,  0.0382]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.21.intermediate.dense.bias',\n",
       "               tensor([-0.0255, -0.0450,  0.0188,  ..., -0.0301, -0.0034, -0.0151],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.21.output.dense.weight',\n",
       "               tensor([[-0.0118,  0.0005, -0.0038,  ...,  0.0360, -0.0205, -0.0351],\n",
       "                       [ 0.0025,  0.0127, -0.0347,  ...,  0.0152, -0.0354,  0.0513],\n",
       "                       [-0.0182,  0.0002,  0.0019,  ...,  0.0121,  0.0048,  0.0123],\n",
       "                       ...,\n",
       "                       [-0.0311,  0.0123,  0.0245,  ..., -0.0185, -0.0135, -0.0044],\n",
       "                       [-0.0340,  0.0021, -0.0369,  ..., -0.0359, -0.1036,  0.0085],\n",
       "                       [-0.0080, -0.0055,  0.0025,  ..., -0.0032, -0.0314,  0.0014]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.21.output.dense.bias',\n",
       "               tensor([-0.0102,  0.0067, -0.0726,  ...,  0.0921, -0.1209,  0.0154],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.21.output.LayerNorm.weight',\n",
       "               tensor([0.9694, 0.9909, 0.9962,  ..., 0.9832, 0.9863, 0.9964], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.21.output.LayerNorm.bias',\n",
       "               tensor([-0.0435, -0.0139,  0.0397,  ..., -0.0393, -0.0567, -0.0170],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.22.attention.self.query.weight',\n",
       "               tensor([[ 0.0033,  0.0378,  0.0876,  ...,  0.0187,  0.0169,  0.0582],\n",
       "                       [ 0.0182, -0.0408,  0.0043,  ..., -0.1017,  0.0531,  0.0099],\n",
       "                       [ 0.0975, -0.0285,  0.1844,  ...,  0.0121,  0.0569, -0.0078],\n",
       "                       ...,\n",
       "                       [-0.0079, -0.0129, -0.0795,  ..., -0.0675, -0.0028,  0.0724],\n",
       "                       [-0.0413,  0.0721, -0.0110,  ...,  0.0608, -0.0370, -0.0324],\n",
       "                       [ 0.0365,  0.0596,  0.0999,  ...,  0.0263, -0.0223, -0.0810]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.22.attention.self.query.bias',\n",
       "               tensor([-0.0049,  0.0072,  0.1515,  ...,  0.0021,  0.0991, -0.0555],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.22.attention.self.key.weight',\n",
       "               tensor([[-0.0665, -0.0530,  0.0720,  ...,  0.0042, -0.0582,  0.0475],\n",
       "                       [ 0.0304, -0.0271,  0.0238,  ...,  0.0317, -0.0107,  0.0133],\n",
       "                       [ 0.0019,  0.0328,  0.0956,  ...,  0.0177, -0.0129,  0.0159],\n",
       "                       ...,\n",
       "                       [ 0.0752,  0.0003, -0.0992,  ..., -0.0611, -0.0546, -0.0923],\n",
       "                       [ 0.0232,  0.0672, -0.0535,  ...,  0.0362,  0.0366, -0.0388],\n",
       "                       [-0.0530,  0.0173, -0.0274,  ..., -0.0099,  0.0197, -0.0084]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.22.attention.self.key.bias',\n",
       "               tensor([-9.2472e-06, -1.5771e-04,  4.3453e-04,  ..., -1.6064e-04,\n",
       "                       -6.7599e-04, -7.0374e-04], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.22.attention.self.value.weight',\n",
       "               tensor([[ 0.0256,  0.0333,  0.0429,  ...,  0.0434, -0.0222,  0.0517],\n",
       "                       [-0.0441, -0.0137, -0.0154,  ...,  0.0525, -0.0724,  0.0560],\n",
       "                       [-0.0191,  0.0347,  0.0061,  ..., -0.0043, -0.0187,  0.0227],\n",
       "                       ...,\n",
       "                       [-0.0414,  0.0006, -0.0150,  ..., -0.0331,  0.0289, -0.0466],\n",
       "                       [ 0.0183,  0.0147,  0.0360,  ...,  0.0060,  0.0050, -0.0354],\n",
       "                       [-0.0229, -0.0195, -0.0385,  ..., -0.0249,  0.0118,  0.0233]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.22.attention.self.value.bias',\n",
       "               tensor([ 0.0077, -0.0129,  0.0142,  ..., -0.0118, -0.0047, -0.0074],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.22.attention.output.dense.weight',\n",
       "               tensor([[ 0.0415,  0.0489, -0.0050,  ..., -0.0355, -0.0328, -0.0120],\n",
       "                       [ 0.0092,  0.0243,  0.0287,  ..., -0.0476,  0.0069,  0.0275],\n",
       "                       [ 0.0179,  0.0051, -0.0263,  ..., -0.0232,  0.0505, -0.0038],\n",
       "                       ...,\n",
       "                       [ 0.0328,  0.0276, -0.0225,  ...,  0.0104, -0.0218, -0.0118],\n",
       "                       [ 0.0428, -0.0164,  0.0173,  ..., -0.0158, -0.0070, -0.0430],\n",
       "                       [ 0.0328,  0.0400,  0.0391,  ..., -0.0347,  0.0057, -0.0029]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.22.attention.output.dense.bias',\n",
       "               tensor([ 0.0767,  0.0950,  0.0674,  ...,  0.0083,  0.1465, -0.0306],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.22.attention.output.LayerNorm.weight',\n",
       "               tensor([0.9539, 0.9882, 0.9968,  ..., 0.9750, 0.9965, 0.9874], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.22.attention.output.LayerNorm.bias',\n",
       "               tensor([-0.0478, -0.0131, -0.1199,  ..., -0.0383, -0.1028,  0.0335],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.22.intermediate.dense.weight',\n",
       "               tensor([[-0.0016, -0.0680, -0.0492,  ..., -0.0091,  0.0079,  0.0769],\n",
       "                       [-0.0169, -0.0196,  0.0643,  ...,  0.0032,  0.0457, -0.0019],\n",
       "                       [-0.0291, -0.0688,  0.0752,  ...,  0.0112, -0.0122, -0.0462],\n",
       "                       ...,\n",
       "                       [-0.0327,  0.0271,  0.0451,  ...,  0.0470,  0.0082,  0.0374],\n",
       "                       [ 0.0629,  0.0207,  0.0444,  ...,  0.0230, -0.0062,  0.0043],\n",
       "                       [ 0.0038, -0.0734, -0.0578,  ..., -0.0045,  0.0220, -0.0506]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.22.intermediate.dense.bias',\n",
       "               tensor([ 0.0177, -0.0076, -0.0130,  ..., -0.0444,  0.0148, -0.0282],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.22.output.dense.weight',\n",
       "               tensor([[-0.0260,  0.0399, -0.0240,  ...,  0.0071, -0.0063, -0.0860],\n",
       "                       [ 0.0119, -0.0277,  0.0234,  ..., -0.0092, -0.0304,  0.0135],\n",
       "                       [-0.0164, -0.0118, -0.0041,  ...,  0.0016, -0.0002,  0.0110],\n",
       "                       ...,\n",
       "                       [-0.0133, -0.0314,  0.0101,  ..., -0.0212, -0.0067,  0.0565],\n",
       "                       [ 0.0158, -0.0375,  0.0406,  ..., -0.0081, -0.0247, -0.0256],\n",
       "                       [-0.0079,  0.0707,  0.0313,  ..., -0.0225,  0.0065, -0.0239]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.22.output.dense.bias',\n",
       "               tensor([ 0.0236,  0.0464, -0.0756,  ...,  0.0239, -0.1325,  0.0456],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.22.output.LayerNorm.weight',\n",
       "               tensor([0.9558, 0.9937, 0.9971,  ..., 0.9825, 0.9913, 0.9834], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.22.output.LayerNorm.bias',\n",
       "               tensor([-0.0229,  0.0381,  0.0502,  ..., -0.0329, -0.0121,  0.0167],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.23.attention.self.query.weight',\n",
       "               tensor([[-0.0343,  0.0237,  0.0925,  ..., -0.0896,  0.0877,  0.0667],\n",
       "                       [-0.0428,  0.0212,  0.1017,  ..., -0.0057, -0.0134, -0.0046],\n",
       "                       [ 0.0349,  0.0420,  0.0307,  ..., -0.0086, -0.0894, -0.0342],\n",
       "                       ...,\n",
       "                       [ 0.1001, -0.0529,  0.1248,  ..., -0.0051, -0.0110,  0.0664],\n",
       "                       [-0.0477,  0.0011, -0.0024,  ..., -0.0515, -0.0170, -0.0157],\n",
       "                       [-0.0128, -0.0463, -0.0592,  ...,  0.0460, -0.0669,  0.0150]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.23.attention.self.query.bias',\n",
       "               tensor([ 0.0779,  0.2723,  0.0302,  ..., -0.2013,  0.1131,  0.0774],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.23.attention.self.key.weight',\n",
       "               tensor([[ 0.0584, -0.0311,  0.2180,  ..., -0.0164,  0.0305,  0.0213],\n",
       "                       [ 0.0737, -0.0645,  0.0659,  ...,  0.0123, -0.0494,  0.0070],\n",
       "                       [-0.1160, -0.0252, -0.0379,  ..., -0.1287,  0.0430, -0.0249],\n",
       "                       ...,\n",
       "                       [ 0.0535,  0.0074,  0.0699,  ..., -0.0457,  0.0010,  0.0545],\n",
       "                       [ 0.0201, -0.0007, -0.0654,  ..., -0.0272,  0.0350,  0.0346],\n",
       "                       [-0.0144, -0.0170, -0.0170,  ...,  0.1073,  0.0039,  0.0636]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.23.attention.self.key.bias',\n",
       "               tensor([ 7.4651e-06, -9.8145e-05,  4.8232e-05,  ...,  6.2495e-02,\n",
       "                       -9.5109e-05, -1.1840e-04], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.23.attention.self.value.weight',\n",
       "               tensor([[-0.0673, -0.0674, -0.0099,  ..., -0.0340,  0.0020,  0.0078],\n",
       "                       [ 0.0229,  0.0074,  0.0389,  ..., -0.0287,  0.0032, -0.0462],\n",
       "                       [-0.0406,  0.0639, -0.0136,  ...,  0.0078, -0.0465, -0.0100],\n",
       "                       ...,\n",
       "                       [ 0.0502,  0.0295, -0.0295,  ..., -0.0130, -0.0232,  0.0162],\n",
       "                       [ 0.0026, -0.0350,  0.0274,  ..., -0.0147, -0.0005,  0.0129],\n",
       "                       [ 0.0114, -0.0210,  0.0245,  ..., -0.0007,  0.0173,  0.0144]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.23.attention.self.value.bias',\n",
       "               tensor([-0.0153,  0.0179,  0.0118,  ...,  0.0076,  0.0071,  0.0132],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.23.attention.output.dense.weight',\n",
       "               tensor([[-0.0207, -0.0079, -0.0011,  ...,  0.0385, -0.0317,  0.0332],\n",
       "                       [-0.0365, -0.0048,  0.0260,  ...,  0.0547, -0.0097, -0.0484],\n",
       "                       [-0.0257,  0.0097,  0.0089,  ..., -0.0102,  0.0159, -0.0319],\n",
       "                       ...,\n",
       "                       [-0.0018, -0.0468, -0.0107,  ..., -0.0216, -0.0017, -0.0087],\n",
       "                       [ 0.0171,  0.0433,  0.0164,  ...,  0.0116,  0.0042,  0.0044],\n",
       "                       [ 0.0381, -0.0133, -0.0239,  ..., -0.0107,  0.0135,  0.0136]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.23.attention.output.dense.bias',\n",
       "               tensor([ 0.0641,  0.0725, -0.0045,  ...,  0.0315,  0.0211,  0.1619],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.23.attention.output.LayerNorm.weight',\n",
       "               tensor([0.9619, 0.9805, 0.9935,  ..., 0.9814, 0.9922, 0.9647], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.23.attention.output.LayerNorm.bias',\n",
       "               tensor([-0.1348,  0.0311, -0.1584,  ..., -0.0664, -0.1432, -0.0919],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.23.intermediate.dense.weight',\n",
       "               tensor([[-0.0111, -0.0868, -0.0142,  ..., -0.0097,  0.0167, -0.0259],\n",
       "                       [-0.0144, -0.0238, -0.0115,  ..., -0.0120,  0.0176, -0.0640],\n",
       "                       [ 0.0009, -0.0922, -0.0031,  ...,  0.0325,  0.0341, -0.0215],\n",
       "                       ...,\n",
       "                       [-0.0411,  0.0268,  0.0117,  ..., -0.0028, -0.0404, -0.0078],\n",
       "                       [ 0.0433,  0.0024, -0.0067,  ..., -0.0123,  0.0637,  0.0382],\n",
       "                       [ 0.0346, -0.0150, -0.0294,  ...,  0.0524,  0.0292,  0.0393]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.23.intermediate.dense.bias',\n",
       "               tensor([ 0.0086, -0.0688, -0.1255,  ..., -0.0401, -0.0952, -0.0114],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.23.output.dense.weight',\n",
       "               tensor([[ 0.0228, -0.0394, -0.0190,  ...,  0.0182,  0.0234, -0.0076],\n",
       "                       [ 0.0121,  0.0641, -0.0238,  ..., -0.0137, -0.0393,  0.0269],\n",
       "                       [-0.0031, -0.0097,  0.0092,  ...,  0.0128, -0.0260, -0.0145],\n",
       "                       ...,\n",
       "                       [ 0.0150, -0.0354,  0.0848,  ...,  0.0315, -0.0137,  0.0416],\n",
       "                       [ 0.0081, -0.0174,  0.0471,  ...,  0.0078,  0.0257, -0.0065],\n",
       "                       [-0.0393,  0.0068,  0.0054,  ...,  0.0364,  0.0075, -0.0130]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.23.output.dense.bias',\n",
       "               tensor([-0.0758, -0.0242, -0.0956,  ...,  0.0764, -0.1582,  0.0786],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.23.output.LayerNorm.weight',\n",
       "               tensor([0.9783, 0.9947, 0.9975,  ..., 0.9821, 1.0003, 0.9883], device='cuda:0')),\n",
       "              ('encoder.module.encoder.layer.23.output.LayerNorm.bias',\n",
       "               tensor([-0.0241, -0.0407, -0.0133,  ..., -0.0476,  0.0083, -0.0058],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.pooler.dense.weight',\n",
       "               tensor([[-0.0222, -0.0229, -0.0050,  ...,  0.0107,  0.0221, -0.0344],\n",
       "                       [-0.0213, -0.0027, -0.0135,  ..., -0.0073, -0.0328,  0.0215],\n",
       "                       [ 0.0131,  0.0175,  0.0092,  ..., -0.0129, -0.0239, -0.0167],\n",
       "                       ...,\n",
       "                       [ 0.0016, -0.0032, -0.0192,  ..., -0.0037,  0.0279, -0.0231],\n",
       "                       [-0.0006, -0.0131, -0.0080,  ..., -0.0057, -0.0309,  0.0086],\n",
       "                       [ 0.0056, -0.0014, -0.0067,  ...,  0.0188, -0.0101,  0.0110]],\n",
       "                      device='cuda:0')),\n",
       "              ('encoder.module.pooler.dense.bias',\n",
       "               tensor([-1.0914e-04, -5.6884e-06, -7.3462e-05,  ..., -1.0166e-05,\n",
       "                        1.0752e-05, -1.1368e-04], device='cuda:0')),\n",
       "              ('decoder.concept_emb.emb.weight',\n",
       "               tensor([[-0.0021, -0.0093, -0.0035,  ...,  0.0264,  0.0093, -0.0249],\n",
       "                       [ 0.0110,  0.0315, -0.0124,  ..., -0.0238, -0.0061,  0.0199],\n",
       "                       [-0.0049, -0.0213, -0.0010,  ..., -0.0176, -0.0216,  0.0018],\n",
       "                       ...,\n",
       "                       [-0.0336,  0.0151,  0.0169,  ..., -0.0195, -0.0170, -0.0008],\n",
       "                       [-0.0311, -0.0065,  0.0086,  ...,  0.0026,  0.0236,  0.0275],\n",
       "                       [-0.0059,  0.0217,  0.0035,  ...,  0.0066,  0.0229,  0.0052]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.concept_emb.cpt_transform.weight',\n",
       "               tensor([[-0.0261, -0.0223, -0.0787,  ...,  0.0410,  0.0095, -0.0131],\n",
       "                       [ 0.0326, -0.0123, -0.0152,  ...,  0.0176,  0.0356, -0.0404],\n",
       "                       [ 0.0368, -0.0123,  0.0049,  ...,  0.0246,  0.0120,  0.0077],\n",
       "                       ...,\n",
       "                       [ 0.0575, -0.0335,  0.0465,  ...,  0.0244, -0.0145,  0.0293],\n",
       "                       [-0.0065,  0.0155,  0.0200,  ..., -0.0192, -0.0238,  0.0177],\n",
       "                       [ 0.0008,  0.0556,  0.0587,  ..., -0.0066,  0.0120,  0.0017]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.concept_emb.cpt_transform.bias',\n",
       "               tensor([-1.4412e-04, -1.3455e-03, -1.5558e-03,  3.5151e-03,  1.4187e-03,\n",
       "                       -2.8012e-03,  9.1978e-04, -8.8056e-03,  5.0289e-03,  4.6891e-03,\n",
       "                        4.8367e-03,  2.3062e-03, -9.3638e-04, -8.0265e-03,  5.6711e-04,\n",
       "                       -1.3954e-03,  3.0733e-03, -5.1915e-04,  1.7739e-04,  4.7920e-03,\n",
       "                       -6.4800e-03,  1.4314e-03, -8.5851e-03, -2.0884e-03,  1.7184e-03,\n",
       "                        4.3466e-03,  9.5161e-04, -4.7719e-04,  1.2588e-03,  4.5807e-03,\n",
       "                        3.4654e-03,  5.6649e-03,  3.4984e-03,  8.0474e-03,  8.2014e-04,\n",
       "                       -1.3068e-04,  4.1048e-03, -6.6709e-03,  2.5043e-03,  3.5412e-03,\n",
       "                        6.1462e-03,  1.1376e-02, -4.0413e-03,  4.2803e-03, -1.7503e-03,\n",
       "                        1.5077e-03,  3.5865e-03, -5.8945e-03, -2.5768e-03,  4.2645e-03,\n",
       "                        1.4766e-03,  5.8837e-03,  3.9391e-03, -5.5847e-04,  5.7460e-03,\n",
       "                        1.0291e-02,  1.3220e-03,  1.5369e-03,  4.4432e-03,  7.5385e-03,\n",
       "                       -3.3466e-04, -2.5860e-03,  9.7495e-03,  7.9255e-03,  7.2938e-03,\n",
       "                        3.1890e-03, -7.1955e-03, -2.9941e-03,  3.3290e-04,  4.2594e-03,\n",
       "                       -3.3322e-03,  4.0706e-03,  2.6884e-03,  3.9320e-03,  8.9764e-03,\n",
       "                       -4.0281e-03, -3.3583e-03,  5.5277e-04, -4.7081e-03, -6.6360e-03,\n",
       "                       -3.4894e-03, -3.4223e-03,  4.1334e-03,  3.9148e-03,  1.3284e-03,\n",
       "                       -5.1087e-03,  1.6737e-03,  3.3628e-03,  7.0820e-04,  2.0758e-03,\n",
       "                        6.9778e-03,  5.9217e-03,  4.5069e-03, -2.5562e-03, -4.9841e-03,\n",
       "                       -9.8979e-04,  6.8510e-03,  8.1777e-03, -6.4643e-03,  2.9687e-03,\n",
       "                        1.4244e-03, -8.1463e-04,  5.8132e-03,  5.3942e-03, -2.2554e-03,\n",
       "                        1.2681e-03,  1.8258e-03,  2.5328e-03,  1.7381e-03, -3.4727e-03,\n",
       "                        3.9319e-03, -5.1496e-03, -2.8889e-03,  2.8870e-03,  1.0129e-02,\n",
       "                       -5.6224e-04, -1.2436e-03, -6.7372e-03,  3.9395e-03,  6.2165e-04,\n",
       "                       -3.5744e-03,  3.4591e-03, -7.5553e-03,  6.2993e-03, -2.4101e-03,\n",
       "                        1.0683e-03, -5.2048e-03, -5.0791e-03,  4.2002e-03,  5.4582e-04,\n",
       "                        2.5689e-03,  7.7316e-03,  4.3836e-03, -2.6434e-04,  3.4999e-03,\n",
       "                       -9.0906e-04,  3.2814e-03,  4.2027e-03,  7.8210e-05,  8.3546e-03,\n",
       "                       -3.0505e-03, -5.2401e-03, -9.1293e-04,  1.6463e-03,  4.7031e-03,\n",
       "                       -6.3057e-03,  2.1843e-04,  3.3019e-03,  2.5109e-03, -4.3105e-03,\n",
       "                       -6.9763e-03,  2.7634e-03,  3.6391e-03, -4.5386e-03, -4.5071e-03,\n",
       "                        7.1755e-03, -7.0795e-04,  4.8503e-03, -4.2110e-03, -1.5914e-03,\n",
       "                       -5.4100e-04,  4.4430e-03,  7.3457e-03,  1.1669e-02,  2.8427e-03,\n",
       "                       -1.5164e-04, -2.8106e-04, -8.0606e-03,  1.5429e-03,  1.3314e-03,\n",
       "                        1.0562e-03,  1.9810e-03, -1.3426e-03,  1.4027e-03,  3.7663e-03,\n",
       "                        8.7385e-04,  5.0410e-03,  3.8163e-03,  7.2394e-04,  4.9438e-03,\n",
       "                       -1.5160e-03, -1.0695e-03, -7.5346e-03, -2.1936e-03, -3.0228e-04,\n",
       "                       -1.9483e-03,  8.4731e-03,  6.9126e-03,  1.0584e-04, -1.7135e-03,\n",
       "                        1.3586e-03, -1.2804e-03,  4.5278e-03,  2.4855e-03, -1.7020e-03,\n",
       "                        5.4938e-03, -1.4628e-03, -2.9341e-03, -4.4272e-03,  1.5379e-03],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.svec2nvec.weight',\n",
       "               tensor([[-0.0099,  0.0258, -0.0242,  ...,  0.0048,  0.0278,  0.0114],\n",
       "                       [ 0.0036,  0.0189, -0.0037,  ...,  0.0122,  0.0289,  0.0073],\n",
       "                       [-0.0451, -0.0067,  0.0235,  ..., -0.0122,  0.0139,  0.0152],\n",
       "                       ...,\n",
       "                       [-0.0122, -0.0294,  0.0005,  ...,  0.0206, -0.0134,  0.0174],\n",
       "                       [-0.0230,  0.0245, -0.0122,  ..., -0.0002,  0.0092, -0.0127],\n",
       "                       [ 0.0054,  0.0229,  0.0269,  ..., -0.0247, -0.0009, -0.0030]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.svec2nvec.bias',\n",
       "               tensor([-0.0092, -0.0039,  0.0008, -0.0112, -0.0080, -0.0027, -0.0099,  0.0023,\n",
       "                       -0.0189, -0.0061, -0.0183, -0.0234, -0.0128, -0.0042, -0.0044, -0.0075,\n",
       "                       -0.0042, -0.0027, -0.0018, -0.0039, -0.0031, -0.0103, -0.0005, -0.0107,\n",
       "                       -0.0078, -0.0166, -0.0167,  0.0054, -0.0106, -0.0154, -0.0031, -0.0090,\n",
       "                        0.0014, -0.0151, -0.0053, -0.0138, -0.0193,  0.0064, -0.0078, -0.0081,\n",
       "                       -0.0083, -0.0142, -0.0046, -0.0106, -0.0097, -0.0118, -0.0018,  0.0071,\n",
       "                       -0.0030, -0.0029, -0.0125, -0.0193, -0.0144, -0.0026, -0.0042, -0.0180,\n",
       "                       -0.0068, -0.0145, -0.0042, -0.0109, -0.0020, -0.0108, -0.0136, -0.0081,\n",
       "                       -0.0066, -0.0066,  0.0003, -0.0157, -0.0166, -0.0023,  0.0001, -0.0060,\n",
       "                       -0.0091, -0.0118, -0.0034, -0.0018, -0.0014, -0.0043,  0.0080, -0.0014,\n",
       "                       -0.0029,  0.0019, -0.0030, -0.0046, -0.0069, -0.0034, -0.0147, -0.0033,\n",
       "                       -0.0063, -0.0006, -0.0156, -0.0037, -0.0135, -0.0119, -0.0126, -0.0129,\n",
       "                       -0.0153, -0.0149,  0.0072, -0.0032, -0.0236, -0.0001, -0.0093, -0.0096,\n",
       "                       -0.0221, -0.0044, -0.0090, -0.0032, -0.0189, -0.0015, -0.0109,  0.0020,\n",
       "                       -0.0075,  0.0016, -0.0189, -0.0143, -0.0071, -0.0028, -0.0154, -0.0094,\n",
       "                        0.0002, -0.0016,  0.0013, -0.0123,  0.0037,  0.0088,  0.0012, -0.0008,\n",
       "                       -0.0198, -0.0181, -0.0144, -0.0096, -0.0087, -0.0043, -0.0041, -0.0108,\n",
       "                       -0.0172, -0.0060,  0.0065, -0.0168,  0.0041, -0.0157,  0.0017, -0.0015,\n",
       "                       -0.0009, -0.0038,  0.0052, -0.0119, -0.0138,  0.0005, -0.0032, -0.0046,\n",
       "                       -0.0171, -0.0022, -0.0103, -0.0119,  0.0027, -0.0014, -0.0122, -0.0050,\n",
       "                       -0.0072, -0.0013, -0.0125, -0.0086, -0.0129, -0.0160, -0.0052, -0.0092,\n",
       "                       -0.0067, -0.0018, -0.0173, -0.0087, -0.0160, -0.0007, -0.0165,  0.0023,\n",
       "                       -0.0127, -0.0114, -0.0025, -0.0024, -0.0058, -0.0058,  0.0003, -0.0018,\n",
       "                       -0.0063, -0.0053, -0.0066, -0.0178, -0.0112, -0.0052, -0.0155, -0.0033,\n",
       "                       -0.0106, -0.0108, -0.0002, -0.0153, -0.0053, -0.0042, -0.0015, -0.0032],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.emb_node_type.weight',\n",
       "               tensor([[-0.0575,  0.0560, -0.0019, -0.0095],\n",
       "                       [ 0.0643, -0.0029, -0.0709, -0.0031],\n",
       "                       [ 0.0582, -0.0688, -0.0201, -0.0214],\n",
       "                       [ 0.0586,  0.0015, -0.0386, -0.0172],\n",
       "                       [-0.0405,  0.1053, -0.0176,  0.0871],\n",
       "                       [ 0.0403, -0.0954,  0.0321, -0.0297],\n",
       "                       [-0.0319, -0.0305,  0.0462, -0.0109],\n",
       "                       [ 0.0652, -0.0594,  0.0503, -0.0361],\n",
       "                       [-0.0601,  0.0368,  0.0201, -0.0218],\n",
       "                       [ 0.0985,  0.0199, -0.0333, -0.0168],\n",
       "                       [-0.0591,  0.0487, -0.0400,  0.0215],\n",
       "                       [-0.1078, -0.0320,  0.0111, -0.0211],\n",
       "                       [ 0.0329, -0.0985,  0.0194, -0.0714],\n",
       "                       [-0.0518,  0.0117,  0.0422, -0.0438],\n",
       "                       [-0.0312,  0.0416, -0.0349,  0.0011],\n",
       "                       [ 0.0742, -0.0559, -0.0106,  0.0307],\n",
       "                       [ 0.0453, -0.0738,  0.0489, -0.0298],\n",
       "                       [-0.0516,  0.1062, -0.0013, -0.0002],\n",
       "                       [ 0.0200, -0.0390,  0.0522, -0.0051],\n",
       "                       [-0.0318,  0.0552, -0.0061, -0.0373],\n",
       "                       [ 0.0315, -0.0781,  0.0033,  0.0307],\n",
       "                       [ 0.0812, -0.0301,  0.0448, -0.0093],\n",
       "                       [-0.0371,  0.0669, -0.0382,  0.0126],\n",
       "                       [ 0.0581, -0.0410,  0.0483,  0.0090],\n",
       "                       [-0.0009, -0.0713,  0.0010, -0.0091],\n",
       "                       [-0.0352,  0.0898, -0.0175,  0.0594],\n",
       "                       [-0.0427,  0.0357, -0.0555,  0.0136],\n",
       "                       [-0.0576,  0.0303,  0.0128,  0.0316],\n",
       "                       [ 0.0314,  0.0329, -0.0014,  0.0130],\n",
       "                       [ 0.0312, -0.0009, -0.0530,  0.0359],\n",
       "                       [-0.0558,  0.0342, -0.0138,  0.0044],\n",
       "                       [ 0.0983, -0.0707,  0.0061, -0.0555],\n",
       "                       [ 0.0278, -0.1175,  0.0065,  0.0051],\n",
       "                       [ 0.0845, -0.0536, -0.0268, -0.0037],\n",
       "                       [ 0.0392,  0.0255, -0.0550,  0.0435],\n",
       "                       [-0.0422,  0.1056, -0.0068, -0.0335],\n",
       "                       [-0.0102,  0.0794,  0.0307,  0.0191],\n",
       "                       [ 0.0495,  0.0582, -0.0199,  0.0284],\n",
       "                       [ 0.0998, -0.0417, -0.0194,  0.0244],\n",
       "                       [-0.0489, -0.0505,  0.0262, -0.0151],\n",
       "                       [ 0.0458, -0.0675, -0.0020,  0.0730],\n",
       "                       [-0.0475,  0.0474,  0.0299, -0.0071],\n",
       "                       [ 0.0132,  0.0074, -0.0393,  0.0200],\n",
       "                       [-0.1036,  0.0546, -0.0100, -0.0172],\n",
       "                       [ 0.0637, -0.0708,  0.0423, -0.0043],\n",
       "                       [ 0.1023, -0.0521, -0.0199,  0.0192],\n",
       "                       [-0.0542,  0.0978, -0.0141,  0.0174],\n",
       "                       [ 0.0603, -0.0510,  0.0359, -0.0110],\n",
       "                       [ 0.0519, -0.0794,  0.0269, -0.0175],\n",
       "                       [ 0.0732,  0.0493, -0.0213,  0.0116],\n",
       "                       [ 0.0200,  0.0678, -0.0200,  0.0700],\n",
       "                       [-0.0631,  0.0953, -0.0081,  0.0691],\n",
       "                       [ 0.0470, -0.0454,  0.0385, -0.0217],\n",
       "                       [-0.0405,  0.0771, -0.0166,  0.0252],\n",
       "                       [-0.0696,  0.0661, -0.0047,  0.0479],\n",
       "                       [-0.0332,  0.0315,  0.0552,  0.0106],\n",
       "                       [-0.0044,  0.0766,  0.0054,  0.0026],\n",
       "                       [ 0.0700,  0.0096, -0.0435,  0.0041],\n",
       "                       [-0.0894,  0.0464,  0.0585,  0.0120],\n",
       "                       [ 0.0456, -0.0812,  0.0093,  0.0281],\n",
       "                       [-0.0708,  0.0756,  0.0061,  0.0641],\n",
       "                       [ 0.0477, -0.0745,  0.0394, -0.0960],\n",
       "                       [-0.0435,  0.0259,  0.0139,  0.0286],\n",
       "                       [ 0.0686, -0.0703,  0.0099, -0.0640],\n",
       "                       [ 0.0749, -0.0070, -0.0133, -0.0014],\n",
       "                       [-0.0708,  0.0422, -0.0194,  0.0221],\n",
       "                       [ 0.0583, -0.0594, -0.0440, -0.0235],\n",
       "                       [-0.0340, -0.0214,  0.0223,  0.0540],\n",
       "                       [ 0.0335, -0.0326,  0.0576, -0.0074],\n",
       "                       [ 0.0652,  0.0652, -0.0326,  0.0102],\n",
       "                       [-0.0395,  0.0915, -0.0074,  0.0595],\n",
       "                       [ 0.0615, -0.0214,  0.0112,  0.0073],\n",
       "                       [-0.0255,  0.1036, -0.0221,  0.0484],\n",
       "                       [-0.0219,  0.0730, -0.0367,  0.0257],\n",
       "                       [-0.0437,  0.1042,  0.0075,  0.0546],\n",
       "                       [ 0.0164, -0.0056,  0.0151,  0.0640],\n",
       "                       [ 0.0403,  0.0096, -0.0567, -0.0024],\n",
       "                       [ 0.0739, -0.0493,  0.0054,  0.0136],\n",
       "                       [-0.0536,  0.0741, -0.0107,  0.0479],\n",
       "                       [-0.0382,  0.0521,  0.0286, -0.0134],\n",
       "                       [ 0.0615, -0.0552, -0.0510,  0.0121],\n",
       "                       [ 0.0150, -0.0645, -0.0089,  0.0755],\n",
       "                       [-0.0325, -0.0463,  0.0474, -0.0469],\n",
       "                       [ 0.0666, -0.0282, -0.0364, -0.0006],\n",
       "                       [ 0.0398, -0.1003,  0.0226, -0.0189],\n",
       "                       [ 0.0293, -0.0486, -0.0192, -0.0063],\n",
       "                       [-0.0563,  0.0310,  0.0438,  0.0302],\n",
       "                       [ 0.0285, -0.0293, -0.0141, -0.0750],\n",
       "                       [ 0.0422, -0.0142, -0.0498,  0.0265],\n",
       "                       [-0.0510,  0.0242,  0.0479, -0.0352],\n",
       "                       [-0.1082,  0.0565,  0.0082, -0.0190],\n",
       "                       [ 0.0277,  0.0151,  0.0483, -0.0021],\n",
       "                       [ 0.0773,  0.0175,  0.0170,  0.0418],\n",
       "                       [-0.0170,  0.0829, -0.1047,  0.0285],\n",
       "                       [-0.0294,  0.1167, -0.0176,  0.0352],\n",
       "                       [-0.0655,  0.0648,  0.0341,  0.0008],\n",
       "                       [ 0.0469,  0.0051,  0.0879,  0.0075],\n",
       "                       [-0.0893,  0.0766, -0.0138, -0.0110],\n",
       "                       [ 0.0438, -0.0599, -0.0076, -0.0132],\n",
       "                       [ 0.0698, -0.0293,  0.0246,  0.0009]], device='cuda:0')),\n",
       "              ('decoder.gnn.emb_node_type.bias',\n",
       "               tensor([-1.7244e-03, -1.2611e-02, -6.3562e-03, -3.4311e-03,  1.1325e-02,\n",
       "                        2.0210e-03,  1.1851e-02,  2.5032e-02, -2.0607e-04,  5.1416e-03,\n",
       "                       -2.1123e-02, -9.2990e-03, -1.4026e-03,  3.2679e-04, -8.6463e-03,\n",
       "                        4.0055e-03,  1.5199e-02,  5.1943e-03,  2.4899e-02, -3.6126e-03,\n",
       "                       -6.6937e-04,  3.3157e-02, -5.5833e-03,  3.2293e-02, -4.7288e-03,\n",
       "                        1.0243e-02, -2.1952e-02, -8.3966e-05,  2.2345e-03, -8.5305e-03,\n",
       "                       -9.5624e-03,  1.0917e-03,  3.3697e-03,  7.7774e-03, -1.0185e-02,\n",
       "                        2.0124e-03,  1.8276e-02,  1.0287e-02,  9.6984e-03, -2.8847e-04,\n",
       "                        4.3604e-03,  9.0700e-03, -6.5484e-03, -7.0139e-03,  1.0808e-02,\n",
       "                        4.8732e-03,  1.3507e-03,  2.1852e-02,  6.9488e-03,  5.7913e-03,\n",
       "                        9.0181e-03,  5.7041e-03,  2.4900e-02,  5.5354e-03,  3.0704e-03,\n",
       "                        1.9322e-02,  7.0766e-03, -8.4721e-04,  1.5402e-02,  2.5136e-03,\n",
       "                        6.5178e-03,  1.3641e-02,  4.3347e-03,  4.2477e-03,  4.1811e-03,\n",
       "                       -4.3966e-03, -1.5422e-02,  6.7477e-03,  2.4053e-02,  9.9347e-03,\n",
       "                        6.8836e-03,  1.7362e-02,  8.6351e-03, -3.6376e-03,  1.4597e-02,\n",
       "                        2.1104e-02, -8.3994e-03,  1.7945e-02,  6.4021e-03,  1.1530e-02,\n",
       "                       -1.0867e-02, -2.9725e-03,  3.3500e-03,  2.7570e-04,  2.1235e-03,\n",
       "                       -1.2688e-02,  1.2620e-02, -1.0303e-02, -9.8016e-03,  1.9308e-02,\n",
       "                       -4.2995e-03,  2.4803e-02,  1.8347e-02, -1.2493e-02,  8.6543e-03,\n",
       "                        1.2488e-02,  3.4106e-02, -6.2364e-03, -5.3477e-03,  2.2741e-02],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.emb_score.weight',\n",
       "               tensor([[ 0.0078, -0.0042, -0.0100,  ..., -0.0720,  0.0973, -0.0618],\n",
       "                       [-0.0088, -0.0530, -0.0431,  ..., -0.0236, -0.0097, -0.0369],\n",
       "                       [-0.0213,  0.0119,  0.0003,  ...,  0.0503,  0.0331,  0.0095],\n",
       "                       ...,\n",
       "                       [ 0.0475,  0.0317,  0.0337,  ..., -0.0036,  0.0375,  0.0161],\n",
       "                       [ 0.0533,  0.0819,  0.0611,  ..., -0.0545,  0.0780, -0.0234],\n",
       "                       [-0.0191,  0.0348, -0.0284,  ...,  0.0231,  0.0246, -0.0444]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.emb_score.bias',\n",
       "               tensor([-0.0170,  0.0160,  0.0384,  0.0003,  0.0312,  0.0157,  0.0198,  0.0045,\n",
       "                        0.0458, -0.0108,  0.0094,  0.0111,  0.0003,  0.0087,  0.0200,  0.0117,\n",
       "                        0.0396,  0.0177,  0.0109,  0.0510,  0.0196, -0.0052,  0.0072,  0.0250,\n",
       "                        0.0058,  0.0036,  0.0225,  0.0172, -0.0016,  0.0303,  0.0265,  0.0007,\n",
       "                       -0.0036,  0.0227,  0.0041, -0.0048,  0.0063,  0.0421,  0.0133, -0.0047,\n",
       "                        0.0083,  0.0087,  0.0072,  0.0302,  0.0101, -0.0021,  0.0525,  0.0520,\n",
       "                       -0.0023,  0.0138,  0.0110,  0.0279,  0.0045,  0.0111,  0.0158,  0.0146,\n",
       "                        0.0064,  0.0159, -0.0005,  0.0028,  0.0062,  0.0118, -0.0010, -0.0058,\n",
       "                        0.0277,  0.0265,  0.0182,  0.0133,  0.0133, -0.0014,  0.0417,  0.0171,\n",
       "                        0.0314,  0.0230,  0.0494,  0.0091,  0.0222,  0.0009,  0.0185,  0.0354,\n",
       "                        0.0074, -0.0031, -0.0010,  0.0177,  0.0460, -0.0056,  0.0126,  0.0119,\n",
       "                        0.0203, -0.0103,  0.0235,  0.0160,  0.0184, -0.0099,  0.0226,  0.0253,\n",
       "                       -0.0006,  0.0175,  0.0085, -0.0090], device='cuda:0')),\n",
       "              ('decoder.gnn.edge_encoder.0.weight',\n",
       "               tensor([[ 0.0306, -0.0353,  0.0325,  ..., -0.0054, -0.0064, -0.0239],\n",
       "                       [ 0.0247,  0.0387,  0.0236,  ...,  0.0328,  0.0120, -0.0459],\n",
       "                       [ 0.0180, -0.0081, -0.0130,  ..., -0.0158,  0.0251,  0.0164],\n",
       "                       ...,\n",
       "                       [ 0.0070,  0.0437, -0.0125,  ..., -0.0002, -0.0051, -0.0569],\n",
       "                       [ 0.0213,  0.0714,  0.0441,  ..., -0.0479,  0.0109, -0.0085],\n",
       "                       [ 0.0176, -0.0074, -0.0351,  ..., -0.0420,  0.0276, -0.0018]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.edge_encoder.0.bias',\n",
       "               tensor([ 0.0077,  0.0119,  0.0017, -0.0190, -0.0046,  0.0056,  0.0168,  0.0094,\n",
       "                       -0.0051,  0.0039, -0.0029,  0.0186, -0.0180,  0.0189,  0.0191, -0.0094,\n",
       "                        0.0084,  0.0184, -0.0068, -0.0066, -0.0126, -0.0144,  0.0322,  0.0054,\n",
       "                        0.0056, -0.0084,  0.0076,  0.0117, -0.0092, -0.0210,  0.0302,  0.0111,\n",
       "                        0.0049,  0.0133,  0.0009,  0.0033,  0.0078, -0.0005,  0.0011,  0.0380,\n",
       "                        0.0042, -0.0085, -0.0131, -0.0191, -0.0132, -0.0132,  0.0060,  0.0126,\n",
       "                        0.0204, -0.0218, -0.0039,  0.0289,  0.0030,  0.0034,  0.0042,  0.0069,\n",
       "                        0.0276,  0.0014,  0.0052, -0.0010,  0.0165, -0.0045, -0.0037,  0.0045,\n",
       "                        0.0175, -0.0177, -0.0008,  0.0173, -0.0091,  0.0122, -0.0022, -0.0185,\n",
       "                       -0.0071, -0.0143,  0.0194,  0.0052,  0.0028,  0.0003, -0.0044,  0.0021,\n",
       "                       -0.0239, -0.0257,  0.0002,  0.0104,  0.0085,  0.0029,  0.0085,  0.0186,\n",
       "                        0.0136, -0.0184,  0.0170,  0.0219,  0.0114,  0.0373, -0.0013, -0.0081,\n",
       "                        0.0079,  0.0001,  0.0129, -0.0018,  0.0132,  0.0188,  0.0141, -0.0070,\n",
       "                        0.0138,  0.0063, -0.0268, -0.0065,  0.0113,  0.0060,  0.0369,  0.0077,\n",
       "                        0.0054, -0.0095, -0.0127, -0.0155, -0.0099, -0.0243, -0.0093,  0.0114,\n",
       "                       -0.0292, -0.0092, -0.0165,  0.0360, -0.0180,  0.0009, -0.0012, -0.0136,\n",
       "                       -0.0028, -0.0299, -0.0139,  0.0060, -0.0042,  0.0075, -0.0028,  0.0032,\n",
       "                        0.0168, -0.0089,  0.0203,  0.0222,  0.0033, -0.0214,  0.0055, -0.0004,\n",
       "                       -0.0070, -0.0103,  0.0122,  0.0016,  0.0049,  0.0059,  0.0101, -0.0175,\n",
       "                       -0.0075,  0.0347, -0.0166,  0.0217,  0.0009, -0.0263,  0.0026,  0.0296,\n",
       "                        0.0109,  0.0100, -0.0139, -0.0151,  0.0139,  0.0117,  0.0224,  0.0200,\n",
       "                        0.0159,  0.0146, -0.0090,  0.0056,  0.0198, -0.0114,  0.0122, -0.0099,\n",
       "                       -0.0116,  0.0004, -0.0143, -0.0011,  0.0056,  0.0021,  0.0154, -0.0226,\n",
       "                       -0.0033, -0.0069, -0.0072, -0.0033, -0.0062, -0.0068, -0.0164,  0.0153,\n",
       "                       -0.0333,  0.0075, -0.0050, -0.0042, -0.0204,  0.0111, -0.0367,  0.0139],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.edge_encoder.1.weight',\n",
       "               tensor([0.9628, 0.9829, 0.9672, 0.9673, 0.9706, 0.9835, 0.9779, 0.9585, 0.9801,\n",
       "                       1.0104, 0.9749, 0.9749, 0.9704, 0.9653, 0.9617, 0.9588, 0.9810, 0.9747,\n",
       "                       0.9706, 0.9653, 0.9548, 0.9736, 0.9918, 0.9715, 0.9768, 0.9686, 0.9768,\n",
       "                       0.9644, 0.9705, 0.9647, 0.9775, 0.9654, 0.9791, 0.9719, 0.9689, 1.0024,\n",
       "                       0.9714, 0.9612, 0.9602, 0.9835, 0.9716, 0.9771, 0.9913, 0.9704, 0.9972,\n",
       "                       0.9774, 0.9673, 0.9556, 0.9649, 0.9712, 0.9714, 0.9532, 0.9586, 0.9630,\n",
       "                       0.9654, 0.9569, 0.9866, 0.9909, 0.9710, 0.9789, 0.9821, 0.9766, 0.9629,\n",
       "                       1.0112, 0.9736, 1.0307, 0.9648, 0.9848, 0.9644, 0.9779, 0.9688, 0.9556,\n",
       "                       0.9911, 0.9716, 0.9692, 0.9976, 0.9801, 0.9737, 0.9750, 1.0032, 0.9712,\n",
       "                       0.9831, 0.9793, 1.0119, 0.9947, 0.9525, 0.9689, 1.0086, 0.9671, 0.9862,\n",
       "                       0.9723, 0.9898, 0.9515, 0.9780, 0.9625, 0.9707, 0.9851, 0.9711, 0.9946,\n",
       "                       0.9929, 1.0127, 0.9705, 0.9535, 0.9593, 0.9769, 0.9911, 0.9627, 0.9748,\n",
       "                       0.9724, 0.9391, 0.9803, 0.9876, 0.9843, 0.9748, 0.9582, 0.9636, 0.9737,\n",
       "                       0.9705, 0.9908, 0.9860, 0.9873, 0.9901, 0.9624, 0.9739, 0.9752, 0.9613,\n",
       "                       0.9775, 0.9644, 0.9877, 0.9880, 0.9751, 0.9752, 0.9599, 0.9629, 0.9751,\n",
       "                       0.9859, 0.9705, 0.9769, 0.9848, 0.9831, 0.9677, 1.0146, 0.9704, 0.9786,\n",
       "                       0.9771, 0.9810, 0.9668, 0.9568, 0.9419, 0.9776, 0.9674, 0.9866, 0.9767,\n",
       "                       0.9543, 0.9812, 1.0107, 0.9792, 0.9727, 0.9707, 0.9655, 0.9763, 0.9820,\n",
       "                       0.9982, 0.9833, 0.9660, 1.0028, 0.9630, 0.9713, 1.0131, 0.9784, 0.9664,\n",
       "                       0.9688, 0.9602, 0.9605, 0.9668, 0.9759, 0.9633, 0.9736, 0.9751, 0.9571,\n",
       "                       0.9551, 0.9673, 0.9850, 0.9753, 0.9827, 0.9796, 0.9681, 0.9709, 0.9784,\n",
       "                       0.9611, 0.9603, 0.9895, 0.9809, 0.9890, 0.9777, 0.9484, 0.9913, 0.9686,\n",
       "                       1.0060, 0.9723], device='cuda:0')),\n",
       "              ('decoder.gnn.edge_encoder.1.bias',\n",
       "               tensor([-2.5693e-02, -9.7445e-03, -1.3280e-02, -1.4876e-02, -1.3010e-02,\n",
       "                       -2.8902e-02, -1.5408e-02, -1.3348e-02, -7.5672e-03,  1.6497e-03,\n",
       "                       -7.8495e-03, -9.1716e-03, -2.0961e-02, -2.2757e-02, -2.0028e-02,\n",
       "                       -1.7987e-02, -7.9770e-03, -1.8736e-03, -5.3145e-03, -3.8504e-03,\n",
       "                       -1.5113e-02, -2.7974e-02,  2.6333e-03, -8.1461e-03, -1.9291e-02,\n",
       "                       -1.5892e-03,  1.6622e-04, -1.8932e-02, -1.3259e-02, -2.7374e-02,\n",
       "                       -1.4522e-02, -1.6898e-02, -8.0646e-03, -1.0664e-02, -1.0739e-02,\n",
       "                       -1.7976e-03, -1.9121e-02, -1.7618e-02, -1.1595e-02, -8.5707e-03,\n",
       "                       -1.0648e-02, -1.1552e-02, -1.4868e-02, -9.6961e-03, -2.4517e-02,\n",
       "                       -7.4088e-03,  7.0666e-03, -1.7505e-02, -1.4665e-02, -2.4669e-02,\n",
       "                       -2.5899e-02, -3.7980e-02, -2.2516e-02, -3.0423e-03, -9.7302e-03,\n",
       "                       -2.5835e-02, -2.2611e-03, -4.0520e-03, -6.8373e-03, -1.9277e-02,\n",
       "                       -8.0628e-03, -1.8217e-02, -1.6750e-02, -1.5095e-02, -1.4788e-03,\n",
       "                       -3.7971e-02, -1.9556e-02,  1.5557e-04, -7.2736e-03, -3.9847e-03,\n",
       "                       -1.2300e-02, -1.9903e-02, -1.9171e-02, -9.9416e-03, -5.3805e-03,\n",
       "                        1.5913e-03, -7.6342e-03, -3.3007e-03, -6.2690e-03, -1.4096e-05,\n",
       "                       -1.5686e-02, -6.8913e-03, -1.7321e-02, -2.5634e-02, -1.4783e-02,\n",
       "                       -2.4108e-02, -1.3706e-02, -2.0894e-02, -2.0094e-02, -6.5898e-03,\n",
       "                       -1.2185e-02, -6.1023e-03, -2.7504e-02, -2.4717e-02, -2.5939e-02,\n",
       "                       -1.5674e-02, -5.1389e-03, -7.2659e-03,  4.9414e-03, -1.5022e-03,\n",
       "                       -1.3755e-02, -2.0142e-02, -2.5539e-02, -3.3021e-02, -1.7456e-02,\n",
       "                       -7.0987e-03, -1.8066e-02, -7.1374e-03, -9.0562e-03, -4.0189e-02,\n",
       "                       -4.1441e-03, -9.2944e-03, -8.8290e-03, -1.3431e-02, -1.1504e-02,\n",
       "                       -2.5691e-02, -1.5559e-02, -2.4027e-02, -1.8737e-02, -6.9398e-03,\n",
       "                       -1.3982e-02, -9.3979e-03, -2.2429e-02, -1.6925e-02, -1.1936e-02,\n",
       "                       -2.2714e-02, -8.0626e-03, -2.0102e-02, -1.1027e-02, -1.1894e-02,\n",
       "                       -2.9027e-02, -1.0246e-02, -2.0020e-02, -2.4571e-02,  1.9411e-03,\n",
       "                       -2.1970e-02, -1.8667e-02, -1.4658e-02, -3.9352e-03, -1.8957e-02,\n",
       "                       -9.4686e-03, -2.8255e-02,  5.2848e-04,  7.7191e-03, -1.7395e-02,\n",
       "                       -1.0582e-02, -1.7854e-02, -2.6494e-02, -3.3694e-02, -2.2807e-02,\n",
       "                       -2.3661e-02, -5.3341e-03, -7.3770e-03, -3.4522e-02, -2.7705e-02,\n",
       "                       -7.6568e-03, -5.1986e-03,  6.7720e-03, -2.3240e-02, -3.5141e-02,\n",
       "                       -1.3055e-02, -8.6289e-03, -2.5888e-02, -1.1771e-02, -1.2512e-02,\n",
       "                       -1.8411e-02, -3.3645e-02, -7.4316e-03, -1.2644e-02, -7.5547e-03,\n",
       "                       -1.6641e-02, -1.9724e-02, -2.6223e-02, -1.5339e-02, -6.3751e-03,\n",
       "                       -5.5682e-03, -2.3769e-02, -8.3162e-03, -7.2813e-03, -3.8014e-02,\n",
       "                       -2.6523e-02, -2.3696e-02, -9.4407e-03, -1.6965e-02, -1.8803e-02,\n",
       "                        4.4039e-03, -1.6914e-02, -1.6613e-02,  7.9222e-03, -2.1573e-02,\n",
       "                       -5.3399e-03, -1.7694e-02, -4.4106e-03, -3.1973e-03, -3.3638e-03,\n",
       "                       -3.0254e-02,  3.6135e-03, -1.7349e-02,  2.9815e-03, -8.8753e-03],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.edge_encoder.1.running_mean',\n",
       "               tensor([ 2.7008e-02,  1.6912e-03,  1.5797e-02, -6.7778e-02,  2.0418e-02,\n",
       "                       -1.1173e-02,  1.5179e-02,  2.4307e-02,  1.2653e-02,  4.6869e-03,\n",
       "                       -1.0762e-02, -1.9674e-03, -1.3291e-02,  3.0813e-02, -1.3610e-03,\n",
       "                        4.5526e-03,  2.5402e-02,  2.0468e-02,  1.6868e-02,  1.5769e-02,\n",
       "                       -3.7985e-03, -2.9739e-02,  3.6873e-02, -1.5693e-03, -2.0923e-02,\n",
       "                        4.5054e-02,  3.2104e-02, -3.1810e-03,  5.9307e-03, -2.4748e-03,\n",
       "                        2.8697e-02,  2.8321e-03,  4.0958e-02,  2.8253e-02,  3.6128e-02,\n",
       "                       -1.6234e-02,  1.5718e-02,  2.1499e-02,  3.2818e-02,  4.5780e-02,\n",
       "                        1.8265e-02, -2.2358e-02,  1.0330e-02, -8.1752e-03, -7.3849e-02,\n",
       "                       -7.7433e-02, -9.5062e-03,  5.6934e-02,  2.9798e-02, -5.6704e-02,\n",
       "                       -2.8998e-04,  3.8911e-02,  7.1862e-02,  2.8319e-02, -1.3835e-03,\n",
       "                        2.4380e-02,  4.7917e-02, -7.5812e-03,  4.3195e-02, -8.7772e-03,\n",
       "                        3.0336e-02, -2.1767e-02, -2.0313e-02, -5.7155e-02,  2.2238e-02,\n",
       "                       -1.7876e-02,  7.2475e-03,  5.9072e-02,  1.7254e-02,  3.5640e-02,\n",
       "                       -5.3690e-02,  3.1887e-02, -6.1408e-02,  1.1748e-02, -2.8399e-02,\n",
       "                        3.6311e-02,  3.8973e-02,  6.4906e-02,  7.8385e-03, -2.0935e-02,\n",
       "                       -5.8416e-02, -2.0047e-02, -3.1496e-02,  2.9189e-02, -3.4504e-02,\n",
       "                       -2.7514e-02,  6.8505e-02,  2.8062e-03,  1.8849e-05, -1.3774e-02,\n",
       "                        9.2343e-03,  3.7521e-02,  4.5121e-02,  1.4074e-02, -1.8121e-04,\n",
       "                       -4.0558e-02, -3.7644e-03,  1.6923e-02,  2.7104e-02, -1.5634e-02,\n",
       "                       -4.1377e-03,  9.3574e-03,  1.9628e-02,  5.6155e-02,  5.2343e-02,\n",
       "                        8.2967e-03, -3.7830e-03, -4.8709e-03, -8.8138e-03,  5.4959e-02,\n",
       "                        9.5033e-02, -8.7470e-03, -2.1711e-03, -2.7213e-02,  2.7870e-02,\n",
       "                       -6.4279e-02, -1.5909e-02, -4.3667e-02, -1.5132e-02, -9.5939e-03,\n",
       "                       -1.8963e-02, -6.7713e-03, -5.5545e-02, -1.0497e-02, -3.9040e-02,\n",
       "                       -4.8672e-03,  1.1762e-02, -1.5282e-02, -4.3349e-02, -5.3518e-02,\n",
       "                        4.6776e-03, -4.4651e-02, -4.5448e-02, -1.2307e-02,  1.7775e-02,\n",
       "                       -4.1911e-03,  2.1014e-02, -4.3004e-03,  2.7901e-02,  1.0977e-02,\n",
       "                       -7.3112e-03, -3.7840e-02, -1.7166e-03,  1.3762e-02, -2.5244e-02,\n",
       "                        1.1566e-02,  7.3994e-02, -4.3874e-03,  4.3512e-02, -4.0878e-02,\n",
       "                        1.8922e-03, -1.0121e-02, -2.9110e-02,  2.4583e-02, -4.8153e-02,\n",
       "                        2.5973e-02, -2.9922e-03, -2.0870e-02, -2.2877e-02, -1.4993e-03,\n",
       "                       -5.9943e-03, -7.2241e-03, -2.0146e-02,  1.2459e-02, -3.8290e-03,\n",
       "                       -2.0011e-02,  3.9809e-02,  1.3255e-02, -4.2352e-04,  1.7046e-02,\n",
       "                       -6.5159e-03,  1.2209e-02,  6.6373e-02, -1.1389e-02,  5.5789e-02,\n",
       "                        1.8531e-02, -1.1453e-02,  2.1218e-02,  1.8626e-02,  1.3585e-02,\n",
       "                       -3.0026e-02,  1.2386e-02, -9.9208e-03, -2.6795e-04, -8.1980e-03,\n",
       "                       -1.3025e-02, -1.7465e-02,  3.8352e-04, -2.6250e-02, -3.8193e-02,\n",
       "                        1.8636e-02, -7.6045e-03, -3.9300e-02,  1.3399e-03,  1.3233e-02,\n",
       "                        1.9639e-02, -1.1317e-02, -1.9422e-02, -3.2577e-02,  5.8234e-02],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.edge_encoder.1.running_var',\n",
       "               tensor([0.0007, 0.0011, 0.0017, 0.0010, 0.0004, 0.0005, 0.0011, 0.0008, 0.0008,\n",
       "                       0.0006, 0.0011, 0.0012, 0.0004, 0.0011, 0.0017, 0.0008, 0.0009, 0.0008,\n",
       "                       0.0008, 0.0017, 0.0010, 0.0005, 0.0005, 0.0005, 0.0007, 0.0009, 0.0004,\n",
       "                       0.0016, 0.0005, 0.0014, 0.0013, 0.0005, 0.0005, 0.0010, 0.0009, 0.0005,\n",
       "                       0.0009, 0.0014, 0.0012, 0.0007, 0.0004, 0.0008, 0.0005, 0.0008, 0.0010,\n",
       "                       0.0010, 0.0010, 0.0012, 0.0016, 0.0011, 0.0004, 0.0004, 0.0009, 0.0014,\n",
       "                       0.0009, 0.0013, 0.0004, 0.0005, 0.0009, 0.0005, 0.0003, 0.0009, 0.0005,\n",
       "                       0.0007, 0.0009, 0.0004, 0.0008, 0.0009, 0.0006, 0.0004, 0.0013, 0.0007,\n",
       "                       0.0007, 0.0006, 0.0007, 0.0004, 0.0007, 0.0007, 0.0007, 0.0003, 0.0020,\n",
       "                       0.0011, 0.0006, 0.0004, 0.0010, 0.0019, 0.0012, 0.0007, 0.0005, 0.0004,\n",
       "                       0.0005, 0.0009, 0.0012, 0.0007, 0.0007, 0.0014, 0.0015, 0.0009, 0.0009,\n",
       "                       0.0006, 0.0004, 0.0006, 0.0008, 0.0008, 0.0012, 0.0005, 0.0013, 0.0009,\n",
       "                       0.0006, 0.0015, 0.0007, 0.0006, 0.0007, 0.0010, 0.0010, 0.0010, 0.0005,\n",
       "                       0.0006, 0.0006, 0.0005, 0.0003, 0.0008, 0.0007, 0.0010, 0.0008, 0.0009,\n",
       "                       0.0008, 0.0012, 0.0011, 0.0014, 0.0014, 0.0012, 0.0019, 0.0012, 0.0016,\n",
       "                       0.0008, 0.0008, 0.0006, 0.0006, 0.0012, 0.0004, 0.0006, 0.0020, 0.0009,\n",
       "                       0.0004, 0.0004, 0.0010, 0.0010, 0.0006, 0.0004, 0.0008, 0.0006, 0.0010,\n",
       "                       0.0016, 0.0006, 0.0004, 0.0010, 0.0015, 0.0007, 0.0009, 0.0008, 0.0008,\n",
       "                       0.0005, 0.0006, 0.0010, 0.0003, 0.0010, 0.0007, 0.0005, 0.0007, 0.0007,\n",
       "                       0.0008, 0.0009, 0.0022, 0.0009, 0.0007, 0.0006, 0.0006, 0.0006, 0.0014,\n",
       "                       0.0004, 0.0004, 0.0003, 0.0004, 0.0008, 0.0010, 0.0010, 0.0010, 0.0016,\n",
       "                       0.0016, 0.0008, 0.0008, 0.0017, 0.0004, 0.0013, 0.0004, 0.0015, 0.0007,\n",
       "                       0.0011, 0.0009], device='cuda:0')),\n",
       "              ('decoder.gnn.edge_encoder.1.num_batches_tracked',\n",
       "               tensor(318750, device='cuda:0')),\n",
       "              ('decoder.gnn.edge_encoder.3.weight',\n",
       "               tensor([[-0.0193, -0.0094, -0.0241,  ...,  0.0122, -0.0301, -0.0028],\n",
       "                       [ 0.0069,  0.0188,  0.0111,  ..., -0.0008, -0.0141,  0.0301],\n",
       "                       [ 0.0371, -0.0236, -0.0005,  ..., -0.0178,  0.0145,  0.0044],\n",
       "                       ...,\n",
       "                       [ 0.0266,  0.0113,  0.0204,  ..., -0.0058,  0.0168, -0.0279],\n",
       "                       [ 0.0263, -0.0120,  0.0145,  ..., -0.0088,  0.0285, -0.0355],\n",
       "                       [ 0.0217,  0.0041,  0.0519,  ...,  0.0308, -0.0709, -0.0156]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.edge_encoder.3.bias',\n",
       "               tensor([-2.3653e-03, -5.7033e-03,  2.7150e-03,  1.7915e-03, -1.3082e-03,\n",
       "                       -3.1844e-04,  8.8534e-04, -5.2766e-03,  1.3499e-03,  4.7690e-03,\n",
       "                       -4.6336e-03,  1.4850e-03, -3.2236e-03,  3.7453e-03, -8.5289e-03,\n",
       "                        7.5043e-03,  5.8532e-03,  2.3962e-04, -5.7625e-04,  5.2903e-04,\n",
       "                       -1.7449e-03,  5.2435e-03,  2.9055e-03, -4.1971e-03, -5.6767e-03,\n",
       "                       -4.0691e-03, -1.4285e-03,  5.0252e-03, -1.9099e-03,  1.1951e-03,\n",
       "                        2.1446e-03, -2.3171e-03,  5.1971e-03,  1.3342e-03, -6.3974e-03,\n",
       "                        7.7394e-04, -5.0417e-03, -4.6538e-04,  8.4626e-03, -4.4000e-04,\n",
       "                       -7.0619e-04,  4.7418e-03, -5.4846e-03, -5.1588e-03, -7.3695e-03,\n",
       "                       -9.4579e-03,  4.9077e-03, -5.9823e-03,  1.0702e-03, -2.1661e-03,\n",
       "                        1.0390e-03,  1.1983e-03, -4.2399e-03, -1.2942e-03, -7.8520e-03,\n",
       "                       -3.5293e-03, -1.0280e-02,  3.5102e-04,  3.8343e-03, -1.2780e-03,\n",
       "                        4.5618e-04,  3.8666e-03,  1.8226e-03,  4.2149e-03, -7.9116e-03,\n",
       "                       -6.3569e-03,  7.4834e-04,  4.8660e-04, -3.4787e-03, -3.4874e-03,\n",
       "                       -2.9350e-03,  6.0196e-03,  2.0707e-03,  6.1710e-03, -2.5195e-04,\n",
       "                        2.7551e-03, -3.0170e-03, -3.2106e-03, -5.5723e-05,  5.0233e-03,\n",
       "                       -5.5378e-03, -8.5195e-03,  2.5666e-03, -1.8356e-03,  1.2716e-03,\n",
       "                       -1.2945e-03,  1.9425e-03,  8.8292e-04,  2.0636e-03,  1.4934e-03,\n",
       "                       -1.9848e-03,  9.8496e-03, -2.1664e-03,  1.9293e-03, -3.8735e-03,\n",
       "                       -5.7664e-03,  3.7731e-03, -2.0194e-03,  5.2783e-03,  3.5625e-03,\n",
       "                       -4.3390e-03, -4.5637e-03,  6.6010e-03,  3.1173e-03,  4.0452e-03,\n",
       "                       -2.6583e-03,  4.5262e-03, -1.5825e-03, -4.2482e-03, -3.4520e-03,\n",
       "                        2.3763e-03,  3.6228e-03,  1.7307e-03,  1.0506e-03,  4.2683e-03,\n",
       "                       -3.5708e-04, -2.0222e-03, -1.5319e-03,  4.2033e-03, -6.7279e-03,\n",
       "                        1.4046e-03,  2.9070e-03,  3.6665e-03,  1.5358e-03,  2.2912e-03,\n",
       "                        1.5417e-03, -5.5028e-03,  1.9160e-03, -3.6478e-03, -3.0722e-03,\n",
       "                       -6.0849e-04,  4.6370e-03,  1.5033e-03,  7.6505e-03,  1.1843e-03,\n",
       "                       -2.6880e-03, -7.3885e-04, -1.9909e-03, -4.8474e-03,  7.0672e-03,\n",
       "                        7.6360e-03, -5.4759e-03, -6.0674e-03, -1.4287e-03,  1.6351e-03,\n",
       "                        4.7338e-03, -4.7588e-03, -5.5839e-03,  1.8682e-03, -1.0032e-03,\n",
       "                       -1.1349e-04,  6.5163e-03,  7.6160e-04,  6.0492e-03,  2.1817e-03,\n",
       "                        5.5140e-04, -5.6854e-03,  2.1677e-04,  1.8623e-03,  1.7347e-03,\n",
       "                       -3.2468e-03,  2.5972e-03, -1.4406e-03, -4.4453e-03, -6.4311e-03,\n",
       "                       -3.7272e-03,  2.8988e-03, -3.4194e-03,  8.8222e-04,  3.5037e-03,\n",
       "                        4.3227e-04, -1.8212e-03,  1.9136e-03, -3.1052e-03, -5.8780e-03,\n",
       "                       -9.3809e-04,  2.1546e-03, -5.0847e-03, -5.3777e-03, -3.2735e-03,\n",
       "                        1.7199e-04, -1.1658e-03,  3.6198e-03,  4.1820e-03,  1.1943e-04,\n",
       "                       -1.7642e-03,  4.1916e-03,  8.8105e-04, -6.2575e-03,  6.1010e-03,\n",
       "                       -4.3334e-04,  1.6691e-03,  8.9472e-06,  5.3347e-03,  4.1516e-03,\n",
       "                        4.4639e-03,  4.7324e-03, -6.6560e-04, -5.5783e-03,  1.1676e-03],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.0.edge_encoder.0.weight',\n",
       "               tensor([[ 0.0306, -0.0353,  0.0325,  ..., -0.0054, -0.0064, -0.0239],\n",
       "                       [ 0.0247,  0.0387,  0.0236,  ...,  0.0328,  0.0120, -0.0459],\n",
       "                       [ 0.0180, -0.0081, -0.0130,  ..., -0.0158,  0.0251,  0.0164],\n",
       "                       ...,\n",
       "                       [ 0.0070,  0.0437, -0.0125,  ..., -0.0002, -0.0051, -0.0569],\n",
       "                       [ 0.0213,  0.0714,  0.0441,  ..., -0.0479,  0.0109, -0.0085],\n",
       "                       [ 0.0176, -0.0074, -0.0351,  ..., -0.0420,  0.0276, -0.0018]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.0.edge_encoder.0.bias',\n",
       "               tensor([ 0.0077,  0.0119,  0.0017, -0.0190, -0.0046,  0.0056,  0.0168,  0.0094,\n",
       "                       -0.0051,  0.0039, -0.0029,  0.0186, -0.0180,  0.0189,  0.0191, -0.0094,\n",
       "                        0.0084,  0.0184, -0.0068, -0.0066, -0.0126, -0.0144,  0.0322,  0.0054,\n",
       "                        0.0056, -0.0084,  0.0076,  0.0117, -0.0092, -0.0210,  0.0302,  0.0111,\n",
       "                        0.0049,  0.0133,  0.0009,  0.0033,  0.0078, -0.0005,  0.0011,  0.0380,\n",
       "                        0.0042, -0.0085, -0.0131, -0.0191, -0.0132, -0.0132,  0.0060,  0.0126,\n",
       "                        0.0204, -0.0218, -0.0039,  0.0289,  0.0030,  0.0034,  0.0042,  0.0069,\n",
       "                        0.0276,  0.0014,  0.0052, -0.0010,  0.0165, -0.0045, -0.0037,  0.0045,\n",
       "                        0.0175, -0.0177, -0.0008,  0.0173, -0.0091,  0.0122, -0.0022, -0.0185,\n",
       "                       -0.0071, -0.0143,  0.0194,  0.0052,  0.0028,  0.0003, -0.0044,  0.0021,\n",
       "                       -0.0239, -0.0257,  0.0002,  0.0104,  0.0085,  0.0029,  0.0085,  0.0186,\n",
       "                        0.0136, -0.0184,  0.0170,  0.0219,  0.0114,  0.0373, -0.0013, -0.0081,\n",
       "                        0.0079,  0.0001,  0.0129, -0.0018,  0.0132,  0.0188,  0.0141, -0.0070,\n",
       "                        0.0138,  0.0063, -0.0268, -0.0065,  0.0113,  0.0060,  0.0369,  0.0077,\n",
       "                        0.0054, -0.0095, -0.0127, -0.0155, -0.0099, -0.0243, -0.0093,  0.0114,\n",
       "                       -0.0292, -0.0092, -0.0165,  0.0360, -0.0180,  0.0009, -0.0012, -0.0136,\n",
       "                       -0.0028, -0.0299, -0.0139,  0.0060, -0.0042,  0.0075, -0.0028,  0.0032,\n",
       "                        0.0168, -0.0089,  0.0203,  0.0222,  0.0033, -0.0214,  0.0055, -0.0004,\n",
       "                       -0.0070, -0.0103,  0.0122,  0.0016,  0.0049,  0.0059,  0.0101, -0.0175,\n",
       "                       -0.0075,  0.0347, -0.0166,  0.0217,  0.0009, -0.0263,  0.0026,  0.0296,\n",
       "                        0.0109,  0.0100, -0.0139, -0.0151,  0.0139,  0.0117,  0.0224,  0.0200,\n",
       "                        0.0159,  0.0146, -0.0090,  0.0056,  0.0198, -0.0114,  0.0122, -0.0099,\n",
       "                       -0.0116,  0.0004, -0.0143, -0.0011,  0.0056,  0.0021,  0.0154, -0.0226,\n",
       "                       -0.0033, -0.0069, -0.0072, -0.0033, -0.0062, -0.0068, -0.0164,  0.0153,\n",
       "                       -0.0333,  0.0075, -0.0050, -0.0042, -0.0204,  0.0111, -0.0367,  0.0139],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.0.edge_encoder.1.weight',\n",
       "               tensor([0.9628, 0.9829, 0.9672, 0.9673, 0.9706, 0.9835, 0.9779, 0.9585, 0.9801,\n",
       "                       1.0104, 0.9749, 0.9749, 0.9704, 0.9653, 0.9617, 0.9588, 0.9810, 0.9747,\n",
       "                       0.9706, 0.9653, 0.9548, 0.9736, 0.9918, 0.9715, 0.9768, 0.9686, 0.9768,\n",
       "                       0.9644, 0.9705, 0.9647, 0.9775, 0.9654, 0.9791, 0.9719, 0.9689, 1.0024,\n",
       "                       0.9714, 0.9612, 0.9602, 0.9835, 0.9716, 0.9771, 0.9913, 0.9704, 0.9972,\n",
       "                       0.9774, 0.9673, 0.9556, 0.9649, 0.9712, 0.9714, 0.9532, 0.9586, 0.9630,\n",
       "                       0.9654, 0.9569, 0.9866, 0.9909, 0.9710, 0.9789, 0.9821, 0.9766, 0.9629,\n",
       "                       1.0112, 0.9736, 1.0307, 0.9648, 0.9848, 0.9644, 0.9779, 0.9688, 0.9556,\n",
       "                       0.9911, 0.9716, 0.9692, 0.9976, 0.9801, 0.9737, 0.9750, 1.0032, 0.9712,\n",
       "                       0.9831, 0.9793, 1.0119, 0.9947, 0.9525, 0.9689, 1.0086, 0.9671, 0.9862,\n",
       "                       0.9723, 0.9898, 0.9515, 0.9780, 0.9625, 0.9707, 0.9851, 0.9711, 0.9946,\n",
       "                       0.9929, 1.0127, 0.9705, 0.9535, 0.9593, 0.9769, 0.9911, 0.9627, 0.9748,\n",
       "                       0.9724, 0.9391, 0.9803, 0.9876, 0.9843, 0.9748, 0.9582, 0.9636, 0.9737,\n",
       "                       0.9705, 0.9908, 0.9860, 0.9873, 0.9901, 0.9624, 0.9739, 0.9752, 0.9613,\n",
       "                       0.9775, 0.9644, 0.9877, 0.9880, 0.9751, 0.9752, 0.9599, 0.9629, 0.9751,\n",
       "                       0.9859, 0.9705, 0.9769, 0.9848, 0.9831, 0.9677, 1.0146, 0.9704, 0.9786,\n",
       "                       0.9771, 0.9810, 0.9668, 0.9568, 0.9419, 0.9776, 0.9674, 0.9866, 0.9767,\n",
       "                       0.9543, 0.9812, 1.0107, 0.9792, 0.9727, 0.9707, 0.9655, 0.9763, 0.9820,\n",
       "                       0.9982, 0.9833, 0.9660, 1.0028, 0.9630, 0.9713, 1.0131, 0.9784, 0.9664,\n",
       "                       0.9688, 0.9602, 0.9605, 0.9668, 0.9759, 0.9633, 0.9736, 0.9751, 0.9571,\n",
       "                       0.9551, 0.9673, 0.9850, 0.9753, 0.9827, 0.9796, 0.9681, 0.9709, 0.9784,\n",
       "                       0.9611, 0.9603, 0.9895, 0.9809, 0.9890, 0.9777, 0.9484, 0.9913, 0.9686,\n",
       "                       1.0060, 0.9723], device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.0.edge_encoder.1.bias',\n",
       "               tensor([-2.5693e-02, -9.7445e-03, -1.3280e-02, -1.4876e-02, -1.3010e-02,\n",
       "                       -2.8902e-02, -1.5408e-02, -1.3348e-02, -7.5672e-03,  1.6497e-03,\n",
       "                       -7.8495e-03, -9.1716e-03, -2.0961e-02, -2.2757e-02, -2.0028e-02,\n",
       "                       -1.7987e-02, -7.9770e-03, -1.8736e-03, -5.3145e-03, -3.8504e-03,\n",
       "                       -1.5113e-02, -2.7974e-02,  2.6333e-03, -8.1461e-03, -1.9291e-02,\n",
       "                       -1.5892e-03,  1.6622e-04, -1.8932e-02, -1.3259e-02, -2.7374e-02,\n",
       "                       -1.4522e-02, -1.6898e-02, -8.0646e-03, -1.0664e-02, -1.0739e-02,\n",
       "                       -1.7976e-03, -1.9121e-02, -1.7618e-02, -1.1595e-02, -8.5707e-03,\n",
       "                       -1.0648e-02, -1.1552e-02, -1.4868e-02, -9.6961e-03, -2.4517e-02,\n",
       "                       -7.4088e-03,  7.0666e-03, -1.7505e-02, -1.4665e-02, -2.4669e-02,\n",
       "                       -2.5899e-02, -3.7980e-02, -2.2516e-02, -3.0423e-03, -9.7302e-03,\n",
       "                       -2.5835e-02, -2.2611e-03, -4.0520e-03, -6.8373e-03, -1.9277e-02,\n",
       "                       -8.0628e-03, -1.8217e-02, -1.6750e-02, -1.5095e-02, -1.4788e-03,\n",
       "                       -3.7971e-02, -1.9556e-02,  1.5557e-04, -7.2736e-03, -3.9847e-03,\n",
       "                       -1.2300e-02, -1.9903e-02, -1.9171e-02, -9.9416e-03, -5.3805e-03,\n",
       "                        1.5913e-03, -7.6342e-03, -3.3007e-03, -6.2690e-03, -1.4096e-05,\n",
       "                       -1.5686e-02, -6.8913e-03, -1.7321e-02, -2.5634e-02, -1.4783e-02,\n",
       "                       -2.4108e-02, -1.3706e-02, -2.0894e-02, -2.0094e-02, -6.5898e-03,\n",
       "                       -1.2185e-02, -6.1023e-03, -2.7504e-02, -2.4717e-02, -2.5939e-02,\n",
       "                       -1.5674e-02, -5.1389e-03, -7.2659e-03,  4.9414e-03, -1.5022e-03,\n",
       "                       -1.3755e-02, -2.0142e-02, -2.5539e-02, -3.3021e-02, -1.7456e-02,\n",
       "                       -7.0987e-03, -1.8066e-02, -7.1374e-03, -9.0562e-03, -4.0189e-02,\n",
       "                       -4.1441e-03, -9.2944e-03, -8.8290e-03, -1.3431e-02, -1.1504e-02,\n",
       "                       -2.5691e-02, -1.5559e-02, -2.4027e-02, -1.8737e-02, -6.9398e-03,\n",
       "                       -1.3982e-02, -9.3979e-03, -2.2429e-02, -1.6925e-02, -1.1936e-02,\n",
       "                       -2.2714e-02, -8.0626e-03, -2.0102e-02, -1.1027e-02, -1.1894e-02,\n",
       "                       -2.9027e-02, -1.0246e-02, -2.0020e-02, -2.4571e-02,  1.9411e-03,\n",
       "                       -2.1970e-02, -1.8667e-02, -1.4658e-02, -3.9352e-03, -1.8957e-02,\n",
       "                       -9.4686e-03, -2.8255e-02,  5.2848e-04,  7.7191e-03, -1.7395e-02,\n",
       "                       -1.0582e-02, -1.7854e-02, -2.6494e-02, -3.3694e-02, -2.2807e-02,\n",
       "                       -2.3661e-02, -5.3341e-03, -7.3770e-03, -3.4522e-02, -2.7705e-02,\n",
       "                       -7.6568e-03, -5.1986e-03,  6.7720e-03, -2.3240e-02, -3.5141e-02,\n",
       "                       -1.3055e-02, -8.6289e-03, -2.5888e-02, -1.1771e-02, -1.2512e-02,\n",
       "                       -1.8411e-02, -3.3645e-02, -7.4316e-03, -1.2644e-02, -7.5547e-03,\n",
       "                       -1.6641e-02, -1.9724e-02, -2.6223e-02, -1.5339e-02, -6.3751e-03,\n",
       "                       -5.5682e-03, -2.3769e-02, -8.3162e-03, -7.2813e-03, -3.8014e-02,\n",
       "                       -2.6523e-02, -2.3696e-02, -9.4407e-03, -1.6965e-02, -1.8803e-02,\n",
       "                        4.4039e-03, -1.6914e-02, -1.6613e-02,  7.9222e-03, -2.1573e-02,\n",
       "                       -5.3399e-03, -1.7694e-02, -4.4106e-03, -3.1973e-03, -3.3638e-03,\n",
       "                       -3.0254e-02,  3.6135e-03, -1.7349e-02,  2.9815e-03, -8.8753e-03],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.0.edge_encoder.1.running_mean',\n",
       "               tensor([ 2.7008e-02,  1.6912e-03,  1.5797e-02, -6.7778e-02,  2.0418e-02,\n",
       "                       -1.1173e-02,  1.5179e-02,  2.4307e-02,  1.2653e-02,  4.6869e-03,\n",
       "                       -1.0762e-02, -1.9674e-03, -1.3291e-02,  3.0813e-02, -1.3610e-03,\n",
       "                        4.5526e-03,  2.5402e-02,  2.0468e-02,  1.6868e-02,  1.5769e-02,\n",
       "                       -3.7985e-03, -2.9739e-02,  3.6873e-02, -1.5693e-03, -2.0923e-02,\n",
       "                        4.5054e-02,  3.2104e-02, -3.1810e-03,  5.9307e-03, -2.4748e-03,\n",
       "                        2.8697e-02,  2.8321e-03,  4.0958e-02,  2.8253e-02,  3.6128e-02,\n",
       "                       -1.6234e-02,  1.5718e-02,  2.1499e-02,  3.2818e-02,  4.5780e-02,\n",
       "                        1.8265e-02, -2.2358e-02,  1.0330e-02, -8.1752e-03, -7.3849e-02,\n",
       "                       -7.7433e-02, -9.5062e-03,  5.6934e-02,  2.9798e-02, -5.6704e-02,\n",
       "                       -2.8998e-04,  3.8911e-02,  7.1862e-02,  2.8319e-02, -1.3835e-03,\n",
       "                        2.4380e-02,  4.7917e-02, -7.5812e-03,  4.3195e-02, -8.7772e-03,\n",
       "                        3.0336e-02, -2.1767e-02, -2.0313e-02, -5.7155e-02,  2.2238e-02,\n",
       "                       -1.7876e-02,  7.2475e-03,  5.9072e-02,  1.7254e-02,  3.5640e-02,\n",
       "                       -5.3690e-02,  3.1887e-02, -6.1408e-02,  1.1748e-02, -2.8399e-02,\n",
       "                        3.6311e-02,  3.8973e-02,  6.4906e-02,  7.8385e-03, -2.0935e-02,\n",
       "                       -5.8416e-02, -2.0047e-02, -3.1496e-02,  2.9189e-02, -3.4504e-02,\n",
       "                       -2.7514e-02,  6.8505e-02,  2.8062e-03,  1.8849e-05, -1.3774e-02,\n",
       "                        9.2343e-03,  3.7521e-02,  4.5121e-02,  1.4074e-02, -1.8121e-04,\n",
       "                       -4.0558e-02, -3.7644e-03,  1.6923e-02,  2.7104e-02, -1.5634e-02,\n",
       "                       -4.1377e-03,  9.3574e-03,  1.9628e-02,  5.6155e-02,  5.2343e-02,\n",
       "                        8.2967e-03, -3.7830e-03, -4.8709e-03, -8.8138e-03,  5.4959e-02,\n",
       "                        9.5033e-02, -8.7470e-03, -2.1711e-03, -2.7213e-02,  2.7870e-02,\n",
       "                       -6.4279e-02, -1.5909e-02, -4.3667e-02, -1.5132e-02, -9.5939e-03,\n",
       "                       -1.8963e-02, -6.7713e-03, -5.5545e-02, -1.0497e-02, -3.9040e-02,\n",
       "                       -4.8672e-03,  1.1762e-02, -1.5282e-02, -4.3349e-02, -5.3518e-02,\n",
       "                        4.6776e-03, -4.4651e-02, -4.5448e-02, -1.2307e-02,  1.7775e-02,\n",
       "                       -4.1911e-03,  2.1014e-02, -4.3004e-03,  2.7901e-02,  1.0977e-02,\n",
       "                       -7.3112e-03, -3.7840e-02, -1.7166e-03,  1.3762e-02, -2.5244e-02,\n",
       "                        1.1566e-02,  7.3994e-02, -4.3874e-03,  4.3512e-02, -4.0878e-02,\n",
       "                        1.8922e-03, -1.0121e-02, -2.9110e-02,  2.4583e-02, -4.8153e-02,\n",
       "                        2.5973e-02, -2.9922e-03, -2.0870e-02, -2.2877e-02, -1.4993e-03,\n",
       "                       -5.9943e-03, -7.2241e-03, -2.0146e-02,  1.2459e-02, -3.8290e-03,\n",
       "                       -2.0011e-02,  3.9809e-02,  1.3255e-02, -4.2352e-04,  1.7046e-02,\n",
       "                       -6.5159e-03,  1.2209e-02,  6.6373e-02, -1.1389e-02,  5.5789e-02,\n",
       "                        1.8531e-02, -1.1453e-02,  2.1218e-02,  1.8626e-02,  1.3585e-02,\n",
       "                       -3.0026e-02,  1.2386e-02, -9.9208e-03, -2.6795e-04, -8.1980e-03,\n",
       "                       -1.3025e-02, -1.7465e-02,  3.8352e-04, -2.6250e-02, -3.8193e-02,\n",
       "                        1.8636e-02, -7.6045e-03, -3.9300e-02,  1.3399e-03,  1.3233e-02,\n",
       "                        1.9639e-02, -1.1317e-02, -1.9422e-02, -3.2577e-02,  5.8234e-02],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.0.edge_encoder.1.running_var',\n",
       "               tensor([0.0007, 0.0011, 0.0017, 0.0010, 0.0004, 0.0005, 0.0011, 0.0008, 0.0008,\n",
       "                       0.0006, 0.0011, 0.0012, 0.0004, 0.0011, 0.0017, 0.0008, 0.0009, 0.0008,\n",
       "                       0.0008, 0.0017, 0.0010, 0.0005, 0.0005, 0.0005, 0.0007, 0.0009, 0.0004,\n",
       "                       0.0016, 0.0005, 0.0014, 0.0013, 0.0005, 0.0005, 0.0010, 0.0009, 0.0005,\n",
       "                       0.0009, 0.0014, 0.0012, 0.0007, 0.0004, 0.0008, 0.0005, 0.0008, 0.0010,\n",
       "                       0.0010, 0.0010, 0.0012, 0.0016, 0.0011, 0.0004, 0.0004, 0.0009, 0.0014,\n",
       "                       0.0009, 0.0013, 0.0004, 0.0005, 0.0009, 0.0005, 0.0003, 0.0009, 0.0005,\n",
       "                       0.0007, 0.0009, 0.0004, 0.0008, 0.0009, 0.0006, 0.0004, 0.0013, 0.0007,\n",
       "                       0.0007, 0.0006, 0.0007, 0.0004, 0.0007, 0.0007, 0.0007, 0.0003, 0.0020,\n",
       "                       0.0011, 0.0006, 0.0004, 0.0010, 0.0019, 0.0012, 0.0007, 0.0005, 0.0004,\n",
       "                       0.0005, 0.0009, 0.0012, 0.0007, 0.0007, 0.0014, 0.0015, 0.0009, 0.0009,\n",
       "                       0.0006, 0.0004, 0.0006, 0.0008, 0.0008, 0.0012, 0.0005, 0.0013, 0.0009,\n",
       "                       0.0006, 0.0015, 0.0007, 0.0006, 0.0007, 0.0010, 0.0010, 0.0010, 0.0005,\n",
       "                       0.0006, 0.0006, 0.0005, 0.0003, 0.0008, 0.0007, 0.0010, 0.0008, 0.0009,\n",
       "                       0.0008, 0.0012, 0.0011, 0.0014, 0.0014, 0.0012, 0.0019, 0.0012, 0.0016,\n",
       "                       0.0008, 0.0008, 0.0006, 0.0006, 0.0012, 0.0004, 0.0006, 0.0020, 0.0009,\n",
       "                       0.0004, 0.0004, 0.0010, 0.0010, 0.0006, 0.0004, 0.0008, 0.0006, 0.0010,\n",
       "                       0.0016, 0.0006, 0.0004, 0.0010, 0.0015, 0.0007, 0.0009, 0.0008, 0.0008,\n",
       "                       0.0005, 0.0006, 0.0010, 0.0003, 0.0010, 0.0007, 0.0005, 0.0007, 0.0007,\n",
       "                       0.0008, 0.0009, 0.0022, 0.0009, 0.0007, 0.0006, 0.0006, 0.0006, 0.0014,\n",
       "                       0.0004, 0.0004, 0.0003, 0.0004, 0.0008, 0.0010, 0.0010, 0.0010, 0.0016,\n",
       "                       0.0016, 0.0008, 0.0008, 0.0017, 0.0004, 0.0013, 0.0004, 0.0015, 0.0007,\n",
       "                       0.0011, 0.0009], device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.0.edge_encoder.1.num_batches_tracked',\n",
       "               tensor(318750, device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.0.edge_encoder.3.weight',\n",
       "               tensor([[-0.0193, -0.0094, -0.0241,  ...,  0.0122, -0.0301, -0.0028],\n",
       "                       [ 0.0069,  0.0188,  0.0111,  ..., -0.0008, -0.0141,  0.0301],\n",
       "                       [ 0.0371, -0.0236, -0.0005,  ..., -0.0178,  0.0145,  0.0044],\n",
       "                       ...,\n",
       "                       [ 0.0266,  0.0113,  0.0204,  ..., -0.0058,  0.0168, -0.0279],\n",
       "                       [ 0.0263, -0.0120,  0.0145,  ..., -0.0088,  0.0285, -0.0355],\n",
       "                       [ 0.0217,  0.0041,  0.0519,  ...,  0.0308, -0.0709, -0.0156]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.0.edge_encoder.3.bias',\n",
       "               tensor([-2.3653e-03, -5.7033e-03,  2.7150e-03,  1.7915e-03, -1.3082e-03,\n",
       "                       -3.1844e-04,  8.8534e-04, -5.2766e-03,  1.3499e-03,  4.7690e-03,\n",
       "                       -4.6336e-03,  1.4850e-03, -3.2236e-03,  3.7453e-03, -8.5289e-03,\n",
       "                        7.5043e-03,  5.8532e-03,  2.3962e-04, -5.7625e-04,  5.2903e-04,\n",
       "                       -1.7449e-03,  5.2435e-03,  2.9055e-03, -4.1971e-03, -5.6767e-03,\n",
       "                       -4.0691e-03, -1.4285e-03,  5.0252e-03, -1.9099e-03,  1.1951e-03,\n",
       "                        2.1446e-03, -2.3171e-03,  5.1971e-03,  1.3342e-03, -6.3974e-03,\n",
       "                        7.7394e-04, -5.0417e-03, -4.6538e-04,  8.4626e-03, -4.4000e-04,\n",
       "                       -7.0619e-04,  4.7418e-03, -5.4846e-03, -5.1588e-03, -7.3695e-03,\n",
       "                       -9.4579e-03,  4.9077e-03, -5.9823e-03,  1.0702e-03, -2.1661e-03,\n",
       "                        1.0390e-03,  1.1983e-03, -4.2399e-03, -1.2942e-03, -7.8520e-03,\n",
       "                       -3.5293e-03, -1.0280e-02,  3.5102e-04,  3.8343e-03, -1.2780e-03,\n",
       "                        4.5618e-04,  3.8666e-03,  1.8226e-03,  4.2149e-03, -7.9116e-03,\n",
       "                       -6.3569e-03,  7.4834e-04,  4.8660e-04, -3.4787e-03, -3.4874e-03,\n",
       "                       -2.9350e-03,  6.0196e-03,  2.0707e-03,  6.1710e-03, -2.5195e-04,\n",
       "                        2.7551e-03, -3.0170e-03, -3.2106e-03, -5.5723e-05,  5.0233e-03,\n",
       "                       -5.5378e-03, -8.5195e-03,  2.5666e-03, -1.8356e-03,  1.2716e-03,\n",
       "                       -1.2945e-03,  1.9425e-03,  8.8292e-04,  2.0636e-03,  1.4934e-03,\n",
       "                       -1.9848e-03,  9.8496e-03, -2.1664e-03,  1.9293e-03, -3.8735e-03,\n",
       "                       -5.7664e-03,  3.7731e-03, -2.0194e-03,  5.2783e-03,  3.5625e-03,\n",
       "                       -4.3390e-03, -4.5637e-03,  6.6010e-03,  3.1173e-03,  4.0452e-03,\n",
       "                       -2.6583e-03,  4.5262e-03, -1.5825e-03, -4.2482e-03, -3.4520e-03,\n",
       "                        2.3763e-03,  3.6228e-03,  1.7307e-03,  1.0506e-03,  4.2683e-03,\n",
       "                       -3.5708e-04, -2.0222e-03, -1.5319e-03,  4.2033e-03, -6.7279e-03,\n",
       "                        1.4046e-03,  2.9070e-03,  3.6665e-03,  1.5358e-03,  2.2912e-03,\n",
       "                        1.5417e-03, -5.5028e-03,  1.9160e-03, -3.6478e-03, -3.0722e-03,\n",
       "                       -6.0849e-04,  4.6370e-03,  1.5033e-03,  7.6505e-03,  1.1843e-03,\n",
       "                       -2.6880e-03, -7.3885e-04, -1.9909e-03, -4.8474e-03,  7.0672e-03,\n",
       "                        7.6360e-03, -5.4759e-03, -6.0674e-03, -1.4287e-03,  1.6351e-03,\n",
       "                        4.7338e-03, -4.7588e-03, -5.5839e-03,  1.8682e-03, -1.0032e-03,\n",
       "                       -1.1349e-04,  6.5163e-03,  7.6160e-04,  6.0492e-03,  2.1817e-03,\n",
       "                        5.5140e-04, -5.6854e-03,  2.1677e-04,  1.8623e-03,  1.7347e-03,\n",
       "                       -3.2468e-03,  2.5972e-03, -1.4406e-03, -4.4453e-03, -6.4311e-03,\n",
       "                       -3.7272e-03,  2.8988e-03, -3.4194e-03,  8.8222e-04,  3.5037e-03,\n",
       "                        4.3227e-04, -1.8212e-03,  1.9136e-03, -3.1052e-03, -5.8780e-03,\n",
       "                       -9.3809e-04,  2.1546e-03, -5.0847e-03, -5.3777e-03, -3.2735e-03,\n",
       "                        1.7199e-04, -1.1658e-03,  3.6198e-03,  4.1820e-03,  1.1943e-04,\n",
       "                       -1.7642e-03,  4.1916e-03,  8.8105e-04, -6.2575e-03,  6.1010e-03,\n",
       "                       -4.3334e-04,  1.6691e-03,  8.9472e-06,  5.3347e-03,  4.1516e-03,\n",
       "                        4.4639e-03,  4.7324e-03, -6.6560e-04, -5.5783e-03,  1.1676e-03],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.0.linear_key.weight',\n",
       "               tensor([[-0.0106, -0.0202,  0.0185,  ...,  0.0253,  0.0045,  0.0275],\n",
       "                       [-0.0210,  0.0047, -0.0176,  ..., -0.0228, -0.0010,  0.0040],\n",
       "                       [-0.0289, -0.0460,  0.0422,  ..., -0.0065,  0.0403, -0.0174],\n",
       "                       ...,\n",
       "                       [ 0.0261, -0.0126,  0.0230,  ..., -0.0217, -0.0105, -0.0238],\n",
       "                       [ 0.0208, -0.0345,  0.0073,  ...,  0.0367,  0.0091, -0.0063],\n",
       "                       [ 0.0282, -0.0078,  0.0024,  ...,  0.0098,  0.0292, -0.0101]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.0.linear_key.bias',\n",
       "               tensor([ 0.0062, -0.0041, -0.0065, -0.0044,  0.0086, -0.0033, -0.0039,  0.0073,\n",
       "                        0.0069, -0.0070, -0.0016, -0.0057,  0.0053, -0.0058,  0.0021,  0.0104,\n",
       "                       -0.0075,  0.0005, -0.0076, -0.0022, -0.0096, -0.0102,  0.0071, -0.0090,\n",
       "                        0.0084,  0.0051,  0.0006,  0.0091, -0.0088, -0.0021,  0.0104, -0.0083,\n",
       "                        0.0028,  0.0077,  0.0064,  0.0041, -0.0031,  0.0082,  0.0040,  0.0100,\n",
       "                       -0.0019, -0.0126, -0.0043, -0.0051,  0.0089,  0.0056, -0.0024,  0.0069,\n",
       "                       -0.0074, -0.0072, -0.0112, -0.0041,  0.0057, -0.0042, -0.0093,  0.0038,\n",
       "                       -0.0053,  0.0095,  0.0034, -0.0016,  0.0031,  0.0016,  0.0073, -0.0068,\n",
       "                        0.0007, -0.0001, -0.0089, -0.0075, -0.0041,  0.0040, -0.0031,  0.0062,\n",
       "                        0.0051, -0.0042, -0.0060, -0.0027, -0.0070,  0.0045,  0.0074, -0.0039,\n",
       "                       -0.0030, -0.0042, -0.0005,  0.0041, -0.0031,  0.0040, -0.0049, -0.0022,\n",
       "                        0.0077, -0.0033,  0.0015, -0.0066, -0.0086,  0.0092, -0.0035,  0.0047,\n",
       "                        0.0052, -0.0002, -0.0043,  0.0080,  0.0057,  0.0029, -0.0151,  0.0078,\n",
       "                        0.0008,  0.0150,  0.0152, -0.0022,  0.0164, -0.0047, -0.0060, -0.0075,\n",
       "                        0.0022, -0.0127, -0.0057,  0.0104,  0.0111, -0.0102,  0.0073,  0.0035,\n",
       "                        0.0109,  0.0078,  0.0123,  0.0006,  0.0092,  0.0026, -0.0080,  0.0109,\n",
       "                        0.0055, -0.0064, -0.0010, -0.0057,  0.0070,  0.0085, -0.0023, -0.0092,\n",
       "                        0.0038,  0.0098,  0.0015, -0.0062,  0.0032, -0.0029,  0.0014, -0.0069,\n",
       "                        0.0118, -0.0097,  0.0092, -0.0093, -0.0157,  0.0103, -0.0070,  0.0070,\n",
       "                        0.0085,  0.0110, -0.0085,  0.0006,  0.0075, -0.0085,  0.0102,  0.0045,\n",
       "                        0.0090,  0.0062, -0.0001, -0.0071,  0.0108, -0.0087,  0.0081,  0.0065,\n",
       "                       -0.0109,  0.0016, -0.0082,  0.0088, -0.0100,  0.0067,  0.0065,  0.0116,\n",
       "                        0.0063, -0.0071, -0.0094,  0.0094, -0.0045,  0.0038,  0.0016, -0.0075,\n",
       "                       -0.0055, -0.0074,  0.0080,  0.0098,  0.0069, -0.0078,  0.0054,  0.0097,\n",
       "                       -0.0071,  0.0076, -0.0039, -0.0060, -0.0042,  0.0120, -0.0051, -0.0082],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.0.linear_msg.weight',\n",
       "               tensor([[-0.0228, -0.0136,  0.0378,  ...,  0.0103,  0.0072,  0.0245],\n",
       "                       [ 0.0141,  0.0123,  0.0028,  ...,  0.0038, -0.0335,  0.0066],\n",
       "                       [-0.0132,  0.0015, -0.0101,  ...,  0.0129, -0.0269, -0.0066],\n",
       "                       ...,\n",
       "                       [ 0.0091, -0.0016,  0.0010,  ..., -0.0147,  0.0196, -0.0031],\n",
       "                       [-0.0192, -0.0216,  0.0086,  ..., -0.0150, -0.0088, -0.0219],\n",
       "                       [-0.0175,  0.0138,  0.0052,  ...,  0.0363,  0.0165,  0.0085]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.0.linear_msg.bias',\n",
       "               tensor([-5.3866e-03,  3.0472e-03, -1.0344e-03, -5.3162e-04,  4.4062e-03,\n",
       "                       -5.0716e-04, -1.9276e-03, -1.0177e-03,  1.3567e-04, -5.5970e-03,\n",
       "                       -2.7851e-03, -3.2132e-03, -3.1636e-03, -4.6914e-03,  4.6552e-03,\n",
       "                        3.0255e-03, -1.1477e-04,  6.7326e-03,  2.1525e-03,  2.0842e-03,\n",
       "                       -1.4159e-03, -1.8816e-03, -2.7430e-03, -2.0253e-03, -3.3133e-03,\n",
       "                        3.3950e-03, -6.2218e-03, -2.5583e-03,  2.9504e-04,  1.7181e-03,\n",
       "                        3.4868e-03,  3.0991e-03, -2.7674e-03,  2.9744e-03, -1.8529e-03,\n",
       "                       -9.6815e-04,  2.7556e-03, -2.0071e-03, -4.9960e-03,  1.4318e-03,\n",
       "                        3.5195e-03,  8.9290e-04, -9.6203e-04, -8.4096e-04,  1.8201e-03,\n",
       "                        6.7590e-04, -1.2261e-03,  4.2595e-03, -3.2022e-03, -5.6928e-03,\n",
       "                        2.2211e-03,  3.8597e-03,  4.9066e-04, -5.1769e-03, -6.4566e-03,\n",
       "                        1.7851e-04,  2.2519e-03, -1.0342e-03,  2.2334e-03, -1.1121e-03,\n",
       "                        6.2233e-03,  1.2440e-03, -6.4151e-03, -5.2799e-03, -4.2084e-03,\n",
       "                        1.6557e-03, -6.4561e-03, -3.9376e-03, -4.7575e-03, -1.3776e-03,\n",
       "                       -3.5366e-04,  3.2539e-03, -1.0009e-03,  6.7041e-03,  1.5076e-03,\n",
       "                        5.7761e-03,  3.6461e-03,  1.0494e-03,  4.5584e-03, -3.4759e-03,\n",
       "                       -1.1976e-03,  2.3873e-03,  1.8791e-03,  1.5094e-03,  1.4184e-03,\n",
       "                        2.5880e-03, -7.2604e-03, -1.0552e-03, -2.6439e-05, -4.9412e-03,\n",
       "                        8.3266e-04, -4.9513e-04, -1.0583e-03,  3.8993e-03, -1.7337e-03,\n",
       "                       -3.7942e-04,  4.3113e-03, -2.6372e-03, -1.3806e-03, -3.9547e-03,\n",
       "                        2.8319e-03, -2.2481e-03, -1.8163e-03, -1.4476e-03, -1.2262e-03,\n",
       "                       -3.8608e-03, -1.7584e-05,  1.3355e-03,  8.8289e-04,  7.9991e-03,\n",
       "                       -4.4043e-03, -5.5194e-04,  6.6556e-04, -6.3916e-03, -4.4201e-03,\n",
       "                       -1.5257e-03,  3.2736e-03,  1.9878e-03,  8.7840e-04, -4.3335e-04,\n",
       "                       -2.3059e-03, -4.2504e-03,  4.0734e-03,  2.5762e-03, -4.3900e-03,\n",
       "                       -2.6048e-03,  1.8696e-04,  4.6470e-03, -4.5471e-03, -3.7266e-03,\n",
       "                        3.9076e-03, -4.3486e-03,  4.3420e-03, -1.6889e-03,  6.5492e-04,\n",
       "                       -2.3457e-03, -2.9297e-03,  5.5363e-03, -7.1009e-03, -7.8910e-05,\n",
       "                       -4.0479e-03,  3.1595e-03, -1.1460e-03,  1.8486e-04, -1.7223e-03,\n",
       "                       -6.3869e-04, -1.6900e-05,  7.3376e-04, -3.6445e-03,  1.4384e-04,\n",
       "                        2.0924e-03, -3.5593e-03, -7.7534e-04,  2.3928e-03, -4.3426e-03,\n",
       "                        1.3877e-03, -7.9062e-03, -5.3592e-04,  4.3111e-04, -1.5242e-03,\n",
       "                       -7.4259e-04,  9.6477e-04, -4.3018e-04,  1.4458e-03,  3.8325e-03,\n",
       "                       -4.8453e-03,  4.3459e-04, -1.8165e-03, -2.8510e-03, -1.9727e-03,\n",
       "                       -4.6783e-03, -9.2575e-04,  2.4676e-03,  2.8578e-03, -1.8531e-03,\n",
       "                       -1.6163e-03,  6.8544e-03, -5.0037e-03,  9.3849e-04,  1.0190e-04,\n",
       "                       -3.6624e-03, -2.2480e-03,  7.4023e-03,  3.3938e-03, -4.4973e-03,\n",
       "                       -3.8005e-03,  3.5912e-04,  1.0327e-03, -5.3150e-05,  2.3432e-04,\n",
       "                       -6.6851e-04, -4.5942e-05, -5.3540e-03,  9.8767e-04,  3.0459e-03,\n",
       "                       -2.0120e-03,  3.3563e-04, -7.3079e-03, -2.6687e-04, -2.6506e-03],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.0.linear_query.weight',\n",
       "               tensor([[-0.0516,  0.0422, -0.0176,  ...,  0.0181, -0.0072, -0.0207],\n",
       "                       [ 0.0044,  0.0371, -0.0092,  ..., -0.0263, -0.0037, -0.0234],\n",
       "                       [ 0.0194, -0.0003, -0.0198,  ..., -0.0082, -0.0765, -0.0691],\n",
       "                       ...,\n",
       "                       [-0.0085,  0.0230, -0.0192,  ...,  0.0032,  0.0584,  0.0417],\n",
       "                       [-0.0150,  0.0114, -0.0310,  ..., -0.0136, -0.0547,  0.0063],\n",
       "                       [-0.0165, -0.0309,  0.0039,  ..., -0.0168, -0.0604,  0.0306]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.0.linear_query.bias',\n",
       "               tensor([-1.3048e-03,  1.3143e-02, -3.3463e-02, -7.2562e-04,  1.5190e-02,\n",
       "                       -1.3565e-02,  1.5085e-02,  3.4892e-02,  6.7004e-03, -1.6388e-03,\n",
       "                        2.3456e-02, -1.0326e-02,  1.5233e-02,  1.3043e-02, -3.1203e-03,\n",
       "                        9.0739e-03, -1.0168e-02,  1.4681e-02,  1.0482e-02,  2.6054e-02,\n",
       "                       -1.1218e-02,  2.6627e-03,  1.2981e-02, -2.8519e-02,  2.7826e-02,\n",
       "                       -8.0169e-03,  1.3386e-02,  2.3689e-02, -2.4517e-02, -3.0640e-02,\n",
       "                        4.4019e-03, -3.3055e-02,  1.7341e-02,  1.0518e-02,  4.5549e-03,\n",
       "                       -1.4672e-02, -1.8012e-02,  4.2676e-03, -1.6038e-03, -4.9228e-04,\n",
       "                        2.6198e-02, -1.2262e-02, -1.5125e-02, -2.7033e-02, -1.2969e-02,\n",
       "                       -1.4183e-02, -2.8728e-02,  1.3277e-02, -2.9277e-02, -8.1257e-03,\n",
       "                       -1.2792e-02,  1.6587e-02, -1.3765e-02,  4.1715e-04,  5.5216e-03,\n",
       "                       -5.8891e-04,  1.5046e-02, -1.4608e-03, -3.2937e-03,  5.9999e-03,\n",
       "                        1.3464e-02, -1.7645e-02, -1.2387e-02, -1.1575e-02, -1.0044e-02,\n",
       "                        1.4430e-02, -1.1802e-03,  9.8546e-03,  6.4404e-04, -1.4425e-02,\n",
       "                       -1.0247e-02, -9.0136e-03, -4.0311e-03, -2.8320e-03,  2.1966e-03,\n",
       "                       -1.3616e-02, -3.0786e-02,  1.1851e-02,  1.5997e-02,  2.3208e-03,\n",
       "                       -1.3942e-02, -5.7350e-04,  6.6263e-03, -1.5375e-02, -3.2511e-03,\n",
       "                       -1.7610e-02, -1.6912e-02,  2.9337e-02,  4.9077e-03, -8.7931e-03,\n",
       "                       -4.5261e-03,  1.6456e-02, -1.4535e-02,  8.8477e-03,  8.9052e-03,\n",
       "                        1.5605e-02, -1.3958e-03,  2.2376e-02,  1.9827e-04, -1.0853e-02,\n",
       "                       -5.3569e-03, -1.1689e-02, -1.7394e-03,  5.2226e-03,  1.7148e-02,\n",
       "                       -1.2738e-03, -4.0904e-03,  1.5384e-02, -9.2010e-04,  5.0495e-03,\n",
       "                        2.5212e-03,  6.8434e-03, -1.5197e-02,  7.1419e-03, -3.6426e-03,\n",
       "                       -1.9545e-02, -9.2928e-03,  1.1005e-02,  2.5226e-03,  2.0247e-03,\n",
       "                       -9.7193e-04,  7.3842e-04,  2.6807e-03, -9.0500e-03,  1.1912e-02,\n",
       "                        1.7487e-02,  7.4282e-03, -8.9033e-03,  1.1504e-02,  1.6194e-02,\n",
       "                       -8.8229e-03,  1.4104e-02,  8.6888e-03, -1.8632e-02, -2.3129e-02,\n",
       "                       -1.6390e-02, -5.4067e-03,  1.2599e-03,  2.6884e-02,  3.1190e-02,\n",
       "                        2.4626e-02,  1.1444e-02, -1.3179e-02, -2.0083e-02,  1.7062e-02,\n",
       "                       -1.1387e-02, -8.1498e-03,  1.0283e-02, -1.4465e-04,  1.0825e-02,\n",
       "                        4.5048e-03,  2.0595e-02, -7.7697e-03,  2.1224e-02, -2.4167e-02,\n",
       "                       -5.4129e-02, -1.9526e-02, -4.0584e-03,  1.3167e-02,  3.4534e-02,\n",
       "                        1.6628e-02,  1.7803e-02, -1.4351e-02, -2.3478e-02,  1.9458e-02,\n",
       "                       -1.2051e-02, -1.0052e-02,  7.2822e-03, -1.8264e-02,  3.2259e-03,\n",
       "                        6.7427e-03,  2.7694e-02, -8.3914e-03,  2.3780e-02, -3.3070e-03,\n",
       "                        2.4565e-02, -2.0493e-03, -9.4827e-03, -6.1265e-03,  6.8538e-03,\n",
       "                        1.9393e-02, -1.2401e-02, -4.5486e-03,  2.6165e-03, -1.7986e-02,\n",
       "                       -1.7136e-02,  1.6973e-02,  2.3761e-02,  9.4050e-05, -2.0901e-03,\n",
       "                        2.1286e-03,  6.5724e-03,  8.2721e-03,  1.8670e-02, -1.2718e-02,\n",
       "                       -3.1985e-02,  6.5126e-03,  9.9794e-03, -1.4638e-02,  1.3826e-03],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.0.mlp.0.weight',\n",
       "               tensor([[ 1.6657e-02,  1.5687e-02,  1.8132e-02,  ..., -1.4661e-02,\n",
       "                        -3.3071e-02, -1.7409e-02],\n",
       "                       [-1.3960e-02, -9.6247e-03,  6.7486e-03,  ..., -1.2627e-02,\n",
       "                         2.5252e-02, -3.9537e-02],\n",
       "                       [ 2.7990e-02, -1.4181e-02,  9.4380e-03,  ..., -9.8569e-03,\n",
       "                         1.8601e-02, -2.6674e-03],\n",
       "                       ...,\n",
       "                       [-9.2366e-03, -7.1377e-03, -2.0369e-02,  ...,  3.4515e-02,\n",
       "                         2.8048e-02, -1.0333e-02],\n",
       "                       [ 1.6878e-02, -2.0961e-02, -2.0579e-02,  ...,  1.6305e-02,\n",
       "                         2.0228e-02,  3.1984e-02],\n",
       "                       [ 4.3229e-05, -2.1610e-03, -8.0335e-03,  ..., -6.2529e-03,\n",
       "                        -1.1305e-02, -3.6424e-03]], device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.0.mlp.0.bias',\n",
       "               tensor([ 4.3577e-04,  4.5820e-03,  2.0473e-04, -9.9302e-04, -4.1997e-04,\n",
       "                       -4.1784e-03,  1.3987e-04, -1.3511e-03,  3.9601e-03, -1.9253e-03,\n",
       "                        2.2642e-03, -2.8373e-03,  2.6042e-03, -2.2477e-03, -8.4316e-03,\n",
       "                       -9.6520e-04,  6.0221e-03,  2.0839e-03, -3.1792e-03, -4.2746e-04,\n",
       "                        8.0884e-03,  8.4101e-04, -1.0612e-02,  3.7318e-03,  3.6280e-03,\n",
       "                       -3.8061e-03, -1.3495e-03,  1.4304e-03,  1.2664e-03, -1.1938e-04,\n",
       "                       -1.8676e-03,  3.6770e-03,  2.1746e-03, -4.5699e-04,  6.9460e-04,\n",
       "                        1.5253e-03, -5.8806e-03,  8.1981e-04,  2.1371e-03,  8.2786e-04,\n",
       "                        2.2283e-03, -5.6783e-03,  9.6302e-03,  4.4967e-04, -6.1133e-03,\n",
       "                       -7.9009e-03, -4.3020e-03, -2.4285e-03,  1.7245e-03,  3.9040e-03,\n",
       "                       -1.6543e-03, -9.5191e-04, -1.6804e-03,  5.3263e-04,  2.1484e-04,\n",
       "                       -5.6396e-03, -1.2658e-03, -1.3699e-03,  3.0223e-03, -1.1091e-03,\n",
       "                       -4.9535e-03,  1.3860e-03,  7.8258e-04, -4.9289e-03,  2.3428e-03,\n",
       "                        5.1881e-03, -9.4750e-03, -1.2560e-03, -9.5026e-04, -1.2661e-03,\n",
       "                        4.1446e-04,  3.5657e-03, -5.5326e-03, -1.0391e-02, -1.1088e-03,\n",
       "                       -3.8792e-04,  1.6971e-03, -1.2756e-03, -2.1508e-03,  9.6928e-03,\n",
       "                       -2.2760e-03, -2.4665e-03, -3.1939e-03, -3.0002e-03, -8.3616e-03,\n",
       "                        3.9118e-03, -4.2371e-03, -9.5879e-04, -4.0399e-03,  8.7206e-03,\n",
       "                        6.9614e-04,  3.0378e-03, -5.9039e-03,  3.2617e-03, -4.2223e-03,\n",
       "                        4.9237e-03, -1.4390e-03,  4.9815e-03, -6.6383e-04, -4.2856e-03,\n",
       "                        3.5415e-04, -2.3182e-03, -3.1924e-03, -2.2508e-03,  6.1779e-03,\n",
       "                        3.5841e-03, -1.4417e-03,  1.3432e-03, -1.0841e-03, -8.5003e-03,\n",
       "                       -5.1482e-03, -4.3417e-04,  1.3911e-03, -3.6372e-03,  5.6898e-03,\n",
       "                        1.9619e-04, -5.6147e-03, -5.4285e-03, -3.3266e-03,  9.0165e-03,\n",
       "                        4.9857e-04, -2.1467e-03,  4.2012e-04, -8.8901e-03, -1.3858e-03,\n",
       "                       -2.6379e-03,  2.0068e-03, -1.5239e-03, -2.4281e-03, -2.4368e-03,\n",
       "                       -2.5441e-03,  2.5771e-03,  7.5714e-03, -1.0776e-03, -8.3730e-04,\n",
       "                        1.8768e-03, -7.5132e-04, -5.3999e-03, -4.3701e-03,  3.6481e-04,\n",
       "                       -1.1754e-03, -1.6872e-03, -9.9957e-03,  5.9752e-03, -5.4038e-03,\n",
       "                       -2.0414e-04, -6.7352e-03, -2.8580e-03,  1.9297e-03,  6.3862e-03,\n",
       "                       -8.0581e-03,  4.6839e-03,  9.7868e-04, -5.3781e-03, -3.7238e-03,\n",
       "                       -1.6839e-03, -3.5489e-03, -5.6342e-03, -5.2945e-03,  1.2134e-03,\n",
       "                       -3.5639e-03, -1.5847e-05,  2.3967e-04,  3.5757e-05,  1.7236e-03,\n",
       "                        1.4886e-03,  4.1967e-04, -5.6321e-03, -2.1316e-03,  5.1023e-03,\n",
       "                       -2.0554e-03,  6.4604e-04,  2.6754e-03,  6.6370e-04,  6.2641e-04,\n",
       "                        1.1659e-03,  3.3413e-03, -6.0628e-03, -1.0826e-03, -8.3559e-03,\n",
       "                       -2.1499e-03, -8.1090e-03,  5.9019e-04, -5.6903e-03,  8.2018e-06,\n",
       "                       -1.1093e-03, -1.8331e-03, -1.0566e-03,  1.0607e-03,  6.0064e-03,\n",
       "                        1.1950e-03,  1.0427e-04, -3.7364e-03, -1.0931e-03,  6.9853e-03,\n",
       "                        9.2327e-03, -2.6022e-03,  3.6978e-04, -1.3585e-04, -3.2480e-03],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.0.mlp.1.weight',\n",
       "               tensor([0.9653, 0.9636, 0.9631, 0.9629, 0.9647, 0.9761, 0.9731, 0.9756, 0.9680,\n",
       "                       0.9558, 0.9764, 0.9680, 0.9786, 0.9773, 0.9798, 0.9763, 0.9746, 0.9746,\n",
       "                       0.9734, 0.9764, 0.9814, 0.9577, 0.9787, 0.9711, 0.9804, 0.9538, 0.9744,\n",
       "                       0.9728, 0.9766, 0.9717, 0.9664, 0.9764, 0.9793, 0.9770, 0.9780, 0.9667,\n",
       "                       0.9716, 0.9560, 0.9691, 0.9780, 0.9593, 0.9639, 0.9707, 0.9735, 0.9769,\n",
       "                       0.9770, 0.9439, 0.9561, 0.9756, 0.9781, 0.9770, 0.9687, 0.9788, 0.9756,\n",
       "                       0.9609, 0.9633, 0.9733, 0.9771, 0.9699, 0.9691, 0.9779, 0.9660, 0.9545,\n",
       "                       0.9661, 0.9884, 0.9622, 0.9777, 0.9561, 0.9751, 0.9751, 0.9740, 0.9566,\n",
       "                       0.9669, 0.9516, 0.9708, 0.9735, 0.9793, 0.9624, 0.9774, 0.9798, 0.9716,\n",
       "                       0.9754, 0.9605, 0.9618, 0.9676, 0.9850, 0.9759, 0.9738, 0.9576, 0.9645,\n",
       "                       0.9793, 0.9623, 0.9603, 0.9696, 0.9749, 0.9685, 0.9762, 0.9709, 0.9704,\n",
       "                       0.9683, 0.9728, 0.9678, 0.9556, 0.9601, 0.9758, 0.9624, 0.9594, 0.9761,\n",
       "                       0.9816, 0.9754, 0.9707, 0.9735, 0.9727, 0.9709, 0.9682, 0.9775, 0.9520,\n",
       "                       0.9637, 0.9723, 0.9590, 0.9728, 0.9780, 0.9760, 0.9804, 0.9509, 0.9667,\n",
       "                       0.9747, 0.9666, 0.9786, 0.9748, 0.9688, 0.9690, 0.9713, 0.9781, 0.9821,\n",
       "                       0.9755, 0.9746, 0.9820, 0.9745, 0.9743, 0.9751, 0.9539, 0.9838, 0.9692,\n",
       "                       0.9769, 0.9662, 0.9480, 0.9574, 0.9561, 0.9437, 0.9549, 0.9658, 0.9747,\n",
       "                       0.9765, 0.9786, 0.9724, 0.9416, 0.9754, 0.9708, 0.9834, 0.9747, 0.9758,\n",
       "                       0.9730, 0.9586, 0.9730, 0.9727, 0.9777, 0.9644, 0.9663, 0.9750, 0.9716,\n",
       "                       0.9679, 0.9814, 0.9718, 0.9597, 0.9477, 0.9707, 0.9680, 0.9679, 0.9678,\n",
       "                       0.9598, 0.9481, 0.9717, 0.9719, 0.9556, 0.9656, 0.9721, 0.9563, 0.9765,\n",
       "                       0.9759, 0.9809, 0.9448, 0.9674, 0.9758, 0.9681, 0.9673, 0.9708, 0.9795,\n",
       "                       0.9696, 0.9712], device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.0.mlp.1.bias',\n",
       "               tensor([-0.0108, -0.0142, -0.0075, -0.0093, -0.0079, -0.0088,  0.0046, -0.0091,\n",
       "                       -0.0015, -0.0090, -0.0092, -0.0093, -0.0020, -0.0052, -0.0091, -0.0079,\n",
       "                       -0.0074, -0.0056, -0.0060,  0.0068, -0.0117, -0.0177, -0.0035, -0.0086,\n",
       "                       -0.0073, -0.0080, -0.0079, -0.0190, -0.0020, -0.0114,  0.0061, -0.0016,\n",
       "                       -0.0090,  0.0080, -0.0087, -0.0072, -0.0071, -0.0150, -0.0039, -0.0022,\n",
       "                       -0.0189, -0.0084, -0.0051, -0.0060, -0.0052, -0.0100, -0.0161, -0.0146,\n",
       "                        0.0008, -0.0077, -0.0075, -0.0079,  0.0055, -0.0046, -0.0147, -0.0091,\n",
       "                       -0.0070, -0.0065, -0.0104, -0.0070, -0.0030, -0.0124, -0.0098, -0.0012,\n",
       "                       -0.0222, -0.0101, -0.0105, -0.0171, -0.0013, -0.0019, -0.0015, -0.0129,\n",
       "                       -0.0064, -0.0232, -0.0029,  0.0017,  0.0014, -0.0163, -0.0148, -0.0015,\n",
       "                       -0.0006, -0.0060, -0.0103, -0.0062, -0.0076, -0.0040, -0.0058, -0.0018,\n",
       "                       -0.0152, -0.0078, -0.0004, -0.0118, -0.0068, -0.0212, -0.0063, -0.0066,\n",
       "                       -0.0117, -0.0209, -0.0001, -0.0079, -0.0082, -0.0123, -0.0021, -0.0069,\n",
       "                       -0.0081, -0.0159, -0.0077, -0.0049,  0.0011, -0.0037, -0.0078, -0.0078,\n",
       "                       -0.0061, -0.0060, -0.0110, -0.0069,  0.0013, -0.0242, -0.0067, -0.0196,\n",
       "                       -0.0067, -0.0045, -0.0053,  0.0083, -0.0037, -0.0144, -0.0039, -0.0012,\n",
       "                       -0.0030, -0.0023, -0.0086, -0.0106, -0.0029, -0.0080,  0.0041, -0.0049,\n",
       "                       -0.0013,  0.0034, -0.0041, -0.0114, -0.0026, -0.0113,  0.0101, -0.0052,\n",
       "                       -0.0014, -0.0020, -0.0224, -0.0005, -0.0106, -0.0045, -0.0310, -0.0026,\n",
       "                       -0.0049,  0.0023,  0.0017, -0.0076, -0.0264, -0.0108, -0.0033, -0.0010,\n",
       "                       -0.0033, -0.0081, -0.0064, -0.0147,  0.0080, -0.0106, -0.0030, -0.0130,\n",
       "                       -0.0171,  0.0060, -0.0079, -0.0098, -0.0074, -0.0027, -0.0021, -0.0119,\n",
       "                       -0.0063, -0.0159, -0.0008,  0.0036, -0.0126, -0.0245,  0.0001, -0.0244,\n",
       "                       -0.0291, -0.0142, -0.0039, -0.0146, -0.0011, -0.0099,  0.0081, -0.0181,\n",
       "                       -0.0038, -0.0040, -0.0022, -0.0184, -0.0072,  0.0006, -0.0068, -0.0065],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.0.mlp.1.running_mean',\n",
       "               tensor([ 0.0348, -0.6955, -0.3395, -0.5132, -0.5143, -0.7179, -0.1752, -0.0833,\n",
       "                       -0.3422, -0.2998, -0.4089, -0.5220, -0.3514, -0.2437, -0.5897,  0.1467,\n",
       "                       -0.4386, -0.7936, -0.1423,  0.2878, -0.3872, -0.4091, -0.3015, -0.4604,\n",
       "                       -0.9507, -1.0802, -0.1988, -0.0728, -0.0120, -0.6125, -0.2735, -0.4206,\n",
       "                       -0.1806,  0.2414, -0.2712, -0.3150, -0.5112, -0.2677, -0.4636, -0.1690,\n",
       "                       -0.5382, -0.5978, -0.7204, -0.4606, -0.2252, -0.3948, -1.0849, -0.0471,\n",
       "                        0.9185, -0.1615, -0.1606, -0.1482, -0.1835, -0.3528, -1.0209, -0.5745,\n",
       "                       -0.5423, -0.2527, -0.7287,  0.4678,  0.0145, -0.7268,  0.6900,  0.4437,\n",
       "                        0.5461, -0.5311, -0.2255, -0.2552, -0.4489, -0.9165, -0.0913, -1.5561,\n",
       "                       -0.3915, -0.7370, -0.4230, -0.2617, -0.3447, -1.1374,  0.5902, -0.2980,\n",
       "                       -0.1094, -0.2633, -0.3273, -0.1937, -0.9232,  0.2420, -1.1982, -0.5430,\n",
       "                       -0.4611,  0.9024, -0.2988, -0.5611,  0.4811,  0.0492, -0.3505, -0.2595,\n",
       "                        0.0934,  0.0210,  0.7994, -0.6407, -0.4306,  0.5143, -0.2517,  0.8409,\n",
       "                       -0.5028,  0.8681, -0.0858,  0.1676, -0.2850, -0.5700, -0.2303, -0.3858,\n",
       "                       -0.5609, -0.5199, -0.4063, -0.2851, -0.4905, -0.6951, -0.9471,  0.4505,\n",
       "                       -0.4306, -0.3361, -0.2676, -0.2408, -0.7015, -0.6924, -0.6157, -1.0778,\n",
       "                       -0.3185, -0.3188, -0.3528, -0.5589,  0.2995, -0.4023, -0.1794, -0.3215,\n",
       "                       -0.1907, -0.3551, -0.4454, -0.3965, -0.2717, -0.4375, -0.7220,  0.0942,\n",
       "                       -0.3252,  0.3781, -1.4723,  0.1406, -1.1783,  0.2805, -0.9298,  0.0358,\n",
       "                       -0.0859, -0.4537, -0.1489, -0.3840, -0.8591, -0.5688,  0.2447, -0.3901,\n",
       "                       -1.0170,  0.0920, -0.2206, -0.4733,  0.5490,  0.2556, -0.3856, -0.8238,\n",
       "                       -0.8762, -0.3987, -0.2345, -0.8856, -0.4896, -0.2385, -0.0337, -0.4796,\n",
       "                       -0.3059, -0.4071, -0.3385,  0.1694, -0.6041, -0.9376, -0.6252, -0.4438,\n",
       "                       -0.9682, -0.7494, -0.0032, -0.6176, -0.0322,  0.0788,  0.2693, -1.0284,\n",
       "                       -0.3599, -0.3963,  0.7580, -0.7469, -0.0778, -0.0576, -0.2885, -0.3659],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.0.mlp.1.running_var',\n",
       "               tensor([1.0103, 1.4869, 1.4460, 1.7346, 1.4003, 0.8513, 1.4452, 0.6558, 0.3095,\n",
       "                       1.5030, 0.8842, 0.7946, 1.2833, 0.4149, 1.0727, 0.8240, 1.1954, 4.0139,\n",
       "                       0.7707, 2.4695, 1.0372, 0.8378, 0.4328, 2.2226, 4.8616, 5.8752, 0.9008,\n",
       "                       1.3284, 0.7847, 2.3498, 0.3212, 1.2535, 0.7711, 1.4526, 0.4220, 1.1635,\n",
       "                       0.4478, 2.6286, 1.2753, 0.8678, 3.8110, 1.5364, 2.9672, 1.5432, 0.1338,\n",
       "                       0.2549, 6.4604, 0.8513, 2.4544, 0.6110, 1.1899, 0.9674, 0.6564, 1.3006,\n",
       "                       8.2557, 0.9007, 1.4249, 0.7896, 3.0376, 3.6930, 1.2403, 2.4150, 2.7255,\n",
       "                       1.7195, 1.7672, 0.6528, 1.1370, 1.2011, 0.7155, 5.5027, 0.3534, 4.5980,\n",
       "                       0.6212, 3.1651, 0.6381, 0.2882, 0.4119, 6.5914, 1.3127, 1.3248, 0.6145,\n",
       "                       0.8489, 0.7112, 1.5397, 1.3213, 1.1442, 4.1378, 0.6150, 3.2615, 2.4661,\n",
       "                       1.2671, 3.9459, 2.4295, 0.8892, 1.2828, 0.2970, 0.6433, 2.6541, 1.7471,\n",
       "                       1.4250, 0.7834, 2.0207, 1.2955, 4.0219, 0.7452, 1.7421, 1.2558, 1.3682,\n",
       "                       0.2239, 0.6189, 1.5492, 0.6292, 2.6898, 1.6456, 2.2928, 0.5985, 1.6883,\n",
       "                       3.9309, 2.1393, 2.4118, 0.7536, 0.8163, 0.5976, 0.9352, 1.5058, 0.7570,\n",
       "                       1.7556, 2.0584, 0.8493, 0.4096, 0.6225, 1.8344, 1.0065, 0.7136, 0.6286,\n",
       "                       0.4602, 0.3381, 0.7996, 1.5961, 1.1262, 1.0812, 1.4527, 5.1622, 1.8803,\n",
       "                       1.1718, 0.8973, 5.3842, 0.7455, 4.7927, 3.3100, 5.6743, 1.5364, 0.4176,\n",
       "                       0.7806, 0.8981, 1.1734, 5.5778, 0.5229, 2.5432, 0.8874, 1.7319, 1.3768,\n",
       "                       0.9950, 2.5425, 2.2424, 2.4355, 0.4406, 0.9015, 4.7255, 0.5865, 0.7082,\n",
       "                       1.9491, 2.1298, 1.6515, 2.9478, 2.5302, 0.7548, 1.9166, 0.9407, 2.7675,\n",
       "                       2.2128, 4.4531, 1.7177, 0.8124, 6.5790, 1.9141, 0.9096, 2.8123, 0.4780,\n",
       "                       1.6383, 0.4880, 6.2568, 0.5417, 1.6303, 1.1658, 5.8302, 0.5142, 0.6458,\n",
       "                       0.2000, 1.0181], device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.0.mlp.1.num_batches_tracked',\n",
       "               tensor(63750, device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.0.mlp.3.weight',\n",
       "               tensor([[ 0.0391, -0.0233, -0.0011,  ..., -0.0115, -0.0527, -0.0179],\n",
       "                       [ 0.0213, -0.0177,  0.0146,  ...,  0.0187, -0.0158, -0.0398],\n",
       "                       [-0.0148, -0.0247,  0.0110,  ...,  0.0077, -0.0040,  0.0171],\n",
       "                       ...,\n",
       "                       [ 0.0134, -0.0173,  0.0004,  ..., -0.0150,  0.0197, -0.0217],\n",
       "                       [ 0.0160, -0.0105,  0.0368,  ..., -0.0177, -0.0026, -0.0115],\n",
       "                       [-0.0053, -0.0051, -0.0071,  ...,  0.0119,  0.0161, -0.0116]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.0.mlp.3.bias',\n",
       "               tensor([ 6.1656e-03, -1.6013e-03, -1.2074e-02,  2.4041e-03,  1.1872e-03,\n",
       "                        3.6780e-03, -5.4945e-03, -4.7247e-03, -9.2426e-03,  8.8125e-03,\n",
       "                        5.5197e-03,  2.3557e-03, -4.9113e-03, -4.7857e-03, -2.7365e-03,\n",
       "                       -4.7056e-03, -4.9088e-03,  2.4217e-04, -7.6868e-03, -3.4240e-03,\n",
       "                       -5.6801e-03,  2.2867e-03,  1.8062e-04, -4.7625e-03, -6.8584e-04,\n",
       "                       -1.1274e-04, -4.9655e-03, -5.6618e-03, -4.8039e-03,  6.0584e-04,\n",
       "                       -1.0462e-02,  4.7391e-03, -4.0945e-04,  9.6821e-03,  5.7003e-03,\n",
       "                       -1.5687e-03,  2.4432e-03, -5.5219e-03,  5.6147e-03, -2.7387e-04,\n",
       "                        1.0691e-03, -3.3603e-03, -1.0725e-03, -8.7726e-04, -1.7824e-02,\n",
       "                       -1.5356e-03, -9.7902e-03, -3.4480e-03,  5.8102e-03, -2.8719e-03,\n",
       "                       -3.5965e-03,  2.7789e-03, -2.8272e-03, -2.6312e-03,  6.4739e-04,\n",
       "                       -5.6602e-04,  1.4045e-03,  7.2688e-04, -1.0636e-02,  2.1185e-03,\n",
       "                        6.1663e-03, -2.2531e-03, -3.5379e-03,  5.4876e-03,  6.9310e-04,\n",
       "                       -1.6002e-02, -1.4426e-03, -3.5430e-03, -2.2429e-03,  1.7953e-03,\n",
       "                       -2.0058e-03, -6.5645e-03, -3.4517e-03, -5.6321e-04,  6.6759e-03,\n",
       "                       -6.2497e-03,  2.8620e-03,  3.9470e-05, -5.9009e-03, -6.7758e-03,\n",
       "                        5.6686e-03, -2.0457e-02,  4.5145e-03,  6.7969e-04, -9.5544e-03,\n",
       "                        2.3405e-03,  1.4647e-03, -1.4021e-02,  2.2342e-03, -1.6473e-03,\n",
       "                        2.7336e-03,  1.8282e-03, -9.8884e-03, -6.9640e-03,  1.3750e-03,\n",
       "                        8.1067e-04, -4.7351e-03,  8.9939e-04, -2.4000e-03, -1.0163e-02,\n",
       "                       -2.4920e-03, -1.0303e-02, -2.0414e-03, -2.9255e-03, -1.4921e-03,\n",
       "                        5.9379e-03, -2.2645e-03, -3.5402e-03,  1.8713e-03,  1.1765e-02,\n",
       "                       -6.4096e-03, -6.5818e-03, -2.9672e-03,  5.8839e-03, -4.1309e-03,\n",
       "                        2.1946e-03, -2.8485e-03,  8.3156e-03,  1.7059e-03,  1.5674e-03,\n",
       "                       -1.1214e-03, -6.8867e-03, -5.5665e-03, -6.3646e-03,  1.2962e-02,\n",
       "                       -4.0549e-03,  2.2176e-03,  6.3715e-03, -7.6524e-03, -6.1581e-03,\n",
       "                       -9.7678e-03,  8.7629e-05, -4.4168e-03,  2.2758e-03,  7.4711e-03,\n",
       "                        1.9315e-03,  1.8770e-03, -7.7843e-04, -4.2743e-03,  4.2402e-03,\n",
       "                        1.2969e-03,  4.4979e-03,  4.6213e-03,  1.9717e-03, -6.0349e-03,\n",
       "                       -1.3733e-03,  4.4808e-03, -6.1763e-03,  1.3049e-02,  7.0629e-03,\n",
       "                       -8.0208e-03,  4.9048e-04,  4.1246e-03,  7.6936e-04, -8.3762e-04,\n",
       "                        4.7761e-04, -7.1701e-03, -7.8831e-03, -5.4977e-03,  3.2217e-03,\n",
       "                       -3.1478e-03, -3.6775e-03, -1.1571e-04, -2.7461e-03,  3.7741e-03,\n",
       "                       -2.3699e-03, -2.6787e-03,  5.1696e-05, -2.9382e-03, -6.4471e-03,\n",
       "                       -2.9009e-03,  2.8574e-04, -6.5929e-03,  3.2578e-03,  1.6331e-03,\n",
       "                       -5.8458e-03,  5.9876e-04,  1.4955e-03, -3.2912e-03, -7.8528e-03,\n",
       "                        2.3808e-03, -1.2136e-03,  6.1272e-03, -7.3510e-03, -3.4051e-03,\n",
       "                       -4.8326e-03,  2.1165e-03, -9.5132e-03,  1.1284e-03, -6.8466e-03,\n",
       "                       -3.8380e-03, -7.0101e-03, -9.1203e-03,  3.7419e-03, -1.1808e-02,\n",
       "                       -2.8290e-03, -4.4440e-03, -1.9403e-03,  2.0661e-03, -5.5640e-06],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.1.edge_encoder.0.weight',\n",
       "               tensor([[ 0.0306, -0.0353,  0.0325,  ..., -0.0054, -0.0064, -0.0239],\n",
       "                       [ 0.0247,  0.0387,  0.0236,  ...,  0.0328,  0.0120, -0.0459],\n",
       "                       [ 0.0180, -0.0081, -0.0130,  ..., -0.0158,  0.0251,  0.0164],\n",
       "                       ...,\n",
       "                       [ 0.0070,  0.0437, -0.0125,  ..., -0.0002, -0.0051, -0.0569],\n",
       "                       [ 0.0213,  0.0714,  0.0441,  ..., -0.0479,  0.0109, -0.0085],\n",
       "                       [ 0.0176, -0.0074, -0.0351,  ..., -0.0420,  0.0276, -0.0018]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.1.edge_encoder.0.bias',\n",
       "               tensor([ 0.0077,  0.0119,  0.0017, -0.0190, -0.0046,  0.0056,  0.0168,  0.0094,\n",
       "                       -0.0051,  0.0039, -0.0029,  0.0186, -0.0180,  0.0189,  0.0191, -0.0094,\n",
       "                        0.0084,  0.0184, -0.0068, -0.0066, -0.0126, -0.0144,  0.0322,  0.0054,\n",
       "                        0.0056, -0.0084,  0.0076,  0.0117, -0.0092, -0.0210,  0.0302,  0.0111,\n",
       "                        0.0049,  0.0133,  0.0009,  0.0033,  0.0078, -0.0005,  0.0011,  0.0380,\n",
       "                        0.0042, -0.0085, -0.0131, -0.0191, -0.0132, -0.0132,  0.0060,  0.0126,\n",
       "                        0.0204, -0.0218, -0.0039,  0.0289,  0.0030,  0.0034,  0.0042,  0.0069,\n",
       "                        0.0276,  0.0014,  0.0052, -0.0010,  0.0165, -0.0045, -0.0037,  0.0045,\n",
       "                        0.0175, -0.0177, -0.0008,  0.0173, -0.0091,  0.0122, -0.0022, -0.0185,\n",
       "                       -0.0071, -0.0143,  0.0194,  0.0052,  0.0028,  0.0003, -0.0044,  0.0021,\n",
       "                       -0.0239, -0.0257,  0.0002,  0.0104,  0.0085,  0.0029,  0.0085,  0.0186,\n",
       "                        0.0136, -0.0184,  0.0170,  0.0219,  0.0114,  0.0373, -0.0013, -0.0081,\n",
       "                        0.0079,  0.0001,  0.0129, -0.0018,  0.0132,  0.0188,  0.0141, -0.0070,\n",
       "                        0.0138,  0.0063, -0.0268, -0.0065,  0.0113,  0.0060,  0.0369,  0.0077,\n",
       "                        0.0054, -0.0095, -0.0127, -0.0155, -0.0099, -0.0243, -0.0093,  0.0114,\n",
       "                       -0.0292, -0.0092, -0.0165,  0.0360, -0.0180,  0.0009, -0.0012, -0.0136,\n",
       "                       -0.0028, -0.0299, -0.0139,  0.0060, -0.0042,  0.0075, -0.0028,  0.0032,\n",
       "                        0.0168, -0.0089,  0.0203,  0.0222,  0.0033, -0.0214,  0.0055, -0.0004,\n",
       "                       -0.0070, -0.0103,  0.0122,  0.0016,  0.0049,  0.0059,  0.0101, -0.0175,\n",
       "                       -0.0075,  0.0347, -0.0166,  0.0217,  0.0009, -0.0263,  0.0026,  0.0296,\n",
       "                        0.0109,  0.0100, -0.0139, -0.0151,  0.0139,  0.0117,  0.0224,  0.0200,\n",
       "                        0.0159,  0.0146, -0.0090,  0.0056,  0.0198, -0.0114,  0.0122, -0.0099,\n",
       "                       -0.0116,  0.0004, -0.0143, -0.0011,  0.0056,  0.0021,  0.0154, -0.0226,\n",
       "                       -0.0033, -0.0069, -0.0072, -0.0033, -0.0062, -0.0068, -0.0164,  0.0153,\n",
       "                       -0.0333,  0.0075, -0.0050, -0.0042, -0.0204,  0.0111, -0.0367,  0.0139],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.1.edge_encoder.1.weight',\n",
       "               tensor([0.9628, 0.9829, 0.9672, 0.9673, 0.9706, 0.9835, 0.9779, 0.9585, 0.9801,\n",
       "                       1.0104, 0.9749, 0.9749, 0.9704, 0.9653, 0.9617, 0.9588, 0.9810, 0.9747,\n",
       "                       0.9706, 0.9653, 0.9548, 0.9736, 0.9918, 0.9715, 0.9768, 0.9686, 0.9768,\n",
       "                       0.9644, 0.9705, 0.9647, 0.9775, 0.9654, 0.9791, 0.9719, 0.9689, 1.0024,\n",
       "                       0.9714, 0.9612, 0.9602, 0.9835, 0.9716, 0.9771, 0.9913, 0.9704, 0.9972,\n",
       "                       0.9774, 0.9673, 0.9556, 0.9649, 0.9712, 0.9714, 0.9532, 0.9586, 0.9630,\n",
       "                       0.9654, 0.9569, 0.9866, 0.9909, 0.9710, 0.9789, 0.9821, 0.9766, 0.9629,\n",
       "                       1.0112, 0.9736, 1.0307, 0.9648, 0.9848, 0.9644, 0.9779, 0.9688, 0.9556,\n",
       "                       0.9911, 0.9716, 0.9692, 0.9976, 0.9801, 0.9737, 0.9750, 1.0032, 0.9712,\n",
       "                       0.9831, 0.9793, 1.0119, 0.9947, 0.9525, 0.9689, 1.0086, 0.9671, 0.9862,\n",
       "                       0.9723, 0.9898, 0.9515, 0.9780, 0.9625, 0.9707, 0.9851, 0.9711, 0.9946,\n",
       "                       0.9929, 1.0127, 0.9705, 0.9535, 0.9593, 0.9769, 0.9911, 0.9627, 0.9748,\n",
       "                       0.9724, 0.9391, 0.9803, 0.9876, 0.9843, 0.9748, 0.9582, 0.9636, 0.9737,\n",
       "                       0.9705, 0.9908, 0.9860, 0.9873, 0.9901, 0.9624, 0.9739, 0.9752, 0.9613,\n",
       "                       0.9775, 0.9644, 0.9877, 0.9880, 0.9751, 0.9752, 0.9599, 0.9629, 0.9751,\n",
       "                       0.9859, 0.9705, 0.9769, 0.9848, 0.9831, 0.9677, 1.0146, 0.9704, 0.9786,\n",
       "                       0.9771, 0.9810, 0.9668, 0.9568, 0.9419, 0.9776, 0.9674, 0.9866, 0.9767,\n",
       "                       0.9543, 0.9812, 1.0107, 0.9792, 0.9727, 0.9707, 0.9655, 0.9763, 0.9820,\n",
       "                       0.9982, 0.9833, 0.9660, 1.0028, 0.9630, 0.9713, 1.0131, 0.9784, 0.9664,\n",
       "                       0.9688, 0.9602, 0.9605, 0.9668, 0.9759, 0.9633, 0.9736, 0.9751, 0.9571,\n",
       "                       0.9551, 0.9673, 0.9850, 0.9753, 0.9827, 0.9796, 0.9681, 0.9709, 0.9784,\n",
       "                       0.9611, 0.9603, 0.9895, 0.9809, 0.9890, 0.9777, 0.9484, 0.9913, 0.9686,\n",
       "                       1.0060, 0.9723], device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.1.edge_encoder.1.bias',\n",
       "               tensor([-2.5693e-02, -9.7445e-03, -1.3280e-02, -1.4876e-02, -1.3010e-02,\n",
       "                       -2.8902e-02, -1.5408e-02, -1.3348e-02, -7.5672e-03,  1.6497e-03,\n",
       "                       -7.8495e-03, -9.1716e-03, -2.0961e-02, -2.2757e-02, -2.0028e-02,\n",
       "                       -1.7987e-02, -7.9770e-03, -1.8736e-03, -5.3145e-03, -3.8504e-03,\n",
       "                       -1.5113e-02, -2.7974e-02,  2.6333e-03, -8.1461e-03, -1.9291e-02,\n",
       "                       -1.5892e-03,  1.6622e-04, -1.8932e-02, -1.3259e-02, -2.7374e-02,\n",
       "                       -1.4522e-02, -1.6898e-02, -8.0646e-03, -1.0664e-02, -1.0739e-02,\n",
       "                       -1.7976e-03, -1.9121e-02, -1.7618e-02, -1.1595e-02, -8.5707e-03,\n",
       "                       -1.0648e-02, -1.1552e-02, -1.4868e-02, -9.6961e-03, -2.4517e-02,\n",
       "                       -7.4088e-03,  7.0666e-03, -1.7505e-02, -1.4665e-02, -2.4669e-02,\n",
       "                       -2.5899e-02, -3.7980e-02, -2.2516e-02, -3.0423e-03, -9.7302e-03,\n",
       "                       -2.5835e-02, -2.2611e-03, -4.0520e-03, -6.8373e-03, -1.9277e-02,\n",
       "                       -8.0628e-03, -1.8217e-02, -1.6750e-02, -1.5095e-02, -1.4788e-03,\n",
       "                       -3.7971e-02, -1.9556e-02,  1.5557e-04, -7.2736e-03, -3.9847e-03,\n",
       "                       -1.2300e-02, -1.9903e-02, -1.9171e-02, -9.9416e-03, -5.3805e-03,\n",
       "                        1.5913e-03, -7.6342e-03, -3.3007e-03, -6.2690e-03, -1.4096e-05,\n",
       "                       -1.5686e-02, -6.8913e-03, -1.7321e-02, -2.5634e-02, -1.4783e-02,\n",
       "                       -2.4108e-02, -1.3706e-02, -2.0894e-02, -2.0094e-02, -6.5898e-03,\n",
       "                       -1.2185e-02, -6.1023e-03, -2.7504e-02, -2.4717e-02, -2.5939e-02,\n",
       "                       -1.5674e-02, -5.1389e-03, -7.2659e-03,  4.9414e-03, -1.5022e-03,\n",
       "                       -1.3755e-02, -2.0142e-02, -2.5539e-02, -3.3021e-02, -1.7456e-02,\n",
       "                       -7.0987e-03, -1.8066e-02, -7.1374e-03, -9.0562e-03, -4.0189e-02,\n",
       "                       -4.1441e-03, -9.2944e-03, -8.8290e-03, -1.3431e-02, -1.1504e-02,\n",
       "                       -2.5691e-02, -1.5559e-02, -2.4027e-02, -1.8737e-02, -6.9398e-03,\n",
       "                       -1.3982e-02, -9.3979e-03, -2.2429e-02, -1.6925e-02, -1.1936e-02,\n",
       "                       -2.2714e-02, -8.0626e-03, -2.0102e-02, -1.1027e-02, -1.1894e-02,\n",
       "                       -2.9027e-02, -1.0246e-02, -2.0020e-02, -2.4571e-02,  1.9411e-03,\n",
       "                       -2.1970e-02, -1.8667e-02, -1.4658e-02, -3.9352e-03, -1.8957e-02,\n",
       "                       -9.4686e-03, -2.8255e-02,  5.2848e-04,  7.7191e-03, -1.7395e-02,\n",
       "                       -1.0582e-02, -1.7854e-02, -2.6494e-02, -3.3694e-02, -2.2807e-02,\n",
       "                       -2.3661e-02, -5.3341e-03, -7.3770e-03, -3.4522e-02, -2.7705e-02,\n",
       "                       -7.6568e-03, -5.1986e-03,  6.7720e-03, -2.3240e-02, -3.5141e-02,\n",
       "                       -1.3055e-02, -8.6289e-03, -2.5888e-02, -1.1771e-02, -1.2512e-02,\n",
       "                       -1.8411e-02, -3.3645e-02, -7.4316e-03, -1.2644e-02, -7.5547e-03,\n",
       "                       -1.6641e-02, -1.9724e-02, -2.6223e-02, -1.5339e-02, -6.3751e-03,\n",
       "                       -5.5682e-03, -2.3769e-02, -8.3162e-03, -7.2813e-03, -3.8014e-02,\n",
       "                       -2.6523e-02, -2.3696e-02, -9.4407e-03, -1.6965e-02, -1.8803e-02,\n",
       "                        4.4039e-03, -1.6914e-02, -1.6613e-02,  7.9222e-03, -2.1573e-02,\n",
       "                       -5.3399e-03, -1.7694e-02, -4.4106e-03, -3.1973e-03, -3.3638e-03,\n",
       "                       -3.0254e-02,  3.6135e-03, -1.7349e-02,  2.9815e-03, -8.8753e-03],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.1.edge_encoder.1.running_mean',\n",
       "               tensor([ 2.7008e-02,  1.6912e-03,  1.5797e-02, -6.7778e-02,  2.0418e-02,\n",
       "                       -1.1173e-02,  1.5179e-02,  2.4307e-02,  1.2653e-02,  4.6869e-03,\n",
       "                       -1.0762e-02, -1.9674e-03, -1.3291e-02,  3.0813e-02, -1.3610e-03,\n",
       "                        4.5526e-03,  2.5402e-02,  2.0468e-02,  1.6868e-02,  1.5769e-02,\n",
       "                       -3.7985e-03, -2.9739e-02,  3.6873e-02, -1.5693e-03, -2.0923e-02,\n",
       "                        4.5054e-02,  3.2104e-02, -3.1810e-03,  5.9307e-03, -2.4748e-03,\n",
       "                        2.8697e-02,  2.8321e-03,  4.0958e-02,  2.8253e-02,  3.6128e-02,\n",
       "                       -1.6234e-02,  1.5718e-02,  2.1499e-02,  3.2818e-02,  4.5780e-02,\n",
       "                        1.8265e-02, -2.2358e-02,  1.0330e-02, -8.1752e-03, -7.3849e-02,\n",
       "                       -7.7433e-02, -9.5062e-03,  5.6934e-02,  2.9798e-02, -5.6704e-02,\n",
       "                       -2.8998e-04,  3.8911e-02,  7.1862e-02,  2.8319e-02, -1.3835e-03,\n",
       "                        2.4380e-02,  4.7917e-02, -7.5812e-03,  4.3195e-02, -8.7772e-03,\n",
       "                        3.0336e-02, -2.1767e-02, -2.0313e-02, -5.7155e-02,  2.2238e-02,\n",
       "                       -1.7876e-02,  7.2475e-03,  5.9072e-02,  1.7254e-02,  3.5640e-02,\n",
       "                       -5.3690e-02,  3.1887e-02, -6.1408e-02,  1.1748e-02, -2.8399e-02,\n",
       "                        3.6311e-02,  3.8973e-02,  6.4906e-02,  7.8385e-03, -2.0935e-02,\n",
       "                       -5.8416e-02, -2.0047e-02, -3.1496e-02,  2.9189e-02, -3.4504e-02,\n",
       "                       -2.7514e-02,  6.8505e-02,  2.8062e-03,  1.8849e-05, -1.3774e-02,\n",
       "                        9.2343e-03,  3.7521e-02,  4.5121e-02,  1.4074e-02, -1.8121e-04,\n",
       "                       -4.0558e-02, -3.7644e-03,  1.6923e-02,  2.7104e-02, -1.5634e-02,\n",
       "                       -4.1377e-03,  9.3574e-03,  1.9628e-02,  5.6155e-02,  5.2343e-02,\n",
       "                        8.2967e-03, -3.7830e-03, -4.8709e-03, -8.8138e-03,  5.4959e-02,\n",
       "                        9.5033e-02, -8.7470e-03, -2.1711e-03, -2.7213e-02,  2.7870e-02,\n",
       "                       -6.4279e-02, -1.5909e-02, -4.3667e-02, -1.5132e-02, -9.5939e-03,\n",
       "                       -1.8963e-02, -6.7713e-03, -5.5545e-02, -1.0497e-02, -3.9040e-02,\n",
       "                       -4.8672e-03,  1.1762e-02, -1.5282e-02, -4.3349e-02, -5.3518e-02,\n",
       "                        4.6776e-03, -4.4651e-02, -4.5448e-02, -1.2307e-02,  1.7775e-02,\n",
       "                       -4.1911e-03,  2.1014e-02, -4.3004e-03,  2.7901e-02,  1.0977e-02,\n",
       "                       -7.3112e-03, -3.7840e-02, -1.7166e-03,  1.3762e-02, -2.5244e-02,\n",
       "                        1.1566e-02,  7.3994e-02, -4.3874e-03,  4.3512e-02, -4.0878e-02,\n",
       "                        1.8922e-03, -1.0121e-02, -2.9110e-02,  2.4583e-02, -4.8153e-02,\n",
       "                        2.5973e-02, -2.9922e-03, -2.0870e-02, -2.2877e-02, -1.4993e-03,\n",
       "                       -5.9943e-03, -7.2241e-03, -2.0146e-02,  1.2459e-02, -3.8290e-03,\n",
       "                       -2.0011e-02,  3.9809e-02,  1.3255e-02, -4.2352e-04,  1.7046e-02,\n",
       "                       -6.5159e-03,  1.2209e-02,  6.6373e-02, -1.1389e-02,  5.5789e-02,\n",
       "                        1.8531e-02, -1.1453e-02,  2.1218e-02,  1.8626e-02,  1.3585e-02,\n",
       "                       -3.0026e-02,  1.2386e-02, -9.9208e-03, -2.6795e-04, -8.1980e-03,\n",
       "                       -1.3025e-02, -1.7465e-02,  3.8352e-04, -2.6250e-02, -3.8193e-02,\n",
       "                        1.8636e-02, -7.6045e-03, -3.9300e-02,  1.3399e-03,  1.3233e-02,\n",
       "                        1.9639e-02, -1.1317e-02, -1.9422e-02, -3.2577e-02,  5.8234e-02],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.1.edge_encoder.1.running_var',\n",
       "               tensor([0.0007, 0.0011, 0.0017, 0.0010, 0.0004, 0.0005, 0.0011, 0.0008, 0.0008,\n",
       "                       0.0006, 0.0011, 0.0012, 0.0004, 0.0011, 0.0017, 0.0008, 0.0009, 0.0008,\n",
       "                       0.0008, 0.0017, 0.0010, 0.0005, 0.0005, 0.0005, 0.0007, 0.0009, 0.0004,\n",
       "                       0.0016, 0.0005, 0.0014, 0.0013, 0.0005, 0.0005, 0.0010, 0.0009, 0.0005,\n",
       "                       0.0009, 0.0014, 0.0012, 0.0007, 0.0004, 0.0008, 0.0005, 0.0008, 0.0010,\n",
       "                       0.0010, 0.0010, 0.0012, 0.0016, 0.0011, 0.0004, 0.0004, 0.0009, 0.0014,\n",
       "                       0.0009, 0.0013, 0.0004, 0.0005, 0.0009, 0.0005, 0.0003, 0.0009, 0.0005,\n",
       "                       0.0007, 0.0009, 0.0004, 0.0008, 0.0009, 0.0006, 0.0004, 0.0013, 0.0007,\n",
       "                       0.0007, 0.0006, 0.0007, 0.0004, 0.0007, 0.0007, 0.0007, 0.0003, 0.0020,\n",
       "                       0.0011, 0.0006, 0.0004, 0.0010, 0.0019, 0.0012, 0.0007, 0.0005, 0.0004,\n",
       "                       0.0005, 0.0009, 0.0012, 0.0007, 0.0007, 0.0014, 0.0015, 0.0009, 0.0009,\n",
       "                       0.0006, 0.0004, 0.0006, 0.0008, 0.0008, 0.0012, 0.0005, 0.0013, 0.0009,\n",
       "                       0.0006, 0.0015, 0.0007, 0.0006, 0.0007, 0.0010, 0.0010, 0.0010, 0.0005,\n",
       "                       0.0006, 0.0006, 0.0005, 0.0003, 0.0008, 0.0007, 0.0010, 0.0008, 0.0009,\n",
       "                       0.0008, 0.0012, 0.0011, 0.0014, 0.0014, 0.0012, 0.0019, 0.0012, 0.0016,\n",
       "                       0.0008, 0.0008, 0.0006, 0.0006, 0.0012, 0.0004, 0.0006, 0.0020, 0.0009,\n",
       "                       0.0004, 0.0004, 0.0010, 0.0010, 0.0006, 0.0004, 0.0008, 0.0006, 0.0010,\n",
       "                       0.0016, 0.0006, 0.0004, 0.0010, 0.0015, 0.0007, 0.0009, 0.0008, 0.0008,\n",
       "                       0.0005, 0.0006, 0.0010, 0.0003, 0.0010, 0.0007, 0.0005, 0.0007, 0.0007,\n",
       "                       0.0008, 0.0009, 0.0022, 0.0009, 0.0007, 0.0006, 0.0006, 0.0006, 0.0014,\n",
       "                       0.0004, 0.0004, 0.0003, 0.0004, 0.0008, 0.0010, 0.0010, 0.0010, 0.0016,\n",
       "                       0.0016, 0.0008, 0.0008, 0.0017, 0.0004, 0.0013, 0.0004, 0.0015, 0.0007,\n",
       "                       0.0011, 0.0009], device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.1.edge_encoder.1.num_batches_tracked',\n",
       "               tensor(318750, device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.1.edge_encoder.3.weight',\n",
       "               tensor([[-0.0193, -0.0094, -0.0241,  ...,  0.0122, -0.0301, -0.0028],\n",
       "                       [ 0.0069,  0.0188,  0.0111,  ..., -0.0008, -0.0141,  0.0301],\n",
       "                       [ 0.0371, -0.0236, -0.0005,  ..., -0.0178,  0.0145,  0.0044],\n",
       "                       ...,\n",
       "                       [ 0.0266,  0.0113,  0.0204,  ..., -0.0058,  0.0168, -0.0279],\n",
       "                       [ 0.0263, -0.0120,  0.0145,  ..., -0.0088,  0.0285, -0.0355],\n",
       "                       [ 0.0217,  0.0041,  0.0519,  ...,  0.0308, -0.0709, -0.0156]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.1.edge_encoder.3.bias',\n",
       "               tensor([-2.3653e-03, -5.7033e-03,  2.7150e-03,  1.7915e-03, -1.3082e-03,\n",
       "                       -3.1844e-04,  8.8534e-04, -5.2766e-03,  1.3499e-03,  4.7690e-03,\n",
       "                       -4.6336e-03,  1.4850e-03, -3.2236e-03,  3.7453e-03, -8.5289e-03,\n",
       "                        7.5043e-03,  5.8532e-03,  2.3962e-04, -5.7625e-04,  5.2903e-04,\n",
       "                       -1.7449e-03,  5.2435e-03,  2.9055e-03, -4.1971e-03, -5.6767e-03,\n",
       "                       -4.0691e-03, -1.4285e-03,  5.0252e-03, -1.9099e-03,  1.1951e-03,\n",
       "                        2.1446e-03, -2.3171e-03,  5.1971e-03,  1.3342e-03, -6.3974e-03,\n",
       "                        7.7394e-04, -5.0417e-03, -4.6538e-04,  8.4626e-03, -4.4000e-04,\n",
       "                       -7.0619e-04,  4.7418e-03, -5.4846e-03, -5.1588e-03, -7.3695e-03,\n",
       "                       -9.4579e-03,  4.9077e-03, -5.9823e-03,  1.0702e-03, -2.1661e-03,\n",
       "                        1.0390e-03,  1.1983e-03, -4.2399e-03, -1.2942e-03, -7.8520e-03,\n",
       "                       -3.5293e-03, -1.0280e-02,  3.5102e-04,  3.8343e-03, -1.2780e-03,\n",
       "                        4.5618e-04,  3.8666e-03,  1.8226e-03,  4.2149e-03, -7.9116e-03,\n",
       "                       -6.3569e-03,  7.4834e-04,  4.8660e-04, -3.4787e-03, -3.4874e-03,\n",
       "                       -2.9350e-03,  6.0196e-03,  2.0707e-03,  6.1710e-03, -2.5195e-04,\n",
       "                        2.7551e-03, -3.0170e-03, -3.2106e-03, -5.5723e-05,  5.0233e-03,\n",
       "                       -5.5378e-03, -8.5195e-03,  2.5666e-03, -1.8356e-03,  1.2716e-03,\n",
       "                       -1.2945e-03,  1.9425e-03,  8.8292e-04,  2.0636e-03,  1.4934e-03,\n",
       "                       -1.9848e-03,  9.8496e-03, -2.1664e-03,  1.9293e-03, -3.8735e-03,\n",
       "                       -5.7664e-03,  3.7731e-03, -2.0194e-03,  5.2783e-03,  3.5625e-03,\n",
       "                       -4.3390e-03, -4.5637e-03,  6.6010e-03,  3.1173e-03,  4.0452e-03,\n",
       "                       -2.6583e-03,  4.5262e-03, -1.5825e-03, -4.2482e-03, -3.4520e-03,\n",
       "                        2.3763e-03,  3.6228e-03,  1.7307e-03,  1.0506e-03,  4.2683e-03,\n",
       "                       -3.5708e-04, -2.0222e-03, -1.5319e-03,  4.2033e-03, -6.7279e-03,\n",
       "                        1.4046e-03,  2.9070e-03,  3.6665e-03,  1.5358e-03,  2.2912e-03,\n",
       "                        1.5417e-03, -5.5028e-03,  1.9160e-03, -3.6478e-03, -3.0722e-03,\n",
       "                       -6.0849e-04,  4.6370e-03,  1.5033e-03,  7.6505e-03,  1.1843e-03,\n",
       "                       -2.6880e-03, -7.3885e-04, -1.9909e-03, -4.8474e-03,  7.0672e-03,\n",
       "                        7.6360e-03, -5.4759e-03, -6.0674e-03, -1.4287e-03,  1.6351e-03,\n",
       "                        4.7338e-03, -4.7588e-03, -5.5839e-03,  1.8682e-03, -1.0032e-03,\n",
       "                       -1.1349e-04,  6.5163e-03,  7.6160e-04,  6.0492e-03,  2.1817e-03,\n",
       "                        5.5140e-04, -5.6854e-03,  2.1677e-04,  1.8623e-03,  1.7347e-03,\n",
       "                       -3.2468e-03,  2.5972e-03, -1.4406e-03, -4.4453e-03, -6.4311e-03,\n",
       "                       -3.7272e-03,  2.8988e-03, -3.4194e-03,  8.8222e-04,  3.5037e-03,\n",
       "                        4.3227e-04, -1.8212e-03,  1.9136e-03, -3.1052e-03, -5.8780e-03,\n",
       "                       -9.3809e-04,  2.1546e-03, -5.0847e-03, -5.3777e-03, -3.2735e-03,\n",
       "                        1.7199e-04, -1.1658e-03,  3.6198e-03,  4.1820e-03,  1.1943e-04,\n",
       "                       -1.7642e-03,  4.1916e-03,  8.8105e-04, -6.2575e-03,  6.1010e-03,\n",
       "                       -4.3334e-04,  1.6691e-03,  8.9472e-06,  5.3347e-03,  4.1516e-03,\n",
       "                        4.4639e-03,  4.7324e-03, -6.6560e-04, -5.5783e-03,  1.1676e-03],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.1.linear_key.weight',\n",
       "               tensor([[-0.0365,  0.0160,  0.0304,  ...,  0.0168, -0.0122, -0.0278],\n",
       "                       [ 0.0204, -0.0332, -0.0083,  ..., -0.0690,  0.0074,  0.0165],\n",
       "                       [ 0.0280, -0.0092,  0.0230,  ...,  0.0235,  0.0262, -0.0548],\n",
       "                       ...,\n",
       "                       [ 0.0034,  0.0052,  0.0069,  ...,  0.0079,  0.0351, -0.0030],\n",
       "                       [ 0.0025, -0.0380,  0.0424,  ...,  0.0275, -0.0281, -0.0058],\n",
       "                       [-0.0342, -0.0028,  0.0235,  ...,  0.0141,  0.0125,  0.0179]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.1.linear_key.bias',\n",
       "               tensor([ 0.0029, -0.0148,  0.0115,  0.0008, -0.0118, -0.0270,  0.0087, -0.0022,\n",
       "                        0.0169, -0.0030, -0.0077,  0.0154,  0.0082, -0.0040,  0.0022, -0.0124,\n",
       "                       -0.0116,  0.0139,  0.0038,  0.0131,  0.0131, -0.0135,  0.0080,  0.0070,\n",
       "                       -0.0167, -0.0149, -0.0040, -0.0061,  0.0209,  0.0143,  0.0111, -0.0138,\n",
       "                        0.0189, -0.0118, -0.0031,  0.0156,  0.0010, -0.0159, -0.0016,  0.0104,\n",
       "                        0.0187,  0.0154,  0.0144,  0.0141,  0.0071, -0.0189,  0.0039,  0.0008,\n",
       "                       -0.0165, -0.0109, -0.0067, -0.0099, -0.0076,  0.0049, -0.0045, -0.0040,\n",
       "                       -0.0004, -0.0018,  0.0065, -0.0023, -0.0032, -0.0031,  0.0040, -0.0037,\n",
       "                        0.0046, -0.0022, -0.0024,  0.0041,  0.0017,  0.0124, -0.0087, -0.0007,\n",
       "                        0.0086, -0.0008, -0.0021,  0.0026,  0.0021, -0.0015, -0.0025,  0.0049,\n",
       "                        0.0100, -0.0031, -0.0073,  0.0032,  0.0129,  0.0051,  0.0189,  0.0025,\n",
       "                       -0.0061,  0.0060, -0.0010,  0.0055,  0.0014, -0.0110, -0.0020, -0.0017,\n",
       "                       -0.0059,  0.0019,  0.0007,  0.0039,  0.0091,  0.0012,  0.0183,  0.0092,\n",
       "                        0.0100, -0.0046, -0.0043, -0.0072,  0.0064,  0.0145, -0.0092,  0.0140,\n",
       "                       -0.0006, -0.0023,  0.0065,  0.0037,  0.0068,  0.0032,  0.0075,  0.0079,\n",
       "                       -0.0029,  0.0100,  0.0033, -0.0010,  0.0044, -0.0071, -0.0013,  0.0077,\n",
       "                       -0.0053, -0.0024, -0.0012,  0.0081,  0.0026, -0.0050, -0.0080,  0.0052,\n",
       "                        0.0092,  0.0128,  0.0005,  0.0098,  0.0086, -0.0010,  0.0019, -0.0011,\n",
       "                        0.0053, -0.0189,  0.0061,  0.0152, -0.0046, -0.0053, -0.0022, -0.0004,\n",
       "                        0.0040, -0.0008,  0.0016, -0.0059, -0.0104, -0.0087, -0.0002, -0.0070,\n",
       "                       -0.0020, -0.0012,  0.0021, -0.0038, -0.0104, -0.0058,  0.0023, -0.0057,\n",
       "                       -0.0064,  0.0008, -0.0034,  0.0015, -0.0037,  0.0090, -0.0058, -0.0109,\n",
       "                       -0.0042, -0.0005, -0.0086,  0.0039,  0.0051, -0.0036, -0.0010, -0.0064,\n",
       "                        0.0055,  0.0012, -0.0010,  0.0001, -0.0071,  0.0065,  0.0021, -0.0108,\n",
       "                       -0.0070,  0.0045, -0.0049, -0.0012, -0.0005,  0.0119, -0.0039,  0.0031],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.1.linear_msg.weight',\n",
       "               tensor([[ 0.0048, -0.0149, -0.0018,  ...,  0.0110, -0.0394,  0.0062],\n",
       "                       [ 0.0232, -0.0325,  0.0369,  ...,  0.0131, -0.0311, -0.0155],\n",
       "                       [ 0.0492, -0.0144,  0.0010,  ...,  0.0198, -0.0007, -0.0005],\n",
       "                       ...,\n",
       "                       [ 0.0058,  0.0151,  0.0076,  ..., -0.0166,  0.0053, -0.0303],\n",
       "                       [-0.0348, -0.0194,  0.0205,  ...,  0.0008, -0.0134,  0.0208],\n",
       "                       [-0.0215, -0.0121, -0.0110,  ..., -0.0352,  0.0071,  0.0278]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.1.linear_msg.bias',\n",
       "               tensor([-9.0912e-04, -5.0648e-03,  3.7299e-03, -1.8279e-03, -2.4371e-03,\n",
       "                        1.7109e-03, -4.4889e-04, -1.1615e-02,  1.2000e-03,  1.1807e-03,\n",
       "                        8.1594e-04,  9.3078e-03,  6.9018e-04,  2.3660e-03, -6.8374e-04,\n",
       "                        7.9672e-03,  2.7059e-04, -1.9573e-03,  8.6858e-03,  1.5995e-03,\n",
       "                        8.4318e-04, -6.9388e-03, -1.3703e-03, -3.2563e-04,  6.3542e-05,\n",
       "                       -9.3438e-03,  8.8134e-03, -1.8144e-03,  1.2300e-03,  4.2298e-03,\n",
       "                        4.0938e-03,  2.0718e-03,  1.4698e-03,  5.0291e-03,  8.1200e-03,\n",
       "                        7.4951e-04, -3.5666e-03, -6.4744e-03, -8.0286e-03,  7.4153e-03,\n",
       "                        7.9158e-03, -9.8656e-04, -3.3247e-03, -2.1556e-03, -2.2723e-03,\n",
       "                        4.2422e-03,  4.8703e-04, -3.6370e-03, -4.2720e-03, -2.2175e-03,\n",
       "                        5.7013e-03, -3.7225e-03,  6.7038e-03, -6.4706e-03, -4.8568e-03,\n",
       "                       -2.3811e-03, -6.7339e-04,  6.1124e-03, -6.6132e-03, -7.6171e-04,\n",
       "                        9.2039e-03, -3.7094e-03,  2.6749e-04, -2.7393e-04,  2.6166e-03,\n",
       "                       -5.1522e-03, -1.8467e-03, -3.1470e-03, -5.9360e-03, -2.7561e-03,\n",
       "                       -8.7932e-03,  3.2445e-03,  2.9135e-03,  1.8404e-03,  2.5228e-03,\n",
       "                       -1.2404e-03,  7.7573e-03,  3.3276e-04,  1.9922e-03, -5.9718e-03,\n",
       "                        3.8326e-03,  2.1823e-03, -4.8421e-03,  4.1544e-03, -6.7257e-03,\n",
       "                        2.2073e-03,  6.7673e-03,  2.8099e-03,  5.4900e-04,  8.0328e-03,\n",
       "                        3.1768e-03, -5.5188e-03,  7.0734e-03, -1.4710e-04, -2.3696e-03,\n",
       "                        2.3423e-03, -5.7122e-03, -7.9831e-03, -9.8184e-03, -1.4914e-03,\n",
       "                        3.2584e-03,  7.3895e-04,  9.2642e-04, -7.0739e-05, -1.2003e-02,\n",
       "                       -6.1061e-03,  5.6033e-03, -5.2843e-03,  2.0007e-03,  4.6990e-03,\n",
       "                       -1.3144e-03,  9.3308e-03,  1.0047e-02, -3.1056e-03,  5.2875e-03,\n",
       "                       -2.7017e-03,  1.0980e-02,  8.3049e-04, -2.0792e-03, -4.4013e-03,\n",
       "                       -9.4917e-03, -4.1828e-04, -4.7198e-03, -6.2664e-03, -3.0700e-03,\n",
       "                        1.9418e-03,  2.2665e-03, -2.7382e-03, -3.8970e-03, -1.0421e-03,\n",
       "                       -2.8251e-03, -5.8700e-05,  3.4924e-03, -4.3947e-03, -7.5449e-03,\n",
       "                       -4.0517e-03, -4.8447e-04, -5.1811e-03,  1.1685e-02, -3.3938e-03,\n",
       "                        4.6901e-03, -2.2302e-03,  7.1039e-04, -1.4743e-03, -1.2895e-03,\n",
       "                       -1.5571e-03, -3.6816e-03,  2.0535e-03,  4.5843e-03,  5.3252e-03,\n",
       "                       -7.2482e-03,  4.0228e-04, -2.5784e-04, -3.5640e-03, -1.9747e-03,\n",
       "                       -5.3198e-03, -3.4985e-03, -3.0634e-03,  3.0743e-03,  1.4786e-03,\n",
       "                       -8.9372e-05,  9.7279e-03, -3.1692e-03, -3.0507e-03,  2.8973e-03,\n",
       "                        5.2011e-03,  1.0674e-02,  6.8154e-04, -2.9647e-03, -2.3842e-03,\n",
       "                        7.5045e-03, -3.7791e-03, -7.0873e-03, -9.4354e-04, -4.5408e-03,\n",
       "                        4.5879e-03,  8.3450e-03, -3.4509e-03, -1.5138e-03, -9.5911e-03,\n",
       "                        7.5288e-04, -1.2531e-02,  6.8431e-03,  2.6446e-04, -4.3235e-03,\n",
       "                       -9.9384e-04, -4.5522e-03, -8.5807e-04,  8.0314e-03,  2.5149e-03,\n",
       "                        1.3702e-03, -1.0342e-03, -3.1351e-03, -2.0168e-03,  4.8074e-03,\n",
       "                       -5.2633e-03, -3.1573e-03,  3.6774e-04, -2.2373e-04, -1.8178e-04],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.1.linear_query.weight',\n",
       "               tensor([[ 0.0142,  0.0101,  0.0306,  ..., -0.0505, -0.0177,  0.0002],\n",
       "                       [ 0.0120,  0.0043, -0.0289,  ...,  0.0353,  0.0547, -0.0021],\n",
       "                       [ 0.0078,  0.0222,  0.0184,  ..., -0.0820, -0.1114,  0.0175],\n",
       "                       ...,\n",
       "                       [ 0.0190,  0.0298,  0.0034,  ..., -0.0115, -0.0576, -0.0201],\n",
       "                       [-0.0254,  0.0191,  0.0003,  ..., -0.0022, -0.0099,  0.0144],\n",
       "                       [-0.0210,  0.0440,  0.0126,  ...,  0.0340,  0.0001,  0.0250]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.1.linear_query.bias',\n",
       "               tensor([-1.8319e-02,  1.2940e-02,  1.3178e-03, -9.1113e-03,  1.7112e-02,\n",
       "                        5.2464e-03, -9.0499e-03, -5.6258e-04, -1.0589e-02,  4.5054e-03,\n",
       "                       -1.1236e-04,  3.1912e-03, -2.8822e-03,  1.8783e-03, -3.2187e-03,\n",
       "                        8.6453e-03,  1.1903e-02,  1.1733e-03, -9.9742e-04, -1.5913e-02,\n",
       "                       -1.3914e-02,  1.0987e-02,  2.9328e-03, -7.0578e-03,  1.6313e-02,\n",
       "                       -2.6615e-04, -5.6232e-03, -1.5028e-03,  3.1503e-05,  1.0148e-02,\n",
       "                        4.9598e-04,  2.0538e-02, -9.1627e-03,  1.6255e-02,  1.6128e-02,\n",
       "                       -1.1973e-02, -1.2515e-03, -1.9784e-03, -1.0172e-02, -6.0695e-03,\n",
       "                        1.1685e-03, -2.7436e-03, -6.3628e-03,  6.7053e-05, -1.2686e-02,\n",
       "                        4.6722e-03,  1.4873e-02,  1.0082e-02,  5.8529e-03,  9.2943e-03,\n",
       "                        2.7004e-03,  4.4658e-03, -1.1608e-02, -4.6618e-03,  5.5633e-03,\n",
       "                        1.5851e-02, -1.1932e-02, -1.2497e-04, -5.5744e-03,  6.6877e-03,\n",
       "                       -3.5200e-04, -1.2537e-02, -6.3224e-03,  6.6995e-03, -1.3625e-02,\n",
       "                       -8.6008e-03, -1.1688e-02, -4.2383e-03, -5.9802e-03, -3.7829e-03,\n",
       "                       -8.1491e-03,  1.4848e-03, -9.7652e-03,  1.6945e-03,  8.0426e-03,\n",
       "                       -7.9757e-03, -1.0807e-03, -3.2373e-04, -5.0783e-03,  2.7555e-03,\n",
       "                        2.4809e-03,  7.9114e-04, -1.2026e-02, -2.2139e-03,  6.9465e-03,\n",
       "                       -7.2894e-03,  4.0219e-03,  8.2246e-03, -6.0593e-03, -2.3723e-03,\n",
       "                        2.8549e-03, -8.2686e-03, -4.9752e-03, -5.5246e-03, -1.0424e-03,\n",
       "                       -1.0799e-02, -1.2340e-02,  2.6179e-02,  2.9777e-04, -1.9681e-04,\n",
       "                       -1.2187e-02,  3.7354e-03, -1.4337e-03, -7.3035e-03, -2.7303e-03,\n",
       "                        6.4686e-03, -1.1146e-02,  9.8467e-03,  1.1365e-03, -2.9445e-03,\n",
       "                        8.9047e-03, -3.8334e-03,  2.6407e-03, -1.5586e-03,  1.5439e-03,\n",
       "                        4.9970e-03,  6.8578e-04, -4.6590e-03,  6.0809e-04,  1.7876e-03,\n",
       "                       -2.6516e-03, -1.4631e-02,  1.3690e-02,  4.7238e-03, -1.1895e-03,\n",
       "                        1.4812e-03,  1.7772e-03, -1.1229e-03, -2.7222e-04,  4.5907e-03,\n",
       "                        2.1765e-02, -1.4506e-02, -9.8458e-03, -6.5051e-03,  1.0383e-02,\n",
       "                        3.0645e-03,  4.8168e-03,  1.0975e-03,  1.5529e-03, -8.5267e-03,\n",
       "                       -7.3467e-03, -8.1823e-03,  6.0936e-03, -4.4456e-03, -5.7795e-05,\n",
       "                        8.1223e-04, -1.8863e-03, -9.7434e-05, -1.4370e-03, -3.3224e-03,\n",
       "                        1.8769e-03, -1.2764e-03, -3.9746e-03, -3.5161e-03, -3.9262e-03,\n",
       "                       -1.1122e-02,  2.8086e-03,  6.6216e-03,  1.1343e-03,  1.4053e-02,\n",
       "                       -2.5166e-03,  6.7284e-03, -4.9607e-04,  2.6783e-03,  1.0069e-02,\n",
       "                       -5.2321e-03,  3.8605e-03,  1.4648e-03,  1.3540e-02, -1.5866e-03,\n",
       "                       -1.9830e-04,  2.6302e-03, -1.1931e-03,  4.1689e-03,  2.0837e-03,\n",
       "                        8.2169e-03, -5.0124e-03, -1.5231e-02,  9.2464e-03,  1.7778e-03,\n",
       "                       -6.3880e-03, -3.4069e-03,  6.7030e-03, -4.7434e-03,  1.8366e-03,\n",
       "                       -1.1045e-02,  7.9979e-03, -9.1939e-03, -1.7966e-02, -4.5470e-03,\n",
       "                       -1.4129e-02, -3.0200e-03,  3.6540e-03,  2.6913e-03,  2.0685e-02,\n",
       "                        1.5365e-03, -8.1400e-03, -6.2700e-03, -2.9803e-03,  2.2370e-03],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.1.mlp.0.weight',\n",
       "               tensor([[-0.0029,  0.0143,  0.0227,  ...,  0.0141,  0.0331,  0.0199],\n",
       "                       [-0.0150,  0.0040, -0.0245,  ..., -0.0045,  0.0308,  0.0375],\n",
       "                       [-0.0321, -0.0089,  0.0132,  ..., -0.0118, -0.0059, -0.0121],\n",
       "                       ...,\n",
       "                       [-0.0336, -0.0017,  0.0203,  ...,  0.0094, -0.0109,  0.0211],\n",
       "                       [-0.0060,  0.0409,  0.0235,  ..., -0.0253,  0.0107, -0.0086],\n",
       "                       [-0.0190,  0.0116,  0.0115,  ..., -0.0263, -0.0259,  0.0011]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.1.mlp.0.bias',\n",
       "               tensor([-0.0014,  0.0009,  0.0027, -0.0008,  0.0026,  0.0017, -0.0052,  0.0048,\n",
       "                       -0.0068,  0.0064, -0.0039,  0.0008,  0.0027, -0.0044,  0.0040, -0.0010,\n",
       "                        0.0086,  0.0045,  0.0027, -0.0015,  0.0051, -0.0031,  0.0114,  0.0021,\n",
       "                       -0.0032,  0.0044,  0.0053,  0.0078, -0.0023,  0.0025,  0.0086, -0.0002,\n",
       "                       -0.0065,  0.0015, -0.0014, -0.0018,  0.0035,  0.0085,  0.0016, -0.0042,\n",
       "                        0.0007,  0.0060, -0.0036,  0.0013,  0.0024,  0.0032,  0.0002, -0.0010,\n",
       "                        0.0031,  0.0005,  0.0033, -0.0100, -0.0029, -0.0096,  0.0002,  0.0008,\n",
       "                        0.0052,  0.0020, -0.0034, -0.0022, -0.0085,  0.0019,  0.0021, -0.0013,\n",
       "                        0.0046,  0.0024, -0.0076, -0.0119, -0.0070, -0.0076, -0.0090,  0.0041,\n",
       "                        0.0077,  0.0095, -0.0041, -0.0088,  0.0031,  0.0009,  0.0005,  0.0058,\n",
       "                       -0.0042,  0.0019,  0.0031, -0.0014,  0.0018, -0.0023, -0.0026,  0.0050,\n",
       "                       -0.0076, -0.0049, -0.0016, -0.0041,  0.0084, -0.0010, -0.0025,  0.0010,\n",
       "                        0.0002, -0.0052,  0.0112,  0.0039,  0.0036,  0.0058, -0.0006, -0.0046,\n",
       "                        0.0001, -0.0085, -0.0017, -0.0184,  0.0047, -0.0030,  0.0035,  0.0028,\n",
       "                       -0.0019, -0.0011,  0.0023, -0.0029, -0.0065, -0.0028, -0.0002,  0.0016,\n",
       "                        0.0036,  0.0007, -0.0061,  0.0018,  0.0016,  0.0044, -0.0082,  0.0032,\n",
       "                        0.0066, -0.0012, -0.0023, -0.0020, -0.0026, -0.0018, -0.0041,  0.0006,\n",
       "                        0.0027, -0.0016,  0.0030,  0.0052, -0.0025, -0.0038, -0.0027, -0.0028,\n",
       "                       -0.0049, -0.0106,  0.0008, -0.0028, -0.0010, -0.0022, -0.0053,  0.0032,\n",
       "                       -0.0043, -0.0019,  0.0007, -0.0046, -0.0047,  0.0049,  0.0002, -0.0041,\n",
       "                        0.0080,  0.0108,  0.0009,  0.0036, -0.0012, -0.0111,  0.0056, -0.0030,\n",
       "                       -0.0023, -0.0056, -0.0059, -0.0008, -0.0034,  0.0018, -0.0038,  0.0042,\n",
       "                       -0.0056, -0.0042,  0.0014, -0.0020,  0.0096, -0.0049, -0.0011, -0.0039,\n",
       "                       -0.0053, -0.0072,  0.0070, -0.0033, -0.0008, -0.0072, -0.0115, -0.0011,\n",
       "                        0.0039,  0.0019, -0.0019, -0.0093,  0.0095, -0.0048, -0.0004, -0.0072],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.1.mlp.1.weight',\n",
       "               tensor([0.9730, 0.9479, 0.9560, 0.9548, 0.9768, 0.9828, 0.9751, 0.9750, 0.9873,\n",
       "                       0.9672, 0.9756, 0.9669, 0.9686, 0.9723, 0.9805, 0.9837, 0.9656, 0.9780,\n",
       "                       0.9667, 0.9769, 0.9742, 0.9678, 0.9777, 0.9583, 0.9638, 0.9679, 0.9739,\n",
       "                       0.9721, 0.9737, 0.9577, 0.9759, 0.9600, 0.9460, 0.9749, 0.9769, 0.9603,\n",
       "                       0.9727, 0.9676, 0.9691, 0.9774, 0.9824, 0.9694, 0.9802, 0.9831, 0.9514,\n",
       "                       0.9755, 0.9656, 0.9759, 0.9768, 0.9591, 0.9683, 0.9598, 0.9666, 0.9549,\n",
       "                       0.9607, 0.9601, 0.9719, 0.9573, 0.9675, 0.9671, 0.9765, 0.9776, 0.9787,\n",
       "                       0.9745, 0.9806, 0.9868, 0.9788, 0.9685, 0.9631, 0.9737, 0.9595, 0.9800,\n",
       "                       0.9677, 0.9665, 0.9689, 0.9730, 0.9658, 0.9722, 0.9744, 0.9704, 0.9721,\n",
       "                       0.9548, 0.9743, 0.9535, 0.9724, 0.9563, 0.9727, 0.9772, 0.9678, 0.9716,\n",
       "                       0.9692, 0.9699, 0.9741, 0.9844, 0.9322, 0.9726, 0.9557, 0.9669, 0.9788,\n",
       "                       0.9769, 0.9715, 0.9718, 0.9603, 0.9803, 0.9775, 0.9709, 0.9801, 0.9775,\n",
       "                       0.9534, 0.9695, 0.9735, 0.9684, 0.9606, 0.9741, 0.9593, 0.9733, 0.9789,\n",
       "                       0.9722, 0.9754, 0.9673, 0.9583, 0.9669, 0.9619, 0.9665, 0.9701, 0.9754,\n",
       "                       0.9714, 0.9751, 0.9819, 0.9727, 0.9585, 0.9811, 0.9474, 0.9647, 0.9637,\n",
       "                       0.9612, 0.9587, 0.9761, 0.9714, 0.9719, 0.9714, 0.9795, 0.9723, 0.9762,\n",
       "                       0.9710, 0.9765, 0.9656, 0.9420, 0.9748, 0.9760, 0.9737, 0.9819, 0.9654,\n",
       "                       0.9742, 0.9621, 0.9725, 0.9702, 0.9738, 0.9525, 0.9647, 0.9756, 0.9771,\n",
       "                       0.9730, 0.9755, 0.9733, 0.9665, 0.9708, 0.9645, 0.9733, 0.9757, 0.9683,\n",
       "                       0.9674, 0.9898, 0.9834, 0.9603, 0.9634, 0.9783, 0.9778, 0.9763, 0.9604,\n",
       "                       0.9786, 0.9674, 0.9642, 0.9574, 0.9509, 0.9701, 0.9740, 0.9601, 0.9561,\n",
       "                       0.9559, 0.9561, 0.9755, 0.9663, 0.9664, 0.9382, 0.9640, 0.9825, 0.9380,\n",
       "                       0.9778, 0.9701], device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.1.mlp.1.bias',\n",
       "               tensor([ 3.4657e-02, -2.5796e-02, -9.7424e-03,  2.4349e-03, -5.8099e-03,\n",
       "                        2.0100e-03,  3.1973e-02,  1.8742e-03,  1.5664e-02, -1.1924e-02,\n",
       "                        7.8245e-03, -1.7556e-03, -9.7630e-03,  3.4978e-03, -1.3139e-02,\n",
       "                       -4.4988e-03, -1.6876e-02, -1.2673e-02, -2.5421e-03,  1.0009e-02,\n",
       "                       -6.1307e-03, -2.3162e-02,  1.0852e-02, -1.8861e-02,  3.8116e-03,\n",
       "                       -3.2518e-03,  3.2115e-02,  3.4364e-03,  5.0679e-03, -7.0415e-03,\n",
       "                        1.0639e-02, -9.5283e-03, -4.3888e-03, -7.4301e-04, -5.8204e-03,\n",
       "                       -4.0872e-03, -3.5701e-03, -2.8987e-03, -1.1864e-02,  1.1958e-02,\n",
       "                        2.7957e-02, -1.8821e-02,  1.5315e-02,  1.9130e-02, -1.7457e-02,\n",
       "                        7.7958e-03, -1.8994e-02, -7.1359e-03,  6.5180e-03,  5.1095e-03,\n",
       "                       -1.8512e-02, -6.5952e-03, -1.2614e-02, -1.6167e-02, -4.2118e-03,\n",
       "                       -5.2682e-03, -6.2375e-03,  4.3906e-03,  5.2536e-04, -5.0878e-03,\n",
       "                       -1.6170e-03,  2.8812e-03,  6.7783e-03, -1.0945e-02, -5.1501e-03,\n",
       "                        1.2418e-02, -2.7596e-02, -1.5499e-02, -4.0386e-03,  7.5244e-03,\n",
       "                       -2.4812e-02,  9.6813e-03,  1.3508e-02,  5.9364e-03,  1.7945e-02,\n",
       "                       -3.0688e-03, -1.1093e-02,  1.6777e-03,  2.0968e-02, -2.0735e-04,\n",
       "                       -4.9561e-04,  1.3124e-02,  1.6657e-03, -1.1922e-02,  3.0379e-03,\n",
       "                       -7.7480e-03,  1.8005e-02,  6.1652e-03,  1.5581e-02, -1.4317e-02,\n",
       "                        1.7027e-02, -7.3958e-04, -1.0333e-02,  9.7157e-03, -2.7294e-02,\n",
       "                        7.4243e-03, -1.1505e-02,  1.5088e-03,  9.3816e-03, -4.5328e-03,\n",
       "                        8.4314e-03, -1.0564e-02,  1.1185e-02,  2.1622e-02,  1.1859e-02,\n",
       "                        4.7738e-03, -2.4279e-02, -2.4001e-03, -2.1152e-02, -4.3431e-03,\n",
       "                       -1.3474e-03, -8.4990e-03, -8.0952e-03, -5.7850e-03, -4.5457e-03,\n",
       "                       -1.4686e-02, -3.8672e-03,  1.0776e-02, -1.3250e-02, -2.8913e-03,\n",
       "                        6.7150e-03, -8.3765e-03,  8.1725e-03, -6.3875e-03, -1.6412e-03,\n",
       "                        3.1255e-03, -5.9708e-03,  5.7145e-04,  1.8550e-02,  1.5165e-02,\n",
       "                       -1.6426e-02,  2.3533e-02, -1.7556e-02, -2.2022e-02,  9.0658e-03,\n",
       "                       -1.0918e-02, -2.2209e-03, -7.1353e-03, -1.1657e-03,  2.2234e-02,\n",
       "                        2.7679e-03,  8.1843e-03, -9.1998e-03,  1.7549e-02, -7.6342e-03,\n",
       "                        3.5418e-04, -2.3575e-03, -1.5031e-02, -1.5524e-02,  8.6135e-03,\n",
       "                       -3.8239e-03,  1.7929e-02, -7.1128e-03, -1.8793e-03, -8.0501e-03,\n",
       "                        5.2614e-03, -6.5535e-05, -3.1801e-03,  4.8761e-03, -6.9472e-04,\n",
       "                        1.2125e-02,  2.3865e-02,  1.1806e-02,  4.6912e-03, -1.5766e-02,\n",
       "                       -1.9686e-02, -1.9614e-02, -1.1499e-02, -4.8891e-03, -1.3474e-02,\n",
       "                       -1.0109e-02,  8.4595e-04,  2.9266e-02, -1.1496e-03, -6.9487e-03,\n",
       "                        7.5075e-03,  2.1310e-02, -1.3316e-03, -1.9031e-03, -2.0117e-02,\n",
       "                        1.3851e-02, -7.4101e-03, -2.2746e-03, -8.6875e-03, -5.9744e-03,\n",
       "                        6.4316e-03, -8.6449e-03,  1.4165e-02, -1.7105e-02, -2.4247e-02,\n",
       "                       -1.3839e-02,  1.2793e-02,  8.6498e-03, -1.0554e-02, -2.4718e-02,\n",
       "                       -1.8369e-02,  1.6180e-02, -1.7874e-02,  4.5291e-04,  2.1423e-02],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.1.mlp.1.running_mean',\n",
       "               tensor([-1.9018,  1.2350, -1.2466, -1.0402,  1.2086,  1.2372, -0.7383, -0.1799,\n",
       "                       -1.0742,  0.9573, -0.1250, -1.0227, -0.8489, -0.9919,  1.0677, -0.6507,\n",
       "                        1.1216,  0.4074,  0.0934, -0.7853,  1.1803, -0.5442,  0.4770, -0.6731,\n",
       "                       -0.0561,  0.1988, -1.3957, -1.0296,  1.2772,  0.0537, -0.9335, -0.8596,\n",
       "                       -1.4351,  0.7346,  0.4389,  0.5683, -1.1830,  0.3470, -0.8310, -0.8439,\n",
       "                       -0.5251,  0.6873, -1.3599, -1.6161, -1.5387,  0.7854, -0.6310,  1.2680,\n",
       "                       -1.1172, -1.2258, -0.0763,  0.2617, -0.5906, -0.2155, -0.4512, -0.8484,\n",
       "                       -1.1098, -0.8112, -1.1367, -0.1164, -0.9128, -0.5586, -0.7792,  0.9794,\n",
       "                        0.0750, -0.1840, -0.5322, -1.1235, -0.8632, -0.3578, -1.0002, -0.9128,\n",
       "                        0.1307,  0.2575, -0.4078, -0.3072, -1.0140, -0.1760, -1.5258, -0.0268,\n",
       "                       -0.8399, -0.7942,  0.7773, -1.3315, -1.2336, -1.1141, -1.2229, -1.7101,\n",
       "                       -1.0473,  1.6144, -0.7178,  0.3180, -1.3159, -0.4135, -1.2074, -0.7818,\n",
       "                       -1.1531, -0.3401, -0.1141,  0.5687,  0.3275, -0.6129, -0.4887,  0.0744,\n",
       "                        0.2295, -0.2213, -1.0137,  0.7104,  0.1573, -1.1997,  0.5840, -1.2414,\n",
       "                       -0.4011, -0.6611, -0.7690, -0.5846, -1.1595, -0.9829, -0.1730, -0.7789,\n",
       "                       -1.0657, -0.7865, -0.9395, -0.9424,  0.4450, -0.0581,  0.6646, -0.8215,\n",
       "                       -1.2250,  0.0417,  1.2497, -0.9685, -0.6733,  0.9620, -0.0801,  0.7376,\n",
       "                       -0.5008, -0.4851, -0.5995, -0.8281, -0.3317, -0.2665, -0.9882, -1.1438,\n",
       "                       -0.7529,  0.3686, -0.9550, -1.1786, -0.6797, -0.5960,  0.4417, -0.8531,\n",
       "                        0.2004,  0.1227, -0.2102, -0.0819, -0.9619, -1.1526, -0.6693,  0.1620,\n",
       "                        0.1529,  0.3576, -0.1353, -0.0263, -1.2858,  1.6947,  1.5467, -0.7156,\n",
       "                       -0.7420, -0.9128, -1.0362,  0.3653, -0.7109,  0.4740, -0.3168, -0.3448,\n",
       "                       -1.2428, -0.1618, -1.0079,  0.5274, -1.1990, -0.6976,  0.8369, -0.8325,\n",
       "                       -0.9063, -1.3351, -0.3546, -1.0768,  1.3918, -1.1294, -0.1160, -0.1365,\n",
       "                       -0.9668,  1.0820, -0.0231, -0.8065, -0.0665, -0.5379, -0.8331, -1.0104],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.1.mlp.1.running_var',\n",
       "               tensor([15.6093, 11.2765, 11.1716, 13.2752, 12.4612,  4.2778,  8.2131,  3.7636,\n",
       "                        6.4345, 13.1853,  8.7392,  9.0429,  6.4402,  4.4342, 19.1769,  9.4079,\n",
       "                       40.9187, 14.6641, 10.6008,  5.2683, 13.6421,  7.7862, 13.9602,  7.2445,\n",
       "                       11.9010,  9.3483,  5.3953, 11.9577, 18.6280, 17.9788,  7.2981,  3.3670,\n",
       "                       14.1971,  3.6324, 14.9904,  3.0790, 25.4119,  8.4567,  7.6032,  3.4583,\n",
       "                        5.4076,  5.7039, 12.0072, 15.5448, 19.7328, 17.2775,  4.5219,  5.2492,\n",
       "                        5.9599, 20.9502,  3.4222,  2.5347, 17.3620,  3.2524,  5.0107,  9.1462,\n",
       "                       26.9539,  3.6165,  4.9718,  8.5166, 12.6698, 20.2489,  4.3996,  3.6789,\n",
       "                       37.0330,  3.6095, 21.3511, 27.0694, 23.7609,  3.7043, 26.7349,  8.7641,\n",
       "                       23.7088,  5.0398, 12.6161,  4.3804, 13.8621,  4.2274, 14.1595,  6.9625,\n",
       "                        4.0203, 24.1524, 16.2677, 18.2024,  4.5019,  6.6576,  3.1509, 23.6595,\n",
       "                        2.5823,  5.2438,  9.9809, 10.7942, 15.3562,  8.1515, 19.8269,  4.6662,\n",
       "                       13.5855,  3.4182, 30.9927,  3.6731, 14.5170,  7.2436,  7.0728, 17.7914,\n",
       "                        9.4680, 10.6873, 21.5791, 11.0135, 11.0704, 16.4416, 18.1173, 12.4754,\n",
       "                        5.5636,  1.6460, 29.6468,  5.1845,  7.0238,  3.1595, 16.9369,  8.0179,\n",
       "                        5.7837,  9.0538,  8.5782,  7.3702,  6.7267,  8.1097,  9.5133,  8.4042,\n",
       "                        5.3676, 14.5093,  9.3619, 11.5181, 14.8269,  6.2438,  7.2507,  7.6099,\n",
       "                       25.5636,  8.0048,  5.1511,  3.5346, 12.1030,  4.8062,  4.9382,  4.0876,\n",
       "                        3.0160,  2.4918, 31.6461, 22.9607, 14.7001,  2.4750, 11.0183,  3.9124,\n",
       "                       12.7208,  3.2622, 10.2535,  4.1041, 11.7231, 28.4507,  4.1987,  4.2268,\n",
       "                       22.1894, 32.9705,  7.9051, 26.1704,  9.6547, 10.7410, 10.0577,  4.4319,\n",
       "                        5.7534,  8.8782,  9.4884, 11.9906,  6.5902,  4.4263,  4.1643,  5.4643,\n",
       "                       13.1729,  3.2101,  8.4604, 19.4591,  5.8776, 16.0370,  6.7697, 11.2031,\n",
       "                       12.3413, 15.0882,  3.8597,  3.8518,  6.4496, 16.4621,  5.4917, 10.8493,\n",
       "                        6.3166,  8.6840,  6.4952, 10.2355,  5.3703,  8.7177, 18.6377,  6.1089],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.1.mlp.1.num_batches_tracked',\n",
       "               tensor(63750, device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.1.mlp.3.weight',\n",
       "               tensor([[-0.0102,  0.0178, -0.0374,  ...,  0.0037,  0.0166,  0.0462],\n",
       "                       [ 0.0182, -0.0114,  0.0317,  ...,  0.0001, -0.0023, -0.0040],\n",
       "                       [ 0.0119, -0.0107, -0.0037,  ..., -0.0388,  0.0281, -0.0064],\n",
       "                       ...,\n",
       "                       [-0.0193,  0.0196,  0.0064,  ..., -0.0071, -0.0018, -0.0084],\n",
       "                       [ 0.0373,  0.0055, -0.0089,  ..., -0.0323,  0.0147, -0.0027],\n",
       "                       [ 0.0376,  0.0242, -0.0084,  ...,  0.0117, -0.0067,  0.0558]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.1.mlp.3.bias',\n",
       "               tensor([ 7.9622e-03,  3.0279e-03, -1.3626e-02, -1.2081e-03,  5.4394e-04,\n",
       "                       -8.2746e-03,  1.4416e-02,  1.1352e-03, -1.2874e-02,  1.7316e-02,\n",
       "                        7.7454e-04,  7.9596e-03,  5.3997e-04, -8.2379e-03,  1.8186e-03,\n",
       "                        5.3021e-03, -5.9198e-03, -2.4327e-03, -4.5483e-03,  1.5825e-02,\n",
       "                        1.3573e-02, -4.7727e-03, -3.0281e-03, -6.9414e-03, -8.9489e-04,\n",
       "                        4.7818e-03, -2.8690e-02, -1.5221e-02, -4.7864e-03,  2.4478e-03,\n",
       "                       -1.2328e-02,  1.2404e-02, -1.3879e-03,  9.8128e-03,  1.6361e-02,\n",
       "                        4.9717e-04, -6.0779e-03, -5.2219e-03, -5.9310e-03, -1.8407e-02,\n",
       "                       -5.1901e-03, -7.7068e-03,  1.0182e-02, -9.2088e-03, -1.0210e-02,\n",
       "                       -2.7722e-03,  1.9062e-02, -2.4709e-02, -2.1461e-03,  4.8032e-03,\n",
       "                        4.8923e-03,  5.1593e-03,  9.0809e-03, -1.5027e-02, -1.2803e-02,\n",
       "                       -4.9469e-03, -1.3475e-02, -9.6674e-03, -1.6612e-03,  7.9335e-05,\n",
       "                        1.6235e-03, -1.1803e-02,  4.8681e-03, -1.3161e-02,  1.2751e-02,\n",
       "                       -9.2351e-03, -8.6782e-03,  6.9510e-03, -3.0491e-03, -9.8829e-03,\n",
       "                       -1.0581e-02, -1.1235e-02, -1.8225e-02, -3.6400e-03, -9.8334e-04,\n",
       "                        1.8641e-03, -8.8023e-03, -8.4616e-03, -3.0854e-03,  1.0353e-02,\n",
       "                       -9.3986e-03, -1.6239e-02, -2.7110e-03, -1.1658e-02, -8.7415e-03,\n",
       "                       -4.5652e-04, -1.9645e-02,  7.6536e-03, -5.5074e-03, -1.6572e-02,\n",
       "                       -7.7241e-03,  1.3777e-02,  1.1985e-02, -9.2298e-04, -2.7899e-03,\n",
       "                        3.2833e-03,  1.4790e-02, -7.9666e-03,  1.6684e-02, -5.5535e-03,\n",
       "                        9.4298e-03,  9.6350e-03,  2.2107e-02, -1.0452e-02, -3.7505e-03,\n",
       "                       -1.4268e-02, -1.2437e-02, -5.4459e-03, -1.2796e-02, -1.9765e-02,\n",
       "                       -1.2251e-02, -7.9006e-03,  3.2686e-03, -8.9631e-03,  1.6452e-02,\n",
       "                       -2.2352e-02, -1.1301e-02,  5.7909e-03, -1.5489e-02, -1.5036e-02,\n",
       "                       -1.4079e-02,  2.3820e-03,  9.0787e-03, -4.9153e-03,  2.8135e-03,\n",
       "                       -2.8659e-03, -6.7451e-03, -1.2422e-02, -1.4631e-02,  4.8998e-03,\n",
       "                       -1.4261e-02,  9.7226e-04, -1.3832e-02,  2.9070e-03, -4.1635e-03,\n",
       "                        9.6605e-03, -1.7645e-02, -1.6591e-02, -3.4265e-04,  7.3928e-03,\n",
       "                       -1.7140e-02, -1.9455e-02,  6.8476e-04,  7.1272e-03,  1.0946e-02,\n",
       "                       -3.3400e-03, -1.1697e-02, -6.0892e-03,  1.7221e-02, -2.5453e-03,\n",
       "                       -5.6772e-03,  1.6864e-02,  1.0187e-02, -2.3305e-03, -8.5733e-03,\n",
       "                        9.8183e-03, -1.0430e-02, -4.1665e-03,  1.4880e-02, -8.2354e-03,\n",
       "                       -1.6649e-03, -2.3944e-03, -1.8005e-02, -1.3927e-02, -4.0511e-03,\n",
       "                       -8.0677e-03, -8.8939e-03, -1.9296e-02,  2.1850e-02, -1.8827e-02,\n",
       "                       -1.4240e-02, -6.9041e-03, -1.4883e-02, -1.5523e-04, -1.3082e-02,\n",
       "                        1.9668e-03, -1.7202e-02, -1.4444e-02,  4.8704e-04,  4.9032e-03,\n",
       "                       -1.5775e-02,  3.5383e-03, -1.8642e-03, -5.7349e-05, -1.0353e-02,\n",
       "                        1.4028e-02,  3.1695e-03, -9.4482e-03,  1.3516e-02,  5.6247e-03,\n",
       "                       -1.4536e-02, -1.4192e-03, -1.1911e-02,  1.0714e-02,  1.3734e-02,\n",
       "                       -6.8823e-03,  6.7205e-03, -1.5873e-02,  1.4803e-02,  1.3652e-02],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.2.edge_encoder.0.weight',\n",
       "               tensor([[ 0.0306, -0.0353,  0.0325,  ..., -0.0054, -0.0064, -0.0239],\n",
       "                       [ 0.0247,  0.0387,  0.0236,  ...,  0.0328,  0.0120, -0.0459],\n",
       "                       [ 0.0180, -0.0081, -0.0130,  ..., -0.0158,  0.0251,  0.0164],\n",
       "                       ...,\n",
       "                       [ 0.0070,  0.0437, -0.0125,  ..., -0.0002, -0.0051, -0.0569],\n",
       "                       [ 0.0213,  0.0714,  0.0441,  ..., -0.0479,  0.0109, -0.0085],\n",
       "                       [ 0.0176, -0.0074, -0.0351,  ..., -0.0420,  0.0276, -0.0018]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.2.edge_encoder.0.bias',\n",
       "               tensor([ 0.0077,  0.0119,  0.0017, -0.0190, -0.0046,  0.0056,  0.0168,  0.0094,\n",
       "                       -0.0051,  0.0039, -0.0029,  0.0186, -0.0180,  0.0189,  0.0191, -0.0094,\n",
       "                        0.0084,  0.0184, -0.0068, -0.0066, -0.0126, -0.0144,  0.0322,  0.0054,\n",
       "                        0.0056, -0.0084,  0.0076,  0.0117, -0.0092, -0.0210,  0.0302,  0.0111,\n",
       "                        0.0049,  0.0133,  0.0009,  0.0033,  0.0078, -0.0005,  0.0011,  0.0380,\n",
       "                        0.0042, -0.0085, -0.0131, -0.0191, -0.0132, -0.0132,  0.0060,  0.0126,\n",
       "                        0.0204, -0.0218, -0.0039,  0.0289,  0.0030,  0.0034,  0.0042,  0.0069,\n",
       "                        0.0276,  0.0014,  0.0052, -0.0010,  0.0165, -0.0045, -0.0037,  0.0045,\n",
       "                        0.0175, -0.0177, -0.0008,  0.0173, -0.0091,  0.0122, -0.0022, -0.0185,\n",
       "                       -0.0071, -0.0143,  0.0194,  0.0052,  0.0028,  0.0003, -0.0044,  0.0021,\n",
       "                       -0.0239, -0.0257,  0.0002,  0.0104,  0.0085,  0.0029,  0.0085,  0.0186,\n",
       "                        0.0136, -0.0184,  0.0170,  0.0219,  0.0114,  0.0373, -0.0013, -0.0081,\n",
       "                        0.0079,  0.0001,  0.0129, -0.0018,  0.0132,  0.0188,  0.0141, -0.0070,\n",
       "                        0.0138,  0.0063, -0.0268, -0.0065,  0.0113,  0.0060,  0.0369,  0.0077,\n",
       "                        0.0054, -0.0095, -0.0127, -0.0155, -0.0099, -0.0243, -0.0093,  0.0114,\n",
       "                       -0.0292, -0.0092, -0.0165,  0.0360, -0.0180,  0.0009, -0.0012, -0.0136,\n",
       "                       -0.0028, -0.0299, -0.0139,  0.0060, -0.0042,  0.0075, -0.0028,  0.0032,\n",
       "                        0.0168, -0.0089,  0.0203,  0.0222,  0.0033, -0.0214,  0.0055, -0.0004,\n",
       "                       -0.0070, -0.0103,  0.0122,  0.0016,  0.0049,  0.0059,  0.0101, -0.0175,\n",
       "                       -0.0075,  0.0347, -0.0166,  0.0217,  0.0009, -0.0263,  0.0026,  0.0296,\n",
       "                        0.0109,  0.0100, -0.0139, -0.0151,  0.0139,  0.0117,  0.0224,  0.0200,\n",
       "                        0.0159,  0.0146, -0.0090,  0.0056,  0.0198, -0.0114,  0.0122, -0.0099,\n",
       "                       -0.0116,  0.0004, -0.0143, -0.0011,  0.0056,  0.0021,  0.0154, -0.0226,\n",
       "                       -0.0033, -0.0069, -0.0072, -0.0033, -0.0062, -0.0068, -0.0164,  0.0153,\n",
       "                       -0.0333,  0.0075, -0.0050, -0.0042, -0.0204,  0.0111, -0.0367,  0.0139],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.2.edge_encoder.1.weight',\n",
       "               tensor([0.9628, 0.9829, 0.9672, 0.9673, 0.9706, 0.9835, 0.9779, 0.9585, 0.9801,\n",
       "                       1.0104, 0.9749, 0.9749, 0.9704, 0.9653, 0.9617, 0.9588, 0.9810, 0.9747,\n",
       "                       0.9706, 0.9653, 0.9548, 0.9736, 0.9918, 0.9715, 0.9768, 0.9686, 0.9768,\n",
       "                       0.9644, 0.9705, 0.9647, 0.9775, 0.9654, 0.9791, 0.9719, 0.9689, 1.0024,\n",
       "                       0.9714, 0.9612, 0.9602, 0.9835, 0.9716, 0.9771, 0.9913, 0.9704, 0.9972,\n",
       "                       0.9774, 0.9673, 0.9556, 0.9649, 0.9712, 0.9714, 0.9532, 0.9586, 0.9630,\n",
       "                       0.9654, 0.9569, 0.9866, 0.9909, 0.9710, 0.9789, 0.9821, 0.9766, 0.9629,\n",
       "                       1.0112, 0.9736, 1.0307, 0.9648, 0.9848, 0.9644, 0.9779, 0.9688, 0.9556,\n",
       "                       0.9911, 0.9716, 0.9692, 0.9976, 0.9801, 0.9737, 0.9750, 1.0032, 0.9712,\n",
       "                       0.9831, 0.9793, 1.0119, 0.9947, 0.9525, 0.9689, 1.0086, 0.9671, 0.9862,\n",
       "                       0.9723, 0.9898, 0.9515, 0.9780, 0.9625, 0.9707, 0.9851, 0.9711, 0.9946,\n",
       "                       0.9929, 1.0127, 0.9705, 0.9535, 0.9593, 0.9769, 0.9911, 0.9627, 0.9748,\n",
       "                       0.9724, 0.9391, 0.9803, 0.9876, 0.9843, 0.9748, 0.9582, 0.9636, 0.9737,\n",
       "                       0.9705, 0.9908, 0.9860, 0.9873, 0.9901, 0.9624, 0.9739, 0.9752, 0.9613,\n",
       "                       0.9775, 0.9644, 0.9877, 0.9880, 0.9751, 0.9752, 0.9599, 0.9629, 0.9751,\n",
       "                       0.9859, 0.9705, 0.9769, 0.9848, 0.9831, 0.9677, 1.0146, 0.9704, 0.9786,\n",
       "                       0.9771, 0.9810, 0.9668, 0.9568, 0.9419, 0.9776, 0.9674, 0.9866, 0.9767,\n",
       "                       0.9543, 0.9812, 1.0107, 0.9792, 0.9727, 0.9707, 0.9655, 0.9763, 0.9820,\n",
       "                       0.9982, 0.9833, 0.9660, 1.0028, 0.9630, 0.9713, 1.0131, 0.9784, 0.9664,\n",
       "                       0.9688, 0.9602, 0.9605, 0.9668, 0.9759, 0.9633, 0.9736, 0.9751, 0.9571,\n",
       "                       0.9551, 0.9673, 0.9850, 0.9753, 0.9827, 0.9796, 0.9681, 0.9709, 0.9784,\n",
       "                       0.9611, 0.9603, 0.9895, 0.9809, 0.9890, 0.9777, 0.9484, 0.9913, 0.9686,\n",
       "                       1.0060, 0.9723], device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.2.edge_encoder.1.bias',\n",
       "               tensor([-2.5693e-02, -9.7445e-03, -1.3280e-02, -1.4876e-02, -1.3010e-02,\n",
       "                       -2.8902e-02, -1.5408e-02, -1.3348e-02, -7.5672e-03,  1.6497e-03,\n",
       "                       -7.8495e-03, -9.1716e-03, -2.0961e-02, -2.2757e-02, -2.0028e-02,\n",
       "                       -1.7987e-02, -7.9770e-03, -1.8736e-03, -5.3145e-03, -3.8504e-03,\n",
       "                       -1.5113e-02, -2.7974e-02,  2.6333e-03, -8.1461e-03, -1.9291e-02,\n",
       "                       -1.5892e-03,  1.6622e-04, -1.8932e-02, -1.3259e-02, -2.7374e-02,\n",
       "                       -1.4522e-02, -1.6898e-02, -8.0646e-03, -1.0664e-02, -1.0739e-02,\n",
       "                       -1.7976e-03, -1.9121e-02, -1.7618e-02, -1.1595e-02, -8.5707e-03,\n",
       "                       -1.0648e-02, -1.1552e-02, -1.4868e-02, -9.6961e-03, -2.4517e-02,\n",
       "                       -7.4088e-03,  7.0666e-03, -1.7505e-02, -1.4665e-02, -2.4669e-02,\n",
       "                       -2.5899e-02, -3.7980e-02, -2.2516e-02, -3.0423e-03, -9.7302e-03,\n",
       "                       -2.5835e-02, -2.2611e-03, -4.0520e-03, -6.8373e-03, -1.9277e-02,\n",
       "                       -8.0628e-03, -1.8217e-02, -1.6750e-02, -1.5095e-02, -1.4788e-03,\n",
       "                       -3.7971e-02, -1.9556e-02,  1.5557e-04, -7.2736e-03, -3.9847e-03,\n",
       "                       -1.2300e-02, -1.9903e-02, -1.9171e-02, -9.9416e-03, -5.3805e-03,\n",
       "                        1.5913e-03, -7.6342e-03, -3.3007e-03, -6.2690e-03, -1.4096e-05,\n",
       "                       -1.5686e-02, -6.8913e-03, -1.7321e-02, -2.5634e-02, -1.4783e-02,\n",
       "                       -2.4108e-02, -1.3706e-02, -2.0894e-02, -2.0094e-02, -6.5898e-03,\n",
       "                       -1.2185e-02, -6.1023e-03, -2.7504e-02, -2.4717e-02, -2.5939e-02,\n",
       "                       -1.5674e-02, -5.1389e-03, -7.2659e-03,  4.9414e-03, -1.5022e-03,\n",
       "                       -1.3755e-02, -2.0142e-02, -2.5539e-02, -3.3021e-02, -1.7456e-02,\n",
       "                       -7.0987e-03, -1.8066e-02, -7.1374e-03, -9.0562e-03, -4.0189e-02,\n",
       "                       -4.1441e-03, -9.2944e-03, -8.8290e-03, -1.3431e-02, -1.1504e-02,\n",
       "                       -2.5691e-02, -1.5559e-02, -2.4027e-02, -1.8737e-02, -6.9398e-03,\n",
       "                       -1.3982e-02, -9.3979e-03, -2.2429e-02, -1.6925e-02, -1.1936e-02,\n",
       "                       -2.2714e-02, -8.0626e-03, -2.0102e-02, -1.1027e-02, -1.1894e-02,\n",
       "                       -2.9027e-02, -1.0246e-02, -2.0020e-02, -2.4571e-02,  1.9411e-03,\n",
       "                       -2.1970e-02, -1.8667e-02, -1.4658e-02, -3.9352e-03, -1.8957e-02,\n",
       "                       -9.4686e-03, -2.8255e-02,  5.2848e-04,  7.7191e-03, -1.7395e-02,\n",
       "                       -1.0582e-02, -1.7854e-02, -2.6494e-02, -3.3694e-02, -2.2807e-02,\n",
       "                       -2.3661e-02, -5.3341e-03, -7.3770e-03, -3.4522e-02, -2.7705e-02,\n",
       "                       -7.6568e-03, -5.1986e-03,  6.7720e-03, -2.3240e-02, -3.5141e-02,\n",
       "                       -1.3055e-02, -8.6289e-03, -2.5888e-02, -1.1771e-02, -1.2512e-02,\n",
       "                       -1.8411e-02, -3.3645e-02, -7.4316e-03, -1.2644e-02, -7.5547e-03,\n",
       "                       -1.6641e-02, -1.9724e-02, -2.6223e-02, -1.5339e-02, -6.3751e-03,\n",
       "                       -5.5682e-03, -2.3769e-02, -8.3162e-03, -7.2813e-03, -3.8014e-02,\n",
       "                       -2.6523e-02, -2.3696e-02, -9.4407e-03, -1.6965e-02, -1.8803e-02,\n",
       "                        4.4039e-03, -1.6914e-02, -1.6613e-02,  7.9222e-03, -2.1573e-02,\n",
       "                       -5.3399e-03, -1.7694e-02, -4.4106e-03, -3.1973e-03, -3.3638e-03,\n",
       "                       -3.0254e-02,  3.6135e-03, -1.7349e-02,  2.9815e-03, -8.8753e-03],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.2.edge_encoder.1.running_mean',\n",
       "               tensor([ 2.7008e-02,  1.6912e-03,  1.5797e-02, -6.7778e-02,  2.0418e-02,\n",
       "                       -1.1173e-02,  1.5179e-02,  2.4307e-02,  1.2653e-02,  4.6869e-03,\n",
       "                       -1.0762e-02, -1.9674e-03, -1.3291e-02,  3.0813e-02, -1.3610e-03,\n",
       "                        4.5526e-03,  2.5402e-02,  2.0468e-02,  1.6868e-02,  1.5769e-02,\n",
       "                       -3.7985e-03, -2.9739e-02,  3.6873e-02, -1.5693e-03, -2.0923e-02,\n",
       "                        4.5054e-02,  3.2104e-02, -3.1810e-03,  5.9307e-03, -2.4748e-03,\n",
       "                        2.8697e-02,  2.8321e-03,  4.0958e-02,  2.8253e-02,  3.6128e-02,\n",
       "                       -1.6234e-02,  1.5718e-02,  2.1499e-02,  3.2818e-02,  4.5780e-02,\n",
       "                        1.8265e-02, -2.2358e-02,  1.0330e-02, -8.1752e-03, -7.3849e-02,\n",
       "                       -7.7433e-02, -9.5062e-03,  5.6934e-02,  2.9798e-02, -5.6704e-02,\n",
       "                       -2.8998e-04,  3.8911e-02,  7.1862e-02,  2.8319e-02, -1.3835e-03,\n",
       "                        2.4380e-02,  4.7917e-02, -7.5812e-03,  4.3195e-02, -8.7772e-03,\n",
       "                        3.0336e-02, -2.1767e-02, -2.0313e-02, -5.7155e-02,  2.2238e-02,\n",
       "                       -1.7876e-02,  7.2475e-03,  5.9072e-02,  1.7254e-02,  3.5640e-02,\n",
       "                       -5.3690e-02,  3.1887e-02, -6.1408e-02,  1.1748e-02, -2.8399e-02,\n",
       "                        3.6311e-02,  3.8973e-02,  6.4906e-02,  7.8385e-03, -2.0935e-02,\n",
       "                       -5.8416e-02, -2.0047e-02, -3.1496e-02,  2.9189e-02, -3.4504e-02,\n",
       "                       -2.7514e-02,  6.8505e-02,  2.8062e-03,  1.8849e-05, -1.3774e-02,\n",
       "                        9.2343e-03,  3.7521e-02,  4.5121e-02,  1.4074e-02, -1.8121e-04,\n",
       "                       -4.0558e-02, -3.7644e-03,  1.6923e-02,  2.7104e-02, -1.5634e-02,\n",
       "                       -4.1377e-03,  9.3574e-03,  1.9628e-02,  5.6155e-02,  5.2343e-02,\n",
       "                        8.2967e-03, -3.7830e-03, -4.8709e-03, -8.8138e-03,  5.4959e-02,\n",
       "                        9.5033e-02, -8.7470e-03, -2.1711e-03, -2.7213e-02,  2.7870e-02,\n",
       "                       -6.4279e-02, -1.5909e-02, -4.3667e-02, -1.5132e-02, -9.5939e-03,\n",
       "                       -1.8963e-02, -6.7713e-03, -5.5545e-02, -1.0497e-02, -3.9040e-02,\n",
       "                       -4.8672e-03,  1.1762e-02, -1.5282e-02, -4.3349e-02, -5.3518e-02,\n",
       "                        4.6776e-03, -4.4651e-02, -4.5448e-02, -1.2307e-02,  1.7775e-02,\n",
       "                       -4.1911e-03,  2.1014e-02, -4.3004e-03,  2.7901e-02,  1.0977e-02,\n",
       "                       -7.3112e-03, -3.7840e-02, -1.7166e-03,  1.3762e-02, -2.5244e-02,\n",
       "                        1.1566e-02,  7.3994e-02, -4.3874e-03,  4.3512e-02, -4.0878e-02,\n",
       "                        1.8922e-03, -1.0121e-02, -2.9110e-02,  2.4583e-02, -4.8153e-02,\n",
       "                        2.5973e-02, -2.9922e-03, -2.0870e-02, -2.2877e-02, -1.4993e-03,\n",
       "                       -5.9943e-03, -7.2241e-03, -2.0146e-02,  1.2459e-02, -3.8290e-03,\n",
       "                       -2.0011e-02,  3.9809e-02,  1.3255e-02, -4.2352e-04,  1.7046e-02,\n",
       "                       -6.5159e-03,  1.2209e-02,  6.6373e-02, -1.1389e-02,  5.5789e-02,\n",
       "                        1.8531e-02, -1.1453e-02,  2.1218e-02,  1.8626e-02,  1.3585e-02,\n",
       "                       -3.0026e-02,  1.2386e-02, -9.9208e-03, -2.6795e-04, -8.1980e-03,\n",
       "                       -1.3025e-02, -1.7465e-02,  3.8352e-04, -2.6250e-02, -3.8193e-02,\n",
       "                        1.8636e-02, -7.6045e-03, -3.9300e-02,  1.3399e-03,  1.3233e-02,\n",
       "                        1.9639e-02, -1.1317e-02, -1.9422e-02, -3.2577e-02,  5.8234e-02],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.2.edge_encoder.1.running_var',\n",
       "               tensor([0.0007, 0.0011, 0.0017, 0.0010, 0.0004, 0.0005, 0.0011, 0.0008, 0.0008,\n",
       "                       0.0006, 0.0011, 0.0012, 0.0004, 0.0011, 0.0017, 0.0008, 0.0009, 0.0008,\n",
       "                       0.0008, 0.0017, 0.0010, 0.0005, 0.0005, 0.0005, 0.0007, 0.0009, 0.0004,\n",
       "                       0.0016, 0.0005, 0.0014, 0.0013, 0.0005, 0.0005, 0.0010, 0.0009, 0.0005,\n",
       "                       0.0009, 0.0014, 0.0012, 0.0007, 0.0004, 0.0008, 0.0005, 0.0008, 0.0010,\n",
       "                       0.0010, 0.0010, 0.0012, 0.0016, 0.0011, 0.0004, 0.0004, 0.0009, 0.0014,\n",
       "                       0.0009, 0.0013, 0.0004, 0.0005, 0.0009, 0.0005, 0.0003, 0.0009, 0.0005,\n",
       "                       0.0007, 0.0009, 0.0004, 0.0008, 0.0009, 0.0006, 0.0004, 0.0013, 0.0007,\n",
       "                       0.0007, 0.0006, 0.0007, 0.0004, 0.0007, 0.0007, 0.0007, 0.0003, 0.0020,\n",
       "                       0.0011, 0.0006, 0.0004, 0.0010, 0.0019, 0.0012, 0.0007, 0.0005, 0.0004,\n",
       "                       0.0005, 0.0009, 0.0012, 0.0007, 0.0007, 0.0014, 0.0015, 0.0009, 0.0009,\n",
       "                       0.0006, 0.0004, 0.0006, 0.0008, 0.0008, 0.0012, 0.0005, 0.0013, 0.0009,\n",
       "                       0.0006, 0.0015, 0.0007, 0.0006, 0.0007, 0.0010, 0.0010, 0.0010, 0.0005,\n",
       "                       0.0006, 0.0006, 0.0005, 0.0003, 0.0008, 0.0007, 0.0010, 0.0008, 0.0009,\n",
       "                       0.0008, 0.0012, 0.0011, 0.0014, 0.0014, 0.0012, 0.0019, 0.0012, 0.0016,\n",
       "                       0.0008, 0.0008, 0.0006, 0.0006, 0.0012, 0.0004, 0.0006, 0.0020, 0.0009,\n",
       "                       0.0004, 0.0004, 0.0010, 0.0010, 0.0006, 0.0004, 0.0008, 0.0006, 0.0010,\n",
       "                       0.0016, 0.0006, 0.0004, 0.0010, 0.0015, 0.0007, 0.0009, 0.0008, 0.0008,\n",
       "                       0.0005, 0.0006, 0.0010, 0.0003, 0.0010, 0.0007, 0.0005, 0.0007, 0.0007,\n",
       "                       0.0008, 0.0009, 0.0022, 0.0009, 0.0007, 0.0006, 0.0006, 0.0006, 0.0014,\n",
       "                       0.0004, 0.0004, 0.0003, 0.0004, 0.0008, 0.0010, 0.0010, 0.0010, 0.0016,\n",
       "                       0.0016, 0.0008, 0.0008, 0.0017, 0.0004, 0.0013, 0.0004, 0.0015, 0.0007,\n",
       "                       0.0011, 0.0009], device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.2.edge_encoder.1.num_batches_tracked',\n",
       "               tensor(318750, device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.2.edge_encoder.3.weight',\n",
       "               tensor([[-0.0193, -0.0094, -0.0241,  ...,  0.0122, -0.0301, -0.0028],\n",
       "                       [ 0.0069,  0.0188,  0.0111,  ..., -0.0008, -0.0141,  0.0301],\n",
       "                       [ 0.0371, -0.0236, -0.0005,  ..., -0.0178,  0.0145,  0.0044],\n",
       "                       ...,\n",
       "                       [ 0.0266,  0.0113,  0.0204,  ..., -0.0058,  0.0168, -0.0279],\n",
       "                       [ 0.0263, -0.0120,  0.0145,  ..., -0.0088,  0.0285, -0.0355],\n",
       "                       [ 0.0217,  0.0041,  0.0519,  ...,  0.0308, -0.0709, -0.0156]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.2.edge_encoder.3.bias',\n",
       "               tensor([-2.3653e-03, -5.7033e-03,  2.7150e-03,  1.7915e-03, -1.3082e-03,\n",
       "                       -3.1844e-04,  8.8534e-04, -5.2766e-03,  1.3499e-03,  4.7690e-03,\n",
       "                       -4.6336e-03,  1.4850e-03, -3.2236e-03,  3.7453e-03, -8.5289e-03,\n",
       "                        7.5043e-03,  5.8532e-03,  2.3962e-04, -5.7625e-04,  5.2903e-04,\n",
       "                       -1.7449e-03,  5.2435e-03,  2.9055e-03, -4.1971e-03, -5.6767e-03,\n",
       "                       -4.0691e-03, -1.4285e-03,  5.0252e-03, -1.9099e-03,  1.1951e-03,\n",
       "                        2.1446e-03, -2.3171e-03,  5.1971e-03,  1.3342e-03, -6.3974e-03,\n",
       "                        7.7394e-04, -5.0417e-03, -4.6538e-04,  8.4626e-03, -4.4000e-04,\n",
       "                       -7.0619e-04,  4.7418e-03, -5.4846e-03, -5.1588e-03, -7.3695e-03,\n",
       "                       -9.4579e-03,  4.9077e-03, -5.9823e-03,  1.0702e-03, -2.1661e-03,\n",
       "                        1.0390e-03,  1.1983e-03, -4.2399e-03, -1.2942e-03, -7.8520e-03,\n",
       "                       -3.5293e-03, -1.0280e-02,  3.5102e-04,  3.8343e-03, -1.2780e-03,\n",
       "                        4.5618e-04,  3.8666e-03,  1.8226e-03,  4.2149e-03, -7.9116e-03,\n",
       "                       -6.3569e-03,  7.4834e-04,  4.8660e-04, -3.4787e-03, -3.4874e-03,\n",
       "                       -2.9350e-03,  6.0196e-03,  2.0707e-03,  6.1710e-03, -2.5195e-04,\n",
       "                        2.7551e-03, -3.0170e-03, -3.2106e-03, -5.5723e-05,  5.0233e-03,\n",
       "                       -5.5378e-03, -8.5195e-03,  2.5666e-03, -1.8356e-03,  1.2716e-03,\n",
       "                       -1.2945e-03,  1.9425e-03,  8.8292e-04,  2.0636e-03,  1.4934e-03,\n",
       "                       -1.9848e-03,  9.8496e-03, -2.1664e-03,  1.9293e-03, -3.8735e-03,\n",
       "                       -5.7664e-03,  3.7731e-03, -2.0194e-03,  5.2783e-03,  3.5625e-03,\n",
       "                       -4.3390e-03, -4.5637e-03,  6.6010e-03,  3.1173e-03,  4.0452e-03,\n",
       "                       -2.6583e-03,  4.5262e-03, -1.5825e-03, -4.2482e-03, -3.4520e-03,\n",
       "                        2.3763e-03,  3.6228e-03,  1.7307e-03,  1.0506e-03,  4.2683e-03,\n",
       "                       -3.5708e-04, -2.0222e-03, -1.5319e-03,  4.2033e-03, -6.7279e-03,\n",
       "                        1.4046e-03,  2.9070e-03,  3.6665e-03,  1.5358e-03,  2.2912e-03,\n",
       "                        1.5417e-03, -5.5028e-03,  1.9160e-03, -3.6478e-03, -3.0722e-03,\n",
       "                       -6.0849e-04,  4.6370e-03,  1.5033e-03,  7.6505e-03,  1.1843e-03,\n",
       "                       -2.6880e-03, -7.3885e-04, -1.9909e-03, -4.8474e-03,  7.0672e-03,\n",
       "                        7.6360e-03, -5.4759e-03, -6.0674e-03, -1.4287e-03,  1.6351e-03,\n",
       "                        4.7338e-03, -4.7588e-03, -5.5839e-03,  1.8682e-03, -1.0032e-03,\n",
       "                       -1.1349e-04,  6.5163e-03,  7.6160e-04,  6.0492e-03,  2.1817e-03,\n",
       "                        5.5140e-04, -5.6854e-03,  2.1677e-04,  1.8623e-03,  1.7347e-03,\n",
       "                       -3.2468e-03,  2.5972e-03, -1.4406e-03, -4.4453e-03, -6.4311e-03,\n",
       "                       -3.7272e-03,  2.8988e-03, -3.4194e-03,  8.8222e-04,  3.5037e-03,\n",
       "                        4.3227e-04, -1.8212e-03,  1.9136e-03, -3.1052e-03, -5.8780e-03,\n",
       "                       -9.3809e-04,  2.1546e-03, -5.0847e-03, -5.3777e-03, -3.2735e-03,\n",
       "                        1.7199e-04, -1.1658e-03,  3.6198e-03,  4.1820e-03,  1.1943e-04,\n",
       "                       -1.7642e-03,  4.1916e-03,  8.8105e-04, -6.2575e-03,  6.1010e-03,\n",
       "                       -4.3334e-04,  1.6691e-03,  8.9472e-06,  5.3347e-03,  4.1516e-03,\n",
       "                        4.4639e-03,  4.7324e-03, -6.6560e-04, -5.5783e-03,  1.1676e-03],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.2.linear_key.weight',\n",
       "               tensor([[-0.0050,  0.0286, -0.0298,  ...,  0.0195,  0.0095,  0.0048],\n",
       "                       [-0.0067, -0.0032,  0.0213,  ...,  0.0169, -0.0141,  0.0331],\n",
       "                       [-0.0307, -0.0036, -0.0123,  ..., -0.0191, -0.0231,  0.0377],\n",
       "                       ...,\n",
       "                       [-0.0191, -0.0043, -0.0128,  ..., -0.0029,  0.0061, -0.0056],\n",
       "                       [-0.0050, -0.0293, -0.0038,  ..., -0.0536,  0.0291,  0.0308],\n",
       "                       [ 0.0055, -0.0071,  0.0039,  ..., -0.0004, -0.0236, -0.0107]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.2.linear_key.bias',\n",
       "               tensor([ 0.0031,  0.0115,  0.0075,  0.0047, -0.0123, -0.0102,  0.0011, -0.0035,\n",
       "                        0.0029, -0.0103,  0.0116, -0.0100, -0.0151,  0.0058,  0.0023, -0.0030,\n",
       "                       -0.0099,  0.0140, -0.0279, -0.0145, -0.0154, -0.0037, -0.0073, -0.0116,\n",
       "                        0.0035,  0.0055, -0.0106,  0.0162, -0.0039,  0.0056,  0.0088, -0.0053,\n",
       "                        0.0087,  0.0002,  0.0119,  0.0153,  0.0012, -0.0048, -0.0126, -0.0043,\n",
       "                        0.0077,  0.0078, -0.0044, -0.0038,  0.0038, -0.0140, -0.0092, -0.0075,\n",
       "                       -0.0027, -0.0022,  0.0048, -0.0042, -0.0034, -0.0051,  0.0084, -0.0106,\n",
       "                        0.0034, -0.0025, -0.0120,  0.0067,  0.0013,  0.0271, -0.0268, -0.0256,\n",
       "                        0.0021,  0.0023,  0.0018,  0.0145,  0.0183, -0.0120, -0.0223, -0.0051,\n",
       "                       -0.0124, -0.0263,  0.0059,  0.0081, -0.0039, -0.0102, -0.0187,  0.0215,\n",
       "                        0.0310,  0.0283, -0.0033,  0.0053,  0.0123,  0.0291,  0.0010, -0.0197,\n",
       "                       -0.0110, -0.0105, -0.0156, -0.0107,  0.0133,  0.0156,  0.0083,  0.0119,\n",
       "                       -0.0038, -0.0128, -0.0107,  0.0189, -0.0177, -0.0071,  0.0112,  0.0092,\n",
       "                       -0.0139, -0.0008,  0.0108,  0.0039, -0.0166, -0.0262, -0.0043,  0.0034,\n",
       "                        0.0132,  0.0079, -0.0082, -0.0199, -0.0052,  0.0032,  0.0045, -0.0045,\n",
       "                       -0.0052,  0.0026,  0.0061,  0.0113, -0.0002, -0.0280,  0.0036,  0.0107,\n",
       "                       -0.0053, -0.0104,  0.0116, -0.0212, -0.0079,  0.0055, -0.0132,  0.0025,\n",
       "                       -0.0148, -0.0249, -0.0187,  0.0306,  0.0206, -0.0100,  0.0282,  0.0104,\n",
       "                       -0.0083,  0.0274, -0.0031, -0.0042,  0.0108, -0.0194, -0.0102, -0.0107,\n",
       "                        0.0027, -0.0333, -0.0202,  0.0077,  0.0174, -0.0057,  0.0097,  0.0137,\n",
       "                       -0.0057, -0.0141,  0.0022,  0.0055, -0.0076, -0.0112,  0.0037,  0.0040,\n",
       "                        0.0230, -0.0255,  0.0031, -0.0287, -0.0073, -0.0044, -0.0057,  0.0140,\n",
       "                        0.0121, -0.0055,  0.0044,  0.0260,  0.0103, -0.0086, -0.0082,  0.0011,\n",
       "                       -0.0143, -0.0008,  0.0168, -0.0138,  0.0104,  0.0175, -0.0011, -0.0126,\n",
       "                       -0.0118,  0.0039,  0.0094,  0.0058,  0.0031, -0.0157,  0.0182,  0.0174],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.2.linear_msg.weight',\n",
       "               tensor([[ 0.0234, -0.0279,  0.0103,  ..., -0.0244,  0.0069, -0.0083],\n",
       "                       [ 0.0144,  0.0296,  0.0031,  ...,  0.0054,  0.0159, -0.0063],\n",
       "                       [ 0.0312,  0.0186,  0.0028,  ..., -0.0151, -0.0157,  0.0044],\n",
       "                       ...,\n",
       "                       [ 0.0299, -0.0076,  0.0167,  ..., -0.0208, -0.0082, -0.0151],\n",
       "                       [-0.0178,  0.0180,  0.0519,  ...,  0.0306, -0.0058,  0.0247],\n",
       "                       [-0.0082,  0.0046,  0.0048,  ...,  0.0122, -0.0337, -0.0204]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.2.linear_msg.bias',\n",
       "               tensor([ 3.5557e-03, -3.3683e-03,  7.3093e-03,  3.1990e-03,  5.7287e-04,\n",
       "                       -3.5040e-03, -2.4501e-03,  4.3191e-03,  4.5917e-03,  1.8703e-03,\n",
       "                       -2.9002e-03,  1.5357e-02,  1.4043e-03,  4.7136e-03,  3.7502e-04,\n",
       "                        7.5452e-03,  1.3831e-04,  1.4531e-03,  1.1832e-02, -3.2456e-03,\n",
       "                       -8.0041e-03, -5.3356e-03,  1.3095e-02, -2.2812e-03, -2.0043e-03,\n",
       "                       -2.0252e-04,  2.5035e-03, -1.2835e-03,  1.6587e-03, -3.9106e-03,\n",
       "                        3.8810e-03, -3.3573e-03,  6.2365e-04,  1.5213e-03, -8.0388e-03,\n",
       "                       -1.2511e-04, -9.7592e-04, -6.2524e-04, -1.1221e-03, -7.2151e-03,\n",
       "                       -1.8895e-03,  3.2902e-03, -6.8993e-03, -2.2584e-03, -3.1210e-03,\n",
       "                       -2.2678e-03,  5.2657e-03, -2.8013e-03, -7.7860e-04,  6.1690e-03,\n",
       "                        1.8209e-03,  8.3377e-03, -4.3679e-03, -2.2022e-03,  3.4671e-03,\n",
       "                       -3.3009e-03, -4.1262e-03, -9.9036e-04, -6.7728e-03,  9.7956e-03,\n",
       "                        1.1102e-02,  6.0470e-03, -8.3191e-03,  4.6018e-03, -8.0117e-04,\n",
       "                        6.1408e-03,  1.0074e-02, -1.3606e-02,  7.1714e-04, -6.9246e-03,\n",
       "                        1.5943e-02,  1.5409e-02,  7.2093e-03, -6.2534e-03,  2.9874e-03,\n",
       "                        9.4798e-03,  8.9367e-03, -4.7450e-03, -3.5330e-03,  5.4665e-03,\n",
       "                       -7.4053e-03, -3.5909e-03, -3.4037e-03, -9.6878e-03, -6.3166e-03,\n",
       "                       -6.9543e-03, -4.8313e-03, -4.6280e-03,  1.4641e-02, -1.0825e-02,\n",
       "                        4.8183e-03,  1.1814e-02, -7.2031e-03, -3.7738e-05, -1.2903e-02,\n",
       "                       -7.9356e-03,  6.0336e-03, -9.2157e-03, -1.0405e-02,  1.5260e-03,\n",
       "                       -1.2206e-03,  2.8135e-03, -6.4011e-03,  1.9506e-04,  1.3696e-03,\n",
       "                        1.8914e-03, -4.6111e-03,  4.1951e-03,  8.4058e-03, -3.4946e-05,\n",
       "                        2.5874e-03,  5.9644e-03, -1.5645e-03, -3.7658e-03, -7.1780e-03,\n",
       "                        8.0830e-04, -6.4758e-04,  1.2526e-02, -1.4460e-02,  5.7091e-04,\n",
       "                        2.1390e-03, -3.7827e-03,  3.8974e-03, -1.2054e-03, -6.0569e-03,\n",
       "                        4.8305e-04,  3.4000e-03,  1.2341e-03, -4.7774e-04, -6.2685e-03,\n",
       "                       -5.5003e-03,  7.3050e-03, -3.6272e-03,  3.8701e-03, -5.0708e-04,\n",
       "                        1.3514e-03,  1.2959e-03,  5.2070e-03,  9.6303e-03,  6.0838e-03,\n",
       "                        6.3478e-03,  5.6866e-03,  1.1448e-03, -1.4471e-02, -7.2873e-04,\n",
       "                       -2.0081e-03, -5.6453e-03,  6.2539e-03,  7.0338e-03,  2.8993e-03,\n",
       "                       -9.8970e-03, -6.2293e-03, -4.4407e-03,  7.0187e-05,  1.0056e-03,\n",
       "                       -2.6419e-03,  4.6824e-03,  6.8164e-03,  3.5277e-03, -9.8037e-03,\n",
       "                       -1.0242e-02,  5.1112e-03, -3.3304e-03,  3.6380e-03, -1.7803e-03,\n",
       "                       -6.4673e-03, -1.0467e-02,  2.3282e-03,  6.8396e-03,  1.1173e-02,\n",
       "                        7.0380e-03, -9.3256e-03,  6.7246e-03,  6.6077e-03,  1.5466e-02,\n",
       "                       -1.0292e-03, -1.4538e-02, -8.6535e-03, -3.6473e-03,  6.1595e-03,\n",
       "                        3.5209e-03,  1.6608e-02,  8.0942e-03, -8.1379e-03, -8.0691e-04,\n",
       "                        1.7681e-02,  1.0757e-02, -9.3825e-04, -1.9188e-03, -4.1992e-03,\n",
       "                        1.1618e-02, -2.8175e-03,  3.4841e-03,  3.1969e-03, -3.2854e-03,\n",
       "                       -1.0237e-02,  5.2765e-03,  1.4662e-02, -1.6197e-02, -4.6431e-03],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.2.linear_query.weight',\n",
       "               tensor([[-0.0102,  0.0240,  0.0161,  ...,  0.0230, -0.0343,  0.0014],\n",
       "                       [-0.0187,  0.0017,  0.0214,  ..., -0.0012,  0.0257, -0.0325],\n",
       "                       [ 0.0013,  0.0147, -0.0097,  ..., -0.0008, -0.0222,  0.0151],\n",
       "                       ...,\n",
       "                       [ 0.0151,  0.0154,  0.0266,  ...,  0.0318,  0.0185,  0.0108],\n",
       "                       [ 0.0094,  0.0029,  0.0079,  ..., -0.0141, -0.0363, -0.0174],\n",
       "                       [-0.0522,  0.0188,  0.0139,  ...,  0.0138, -0.0021,  0.0313]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.2.linear_query.bias',\n",
       "               tensor([ 0.0229, -0.0248, -0.0207, -0.0280, -0.0243,  0.0315, -0.0306,  0.0003,\n",
       "                        0.0065,  0.0192, -0.0325,  0.0232, -0.0035, -0.0195,  0.0279,  0.0327,\n",
       "                        0.0314, -0.0299,  0.0220, -0.0105,  0.0195,  0.0008,  0.0225,  0.0285,\n",
       "                       -0.0259, -0.0243,  0.0331, -0.0255,  0.0339,  0.0066,  0.0234, -0.0201,\n",
       "                        0.0344,  0.0156, -0.0338, -0.0284,  0.0240,  0.0259,  0.0268, -0.0249,\n",
       "                       -0.0184,  0.0329,  0.0247,  0.0184,  0.0244,  0.0227,  0.0347,  0.0176,\n",
       "                       -0.0339, -0.0110,  0.0053, -0.0154, -0.0314,  0.0063,  0.0151, -0.0204,\n",
       "                       -0.0055,  0.0050, -0.0043,  0.0043,  0.0169,  0.0198, -0.0026, -0.0255,\n",
       "                        0.0006, -0.0088, -0.0110,  0.0331,  0.0203, -0.0274, -0.0205, -0.0176,\n",
       "                       -0.0117, -0.0116,  0.0156, -0.0186, -0.0148, -0.0154, -0.0262,  0.0164,\n",
       "                        0.0032,  0.0218,  0.0129,  0.0008,  0.0053,  0.0088,  0.0003, -0.0076,\n",
       "                        0.0015, -0.0261, -0.0265, -0.0157,  0.0206,  0.0236,  0.0178,  0.0197,\n",
       "                       -0.0176, -0.0021,  0.0021, -0.0027, -0.0453, -0.0247,  0.0139,  0.0381,\n",
       "                       -0.0200,  0.0367,  0.0530, -0.0068, -0.0220, -0.0414, -0.0190, -0.0051,\n",
       "                        0.0466,  0.0493, -0.0255, -0.0221,  0.0156, -0.0458, -0.0094, -0.0342,\n",
       "                       -0.0269,  0.0326,  0.0547,  0.0229,  0.0649, -0.0338,  0.0370,  0.0173,\n",
       "                        0.0033,  0.0497,  0.0175, -0.0061, -0.0181,  0.0510, -0.0160, -0.0562,\n",
       "                       -0.0102, -0.0486, -0.0234,  0.0352,  0.0211, -0.0319,  0.0611,  0.0490,\n",
       "                       -0.0299,  0.0120, -0.0462, -0.0527,  0.0280, -0.0265, -0.0042,  0.0070,\n",
       "                        0.0154,  0.0024,  0.0049,  0.0118, -0.0049, -0.0098, -0.0037, -0.0180,\n",
       "                        0.0002,  0.0186, -0.0052,  0.0100,  0.0054,  0.0065, -0.0124,  0.0141,\n",
       "                        0.0032, -0.0030, -0.0076,  0.0158,  0.0230,  0.0131,  0.0014, -0.0120,\n",
       "                       -0.0033, -0.0063,  0.0116, -0.0042, -0.0008,  0.0055, -0.0080, -0.0083,\n",
       "                        0.0015,  0.0017, -0.0191,  0.0032, -0.0065, -0.0045, -0.0126,  0.0038,\n",
       "                       -0.0089, -0.0045, -0.0056,  0.0198, -0.0151,  0.0167,  0.0097, -0.0052],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.2.mlp.0.weight',\n",
       "               tensor([[ 0.0033, -0.0183,  0.0277,  ..., -0.0124, -0.0121, -0.0183],\n",
       "                       [-0.0050,  0.0179, -0.0056,  ..., -0.0369,  0.0033,  0.0003],\n",
       "                       [-0.0173,  0.0022, -0.0198,  ...,  0.0007,  0.0325, -0.0164],\n",
       "                       ...,\n",
       "                       [ 0.0126,  0.0157, -0.0235,  ..., -0.0402,  0.0127, -0.0104],\n",
       "                       [ 0.0044, -0.0070,  0.0353,  ...,  0.0231,  0.0206,  0.0227],\n",
       "                       [-0.0301,  0.0023, -0.0192,  ...,  0.0183, -0.0231,  0.0131]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.2.mlp.0.bias',\n",
       "               tensor([-1.1284e-02, -4.8851e-03,  1.2102e-03, -2.3576e-03, -1.6810e-02,\n",
       "                       -5.9505e-03, -1.4583e-02, -1.3196e-02, -7.6875e-03,  2.8414e-03,\n",
       "                        6.1533e-04,  7.4024e-03,  1.4893e-03, -3.6733e-03,  3.1031e-03,\n",
       "                       -1.9047e-02,  7.0520e-03,  9.8696e-03, -8.8089e-03, -3.0547e-03,\n",
       "                        9.5064e-04, -6.3215e-03, -4.1793e-04, -5.3268e-03, -1.1905e-03,\n",
       "                       -1.3343e-02,  1.8871e-02, -2.4816e-03,  8.1144e-04, -2.1901e-03,\n",
       "                       -1.8551e-03,  1.3221e-03,  1.9266e-03, -4.4540e-03,  5.6795e-03,\n",
       "                       -1.8956e-03,  3.2184e-03, -7.4837e-05, -2.2051e-03, -2.9701e-04,\n",
       "                       -9.4856e-03, -7.7798e-03, -6.9508e-03, -8.5345e-04,  1.2676e-02,\n",
       "                        2.3962e-04,  2.6541e-03, -5.8712e-03,  1.4660e-03, -1.0572e-02,\n",
       "                        2.3240e-03, -2.3950e-03,  3.7385e-03, -1.0757e-03, -5.3231e-03,\n",
       "                        3.8618e-06,  9.1415e-03, -2.3264e-03, -5.5155e-03, -4.1281e-04,\n",
       "                       -1.9577e-03, -5.4460e-03,  1.0557e-02, -5.4249e-03,  8.1611e-03,\n",
       "                        3.0906e-03,  1.1314e-04,  7.5793e-04, -2.6828e-03,  2.3193e-03,\n",
       "                        7.7505e-03, -2.6651e-04, -7.5420e-03, -1.2085e-02,  1.1013e-03,\n",
       "                       -7.8453e-03,  9.0256e-04, -4.8060e-03,  1.7421e-03,  2.1741e-03,\n",
       "                        1.0683e-02, -1.3267e-02, -6.5426e-03,  4.2389e-03, -1.1185e-02,\n",
       "                        1.8687e-03, -1.8414e-02, -2.8016e-03, -2.6849e-04,  3.5103e-03,\n",
       "                        3.3442e-03, -1.2484e-03,  8.0259e-04, -2.2083e-02, -1.9019e-02,\n",
       "                        2.9514e-03, -1.5928e-03, -7.5794e-04, -8.2260e-04,  7.9840e-04,\n",
       "                       -6.9188e-03, -3.0512e-03,  6.7043e-04, -4.6597e-03,  1.9815e-03,\n",
       "                       -1.8107e-03, -2.4113e-03, -5.5248e-04, -9.4259e-04, -2.3180e-03,\n",
       "                        4.3322e-04,  4.6038e-03, -1.0409e-02, -4.6087e-03, -4.2075e-03,\n",
       "                       -1.5905e-02, -1.2865e-02, -5.5172e-03,  1.1443e-03, -8.1086e-03,\n",
       "                       -9.7415e-03, -6.6315e-03, -8.5304e-03,  4.2073e-03,  1.6807e-03,\n",
       "                        8.2835e-04,  9.0408e-03, -3.4338e-03, -2.2048e-03, -4.4344e-03,\n",
       "                        6.2737e-03,  2.1362e-04,  1.6117e-02, -1.1636e-02,  3.6640e-04,\n",
       "                       -1.1576e-03, -3.3897e-03,  1.4295e-03, -2.4082e-03,  4.9522e-03,\n",
       "                       -8.7211e-04, -5.6396e-03, -6.8201e-04, -1.8719e-03,  5.5256e-03,\n",
       "                       -1.0254e-03, -8.0866e-03,  1.7012e-03,  5.5509e-03,  7.2070e-03,\n",
       "                        4.5989e-03,  2.0866e-03, -4.7362e-03,  6.8217e-03, -7.2540e-03,\n",
       "                       -6.2590e-03,  1.2591e-02,  2.2083e-03,  7.2825e-03, -5.1907e-03,\n",
       "                        5.8627e-03,  4.7043e-03, -1.2656e-03, -9.3565e-04,  1.9048e-03,\n",
       "                        3.0422e-03,  4.1128e-03, -8.2928e-03,  1.1911e-03, -7.4020e-03,\n",
       "                        7.3585e-03, -5.5995e-04, -2.6928e-03,  1.0748e-02, -9.2013e-03,\n",
       "                        2.9504e-03,  5.4912e-03, -5.4928e-03, -3.5354e-03, -4.0140e-05,\n",
       "                        4.2302e-03, -1.2092e-03, -7.3597e-03,  1.1647e-02,  7.2732e-03,\n",
       "                       -2.5340e-03,  2.4824e-03, -1.4984e-03, -9.9228e-03, -6.7766e-03,\n",
       "                       -2.1154e-03, -3.0980e-03, -5.0699e-03, -9.5963e-03, -1.7905e-02,\n",
       "                        7.6631e-03, -1.2705e-02, -9.4830e-03, -6.9931e-03, -3.4110e-03],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.2.mlp.1.weight',\n",
       "               tensor([0.9610, 0.9648, 0.9724, 0.9757, 0.9614, 0.9729, 0.9762, 0.9721, 0.9702,\n",
       "                       0.9727, 0.9750, 0.9701, 0.9707, 0.9579, 0.9748, 0.9718, 0.9573, 0.9653,\n",
       "                       0.9770, 0.9723, 0.9679, 0.9694, 0.9727, 0.9736, 0.9583, 0.9597, 0.9709,\n",
       "                       0.9646, 0.9643, 0.9665, 0.9508, 0.9757, 0.9745, 0.9819, 0.9653, 0.9604,\n",
       "                       0.9683, 0.9676, 0.9750, 0.9710, 0.9641, 0.9617, 0.9800, 0.9625, 0.9657,\n",
       "                       0.9507, 0.9737, 0.9517, 0.9562, 0.9606, 0.9721, 0.9744, 0.9799, 0.9642,\n",
       "                       0.9532, 0.9686, 0.9727, 0.9632, 0.9753, 0.9735, 0.9630, 0.9697, 0.9621,\n",
       "                       0.9689, 0.9825, 0.9758, 0.9779, 0.9625, 0.9826, 0.9719, 0.9813, 0.9690,\n",
       "                       0.9709, 0.9582, 0.9580, 0.9510, 0.9369, 0.9720, 0.9568, 0.9710, 0.9620,\n",
       "                       0.9685, 0.9726, 0.9797, 0.9671, 0.9669, 0.9672, 0.9791, 0.9718, 0.9476,\n",
       "                       0.9910, 0.9681, 0.9638, 0.9760, 0.9702, 0.9743, 0.9655, 0.9630, 0.9780,\n",
       "                       0.9579, 0.9679, 0.9842, 0.9779, 0.9548, 0.9670, 0.9711, 0.9793, 0.9774,\n",
       "                       0.9896, 0.9695, 0.9715, 0.9633, 0.9764, 0.9851, 0.9611, 0.9688, 0.9702,\n",
       "                       0.9487, 0.9666, 0.9645, 0.9694, 0.9632, 0.9463, 0.9770, 0.9750, 0.9743,\n",
       "                       0.9543, 0.9707, 0.9649, 0.9699, 0.9747, 0.9752, 0.9799, 0.9701, 0.9719,\n",
       "                       0.9714, 0.9809, 0.9694, 0.9592, 0.9837, 0.9616, 0.9663, 0.9695, 0.9532,\n",
       "                       0.9683, 0.9546, 0.9545, 0.9697, 0.9703, 0.9693, 0.9777, 0.9657, 0.9789,\n",
       "                       0.9611, 0.9704, 0.9732, 0.9751, 0.9617, 0.9790, 0.9661, 0.9586, 0.9583,\n",
       "                       0.9759, 0.9698, 0.9709, 0.9741, 0.9779, 0.9700, 0.9660, 0.9677, 0.9713,\n",
       "                       0.9653, 0.9618, 0.9527, 0.9659, 0.9837, 0.9737, 0.9561, 0.9528, 0.9706,\n",
       "                       0.9729, 0.9833, 0.9710, 0.9649, 0.9729, 0.9671, 0.9615, 0.9650, 0.9834,\n",
       "                       0.9649, 0.9652, 0.9650, 0.9741, 0.9673, 0.9617, 0.9641, 0.9888, 0.9596,\n",
       "                       0.9634, 0.9690], device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.2.mlp.1.bias',\n",
       "               tensor([-6.1240e-03, -2.0490e-02, -6.1568e-03, -1.5790e-02,  1.9195e-02,\n",
       "                       -1.0463e-02, -4.8692e-02, -2.7613e-02, -7.5193e-03, -3.5507e-03,\n",
       "                        1.6371e-02, -2.1050e-02,  2.3939e-02, -2.2751e-02,  1.7430e-02,\n",
       "                       -7.3674e-03, -2.4411e-02, -1.4509e-02, -2.5964e-02, -1.8335e-02,\n",
       "                       -1.1912e-02, -6.5637e-03, -2.3153e-02, -2.0549e-02,  1.7197e-03,\n",
       "                       -1.6210e-02, -1.0512e-02, -2.3755e-02, -1.9268e-02, -1.7810e-02,\n",
       "                       -6.4909e-03,  7.8663e-03, -1.2652e-02,  1.9175e-02, -1.4401e-02,\n",
       "                       -8.5590e-03, -2.4286e-03, -1.2499e-02, -9.8570e-03, -1.8805e-02,\n",
       "                       -2.0775e-02, -2.5532e-02, -3.3604e-03, -2.5661e-02,  1.5783e-02,\n",
       "                       -2.8856e-02, -9.4566e-03, -2.5915e-02, -4.0702e-03,  1.6345e-04,\n",
       "                        1.2483e-02, -1.1715e-02, -2.1569e-04, -9.6732e-03, -2.6981e-02,\n",
       "                       -8.4525e-03, -5.4613e-03, -3.9169e-03,  1.5303e-02, -2.9718e-02,\n",
       "                       -2.5357e-02, -7.8436e-03,  1.0006e-02, -1.3445e-02,  1.2611e-02,\n",
       "                        3.6377e-03,  3.4957e-03, -2.2243e-02, -7.9200e-03,  6.1218e-03,\n",
       "                        2.5842e-02, -2.5371e-02, -4.5990e-03, -1.7996e-02, -6.1422e-03,\n",
       "                       -1.9938e-02, -2.8308e-02, -8.2369e-03, -4.8432e-02, -2.1160e-03,\n",
       "                       -1.7766e-02, -1.1169e-02, -1.7043e-02,  9.5663e-03, -2.8479e-02,\n",
       "                       -2.7480e-03, -5.0248e-02, -4.9671e-03, -1.2542e-02, -9.2796e-04,\n",
       "                       -1.1169e-02,  9.3178e-03, -1.3993e-02, -1.4114e-02,  2.3288e-03,\n",
       "                       -9.0428e-03, -7.2124e-03, -2.2107e-02, -4.6714e-03, -2.3701e-02,\n",
       "                       -1.8159e-02, -1.2182e-02,  2.5050e-02, -3.3950e-02,  7.4664e-03,\n",
       "                        1.0891e-03, -3.6911e-03, -3.6664e-03, -2.6299e-03, -1.9009e-02,\n",
       "                       -3.2103e-03, -1.1103e-02, -2.1934e-02,  6.2887e-05, -5.1002e-03,\n",
       "                       -1.0132e-02, -2.1678e-02, -1.4331e-02,  1.1011e-02, -5.1645e-03,\n",
       "                       -2.4202e-02,  1.0215e-02, -2.8818e-02,  4.6237e-03, -4.5970e-03,\n",
       "                       -9.5626e-03, -4.9581e-02, -1.3041e-02,  1.2372e-03, -1.2646e-02,\n",
       "                       -5.3054e-03, -1.7655e-02,  4.7960e-03, -1.1725e-02, -9.5259e-03,\n",
       "                       -2.4150e-03, -2.4690e-02, -9.0231e-03,  1.2652e-02,  1.0612e-02,\n",
       "                       -3.3709e-02,  6.7261e-03, -1.1275e-02, -9.8663e-03, -8.9868e-03,\n",
       "                       -3.5603e-02, -2.9399e-02, -1.4285e-02, -4.7240e-03,  9.7647e-03,\n",
       "                       -1.1051e-02,  5.3087e-03, -8.2503e-04, -3.7878e-03, -1.0934e-02,\n",
       "                       -6.3278e-03, -1.8109e-02, -2.2617e-02, -1.2299e-02, -2.3731e-02,\n",
       "                       -1.9370e-02, -2.4127e-02, -1.0356e-02, -4.7337e-03,  1.2092e-02,\n",
       "                       -2.0064e-02, -1.3533e-02, -3.3310e-04, -1.7387e-02,  4.3918e-03,\n",
       "                       -2.6446e-02, -6.2157e-03,  1.2004e-02, -1.6786e-02, -1.5954e-02,\n",
       "                       -1.3820e-02, -6.2756e-03, -3.9450e-06, -2.8511e-02, -1.9857e-02,\n",
       "                       -1.6897e-02,  8.6487e-03, -8.6894e-03, -2.4654e-02, -1.6069e-03,\n",
       "                       -2.2587e-02, -3.6015e-03, -7.0541e-03, -1.8340e-02, -9.4616e-03,\n",
       "                       -1.4547e-02, -2.5621e-02, -1.3895e-02,  1.3580e-02, -3.1093e-03,\n",
       "                       -2.3308e-02, -9.9155e-05, -6.3593e-03, -4.5416e-03, -3.7272e-02],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.2.mlp.1.running_mean',\n",
       "               tensor([ 0.8303, -1.2419, -2.3097, -2.1199,  0.5161, -2.2670,  3.0922,  2.8198,\n",
       "                       -2.2673, -2.8437,  0.3924, -1.2908,  0.6406, -1.6918, -0.6915, -1.2085,\n",
       "                       -2.7616, -1.2017,  0.9373,  1.8842, -2.6021, -2.6005,  2.3392,  0.9395,\n",
       "                       -2.2562, -2.9473, -0.8573,  1.8757,  1.2875,  1.7642,  1.1980, -0.0455,\n",
       "                       -1.5185,  1.1558, -1.3143, -2.4603, -2.3840, -1.5825, -0.8291,  1.5794,\n",
       "                        1.3578, -1.1185, -1.1044, -0.4371,  0.5396, -0.5274, -1.9624,  0.6189,\n",
       "                       -1.5335,  0.7308,  1.4529,  1.0757, -1.4838,  2.4813, -2.1580, -1.8025,\n",
       "                        1.2179, -2.6690, -2.1558, -0.3065,  1.8744, -1.8761,  1.6500, -1.6641,\n",
       "                        0.8238, -1.9283,  0.6327, -1.7768, -1.6295,  0.9277,  1.3210,  1.3412,\n",
       "                       -1.2068, -2.3078,  0.7101, -1.9040, -2.9574, -1.1712,  2.5767, -2.0881,\n",
       "                       -0.9942, -1.7785, -2.4412, -2.2668, -2.8842, -2.7666,  2.0469, -1.0843,\n",
       "                       -1.6182,  2.1738, -2.3407, -0.7975,  0.2278, -0.3530,  0.4510, -2.3321,\n",
       "                       -1.5503,  3.0402, -1.7864,  1.6915, -1.7080, -2.6557,  1.0694, -0.7554,\n",
       "                       -0.5404, -2.4736, -2.3028, -0.9026, -1.6640, -1.4528, -1.5015, -1.5256,\n",
       "                       -0.6599, -2.3125,  1.6171, -0.7385, -1.7463,  1.0296, -0.8421, -0.8802,\n",
       "                        1.2803, -1.3485,  1.2996, -1.3131, -0.7808,  2.7407,  0.2878, -2.4964,\n",
       "                        2.2600, -2.1481, -2.0986, -1.9132, -1.3086, -2.3831, -2.0768, -3.0500,\n",
       "                        1.6640,  1.9357,  1.3011,  1.4731,  1.4788, -2.1873, -1.6396, -1.9729,\n",
       "                       -1.8171,  1.6395, -2.1725, -1.6482, -2.4356,  1.1730, -1.4637, -0.8881,\n",
       "                       -1.0549,  0.1815, -1.4692, -2.1475,  2.2731, -1.8244, -2.2140, -0.3678,\n",
       "                        1.6423,  3.0464, -1.0822, -2.3926,  1.4768, -2.7179, -2.1886, -1.4338,\n",
       "                       -1.7099, -1.8036,  2.5709, -0.8153,  0.7717, -1.3210,  1.2779, -2.4352,\n",
       "                       -2.2131,  1.9006,  2.0553, -1.6676, -0.8575, -0.3557,  1.8543,  0.8823,\n",
       "                       -1.4259, -1.9966, -1.0239, -2.3717, -2.2979,  0.8525, -2.2021,  0.6779,\n",
       "                       -0.5575,  2.4761,  1.7045, -1.0937, -2.1765, -2.3550,  1.3965,  2.7160],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.2.mlp.1.running_var',\n",
       "               tensor([ 7.6567,  7.2152,  9.8320, 13.2183, 10.5945, 18.7285, 31.9680, 39.6737,\n",
       "                       13.9750, 19.2513, 13.2395,  4.2182, 10.5255,  7.7199,  3.7701,  3.5169,\n",
       "                       20.9712,  7.1871, 14.0668, 20.4405, 14.7967, 24.1368, 27.6561, 14.3395,\n",
       "                       13.7610, 25.5228,  8.1007, 15.4653, 11.9040, 16.6213,  7.9934,  8.4686,\n",
       "                        7.7961, 13.1679,  3.9822, 26.3894, 16.4438,  6.8913,  6.8951, 17.5795,\n",
       "                       11.6276, 25.7982,  6.1216,  9.2506,  8.7946, 11.0476,  7.1647, 15.2910,\n",
       "                       11.4329, 10.2268, 13.7344, 10.8192,  4.9873, 26.9188, 11.5801, 11.6176,\n",
       "                       22.3323, 24.4622, 13.2052, 17.2312, 19.6947, 15.4660,  7.8659,  8.8992,\n",
       "                        8.1239, 18.3633,  7.3603, 14.7590, 10.3308,  5.2066, 14.4574,  6.8883,\n",
       "                        3.5958, 17.8272,  3.6519,  8.6386, 29.8705,  3.1111, 14.7723, 16.3070,\n",
       "                       10.2895,  6.7574, 14.7771, 15.6120, 21.2806, 18.8022, 20.4276,  6.6382,\n",
       "                        7.4209, 34.1657, 11.6490,  5.7186, 16.1182,  4.6426,  8.1763, 12.4206,\n",
       "                        6.9840, 35.9138, 25.2906, 15.8380,  9.1822, 17.6924,  7.4420,  4.1050,\n",
       "                       12.1490, 14.2341, 17.6356,  5.1978,  8.3083, 46.5002,  8.6265,  6.1155,\n",
       "                       16.6870, 13.6883, 14.3624,  3.9465,  9.4192,  6.8826,  7.4241,  2.8831,\n",
       "                       17.2076, 22.5885,  8.7049, 12.0305,  6.3687, 25.0743,  7.2606, 11.9280,\n",
       "                       18.3186,  8.8320, 19.1884, 12.4294,  5.9244, 10.8255, 26.6246, 37.5289,\n",
       "                       16.9815, 23.9416, 13.2272,  8.7240, 14.2074,  9.4403,  5.1428, 12.4803,\n",
       "                       10.3023, 11.6293, 12.4158, 18.1196, 12.5469, 14.4127,  6.5081, 14.2641,\n",
       "                        4.3938,  7.2922,  5.3457, 16.1331, 15.8369, 10.8660, 15.8458, 12.3500,\n",
       "                       26.5500, 28.3429,  6.2145, 24.9494, 18.1027, 15.9282, 10.3887,  5.2352,\n",
       "                       12.9217, 18.4363, 28.9517,  4.2616,  4.1475,  9.8633,  7.4873, 14.8568,\n",
       "                       21.6818,  9.4750, 17.2413, 30.6068,  5.7274,  8.6642,  8.0790,  6.7514,\n",
       "                       17.8713,  9.9266,  8.2369, 28.6040, 13.9913, 11.4074, 18.8710,  6.9688,\n",
       "                        5.1993, 14.8264,  9.7983, 15.8449,  9.8004, 14.8109, 25.7226, 24.7865],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.2.mlp.1.num_batches_tracked',\n",
       "               tensor(63750, device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.2.mlp.3.weight',\n",
       "               tensor([[ 0.0303, -0.0169,  0.0019,  ..., -0.0222,  0.0024, -0.0116],\n",
       "                       [-0.0239,  0.0583,  0.0070,  ..., -0.0148,  0.0087, -0.0138],\n",
       "                       [ 0.0094,  0.0290, -0.0138,  ..., -0.0024, -0.0099, -0.0095],\n",
       "                       ...,\n",
       "                       [-0.0041, -0.0024,  0.0061,  ..., -0.0036,  0.0164, -0.0283],\n",
       "                       [-0.0439, -0.0012,  0.0165,  ...,  0.0297,  0.0260, -0.0252],\n",
       "                       [ 0.0267,  0.0031,  0.0097,  ...,  0.0170,  0.0090,  0.0128]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.2.mlp.3.bias',\n",
       "               tensor([ 8.7054e-04, -6.6267e-03,  1.9747e-02,  1.3476e-02,  1.1565e-02,\n",
       "                       -4.9119e-03, -1.4323e-02,  2.9737e-02, -3.0976e-03,  6.5166e-03,\n",
       "                        1.0614e-02,  2.8126e-04, -1.7283e-03, -1.1591e-03,  5.9588e-03,\n",
       "                        1.3323e-02, -3.2746e-03,  8.8303e-03,  1.3161e-03,  3.0525e-03,\n",
       "                       -2.0261e-02,  1.6040e-02, -6.8260e-03, -3.8821e-03, -4.2605e-03,\n",
       "                        1.4317e-02, -1.4690e-02, -2.2616e-02, -6.1217e-03, -3.1910e-03,\n",
       "                        2.7103e-03,  1.8549e-02,  1.8048e-02,  1.8562e-02,  2.5272e-03,\n",
       "                        9.8293e-03, -1.1869e-02,  1.7767e-02,  2.4271e-03,  5.9234e-03,\n",
       "                        7.5009e-03, -2.8277e-03,  1.9857e-02,  4.0175e-03,  1.4523e-02,\n",
       "                       -2.7165e-03, -6.9286e-03,  2.1091e-02,  2.0177e-02, -8.6327e-04,\n",
       "                        2.7595e-02, -6.7668e-04, -1.0050e-02, -4.5129e-03, -1.6938e-03,\n",
       "                       -3.2883e-03, -1.1644e-02,  3.8751e-02, -1.1636e-02, -3.1741e-03,\n",
       "                        2.2423e-02,  4.2888e-03,  2.8705e-03, -2.5553e-03,  1.3982e-02,\n",
       "                       -2.1512e-02,  1.0843e-02,  1.1842e-02, -2.3143e-03,  1.3468e-03,\n",
       "                       -1.7977e-02, -1.2390e-03,  4.3621e-02,  1.2525e-03,  1.5094e-02,\n",
       "                        3.0714e-02, -5.0541e-03,  2.7482e-02,  4.8315e-03,  1.5723e-03,\n",
       "                       -4.2895e-03, -1.0948e-03,  1.7236e-02,  7.1153e-05,  2.0038e-02,\n",
       "                       -2.9459e-03, -7.8115e-04,  2.0600e-02,  2.4917e-02,  3.8050e-03,\n",
       "                       -6.0510e-04,  1.3227e-02, -1.1102e-02, -6.9384e-03,  1.9340e-02,\n",
       "                        3.6418e-02,  7.8827e-04, -5.0456e-03,  3.4268e-03,  5.6099e-03,\n",
       "                        1.4852e-03,  2.7232e-02, -1.0136e-02,  3.2878e-03,  9.9975e-03,\n",
       "                       -8.9942e-03,  2.4030e-02,  2.8560e-03, -1.0682e-02,  1.4672e-02,\n",
       "                       -3.4824e-04, -1.5826e-02, -1.2925e-03, -1.4908e-02,  5.6205e-03,\n",
       "                        2.5162e-03,  7.4495e-03, -4.8404e-03, -1.4742e-02,  7.0922e-03,\n",
       "                        2.5375e-03, -1.2990e-03, -7.4052e-03,  3.1700e-03, -1.4648e-02,\n",
       "                        2.2179e-02,  1.2813e-02, -1.0732e-02, -2.7754e-02,  3.2636e-02,\n",
       "                       -2.0182e-02,  1.0199e-02, -3.3452e-03,  1.3525e-02, -1.5891e-02,\n",
       "                       -1.5970e-02,  4.4147e-03, -5.7740e-03, -7.4802e-04, -8.0601e-04,\n",
       "                        2.0029e-02,  1.6532e-02, -3.0088e-03, -1.0124e-02,  2.1734e-04,\n",
       "                       -5.5306e-03, -1.1395e-03, -9.0653e-03, -1.7462e-02,  2.8172e-03,\n",
       "                       -9.0531e-03,  6.7841e-04, -7.1417e-03,  3.4618e-02,  1.7215e-02,\n",
       "                       -5.1776e-03,  8.2269e-03, -7.0922e-03, -4.5566e-03,  2.4787e-03,\n",
       "                       -8.2692e-04,  1.3688e-02,  9.5636e-03, -9.3728e-03,  2.2388e-02,\n",
       "                        2.0814e-02,  2.9135e-02, -7.9737e-03,  1.4104e-03, -1.9412e-02,\n",
       "                       -1.3269e-02, -3.7005e-03, -1.0934e-02, -8.0501e-03, -1.2621e-02,\n",
       "                        2.9776e-03,  2.1363e-02, -8.3281e-03,  5.5439e-03, -1.8556e-02,\n",
       "                       -2.9854e-03,  1.4664e-02,  2.8348e-03,  2.7314e-03, -7.4287e-03,\n",
       "                        4.4195e-04,  3.6514e-03, -4.2109e-03, -8.3028e-03,  1.5438e-03,\n",
       "                       -6.5564e-03,  1.8654e-02,  1.2327e-02,  5.9583e-03,  1.7673e-02,\n",
       "                        1.6283e-02,  1.5410e-02,  5.8159e-03,  1.9708e-02,  1.5401e-02],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.3.edge_encoder.0.weight',\n",
       "               tensor([[ 0.0306, -0.0353,  0.0325,  ..., -0.0054, -0.0064, -0.0239],\n",
       "                       [ 0.0247,  0.0387,  0.0236,  ...,  0.0328,  0.0120, -0.0459],\n",
       "                       [ 0.0180, -0.0081, -0.0130,  ..., -0.0158,  0.0251,  0.0164],\n",
       "                       ...,\n",
       "                       [ 0.0070,  0.0437, -0.0125,  ..., -0.0002, -0.0051, -0.0569],\n",
       "                       [ 0.0213,  0.0714,  0.0441,  ..., -0.0479,  0.0109, -0.0085],\n",
       "                       [ 0.0176, -0.0074, -0.0351,  ..., -0.0420,  0.0276, -0.0018]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.3.edge_encoder.0.bias',\n",
       "               tensor([ 0.0077,  0.0119,  0.0017, -0.0190, -0.0046,  0.0056,  0.0168,  0.0094,\n",
       "                       -0.0051,  0.0039, -0.0029,  0.0186, -0.0180,  0.0189,  0.0191, -0.0094,\n",
       "                        0.0084,  0.0184, -0.0068, -0.0066, -0.0126, -0.0144,  0.0322,  0.0054,\n",
       "                        0.0056, -0.0084,  0.0076,  0.0117, -0.0092, -0.0210,  0.0302,  0.0111,\n",
       "                        0.0049,  0.0133,  0.0009,  0.0033,  0.0078, -0.0005,  0.0011,  0.0380,\n",
       "                        0.0042, -0.0085, -0.0131, -0.0191, -0.0132, -0.0132,  0.0060,  0.0126,\n",
       "                        0.0204, -0.0218, -0.0039,  0.0289,  0.0030,  0.0034,  0.0042,  0.0069,\n",
       "                        0.0276,  0.0014,  0.0052, -0.0010,  0.0165, -0.0045, -0.0037,  0.0045,\n",
       "                        0.0175, -0.0177, -0.0008,  0.0173, -0.0091,  0.0122, -0.0022, -0.0185,\n",
       "                       -0.0071, -0.0143,  0.0194,  0.0052,  0.0028,  0.0003, -0.0044,  0.0021,\n",
       "                       -0.0239, -0.0257,  0.0002,  0.0104,  0.0085,  0.0029,  0.0085,  0.0186,\n",
       "                        0.0136, -0.0184,  0.0170,  0.0219,  0.0114,  0.0373, -0.0013, -0.0081,\n",
       "                        0.0079,  0.0001,  0.0129, -0.0018,  0.0132,  0.0188,  0.0141, -0.0070,\n",
       "                        0.0138,  0.0063, -0.0268, -0.0065,  0.0113,  0.0060,  0.0369,  0.0077,\n",
       "                        0.0054, -0.0095, -0.0127, -0.0155, -0.0099, -0.0243, -0.0093,  0.0114,\n",
       "                       -0.0292, -0.0092, -0.0165,  0.0360, -0.0180,  0.0009, -0.0012, -0.0136,\n",
       "                       -0.0028, -0.0299, -0.0139,  0.0060, -0.0042,  0.0075, -0.0028,  0.0032,\n",
       "                        0.0168, -0.0089,  0.0203,  0.0222,  0.0033, -0.0214,  0.0055, -0.0004,\n",
       "                       -0.0070, -0.0103,  0.0122,  0.0016,  0.0049,  0.0059,  0.0101, -0.0175,\n",
       "                       -0.0075,  0.0347, -0.0166,  0.0217,  0.0009, -0.0263,  0.0026,  0.0296,\n",
       "                        0.0109,  0.0100, -0.0139, -0.0151,  0.0139,  0.0117,  0.0224,  0.0200,\n",
       "                        0.0159,  0.0146, -0.0090,  0.0056,  0.0198, -0.0114,  0.0122, -0.0099,\n",
       "                       -0.0116,  0.0004, -0.0143, -0.0011,  0.0056,  0.0021,  0.0154, -0.0226,\n",
       "                       -0.0033, -0.0069, -0.0072, -0.0033, -0.0062, -0.0068, -0.0164,  0.0153,\n",
       "                       -0.0333,  0.0075, -0.0050, -0.0042, -0.0204,  0.0111, -0.0367,  0.0139],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.3.edge_encoder.1.weight',\n",
       "               tensor([0.9628, 0.9829, 0.9672, 0.9673, 0.9706, 0.9835, 0.9779, 0.9585, 0.9801,\n",
       "                       1.0104, 0.9749, 0.9749, 0.9704, 0.9653, 0.9617, 0.9588, 0.9810, 0.9747,\n",
       "                       0.9706, 0.9653, 0.9548, 0.9736, 0.9918, 0.9715, 0.9768, 0.9686, 0.9768,\n",
       "                       0.9644, 0.9705, 0.9647, 0.9775, 0.9654, 0.9791, 0.9719, 0.9689, 1.0024,\n",
       "                       0.9714, 0.9612, 0.9602, 0.9835, 0.9716, 0.9771, 0.9913, 0.9704, 0.9972,\n",
       "                       0.9774, 0.9673, 0.9556, 0.9649, 0.9712, 0.9714, 0.9532, 0.9586, 0.9630,\n",
       "                       0.9654, 0.9569, 0.9866, 0.9909, 0.9710, 0.9789, 0.9821, 0.9766, 0.9629,\n",
       "                       1.0112, 0.9736, 1.0307, 0.9648, 0.9848, 0.9644, 0.9779, 0.9688, 0.9556,\n",
       "                       0.9911, 0.9716, 0.9692, 0.9976, 0.9801, 0.9737, 0.9750, 1.0032, 0.9712,\n",
       "                       0.9831, 0.9793, 1.0119, 0.9947, 0.9525, 0.9689, 1.0086, 0.9671, 0.9862,\n",
       "                       0.9723, 0.9898, 0.9515, 0.9780, 0.9625, 0.9707, 0.9851, 0.9711, 0.9946,\n",
       "                       0.9929, 1.0127, 0.9705, 0.9535, 0.9593, 0.9769, 0.9911, 0.9627, 0.9748,\n",
       "                       0.9724, 0.9391, 0.9803, 0.9876, 0.9843, 0.9748, 0.9582, 0.9636, 0.9737,\n",
       "                       0.9705, 0.9908, 0.9860, 0.9873, 0.9901, 0.9624, 0.9739, 0.9752, 0.9613,\n",
       "                       0.9775, 0.9644, 0.9877, 0.9880, 0.9751, 0.9752, 0.9599, 0.9629, 0.9751,\n",
       "                       0.9859, 0.9705, 0.9769, 0.9848, 0.9831, 0.9677, 1.0146, 0.9704, 0.9786,\n",
       "                       0.9771, 0.9810, 0.9668, 0.9568, 0.9419, 0.9776, 0.9674, 0.9866, 0.9767,\n",
       "                       0.9543, 0.9812, 1.0107, 0.9792, 0.9727, 0.9707, 0.9655, 0.9763, 0.9820,\n",
       "                       0.9982, 0.9833, 0.9660, 1.0028, 0.9630, 0.9713, 1.0131, 0.9784, 0.9664,\n",
       "                       0.9688, 0.9602, 0.9605, 0.9668, 0.9759, 0.9633, 0.9736, 0.9751, 0.9571,\n",
       "                       0.9551, 0.9673, 0.9850, 0.9753, 0.9827, 0.9796, 0.9681, 0.9709, 0.9784,\n",
       "                       0.9611, 0.9603, 0.9895, 0.9809, 0.9890, 0.9777, 0.9484, 0.9913, 0.9686,\n",
       "                       1.0060, 0.9723], device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.3.edge_encoder.1.bias',\n",
       "               tensor([-2.5693e-02, -9.7445e-03, -1.3280e-02, -1.4876e-02, -1.3010e-02,\n",
       "                       -2.8902e-02, -1.5408e-02, -1.3348e-02, -7.5672e-03,  1.6497e-03,\n",
       "                       -7.8495e-03, -9.1716e-03, -2.0961e-02, -2.2757e-02, -2.0028e-02,\n",
       "                       -1.7987e-02, -7.9770e-03, -1.8736e-03, -5.3145e-03, -3.8504e-03,\n",
       "                       -1.5113e-02, -2.7974e-02,  2.6333e-03, -8.1461e-03, -1.9291e-02,\n",
       "                       -1.5892e-03,  1.6622e-04, -1.8932e-02, -1.3259e-02, -2.7374e-02,\n",
       "                       -1.4522e-02, -1.6898e-02, -8.0646e-03, -1.0664e-02, -1.0739e-02,\n",
       "                       -1.7976e-03, -1.9121e-02, -1.7618e-02, -1.1595e-02, -8.5707e-03,\n",
       "                       -1.0648e-02, -1.1552e-02, -1.4868e-02, -9.6961e-03, -2.4517e-02,\n",
       "                       -7.4088e-03,  7.0666e-03, -1.7505e-02, -1.4665e-02, -2.4669e-02,\n",
       "                       -2.5899e-02, -3.7980e-02, -2.2516e-02, -3.0423e-03, -9.7302e-03,\n",
       "                       -2.5835e-02, -2.2611e-03, -4.0520e-03, -6.8373e-03, -1.9277e-02,\n",
       "                       -8.0628e-03, -1.8217e-02, -1.6750e-02, -1.5095e-02, -1.4788e-03,\n",
       "                       -3.7971e-02, -1.9556e-02,  1.5557e-04, -7.2736e-03, -3.9847e-03,\n",
       "                       -1.2300e-02, -1.9903e-02, -1.9171e-02, -9.9416e-03, -5.3805e-03,\n",
       "                        1.5913e-03, -7.6342e-03, -3.3007e-03, -6.2690e-03, -1.4096e-05,\n",
       "                       -1.5686e-02, -6.8913e-03, -1.7321e-02, -2.5634e-02, -1.4783e-02,\n",
       "                       -2.4108e-02, -1.3706e-02, -2.0894e-02, -2.0094e-02, -6.5898e-03,\n",
       "                       -1.2185e-02, -6.1023e-03, -2.7504e-02, -2.4717e-02, -2.5939e-02,\n",
       "                       -1.5674e-02, -5.1389e-03, -7.2659e-03,  4.9414e-03, -1.5022e-03,\n",
       "                       -1.3755e-02, -2.0142e-02, -2.5539e-02, -3.3021e-02, -1.7456e-02,\n",
       "                       -7.0987e-03, -1.8066e-02, -7.1374e-03, -9.0562e-03, -4.0189e-02,\n",
       "                       -4.1441e-03, -9.2944e-03, -8.8290e-03, -1.3431e-02, -1.1504e-02,\n",
       "                       -2.5691e-02, -1.5559e-02, -2.4027e-02, -1.8737e-02, -6.9398e-03,\n",
       "                       -1.3982e-02, -9.3979e-03, -2.2429e-02, -1.6925e-02, -1.1936e-02,\n",
       "                       -2.2714e-02, -8.0626e-03, -2.0102e-02, -1.1027e-02, -1.1894e-02,\n",
       "                       -2.9027e-02, -1.0246e-02, -2.0020e-02, -2.4571e-02,  1.9411e-03,\n",
       "                       -2.1970e-02, -1.8667e-02, -1.4658e-02, -3.9352e-03, -1.8957e-02,\n",
       "                       -9.4686e-03, -2.8255e-02,  5.2848e-04,  7.7191e-03, -1.7395e-02,\n",
       "                       -1.0582e-02, -1.7854e-02, -2.6494e-02, -3.3694e-02, -2.2807e-02,\n",
       "                       -2.3661e-02, -5.3341e-03, -7.3770e-03, -3.4522e-02, -2.7705e-02,\n",
       "                       -7.6568e-03, -5.1986e-03,  6.7720e-03, -2.3240e-02, -3.5141e-02,\n",
       "                       -1.3055e-02, -8.6289e-03, -2.5888e-02, -1.1771e-02, -1.2512e-02,\n",
       "                       -1.8411e-02, -3.3645e-02, -7.4316e-03, -1.2644e-02, -7.5547e-03,\n",
       "                       -1.6641e-02, -1.9724e-02, -2.6223e-02, -1.5339e-02, -6.3751e-03,\n",
       "                       -5.5682e-03, -2.3769e-02, -8.3162e-03, -7.2813e-03, -3.8014e-02,\n",
       "                       -2.6523e-02, -2.3696e-02, -9.4407e-03, -1.6965e-02, -1.8803e-02,\n",
       "                        4.4039e-03, -1.6914e-02, -1.6613e-02,  7.9222e-03, -2.1573e-02,\n",
       "                       -5.3399e-03, -1.7694e-02, -4.4106e-03, -3.1973e-03, -3.3638e-03,\n",
       "                       -3.0254e-02,  3.6135e-03, -1.7349e-02,  2.9815e-03, -8.8753e-03],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.3.edge_encoder.1.running_mean',\n",
       "               tensor([ 2.7008e-02,  1.6912e-03,  1.5797e-02, -6.7778e-02,  2.0418e-02,\n",
       "                       -1.1173e-02,  1.5179e-02,  2.4307e-02,  1.2653e-02,  4.6869e-03,\n",
       "                       -1.0762e-02, -1.9674e-03, -1.3291e-02,  3.0813e-02, -1.3610e-03,\n",
       "                        4.5526e-03,  2.5402e-02,  2.0468e-02,  1.6868e-02,  1.5769e-02,\n",
       "                       -3.7985e-03, -2.9739e-02,  3.6873e-02, -1.5693e-03, -2.0923e-02,\n",
       "                        4.5054e-02,  3.2104e-02, -3.1810e-03,  5.9307e-03, -2.4748e-03,\n",
       "                        2.8697e-02,  2.8321e-03,  4.0958e-02,  2.8253e-02,  3.6128e-02,\n",
       "                       -1.6234e-02,  1.5718e-02,  2.1499e-02,  3.2818e-02,  4.5780e-02,\n",
       "                        1.8265e-02, -2.2358e-02,  1.0330e-02, -8.1752e-03, -7.3849e-02,\n",
       "                       -7.7433e-02, -9.5062e-03,  5.6934e-02,  2.9798e-02, -5.6704e-02,\n",
       "                       -2.8998e-04,  3.8911e-02,  7.1862e-02,  2.8319e-02, -1.3835e-03,\n",
       "                        2.4380e-02,  4.7917e-02, -7.5812e-03,  4.3195e-02, -8.7772e-03,\n",
       "                        3.0336e-02, -2.1767e-02, -2.0313e-02, -5.7155e-02,  2.2238e-02,\n",
       "                       -1.7876e-02,  7.2475e-03,  5.9072e-02,  1.7254e-02,  3.5640e-02,\n",
       "                       -5.3690e-02,  3.1887e-02, -6.1408e-02,  1.1748e-02, -2.8399e-02,\n",
       "                        3.6311e-02,  3.8973e-02,  6.4906e-02,  7.8385e-03, -2.0935e-02,\n",
       "                       -5.8416e-02, -2.0047e-02, -3.1496e-02,  2.9189e-02, -3.4504e-02,\n",
       "                       -2.7514e-02,  6.8505e-02,  2.8062e-03,  1.8849e-05, -1.3774e-02,\n",
       "                        9.2343e-03,  3.7521e-02,  4.5121e-02,  1.4074e-02, -1.8121e-04,\n",
       "                       -4.0558e-02, -3.7644e-03,  1.6923e-02,  2.7104e-02, -1.5634e-02,\n",
       "                       -4.1377e-03,  9.3574e-03,  1.9628e-02,  5.6155e-02,  5.2343e-02,\n",
       "                        8.2967e-03, -3.7830e-03, -4.8709e-03, -8.8138e-03,  5.4959e-02,\n",
       "                        9.5033e-02, -8.7470e-03, -2.1711e-03, -2.7213e-02,  2.7870e-02,\n",
       "                       -6.4279e-02, -1.5909e-02, -4.3667e-02, -1.5132e-02, -9.5939e-03,\n",
       "                       -1.8963e-02, -6.7713e-03, -5.5545e-02, -1.0497e-02, -3.9040e-02,\n",
       "                       -4.8672e-03,  1.1762e-02, -1.5282e-02, -4.3349e-02, -5.3518e-02,\n",
       "                        4.6776e-03, -4.4651e-02, -4.5448e-02, -1.2307e-02,  1.7775e-02,\n",
       "                       -4.1911e-03,  2.1014e-02, -4.3004e-03,  2.7901e-02,  1.0977e-02,\n",
       "                       -7.3112e-03, -3.7840e-02, -1.7166e-03,  1.3762e-02, -2.5244e-02,\n",
       "                        1.1566e-02,  7.3994e-02, -4.3874e-03,  4.3512e-02, -4.0878e-02,\n",
       "                        1.8922e-03, -1.0121e-02, -2.9110e-02,  2.4583e-02, -4.8153e-02,\n",
       "                        2.5973e-02, -2.9922e-03, -2.0870e-02, -2.2877e-02, -1.4993e-03,\n",
       "                       -5.9943e-03, -7.2241e-03, -2.0146e-02,  1.2459e-02, -3.8290e-03,\n",
       "                       -2.0011e-02,  3.9809e-02,  1.3255e-02, -4.2352e-04,  1.7046e-02,\n",
       "                       -6.5159e-03,  1.2209e-02,  6.6373e-02, -1.1389e-02,  5.5789e-02,\n",
       "                        1.8531e-02, -1.1453e-02,  2.1218e-02,  1.8626e-02,  1.3585e-02,\n",
       "                       -3.0026e-02,  1.2386e-02, -9.9208e-03, -2.6795e-04, -8.1980e-03,\n",
       "                       -1.3025e-02, -1.7465e-02,  3.8352e-04, -2.6250e-02, -3.8193e-02,\n",
       "                        1.8636e-02, -7.6045e-03, -3.9300e-02,  1.3399e-03,  1.3233e-02,\n",
       "                        1.9639e-02, -1.1317e-02, -1.9422e-02, -3.2577e-02,  5.8234e-02],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.3.edge_encoder.1.running_var',\n",
       "               tensor([0.0007, 0.0011, 0.0017, 0.0010, 0.0004, 0.0005, 0.0011, 0.0008, 0.0008,\n",
       "                       0.0006, 0.0011, 0.0012, 0.0004, 0.0011, 0.0017, 0.0008, 0.0009, 0.0008,\n",
       "                       0.0008, 0.0017, 0.0010, 0.0005, 0.0005, 0.0005, 0.0007, 0.0009, 0.0004,\n",
       "                       0.0016, 0.0005, 0.0014, 0.0013, 0.0005, 0.0005, 0.0010, 0.0009, 0.0005,\n",
       "                       0.0009, 0.0014, 0.0012, 0.0007, 0.0004, 0.0008, 0.0005, 0.0008, 0.0010,\n",
       "                       0.0010, 0.0010, 0.0012, 0.0016, 0.0011, 0.0004, 0.0004, 0.0009, 0.0014,\n",
       "                       0.0009, 0.0013, 0.0004, 0.0005, 0.0009, 0.0005, 0.0003, 0.0009, 0.0005,\n",
       "                       0.0007, 0.0009, 0.0004, 0.0008, 0.0009, 0.0006, 0.0004, 0.0013, 0.0007,\n",
       "                       0.0007, 0.0006, 0.0007, 0.0004, 0.0007, 0.0007, 0.0007, 0.0003, 0.0020,\n",
       "                       0.0011, 0.0006, 0.0004, 0.0010, 0.0019, 0.0012, 0.0007, 0.0005, 0.0004,\n",
       "                       0.0005, 0.0009, 0.0012, 0.0007, 0.0007, 0.0014, 0.0015, 0.0009, 0.0009,\n",
       "                       0.0006, 0.0004, 0.0006, 0.0008, 0.0008, 0.0012, 0.0005, 0.0013, 0.0009,\n",
       "                       0.0006, 0.0015, 0.0007, 0.0006, 0.0007, 0.0010, 0.0010, 0.0010, 0.0005,\n",
       "                       0.0006, 0.0006, 0.0005, 0.0003, 0.0008, 0.0007, 0.0010, 0.0008, 0.0009,\n",
       "                       0.0008, 0.0012, 0.0011, 0.0014, 0.0014, 0.0012, 0.0019, 0.0012, 0.0016,\n",
       "                       0.0008, 0.0008, 0.0006, 0.0006, 0.0012, 0.0004, 0.0006, 0.0020, 0.0009,\n",
       "                       0.0004, 0.0004, 0.0010, 0.0010, 0.0006, 0.0004, 0.0008, 0.0006, 0.0010,\n",
       "                       0.0016, 0.0006, 0.0004, 0.0010, 0.0015, 0.0007, 0.0009, 0.0008, 0.0008,\n",
       "                       0.0005, 0.0006, 0.0010, 0.0003, 0.0010, 0.0007, 0.0005, 0.0007, 0.0007,\n",
       "                       0.0008, 0.0009, 0.0022, 0.0009, 0.0007, 0.0006, 0.0006, 0.0006, 0.0014,\n",
       "                       0.0004, 0.0004, 0.0003, 0.0004, 0.0008, 0.0010, 0.0010, 0.0010, 0.0016,\n",
       "                       0.0016, 0.0008, 0.0008, 0.0017, 0.0004, 0.0013, 0.0004, 0.0015, 0.0007,\n",
       "                       0.0011, 0.0009], device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.3.edge_encoder.1.num_batches_tracked',\n",
       "               tensor(318750, device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.3.edge_encoder.3.weight',\n",
       "               tensor([[-0.0193, -0.0094, -0.0241,  ...,  0.0122, -0.0301, -0.0028],\n",
       "                       [ 0.0069,  0.0188,  0.0111,  ..., -0.0008, -0.0141,  0.0301],\n",
       "                       [ 0.0371, -0.0236, -0.0005,  ..., -0.0178,  0.0145,  0.0044],\n",
       "                       ...,\n",
       "                       [ 0.0266,  0.0113,  0.0204,  ..., -0.0058,  0.0168, -0.0279],\n",
       "                       [ 0.0263, -0.0120,  0.0145,  ..., -0.0088,  0.0285, -0.0355],\n",
       "                       [ 0.0217,  0.0041,  0.0519,  ...,  0.0308, -0.0709, -0.0156]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.3.edge_encoder.3.bias',\n",
       "               tensor([-2.3653e-03, -5.7033e-03,  2.7150e-03,  1.7915e-03, -1.3082e-03,\n",
       "                       -3.1844e-04,  8.8534e-04, -5.2766e-03,  1.3499e-03,  4.7690e-03,\n",
       "                       -4.6336e-03,  1.4850e-03, -3.2236e-03,  3.7453e-03, -8.5289e-03,\n",
       "                        7.5043e-03,  5.8532e-03,  2.3962e-04, -5.7625e-04,  5.2903e-04,\n",
       "                       -1.7449e-03,  5.2435e-03,  2.9055e-03, -4.1971e-03, -5.6767e-03,\n",
       "                       -4.0691e-03, -1.4285e-03,  5.0252e-03, -1.9099e-03,  1.1951e-03,\n",
       "                        2.1446e-03, -2.3171e-03,  5.1971e-03,  1.3342e-03, -6.3974e-03,\n",
       "                        7.7394e-04, -5.0417e-03, -4.6538e-04,  8.4626e-03, -4.4000e-04,\n",
       "                       -7.0619e-04,  4.7418e-03, -5.4846e-03, -5.1588e-03, -7.3695e-03,\n",
       "                       -9.4579e-03,  4.9077e-03, -5.9823e-03,  1.0702e-03, -2.1661e-03,\n",
       "                        1.0390e-03,  1.1983e-03, -4.2399e-03, -1.2942e-03, -7.8520e-03,\n",
       "                       -3.5293e-03, -1.0280e-02,  3.5102e-04,  3.8343e-03, -1.2780e-03,\n",
       "                        4.5618e-04,  3.8666e-03,  1.8226e-03,  4.2149e-03, -7.9116e-03,\n",
       "                       -6.3569e-03,  7.4834e-04,  4.8660e-04, -3.4787e-03, -3.4874e-03,\n",
       "                       -2.9350e-03,  6.0196e-03,  2.0707e-03,  6.1710e-03, -2.5195e-04,\n",
       "                        2.7551e-03, -3.0170e-03, -3.2106e-03, -5.5723e-05,  5.0233e-03,\n",
       "                       -5.5378e-03, -8.5195e-03,  2.5666e-03, -1.8356e-03,  1.2716e-03,\n",
       "                       -1.2945e-03,  1.9425e-03,  8.8292e-04,  2.0636e-03,  1.4934e-03,\n",
       "                       -1.9848e-03,  9.8496e-03, -2.1664e-03,  1.9293e-03, -3.8735e-03,\n",
       "                       -5.7664e-03,  3.7731e-03, -2.0194e-03,  5.2783e-03,  3.5625e-03,\n",
       "                       -4.3390e-03, -4.5637e-03,  6.6010e-03,  3.1173e-03,  4.0452e-03,\n",
       "                       -2.6583e-03,  4.5262e-03, -1.5825e-03, -4.2482e-03, -3.4520e-03,\n",
       "                        2.3763e-03,  3.6228e-03,  1.7307e-03,  1.0506e-03,  4.2683e-03,\n",
       "                       -3.5708e-04, -2.0222e-03, -1.5319e-03,  4.2033e-03, -6.7279e-03,\n",
       "                        1.4046e-03,  2.9070e-03,  3.6665e-03,  1.5358e-03,  2.2912e-03,\n",
       "                        1.5417e-03, -5.5028e-03,  1.9160e-03, -3.6478e-03, -3.0722e-03,\n",
       "                       -6.0849e-04,  4.6370e-03,  1.5033e-03,  7.6505e-03,  1.1843e-03,\n",
       "                       -2.6880e-03, -7.3885e-04, -1.9909e-03, -4.8474e-03,  7.0672e-03,\n",
       "                        7.6360e-03, -5.4759e-03, -6.0674e-03, -1.4287e-03,  1.6351e-03,\n",
       "                        4.7338e-03, -4.7588e-03, -5.5839e-03,  1.8682e-03, -1.0032e-03,\n",
       "                       -1.1349e-04,  6.5163e-03,  7.6160e-04,  6.0492e-03,  2.1817e-03,\n",
       "                        5.5140e-04, -5.6854e-03,  2.1677e-04,  1.8623e-03,  1.7347e-03,\n",
       "                       -3.2468e-03,  2.5972e-03, -1.4406e-03, -4.4453e-03, -6.4311e-03,\n",
       "                       -3.7272e-03,  2.8988e-03, -3.4194e-03,  8.8222e-04,  3.5037e-03,\n",
       "                        4.3227e-04, -1.8212e-03,  1.9136e-03, -3.1052e-03, -5.8780e-03,\n",
       "                       -9.3809e-04,  2.1546e-03, -5.0847e-03, -5.3777e-03, -3.2735e-03,\n",
       "                        1.7199e-04, -1.1658e-03,  3.6198e-03,  4.1820e-03,  1.1943e-04,\n",
       "                       -1.7642e-03,  4.1916e-03,  8.8105e-04, -6.2575e-03,  6.1010e-03,\n",
       "                       -4.3334e-04,  1.6691e-03,  8.9472e-06,  5.3347e-03,  4.1516e-03,\n",
       "                        4.4639e-03,  4.7324e-03, -6.6560e-04, -5.5783e-03,  1.1676e-03],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.3.linear_key.weight',\n",
       "               tensor([[-0.0250,  0.0194, -0.0263,  ...,  0.0255, -0.0209, -0.0072],\n",
       "                       [-0.0001, -0.0180,  0.0040,  ...,  0.0030, -0.0343,  0.0061],\n",
       "                       [ 0.0091, -0.0014, -0.0426,  ...,  0.0115,  0.0284, -0.0286],\n",
       "                       ...,\n",
       "                       [ 0.0223, -0.0115,  0.0229,  ...,  0.0020,  0.0218, -0.0081],\n",
       "                       [ 0.0017,  0.0456,  0.0441,  ...,  0.0109,  0.0057, -0.0134],\n",
       "                       [-0.0010, -0.0146, -0.0328,  ...,  0.0183,  0.0092, -0.0155]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.3.linear_key.bias',\n",
       "               tensor([ 4.2918e-03, -2.1370e-03, -4.8462e-03, -1.1138e-02, -1.3881e-02,\n",
       "                       -4.7030e-03, -4.1497e-03,  6.1426e-04,  7.4234e-03, -1.5045e-02,\n",
       "                        1.2601e-02,  7.0833e-03,  1.7693e-03, -8.9814e-03,  6.6946e-03,\n",
       "                        1.3289e-02,  1.8041e-03,  1.3949e-02, -5.5115e-03,  5.2350e-03,\n",
       "                       -1.6544e-02, -5.0876e-03,  1.7893e-03,  7.5309e-04,  9.9210e-03,\n",
       "                        1.7701e-03, -1.1219e-03,  1.2466e-02,  2.4871e-03,  1.2461e-02,\n",
       "                        1.5792e-02, -7.0065e-03,  1.2266e-02,  2.7592e-03, -9.6039e-03,\n",
       "                        2.4116e-02,  5.8985e-04, -6.7586e-03, -1.9251e-02, -5.1713e-03,\n",
       "                       -1.4951e-02, -1.3736e-02,  2.7197e-02,  1.9886e-02, -1.2564e-02,\n",
       "                       -2.8641e-03,  7.8703e-03, -4.4442e-03,  5.5606e-03, -1.5373e-02,\n",
       "                       -3.4273e-03,  9.3207e-03,  1.3485e-02,  5.0920e-03,  1.3996e-02,\n",
       "                        7.9046e-04,  6.8437e-03, -1.3771e-02, -6.4161e-04, -3.6874e-03,\n",
       "                        7.3724e-03,  3.4598e-03,  3.8036e-03, -5.3308e-04, -9.8291e-03,\n",
       "                       -6.5341e-03,  8.2710e-03, -1.2257e-02, -6.4948e-03, -4.5766e-03,\n",
       "                       -5.0882e-03, -1.4194e-02,  1.1845e-02, -3.8473e-03,  7.6566e-03,\n",
       "                        1.1042e-03,  6.4095e-03, -1.0619e-02,  4.9411e-03, -1.3960e-03,\n",
       "                        2.9066e-02,  6.0726e-03, -8.3111e-03, -4.4800e-03, -2.0951e-04,\n",
       "                        6.4791e-04,  7.9511e-03,  7.2908e-03, -1.5441e-02, -5.1750e-03,\n",
       "                        5.0317e-03,  7.7267e-03, -4.7041e-03,  1.5865e-02,  2.9893e-04,\n",
       "                        4.0980e-03, -2.1672e-03, -1.1285e-02, -5.1786e-03, -2.0530e-03,\n",
       "                        1.8980e-02,  9.0254e-03, -4.3006e-03,  9.4919e-03,  1.3487e-02,\n",
       "                       -2.7551e-02,  9.7387e-03,  1.3694e-02, -9.1724e-03,  6.1290e-03,\n",
       "                       -1.6390e-02,  1.2537e-02,  1.3482e-02,  7.3137e-03, -5.8259e-03,\n",
       "                       -1.4638e-02,  1.0315e-02, -1.6620e-02,  1.2407e-02, -1.5162e-02,\n",
       "                        2.0290e-02,  1.7127e-02, -1.0949e-02, -1.3520e-02, -2.6606e-04,\n",
       "                       -1.7517e-02,  4.5773e-03,  2.3657e-02,  2.1977e-02,  2.1524e-03,\n",
       "                       -1.1221e-02,  1.9298e-02, -2.0862e-02,  2.7593e-02, -2.1407e-02,\n",
       "                        8.2414e-03, -9.4683e-03, -1.0949e-02,  2.9718e-03,  2.0019e-03,\n",
       "                        2.0446e-02, -6.4929e-03,  1.7065e-02,  6.0453e-03, -1.8251e-02,\n",
       "                       -9.8865e-03,  9.6488e-03, -1.7408e-02, -1.7923e-02, -2.7038e-02,\n",
       "                        8.4755e-03,  3.8143e-03, -1.7843e-02, -1.3603e-02,  9.1592e-03,\n",
       "                       -4.3563e-03, -6.0041e-03,  1.3170e-02,  6.7848e-03, -7.0038e-03,\n",
       "                        4.5807e-03, -6.2733e-03,  3.0199e-03, -1.3571e-02,  5.7319e-04,\n",
       "                       -2.9164e-03, -1.5345e-02, -1.8740e-03, -4.8418e-03, -1.3282e-04,\n",
       "                       -1.1169e-02,  7.9211e-03,  3.5835e-03,  5.4126e-03, -1.0872e-02,\n",
       "                        1.8876e-02, -1.3481e-02, -8.8402e-03,  4.5770e-03,  1.6374e-02,\n",
       "                       -2.9096e-02, -9.6652e-03,  2.1017e-02, -5.9485e-04, -4.5055e-03,\n",
       "                        7.2849e-05, -1.9001e-02,  6.9347e-03, -1.3595e-03, -3.2466e-02,\n",
       "                       -2.3728e-02,  2.3447e-04,  2.0522e-02,  5.3600e-03,  7.8465e-03,\n",
       "                       -5.0879e-03,  1.5813e-02, -8.0621e-03,  6.0345e-03,  3.7412e-03],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.3.linear_msg.weight',\n",
       "               tensor([[-0.0115,  0.0019,  0.0335,  ...,  0.0157, -0.0035,  0.0190],\n",
       "                       [-0.0057,  0.0205, -0.0236,  ..., -0.0351, -0.0123,  0.0170],\n",
       "                       [ 0.0016,  0.0037,  0.0148,  ...,  0.0168, -0.0369,  0.0079],\n",
       "                       ...,\n",
       "                       [ 0.0025, -0.0121, -0.0053,  ..., -0.0419,  0.0004,  0.0292],\n",
       "                       [-0.0323, -0.0024,  0.0205,  ..., -0.0190,  0.0334, -0.0491],\n",
       "                       [-0.0058,  0.0114,  0.0241,  ...,  0.0077, -0.0372,  0.0010]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.3.linear_msg.bias',\n",
       "               tensor([-9.2972e-03,  3.5786e-03, -5.6857e-03,  5.1329e-03, -1.7987e-03,\n",
       "                       -1.1666e-03,  1.4705e-02,  4.0380e-03,  1.1473e-03,  7.8397e-03,\n",
       "                        4.5409e-03, -8.5567e-03,  1.2844e-02,  2.5424e-03,  8.0654e-03,\n",
       "                       -2.5875e-03, -5.4112e-03,  4.0155e-04,  7.8114e-03, -6.0530e-03,\n",
       "                        1.9665e-03, -3.1314e-03,  1.8507e-03, -1.4163e-02, -5.4234e-05,\n",
       "                        2.5361e-03,  9.1829e-03,  1.4077e-02, -5.8525e-03, -7.2719e-03,\n",
       "                       -8.1472e-03, -1.2350e-02,  1.7240e-02,  7.1031e-03,  6.2329e-04,\n",
       "                        3.8994e-03,  3.7115e-03,  5.4724e-03, -8.9645e-03, -1.4701e-02,\n",
       "                        1.2483e-02, -6.1663e-03, -3.3869e-03, -3.3437e-03,  2.7451e-03,\n",
       "                        4.8871e-03,  1.6544e-03,  4.0517e-03,  7.7833e-03,  1.4745e-02,\n",
       "                        6.0989e-03, -7.5479e-03, -5.5616e-04, -6.6934e-03,  1.2342e-02,\n",
       "                        7.6298e-03, -8.1780e-03,  9.9464e-04, -7.7021e-03, -2.7985e-03,\n",
       "                        1.6687e-03, -6.8292e-04,  9.6227e-03, -5.1502e-04,  1.2029e-02,\n",
       "                       -4.1143e-03,  8.4327e-03, -1.5278e-02,  3.4873e-03,  3.0044e-03,\n",
       "                        1.5953e-04,  8.2658e-03,  1.9794e-03,  1.0545e-02,  3.5177e-03,\n",
       "                       -1.0803e-02, -3.4489e-03, -4.9023e-03,  8.3477e-04, -1.1459e-02,\n",
       "                        5.9419e-03, -1.9817e-03,  1.8864e-03,  7.8002e-03,  8.3337e-03,\n",
       "                       -1.7443e-03, -5.2243e-03,  6.1385e-03, -1.4301e-04,  2.7341e-03,\n",
       "                       -7.4565e-03, -5.8470e-03, -2.5784e-04, -2.4033e-03, -4.7456e-03,\n",
       "                        6.9408e-03,  6.7165e-03,  3.8833e-03,  2.7049e-04, -1.2977e-02,\n",
       "                       -4.9218e-03, -4.0622e-03, -3.7776e-03,  6.4094e-03,  9.8976e-03,\n",
       "                        5.2494e-03,  5.0986e-03, -4.7096e-03, -2.3042e-03,  8.7540e-03,\n",
       "                        5.4772e-03, -4.7597e-03, -1.2582e-04,  3.5795e-03, -3.4181e-04,\n",
       "                        5.1009e-03,  7.9694e-04,  6.6775e-03, -7.6926e-03, -1.0444e-03,\n",
       "                       -3.4476e-03,  4.9805e-04,  4.7430e-03, -5.7598e-03, -5.1716e-03,\n",
       "                        5.0748e-03, -9.1366e-03,  3.6491e-03, -2.7144e-03,  2.4564e-03,\n",
       "                        6.3791e-04, -7.4813e-03, -3.2707e-04,  8.3362e-03, -1.0169e-03,\n",
       "                       -3.5500e-03,  4.0592e-03, -1.5248e-03, -2.4933e-03, -2.0193e-03,\n",
       "                        6.5204e-03, -1.7757e-03,  5.8728e-03, -3.1210e-03, -1.7500e-03,\n",
       "                       -1.7530e-03, -3.5873e-03,  1.0930e-03,  9.1384e-03, -3.3935e-03,\n",
       "                        6.4301e-04, -2.3480e-03, -2.6618e-03, -1.2921e-02, -3.2587e-03,\n",
       "                       -7.4466e-03,  1.6869e-02,  3.7200e-03,  6.3730e-03, -4.8379e-03,\n",
       "                        4.1324e-03, -6.5117e-03, -3.7427e-04,  2.8563e-03,  1.3573e-03,\n",
       "                        2.4934e-03, -2.0688e-03,  2.5430e-03, -3.8379e-03, -9.5005e-03,\n",
       "                        8.4213e-03,  8.2432e-03, -4.5166e-04, -3.1925e-03,  1.9597e-03,\n",
       "                       -8.7929e-03, -4.1794e-03,  5.8196e-03,  1.0086e-02, -1.1019e-02,\n",
       "                       -3.9371e-03,  7.5188e-03, -6.0397e-03, -9.3034e-04,  4.8756e-03,\n",
       "                        2.8522e-03, -1.4749e-02, -3.7806e-03, -5.8035e-03, -4.2733e-03,\n",
       "                        2.6382e-03, -5.2518e-04, -3.6234e-03,  3.0737e-03,  1.4377e-02,\n",
       "                       -9.5045e-03,  2.6337e-03,  1.0465e-02,  9.3199e-03,  8.5393e-03],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.3.linear_query.weight',\n",
       "               tensor([[ 0.0206,  0.0156,  0.0208,  ...,  0.0760,  0.0657, -0.0123],\n",
       "                       [-0.0661, -0.0219,  0.0144,  ...,  0.0039, -0.0157,  0.0167],\n",
       "                       [ 0.0125,  0.0406,  0.0816,  ...,  0.0686, -0.0145, -0.0564],\n",
       "                       ...,\n",
       "                       [-0.0312,  0.0196, -0.0066,  ..., -0.0409, -0.0445,  0.0542],\n",
       "                       [-0.0369, -0.0172, -0.0219,  ...,  0.0100,  0.0076,  0.0295],\n",
       "                       [ 0.0173,  0.0087,  0.0528,  ..., -0.0356, -0.0534,  0.0001]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.3.linear_query.bias',\n",
       "               tensor([-0.0080,  0.0308,  0.0005, -0.0134,  0.0286, -0.0243, -0.0166, -0.0095,\n",
       "                        0.0308,  0.0293,  0.0220,  0.0354, -0.0476,  0.0158,  0.0287, -0.0191,\n",
       "                       -0.0032, -0.0327,  0.0239,  0.0013,  0.0141, -0.0312, -0.0225,  0.0111,\n",
       "                        0.0146, -0.0046,  0.0327,  0.0248, -0.0176,  0.0155, -0.0047, -0.0193,\n",
       "                        0.0284,  0.0238, -0.0211, -0.0016,  0.0141, -0.0375,  0.0218, -0.0080,\n",
       "                        0.0061,  0.0069, -0.0126,  0.0026, -0.0053, -0.0336,  0.0270, -0.0233,\n",
       "                       -0.0402, -0.0255,  0.0017,  0.0173, -0.0218,  0.0275,  0.0038, -0.0508,\n",
       "                        0.0233, -0.0479,  0.0057,  0.0162, -0.0032,  0.0016, -0.0173,  0.0132,\n",
       "                        0.0027, -0.0612, -0.0418,  0.0118, -0.0206,  0.0017, -0.0268, -0.0300,\n",
       "                        0.0191,  0.0268,  0.0289,  0.0189,  0.0390, -0.0232, -0.0003, -0.0368,\n",
       "                        0.0480, -0.0014, -0.0119, -0.0252,  0.0114,  0.0112,  0.0004,  0.0473,\n",
       "                        0.0132, -0.0241,  0.0082, -0.0046,  0.0035, -0.0055,  0.0353, -0.0006,\n",
       "                       -0.0210,  0.0309, -0.0033, -0.0198, -0.0009,  0.0181, -0.0390,  0.0174,\n",
       "                        0.0482, -0.0051,  0.0450,  0.0041,  0.0338,  0.0536, -0.0325,  0.0248,\n",
       "                        0.0557,  0.0511, -0.0546, -0.0426, -0.0155, -0.0487,  0.0569, -0.0456,\n",
       "                        0.0312,  0.0545,  0.0236, -0.0351,  0.0236, -0.0381, -0.0036,  0.0371,\n",
       "                        0.0523,  0.0347, -0.0486, -0.0422, -0.0359,  0.0351,  0.0209,  0.0406,\n",
       "                       -0.0327, -0.0397, -0.0343,  0.0161,  0.0388, -0.0542,  0.0614,  0.0007,\n",
       "                       -0.0503,  0.0535, -0.0094, -0.0517, -0.0403, -0.0524,  0.0052, -0.0479,\n",
       "                        0.0119, -0.0469, -0.0042,  0.0114,  0.0104,  0.0127, -0.0302, -0.0592,\n",
       "                        0.0044,  0.0038,  0.0255,  0.0051, -0.0083, -0.0414,  0.0006,  0.0121,\n",
       "                        0.0221, -0.0126, -0.0158, -0.0595, -0.0149,  0.0480,  0.0006, -0.0134,\n",
       "                       -0.0388, -0.0170,  0.0739, -0.0117,  0.0057,  0.0195,  0.0028, -0.0090,\n",
       "                       -0.0169,  0.0310,  0.0141,  0.0355, -0.0260, -0.0101, -0.0127,  0.0331,\n",
       "                        0.0154,  0.0287, -0.0153,  0.0097,  0.0566, -0.0196,  0.0009, -0.0142],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.3.mlp.0.weight',\n",
       "               tensor([[ 0.0405, -0.0099,  0.0266,  ..., -0.0435,  0.0033,  0.0145],\n",
       "                       [ 0.0009, -0.0102,  0.0319,  ..., -0.0162, -0.0006, -0.0017],\n",
       "                       [ 0.0446, -0.0072, -0.0285,  ...,  0.0306,  0.0164, -0.0258],\n",
       "                       ...,\n",
       "                       [ 0.0240, -0.0178,  0.0077,  ...,  0.0041,  0.0144,  0.0173],\n",
       "                       [ 0.0042, -0.0252, -0.0041,  ...,  0.0149,  0.0110, -0.0146],\n",
       "                       [ 0.0114, -0.0207, -0.0386,  ..., -0.0385, -0.0018,  0.0160]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.3.mlp.0.bias',\n",
       "               tensor([-9.5172e-03,  1.0344e-02, -5.4007e-03,  5.8811e-03,  1.8790e-03,\n",
       "                       -2.9831e-03,  5.6831e-03,  1.2634e-04, -4.4788e-03, -3.8998e-03,\n",
       "                       -8.9841e-04, -7.7329e-03, -3.7134e-03, -3.6636e-04, -1.3866e-02,\n",
       "                       -1.9881e-02, -3.4032e-03,  1.2861e-03,  3.9377e-03, -1.0393e-02,\n",
       "                       -4.8011e-03,  8.1925e-03,  4.2041e-03,  1.3576e-02, -3.0987e-03,\n",
       "                        9.6978e-03, -1.0575e-02, -4.2787e-03,  1.1397e-02, -1.3226e-03,\n",
       "                       -7.5323e-03, -6.0839e-03,  3.0977e-03, -4.7847e-03, -6.1844e-03,\n",
       "                       -9.7687e-03, -1.0838e-02,  3.0311e-03, -5.2109e-04, -2.7714e-03,\n",
       "                        2.7970e-03,  2.2669e-02,  8.2701e-03,  7.0387e-03, -6.5292e-03,\n",
       "                        9.8267e-03,  1.8014e-03,  4.1706e-03, -3.5774e-03, -1.8798e-02,\n",
       "                       -1.2260e-02,  3.1820e-03, -6.4230e-04,  1.2814e-02, -2.3370e-03,\n",
       "                       -2.9715e-04, -5.0553e-03, -2.9553e-03, -4.3669e-03, -1.7219e-02,\n",
       "                       -1.2901e-02, -4.1505e-03,  2.0106e-02, -2.5858e-03, -1.3203e-02,\n",
       "                        5.8503e-03,  8.1463e-03,  3.7167e-03,  6.4484e-03,  1.2664e-02,\n",
       "                       -8.9502e-03, -1.2689e-02, -1.4299e-02,  2.6905e-03,  5.8261e-03,\n",
       "                        2.8315e-03,  1.0747e-02, -3.9665e-04,  1.6596e-03, -7.4204e-03,\n",
       "                        3.0230e-03, -1.0489e-02, -4.3785e-03, -1.4071e-03, -5.7662e-03,\n",
       "                       -7.9349e-03,  2.0547e-02, -2.2009e-03, -3.6311e-04, -1.2156e-02,\n",
       "                        1.6181e-02,  2.3768e-03, -1.0895e-02,  3.3452e-03, -7.7467e-03,\n",
       "                       -1.8114e-02, -6.4457e-06, -1.5249e-02, -7.8392e-03, -8.1341e-03,\n",
       "                        2.1305e-03,  1.0553e-02,  7.6435e-03,  8.1693e-03, -7.8992e-03,\n",
       "                       -1.7246e-03, -4.0591e-03, -6.8863e-03,  5.3046e-03,  1.7128e-03,\n",
       "                       -1.1216e-02,  1.2054e-02,  3.9804e-03, -5.9696e-03, -4.4909e-03,\n",
       "                       -7.3462e-03, -1.0292e-02,  6.7007e-03, -1.1432e-02,  1.3732e-03,\n",
       "                       -6.2693e-03,  1.9127e-03,  3.7474e-03,  8.1752e-04,  9.0663e-03,\n",
       "                        4.7490e-03, -1.2445e-02, -7.9311e-03, -1.9963e-02,  4.6431e-03,\n",
       "                        1.5833e-02,  1.4090e-03,  1.8193e-02,  1.2315e-02,  1.1211e-02,\n",
       "                        1.0403e-02,  1.3030e-03,  6.3211e-03, -9.1666e-03,  4.7467e-03,\n",
       "                       -1.6379e-03, -1.3570e-02,  8.7186e-03,  5.4719e-03, -3.5346e-04,\n",
       "                        6.1109e-03,  2.7035e-03, -5.2920e-03, -2.5478e-03, -8.0417e-03,\n",
       "                        4.7235e-03, -1.0432e-02,  6.1484e-03,  1.2054e-02, -1.2534e-03,\n",
       "                       -2.0699e-03,  4.0021e-03, -8.9925e-03, -6.6512e-03,  7.6096e-03,\n",
       "                        2.9166e-03,  1.3358e-04, -1.0777e-02,  1.5155e-02,  3.1260e-03,\n",
       "                        9.1313e-03, -2.3418e-03, -5.4433e-03, -5.7031e-03, -1.2949e-02,\n",
       "                       -8.9656e-03,  5.2324e-03,  4.1253e-03, -1.9001e-03,  6.3223e-03,\n",
       "                       -1.9653e-03, -7.3621e-03,  2.4113e-03,  1.9141e-03,  9.7265e-04,\n",
       "                       -1.0130e-02, -3.4096e-03, -1.0892e-02,  1.0351e-02, -5.0605e-03,\n",
       "                       -2.0626e-03, -1.2366e-02, -2.4421e-03,  9.6134e-03,  8.6219e-03,\n",
       "                       -7.2328e-03,  4.7008e-03,  5.1888e-03, -1.0114e-02, -1.2494e-02,\n",
       "                       -4.1526e-03,  8.0144e-03,  7.0517e-03, -9.4290e-03, -1.2735e-02],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.3.mlp.1.weight',\n",
       "               tensor([0.9653, 0.9688, 0.9760, 0.9662, 0.9742, 0.9741, 0.9885, 0.9743, 0.9764,\n",
       "                       0.9720, 0.9581, 0.9705, 0.9843, 0.9826, 0.9736, 0.9576, 0.9628, 0.9710,\n",
       "                       0.9640, 0.9818, 0.9735, 0.9742, 0.9923, 0.9741, 0.9662, 0.9530, 0.9696,\n",
       "                       0.9642, 0.9538, 0.9750, 0.9662, 0.9617, 0.9648, 0.9684, 0.9900, 0.9707,\n",
       "                       0.9555, 0.9846, 0.9752, 0.9663, 0.9822, 0.9602, 0.9747, 0.9758, 0.9686,\n",
       "                       0.9712, 0.9662, 0.9855, 0.9623, 0.9913, 0.9721, 0.9651, 0.9696, 0.9632,\n",
       "                       0.9713, 0.9706, 0.9815, 0.9793, 0.9753, 0.9677, 0.9829, 0.9860, 0.9534,\n",
       "                       0.9796, 0.9682, 0.9775, 0.9717, 0.9943, 0.9604, 0.9752, 0.9908, 0.9690,\n",
       "                       0.9752, 0.9754, 0.9824, 0.9836, 0.9637, 0.9846, 0.9775, 0.9592, 0.9593,\n",
       "                       0.9730, 0.9611, 0.9711, 0.9749, 0.9779, 0.9800, 0.9381, 0.9565, 0.9698,\n",
       "                       0.9811, 0.9843, 0.9843, 0.9676, 0.9724, 0.9592, 0.9784, 0.9625, 0.9800,\n",
       "                       0.9534, 0.9795, 0.9807, 0.9706, 0.9652, 0.9780, 0.9530, 0.9874, 0.9685,\n",
       "                       0.9754, 0.9582, 0.9585, 0.9658, 0.9191, 0.9593, 0.9794, 0.9706, 0.9710,\n",
       "                       0.9732, 0.9840, 0.9696, 0.9654, 0.9844, 0.9844, 0.9604, 0.9793, 0.9654,\n",
       "                       0.9643, 0.9554, 0.9884, 0.9754, 0.9706, 0.9779, 0.9634, 0.9666, 0.9674,\n",
       "                       0.9860, 0.9724, 0.9864, 0.9660, 0.9728, 0.9841, 0.9529, 0.9410, 0.9830,\n",
       "                       0.9875, 0.9751, 0.9663, 0.9621, 0.9946, 0.9535, 0.9668, 0.9877, 0.9452,\n",
       "                       0.9847, 0.9715, 0.9889, 0.9930, 0.9665, 0.9626, 0.9849, 0.9707, 0.9566,\n",
       "                       0.9585, 0.9660, 0.9881, 0.9745, 0.9687, 0.9601, 0.9637, 0.9727, 0.9762,\n",
       "                       0.9837, 0.9774, 0.9525, 0.9645, 0.9672, 0.9782, 0.9783, 0.9788, 0.9683,\n",
       "                       0.9725, 0.9553, 0.9570, 0.9674, 0.9681, 0.9718, 0.9698, 0.9639, 0.9704,\n",
       "                       0.9715, 0.9805, 0.9727, 0.9873, 0.9531, 0.9682, 0.9632, 0.9718, 0.9631,\n",
       "                       0.9664, 0.9668], device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.3.mlp.1.bias',\n",
       "               tensor([ 1.6840e-02, -6.3337e-02, -6.4440e-03,  1.7163e-05,  9.2320e-04,\n",
       "                        2.0938e-03,  8.2581e-03, -1.6156e-02, -2.0429e-03, -8.5165e-03,\n",
       "                       -1.7291e-02, -8.1102e-03,  5.3742e-03,  7.7875e-03, -3.0644e-02,\n",
       "                        1.6911e-02, -2.3957e-02, -1.5599e-02,  6.7266e-03,  1.1572e-02,\n",
       "                       -5.2639e-03,  8.8660e-05, -3.0953e-03,  6.1086e-03, -4.0255e-03,\n",
       "                       -1.4621e-02,  1.2622e-02, -1.2569e-02,  2.6965e-02, -2.0731e-03,\n",
       "                       -4.7878e-02, -1.1183e-02, -2.2440e-02, -2.8885e-03, -1.7245e-02,\n",
       "                       -1.2952e-02, -1.0746e-02,  6.3439e-03, -3.9163e-03, -1.0467e-02,\n",
       "                       -4.3194e-02, -1.5752e-02, -2.7109e-02, -2.9177e-03, -1.4840e-02,\n",
       "                       -3.5413e-03,  6.0763e-03,  5.2082e-03,  3.0434e-04,  1.2402e-03,\n",
       "                       -2.1208e-02, -4.7834e-03, -3.4132e-02, -4.9791e-03,  1.2124e-02,\n",
       "                        8.1821e-04,  6.8703e-03, -1.6366e-02, -1.1764e-02, -2.1652e-02,\n",
       "                        2.1944e-03,  1.4170e-03, -1.7480e-02,  4.7419e-03, -3.2794e-02,\n",
       "                        2.5858e-02,  1.0888e-02,  2.1641e-02, -5.7780e-02, -2.0130e-02,\n",
       "                        1.2478e-02, -3.6331e-03, -3.3799e-02, -1.1850e-02,  6.1794e-04,\n",
       "                        1.8435e-02, -7.0738e-04, -1.6283e-03, -3.0634e-03, -2.3577e-02,\n",
       "                       -3.8598e-03, -1.0925e-02, -1.5045e-02, -4.6576e-03, -2.0313e-02,\n",
       "                        7.5752e-03,  1.2248e-03,  3.2317e-03, -1.8163e-02,  6.0973e-03,\n",
       "                       -1.2712e-03,  1.2769e-02, -1.7336e-02, -5.8132e-03, -7.7253e-04,\n",
       "                       -4.7653e-03,  4.7265e-03,  7.3526e-04, -4.8856e-02, -2.7997e-02,\n",
       "                        4.9832e-03,  8.3851e-03, -2.1549e-02,  2.1592e-02, -4.1016e-02,\n",
       "                       -3.9317e-02, -6.8482e-03, -1.2110e-03, -2.5410e-04, -6.9236e-04,\n",
       "                       -3.6940e-02,  7.5501e-03, -3.3267e-02,  8.3859e-03,  1.0334e-02,\n",
       "                        6.6046e-04,  1.2591e-02, -1.6658e-02,  3.4753e-03, -1.1793e-02,\n",
       "                        7.5828e-04, -1.1683e-02,  1.1473e-02, -4.5972e-04,  6.0178e-03,\n",
       "                       -2.5325e-02, -1.3138e-02, -3.3847e-03, -9.5791e-03, -6.4085e-03,\n",
       "                       -3.5383e-02, -1.4389e-02, -9.8895e-03, -4.4122e-03, -7.2233e-03,\n",
       "                       -4.4602e-02, -8.6448e-03,  2.0048e-02, -1.2172e-03,  5.6931e-03,\n",
       "                        8.3788e-03, -5.4133e-03, -4.9282e-02,  1.5275e-02, -8.1248e-03,\n",
       "                       -7.8886e-03, -4.8608e-02, -2.3526e-02,  8.9246e-03, -4.5603e-02,\n",
       "                       -1.1186e-03,  5.9955e-03, -2.4943e-02,  9.9545e-03, -2.3680e-03,\n",
       "                       -2.6178e-03,  2.0241e-02, -7.5387e-03, -1.5385e-02, -1.2158e-02,\n",
       "                       -5.6976e-03, -1.3265e-02, -1.6485e-02,  5.8646e-03,  8.5644e-03,\n",
       "                       -1.4430e-02, -1.0980e-02, -3.0647e-02, -1.8852e-02, -1.1750e-02,\n",
       "                       -1.0838e-02, -3.0448e-03, -1.2978e-03, -2.3662e-02, -4.3978e-03,\n",
       "                       -1.2174e-02, -2.1986e-03,  3.4387e-03, -6.0934e-03,  1.1396e-03,\n",
       "                       -6.3280e-03, -1.7538e-02, -8.0300e-03,  1.9911e-02,  1.2648e-02,\n",
       "                       -1.0148e-02,  1.9507e-02,  7.4653e-03, -1.2651e-02,  1.0334e-02,\n",
       "                       -1.5045e-03, -2.7204e-03,  7.4992e-03, -5.5112e-02,  7.7407e-03,\n",
       "                       -2.2689e-02,  4.5753e-03,  4.1462e-03, -1.3165e-02,  3.2177e-02],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.3.mlp.1.running_mean',\n",
       "               tensor([-1.2450,  2.4895, -2.2073, -1.2929, -2.5708, -2.4237, -3.1747, -2.3930,\n",
       "                       -2.3399,  0.7292, -0.6992,  0.4968, -2.4778, -1.9441,  1.2376, -1.1367,\n",
       "                        0.1236,  0.3287, -1.6354, -1.4915, -1.1600, -2.3542, -2.6504, -0.7699,\n",
       "                       -0.7222, -1.2431, -0.7735, -2.2100,  0.1040,  0.9628,  3.0839, -0.4731,\n",
       "                        1.0459,  1.2963,  2.9466, -0.7133,  1.6505, -1.8822, -1.5510,  1.0318,\n",
       "                        2.4857, -0.8986,  1.6592, -2.0162, -1.5342, -2.7552, -2.1840, -1.4439,\n",
       "                       -0.8472, -0.7096,  2.3024, -2.1732, -0.7490, -1.3250, -2.3031, -1.8606,\n",
       "                       -1.4187, -2.0512, -2.0594,  0.8260, -2.0125, -1.7710,  0.8928, -2.5513,\n",
       "                        2.9254, -1.2138, -1.2634, -2.7301,  2.1970,  2.3113, -2.9060, -0.6350,\n",
       "                        2.9007, -1.4416, -2.2641, -1.5283, -1.6761, -2.1683, -2.4238,  0.4912,\n",
       "                        0.8083, -0.5764,  1.5957, -1.8313, -1.2634, -2.9375,  0.0238, -0.2926,\n",
       "                       -1.3587, -0.6733,  0.9349, -2.2249, -1.2464, -0.8170, -2.5882,  0.6710,\n",
       "                       -2.2441, -1.2091,  2.8721, -2.5231, -1.9153, -2.4854, -1.3467, -2.3717,\n",
       "                        2.9509, -1.1256, -2.2785, -2.3796, -2.7281, -3.1141,  1.7208, -1.9615,\n",
       "                        2.6274, -2.9903, -0.2946, -1.9573, -2.6350,  3.6684, -2.7380, -0.8165,\n",
       "                       -0.6821, -2.1525, -3.1276, -0.8281, -2.9783,  1.7016,  0.0284, -0.6371,\n",
       "                        3.1480, -1.3977,  2.6036, -1.7571,  0.9829, -2.7242, -2.5802,  3.9150,\n",
       "                        1.9232, -2.3813, -1.2450,  0.9753,  0.3886, -1.1718,  3.1854, -0.7562,\n",
       "                       -2.4374, -2.3473, -1.0987, -0.8658, -2.0580, -1.6984, -1.7765, -2.2179,\n",
       "                        2.7600, -1.6203, -1.4203, -1.5411, -2.8006, -0.1851, -1.1866,  0.5777,\n",
       "                       -0.3437, -2.0236,  1.1281, -1.0294, -0.8793, -0.9669, -1.9423,  0.4445,\n",
       "                       -1.8172, -1.3322, -2.0109, -1.3815, -2.2938, -0.2737,  0.0701, -2.6862,\n",
       "                       -2.2127,  1.5834, -1.0380, -1.5825, -1.2460, -0.6043, -0.6822, -0.0588,\n",
       "                       -1.0505, -0.1919, -0.9424,  1.0946, -0.9791, -1.7983, -2.3633, -1.1569,\n",
       "                       -2.7655,  2.5920, -1.1498,  2.2374, -0.3448, -0.8324, -0.3944, -1.7926],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.3.mlp.1.running_var',\n",
       "               tensor([ 5.6490, 11.6624, 13.3093,  4.7043, 11.6839, 10.2432, 18.9698, 11.4820,\n",
       "                       11.7550,  3.6701, 10.9618,  6.4676, 11.9775, 13.0490,  5.7158,  7.2491,\n",
       "                       10.0342,  9.5447,  6.3205,  8.2877,  5.2653, 11.2820, 14.1501,  9.1266,\n",
       "                        9.2626,  4.4397,  4.3615,  9.7988,  3.7878,  5.9380, 17.5665,  7.8868,\n",
       "                       10.7442,  9.6606, 15.6137,  9.0050,  6.7363,  8.5412, 15.8288,  4.7229,\n",
       "                       12.6786, 12.4208,  6.0980,  8.5737,  5.2540, 16.1205, 11.6232,  5.8876,\n",
       "                       10.8155,  9.0561, 11.3320,  8.2265,  2.2666,  3.9871, 11.2129, 13.7600,\n",
       "                        5.6460,  8.8254,  8.0989,  2.7909,  8.8297,  9.3913,  3.1882, 14.7143,\n",
       "                       15.9181,  5.9760,  5.2927, 15.2866,  9.2072, 10.7992, 19.8593,  7.8749,\n",
       "                       15.6329,  7.6049, 11.3761,  8.1692, 13.8963, 11.5948, 12.0386,  4.9904,\n",
       "                        4.4286,  2.2093,  6.4303, 18.8106,  5.3576, 16.6782,  9.5721,  4.3648,\n",
       "                        9.8454,  8.7207,  8.9657, 11.8336,  2.8695,  3.5000, 12.5256,  6.4800,\n",
       "                       10.5902, 12.3103, 15.9970, 16.6085,  7.0752, 13.8707,  5.4365, 12.3348,\n",
       "                       16.7483,  6.2262, 11.6397, 13.8623, 14.1475, 23.4764,  9.6048, 13.2442,\n",
       "                       13.0632, 22.3289,  4.0164, 12.1347, 13.1907, 24.0781, 18.3425,  2.7940,\n",
       "                        3.3855, 10.5290, 23.7585, 11.4270, 18.0355,  8.1707, 12.7381, 13.4364,\n",
       "                       17.9258,  3.6217, 13.7130, 12.2575,  5.6624, 14.2554, 18.1771, 24.9913,\n",
       "                        9.2937, 11.3632,  4.5262,  5.7525,  7.9407,  3.8771, 16.6211,  4.1931,\n",
       "                       14.4021,  9.8766,  3.3033,  4.3498,  9.0001,  8.1559,  9.1518, 11.0190,\n",
       "                       16.6558,  6.5191,  8.7372,  7.1063, 16.0966,  6.4720,  9.5512,  4.5819,\n",
       "                        3.0522, 11.6817,  7.7604,  6.3105,  3.3431,  8.4583,  8.7456,  6.1692,\n",
       "                        8.6170,  3.8394, 10.6721,  6.9196, 10.4985, 10.6592,  3.8752, 14.9068,\n",
       "                       16.6154,  6.7120,  3.8397,  9.5364,  4.4039,  8.4026,  9.7888,  3.3155,\n",
       "                        4.1881,  8.6991,  2.6188,  7.7587,  4.8517,  6.8378, 12.8157,  4.6840,\n",
       "                       19.9788, 12.3354,  3.7281, 12.3484,  5.1266,  6.5947,  9.5004,  9.6874],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.3.mlp.1.num_batches_tracked',\n",
       "               tensor(63750, device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.3.mlp.3.weight',\n",
       "               tensor([[ 0.0009, -0.0181,  0.0256,  ...,  0.0003, -0.0315, -0.0080],\n",
       "                       [-0.0056, -0.0146, -0.0240,  ...,  0.0369,  0.0108,  0.0030],\n",
       "                       [-0.0055,  0.0316,  0.0151,  ..., -0.0319, -0.0133,  0.0041],\n",
       "                       ...,\n",
       "                       [-0.0078, -0.0150,  0.0147,  ..., -0.0354,  0.0030,  0.0345],\n",
       "                       [-0.0254, -0.0065, -0.0274,  ..., -0.0124,  0.0230,  0.0432],\n",
       "                       [-0.0334, -0.0243,  0.0069,  ...,  0.0310, -0.0156, -0.0176]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.3.mlp.3.bias',\n",
       "               tensor([ 9.1001e-03,  1.2445e-02, -1.1444e-03,  5.9663e-03,  9.8035e-03,\n",
       "                        1.5954e-02, -1.5896e-02,  1.0790e-02, -8.9629e-03,  1.8887e-02,\n",
       "                        7.3561e-03,  3.8018e-03,  1.9889e-02,  1.3966e-02,  1.8728e-02,\n",
       "                        4.1894e-03,  3.7231e-03, -6.4757e-03,  9.3939e-03,  1.2204e-03,\n",
       "                        1.2392e-02, -1.8794e-02, -4.4216e-03,  2.3699e-02,  5.5036e-03,\n",
       "                       -4.6867e-03,  1.1126e-02, -7.8811e-03,  2.0774e-03,  2.2937e-02,\n",
       "                        1.1766e-02,  1.0888e-02,  1.3914e-02,  6.7895e-03,  1.5910e-02,\n",
       "                        1.6665e-02,  5.5908e-03,  3.4307e-03,  1.6741e-02,  3.5933e-02,\n",
       "                        3.6657e-03,  1.6642e-02, -2.9206e-03, -2.6560e-02,  3.4101e-04,\n",
       "                       -4.6386e-05,  8.9774e-03,  1.2080e-02,  6.0495e-03,  1.1289e-02,\n",
       "                        9.9181e-03,  2.2598e-02,  6.2083e-03, -1.2565e-02,  9.0498e-03,\n",
       "                        1.8340e-02, -8.7903e-03,  1.2204e-02,  2.2420e-02,  1.7635e-02,\n",
       "                        1.2630e-02, -6.9581e-03, -7.5538e-03, -2.8793e-03,  2.1720e-02,\n",
       "                       -6.9438e-03, -9.1123e-04, -6.7090e-03,  9.6207e-03,  7.2143e-03,\n",
       "                        1.5015e-02,  6.8548e-03,  2.4583e-02,  8.6679e-03,  1.4667e-02,\n",
       "                        9.6649e-03,  1.4485e-02, -5.8696e-03,  1.0113e-02,  1.5500e-02,\n",
       "                        3.5528e-03,  2.3111e-02,  1.2688e-02,  1.8902e-02,  1.8136e-02,\n",
       "                        2.1633e-02,  1.2754e-02,  2.6635e-02, -1.1400e-03,  6.6982e-03,\n",
       "                       -8.7034e-03,  8.0057e-03,  2.0764e-03,  2.9824e-03,  2.0906e-02,\n",
       "                        2.3959e-02, -7.0429e-03,  1.7641e-02,  7.0470e-03,  3.8810e-02,\n",
       "                        2.1880e-02,  2.0685e-02,  1.7676e-02,  1.3271e-02,  1.5489e-02,\n",
       "                        3.1439e-03,  1.4043e-02, -2.1893e-02, -3.9217e-03, -1.9317e-02,\n",
       "                       -1.1621e-02,  2.5370e-02,  1.8595e-02,  5.5369e-03,  2.8377e-02,\n",
       "                        7.0321e-04,  3.0216e-03,  1.0885e-02, -3.5471e-03, -3.4434e-03,\n",
       "                       -2.9884e-03,  2.2567e-03,  8.7348e-03,  1.8374e-02,  1.4265e-03,\n",
       "                       -1.0535e-02,  3.0123e-02,  1.3774e-02, -1.3888e-02,  1.9549e-03,\n",
       "                        2.0544e-02,  5.7959e-03,  1.5295e-02, -2.1561e-02,  1.6517e-02,\n",
       "                        1.8871e-03,  5.6566e-03, -2.1870e-02,  1.1841e-02,  1.0172e-02,\n",
       "                        1.0175e-02, -3.4700e-03,  8.9811e-03,  1.6012e-02,  2.6701e-03,\n",
       "                        6.2839e-03,  1.0099e-02,  7.9739e-03,  1.0462e-02,  6.0668e-03,\n",
       "                       -7.5618e-03,  1.5839e-02,  9.0176e-03, -5.3363e-04,  1.3397e-02,\n",
       "                        3.9545e-03, -3.9281e-04, -1.0878e-02, -8.8756e-05, -3.4557e-03,\n",
       "                        1.0853e-02,  7.4721e-03, -1.5804e-05, -2.0941e-02,  7.2353e-03,\n",
       "                       -6.1024e-03, -1.3246e-02,  1.4677e-02,  3.5522e-04,  1.6858e-02,\n",
       "                       -3.0463e-03,  1.8374e-02,  8.8343e-03, -4.0443e-03,  8.9950e-03,\n",
       "                        4.1851e-03,  1.7842e-02,  2.7115e-03,  1.2059e-02,  3.4100e-02,\n",
       "                        2.6609e-03,  2.0812e-02,  7.0620e-03,  9.0362e-03,  1.1689e-02,\n",
       "                        1.3980e-02, -2.8495e-04,  4.3204e-03,  3.6332e-03, -3.2960e-03,\n",
       "                        3.3398e-03, -3.5834e-03,  4.5469e-03,  1.9004e-02,  1.7964e-02,\n",
       "                        1.8289e-02,  2.5478e-02,  6.0373e-03,  1.6054e-02,  3.9777e-03],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.4.edge_encoder.0.weight',\n",
       "               tensor([[ 0.0306, -0.0353,  0.0325,  ..., -0.0054, -0.0064, -0.0239],\n",
       "                       [ 0.0247,  0.0387,  0.0236,  ...,  0.0328,  0.0120, -0.0459],\n",
       "                       [ 0.0180, -0.0081, -0.0130,  ..., -0.0158,  0.0251,  0.0164],\n",
       "                       ...,\n",
       "                       [ 0.0070,  0.0437, -0.0125,  ..., -0.0002, -0.0051, -0.0569],\n",
       "                       [ 0.0213,  0.0714,  0.0441,  ..., -0.0479,  0.0109, -0.0085],\n",
       "                       [ 0.0176, -0.0074, -0.0351,  ..., -0.0420,  0.0276, -0.0018]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.4.edge_encoder.0.bias',\n",
       "               tensor([ 0.0077,  0.0119,  0.0017, -0.0190, -0.0046,  0.0056,  0.0168,  0.0094,\n",
       "                       -0.0051,  0.0039, -0.0029,  0.0186, -0.0180,  0.0189,  0.0191, -0.0094,\n",
       "                        0.0084,  0.0184, -0.0068, -0.0066, -0.0126, -0.0144,  0.0322,  0.0054,\n",
       "                        0.0056, -0.0084,  0.0076,  0.0117, -0.0092, -0.0210,  0.0302,  0.0111,\n",
       "                        0.0049,  0.0133,  0.0009,  0.0033,  0.0078, -0.0005,  0.0011,  0.0380,\n",
       "                        0.0042, -0.0085, -0.0131, -0.0191, -0.0132, -0.0132,  0.0060,  0.0126,\n",
       "                        0.0204, -0.0218, -0.0039,  0.0289,  0.0030,  0.0034,  0.0042,  0.0069,\n",
       "                        0.0276,  0.0014,  0.0052, -0.0010,  0.0165, -0.0045, -0.0037,  0.0045,\n",
       "                        0.0175, -0.0177, -0.0008,  0.0173, -0.0091,  0.0122, -0.0022, -0.0185,\n",
       "                       -0.0071, -0.0143,  0.0194,  0.0052,  0.0028,  0.0003, -0.0044,  0.0021,\n",
       "                       -0.0239, -0.0257,  0.0002,  0.0104,  0.0085,  0.0029,  0.0085,  0.0186,\n",
       "                        0.0136, -0.0184,  0.0170,  0.0219,  0.0114,  0.0373, -0.0013, -0.0081,\n",
       "                        0.0079,  0.0001,  0.0129, -0.0018,  0.0132,  0.0188,  0.0141, -0.0070,\n",
       "                        0.0138,  0.0063, -0.0268, -0.0065,  0.0113,  0.0060,  0.0369,  0.0077,\n",
       "                        0.0054, -0.0095, -0.0127, -0.0155, -0.0099, -0.0243, -0.0093,  0.0114,\n",
       "                       -0.0292, -0.0092, -0.0165,  0.0360, -0.0180,  0.0009, -0.0012, -0.0136,\n",
       "                       -0.0028, -0.0299, -0.0139,  0.0060, -0.0042,  0.0075, -0.0028,  0.0032,\n",
       "                        0.0168, -0.0089,  0.0203,  0.0222,  0.0033, -0.0214,  0.0055, -0.0004,\n",
       "                       -0.0070, -0.0103,  0.0122,  0.0016,  0.0049,  0.0059,  0.0101, -0.0175,\n",
       "                       -0.0075,  0.0347, -0.0166,  0.0217,  0.0009, -0.0263,  0.0026,  0.0296,\n",
       "                        0.0109,  0.0100, -0.0139, -0.0151,  0.0139,  0.0117,  0.0224,  0.0200,\n",
       "                        0.0159,  0.0146, -0.0090,  0.0056,  0.0198, -0.0114,  0.0122, -0.0099,\n",
       "                       -0.0116,  0.0004, -0.0143, -0.0011,  0.0056,  0.0021,  0.0154, -0.0226,\n",
       "                       -0.0033, -0.0069, -0.0072, -0.0033, -0.0062, -0.0068, -0.0164,  0.0153,\n",
       "                       -0.0333,  0.0075, -0.0050, -0.0042, -0.0204,  0.0111, -0.0367,  0.0139],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.4.edge_encoder.1.weight',\n",
       "               tensor([0.9628, 0.9829, 0.9672, 0.9673, 0.9706, 0.9835, 0.9779, 0.9585, 0.9801,\n",
       "                       1.0104, 0.9749, 0.9749, 0.9704, 0.9653, 0.9617, 0.9588, 0.9810, 0.9747,\n",
       "                       0.9706, 0.9653, 0.9548, 0.9736, 0.9918, 0.9715, 0.9768, 0.9686, 0.9768,\n",
       "                       0.9644, 0.9705, 0.9647, 0.9775, 0.9654, 0.9791, 0.9719, 0.9689, 1.0024,\n",
       "                       0.9714, 0.9612, 0.9602, 0.9835, 0.9716, 0.9771, 0.9913, 0.9704, 0.9972,\n",
       "                       0.9774, 0.9673, 0.9556, 0.9649, 0.9712, 0.9714, 0.9532, 0.9586, 0.9630,\n",
       "                       0.9654, 0.9569, 0.9866, 0.9909, 0.9710, 0.9789, 0.9821, 0.9766, 0.9629,\n",
       "                       1.0112, 0.9736, 1.0307, 0.9648, 0.9848, 0.9644, 0.9779, 0.9688, 0.9556,\n",
       "                       0.9911, 0.9716, 0.9692, 0.9976, 0.9801, 0.9737, 0.9750, 1.0032, 0.9712,\n",
       "                       0.9831, 0.9793, 1.0119, 0.9947, 0.9525, 0.9689, 1.0086, 0.9671, 0.9862,\n",
       "                       0.9723, 0.9898, 0.9515, 0.9780, 0.9625, 0.9707, 0.9851, 0.9711, 0.9946,\n",
       "                       0.9929, 1.0127, 0.9705, 0.9535, 0.9593, 0.9769, 0.9911, 0.9627, 0.9748,\n",
       "                       0.9724, 0.9391, 0.9803, 0.9876, 0.9843, 0.9748, 0.9582, 0.9636, 0.9737,\n",
       "                       0.9705, 0.9908, 0.9860, 0.9873, 0.9901, 0.9624, 0.9739, 0.9752, 0.9613,\n",
       "                       0.9775, 0.9644, 0.9877, 0.9880, 0.9751, 0.9752, 0.9599, 0.9629, 0.9751,\n",
       "                       0.9859, 0.9705, 0.9769, 0.9848, 0.9831, 0.9677, 1.0146, 0.9704, 0.9786,\n",
       "                       0.9771, 0.9810, 0.9668, 0.9568, 0.9419, 0.9776, 0.9674, 0.9866, 0.9767,\n",
       "                       0.9543, 0.9812, 1.0107, 0.9792, 0.9727, 0.9707, 0.9655, 0.9763, 0.9820,\n",
       "                       0.9982, 0.9833, 0.9660, 1.0028, 0.9630, 0.9713, 1.0131, 0.9784, 0.9664,\n",
       "                       0.9688, 0.9602, 0.9605, 0.9668, 0.9759, 0.9633, 0.9736, 0.9751, 0.9571,\n",
       "                       0.9551, 0.9673, 0.9850, 0.9753, 0.9827, 0.9796, 0.9681, 0.9709, 0.9784,\n",
       "                       0.9611, 0.9603, 0.9895, 0.9809, 0.9890, 0.9777, 0.9484, 0.9913, 0.9686,\n",
       "                       1.0060, 0.9723], device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.4.edge_encoder.1.bias',\n",
       "               tensor([-2.5693e-02, -9.7445e-03, -1.3280e-02, -1.4876e-02, -1.3010e-02,\n",
       "                       -2.8902e-02, -1.5408e-02, -1.3348e-02, -7.5672e-03,  1.6497e-03,\n",
       "                       -7.8495e-03, -9.1716e-03, -2.0961e-02, -2.2757e-02, -2.0028e-02,\n",
       "                       -1.7987e-02, -7.9770e-03, -1.8736e-03, -5.3145e-03, -3.8504e-03,\n",
       "                       -1.5113e-02, -2.7974e-02,  2.6333e-03, -8.1461e-03, -1.9291e-02,\n",
       "                       -1.5892e-03,  1.6622e-04, -1.8932e-02, -1.3259e-02, -2.7374e-02,\n",
       "                       -1.4522e-02, -1.6898e-02, -8.0646e-03, -1.0664e-02, -1.0739e-02,\n",
       "                       -1.7976e-03, -1.9121e-02, -1.7618e-02, -1.1595e-02, -8.5707e-03,\n",
       "                       -1.0648e-02, -1.1552e-02, -1.4868e-02, -9.6961e-03, -2.4517e-02,\n",
       "                       -7.4088e-03,  7.0666e-03, -1.7505e-02, -1.4665e-02, -2.4669e-02,\n",
       "                       -2.5899e-02, -3.7980e-02, -2.2516e-02, -3.0423e-03, -9.7302e-03,\n",
       "                       -2.5835e-02, -2.2611e-03, -4.0520e-03, -6.8373e-03, -1.9277e-02,\n",
       "                       -8.0628e-03, -1.8217e-02, -1.6750e-02, -1.5095e-02, -1.4788e-03,\n",
       "                       -3.7971e-02, -1.9556e-02,  1.5557e-04, -7.2736e-03, -3.9847e-03,\n",
       "                       -1.2300e-02, -1.9903e-02, -1.9171e-02, -9.9416e-03, -5.3805e-03,\n",
       "                        1.5913e-03, -7.6342e-03, -3.3007e-03, -6.2690e-03, -1.4096e-05,\n",
       "                       -1.5686e-02, -6.8913e-03, -1.7321e-02, -2.5634e-02, -1.4783e-02,\n",
       "                       -2.4108e-02, -1.3706e-02, -2.0894e-02, -2.0094e-02, -6.5898e-03,\n",
       "                       -1.2185e-02, -6.1023e-03, -2.7504e-02, -2.4717e-02, -2.5939e-02,\n",
       "                       -1.5674e-02, -5.1389e-03, -7.2659e-03,  4.9414e-03, -1.5022e-03,\n",
       "                       -1.3755e-02, -2.0142e-02, -2.5539e-02, -3.3021e-02, -1.7456e-02,\n",
       "                       -7.0987e-03, -1.8066e-02, -7.1374e-03, -9.0562e-03, -4.0189e-02,\n",
       "                       -4.1441e-03, -9.2944e-03, -8.8290e-03, -1.3431e-02, -1.1504e-02,\n",
       "                       -2.5691e-02, -1.5559e-02, -2.4027e-02, -1.8737e-02, -6.9398e-03,\n",
       "                       -1.3982e-02, -9.3979e-03, -2.2429e-02, -1.6925e-02, -1.1936e-02,\n",
       "                       -2.2714e-02, -8.0626e-03, -2.0102e-02, -1.1027e-02, -1.1894e-02,\n",
       "                       -2.9027e-02, -1.0246e-02, -2.0020e-02, -2.4571e-02,  1.9411e-03,\n",
       "                       -2.1970e-02, -1.8667e-02, -1.4658e-02, -3.9352e-03, -1.8957e-02,\n",
       "                       -9.4686e-03, -2.8255e-02,  5.2848e-04,  7.7191e-03, -1.7395e-02,\n",
       "                       -1.0582e-02, -1.7854e-02, -2.6494e-02, -3.3694e-02, -2.2807e-02,\n",
       "                       -2.3661e-02, -5.3341e-03, -7.3770e-03, -3.4522e-02, -2.7705e-02,\n",
       "                       -7.6568e-03, -5.1986e-03,  6.7720e-03, -2.3240e-02, -3.5141e-02,\n",
       "                       -1.3055e-02, -8.6289e-03, -2.5888e-02, -1.1771e-02, -1.2512e-02,\n",
       "                       -1.8411e-02, -3.3645e-02, -7.4316e-03, -1.2644e-02, -7.5547e-03,\n",
       "                       -1.6641e-02, -1.9724e-02, -2.6223e-02, -1.5339e-02, -6.3751e-03,\n",
       "                       -5.5682e-03, -2.3769e-02, -8.3162e-03, -7.2813e-03, -3.8014e-02,\n",
       "                       -2.6523e-02, -2.3696e-02, -9.4407e-03, -1.6965e-02, -1.8803e-02,\n",
       "                        4.4039e-03, -1.6914e-02, -1.6613e-02,  7.9222e-03, -2.1573e-02,\n",
       "                       -5.3399e-03, -1.7694e-02, -4.4106e-03, -3.1973e-03, -3.3638e-03,\n",
       "                       -3.0254e-02,  3.6135e-03, -1.7349e-02,  2.9815e-03, -8.8753e-03],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.4.edge_encoder.1.running_mean',\n",
       "               tensor([ 2.7008e-02,  1.6912e-03,  1.5797e-02, -6.7778e-02,  2.0418e-02,\n",
       "                       -1.1173e-02,  1.5179e-02,  2.4307e-02,  1.2653e-02,  4.6869e-03,\n",
       "                       -1.0762e-02, -1.9674e-03, -1.3291e-02,  3.0813e-02, -1.3610e-03,\n",
       "                        4.5526e-03,  2.5402e-02,  2.0468e-02,  1.6868e-02,  1.5769e-02,\n",
       "                       -3.7985e-03, -2.9739e-02,  3.6873e-02, -1.5693e-03, -2.0923e-02,\n",
       "                        4.5054e-02,  3.2104e-02, -3.1810e-03,  5.9307e-03, -2.4748e-03,\n",
       "                        2.8697e-02,  2.8321e-03,  4.0958e-02,  2.8253e-02,  3.6128e-02,\n",
       "                       -1.6234e-02,  1.5718e-02,  2.1499e-02,  3.2818e-02,  4.5780e-02,\n",
       "                        1.8265e-02, -2.2358e-02,  1.0330e-02, -8.1752e-03, -7.3849e-02,\n",
       "                       -7.7433e-02, -9.5062e-03,  5.6934e-02,  2.9798e-02, -5.6704e-02,\n",
       "                       -2.8998e-04,  3.8911e-02,  7.1862e-02,  2.8319e-02, -1.3835e-03,\n",
       "                        2.4380e-02,  4.7917e-02, -7.5812e-03,  4.3195e-02, -8.7772e-03,\n",
       "                        3.0336e-02, -2.1767e-02, -2.0313e-02, -5.7155e-02,  2.2238e-02,\n",
       "                       -1.7876e-02,  7.2475e-03,  5.9072e-02,  1.7254e-02,  3.5640e-02,\n",
       "                       -5.3690e-02,  3.1887e-02, -6.1408e-02,  1.1748e-02, -2.8399e-02,\n",
       "                        3.6311e-02,  3.8973e-02,  6.4906e-02,  7.8385e-03, -2.0935e-02,\n",
       "                       -5.8416e-02, -2.0047e-02, -3.1496e-02,  2.9189e-02, -3.4504e-02,\n",
       "                       -2.7514e-02,  6.8505e-02,  2.8062e-03,  1.8849e-05, -1.3774e-02,\n",
       "                        9.2343e-03,  3.7521e-02,  4.5121e-02,  1.4074e-02, -1.8121e-04,\n",
       "                       -4.0558e-02, -3.7644e-03,  1.6923e-02,  2.7104e-02, -1.5634e-02,\n",
       "                       -4.1377e-03,  9.3574e-03,  1.9628e-02,  5.6155e-02,  5.2343e-02,\n",
       "                        8.2967e-03, -3.7830e-03, -4.8709e-03, -8.8138e-03,  5.4959e-02,\n",
       "                        9.5033e-02, -8.7470e-03, -2.1711e-03, -2.7213e-02,  2.7870e-02,\n",
       "                       -6.4279e-02, -1.5909e-02, -4.3667e-02, -1.5132e-02, -9.5939e-03,\n",
       "                       -1.8963e-02, -6.7713e-03, -5.5545e-02, -1.0497e-02, -3.9040e-02,\n",
       "                       -4.8672e-03,  1.1762e-02, -1.5282e-02, -4.3349e-02, -5.3518e-02,\n",
       "                        4.6776e-03, -4.4651e-02, -4.5448e-02, -1.2307e-02,  1.7775e-02,\n",
       "                       -4.1911e-03,  2.1014e-02, -4.3004e-03,  2.7901e-02,  1.0977e-02,\n",
       "                       -7.3112e-03, -3.7840e-02, -1.7166e-03,  1.3762e-02, -2.5244e-02,\n",
       "                        1.1566e-02,  7.3994e-02, -4.3874e-03,  4.3512e-02, -4.0878e-02,\n",
       "                        1.8922e-03, -1.0121e-02, -2.9110e-02,  2.4583e-02, -4.8153e-02,\n",
       "                        2.5973e-02, -2.9922e-03, -2.0870e-02, -2.2877e-02, -1.4993e-03,\n",
       "                       -5.9943e-03, -7.2241e-03, -2.0146e-02,  1.2459e-02, -3.8290e-03,\n",
       "                       -2.0011e-02,  3.9809e-02,  1.3255e-02, -4.2352e-04,  1.7046e-02,\n",
       "                       -6.5159e-03,  1.2209e-02,  6.6373e-02, -1.1389e-02,  5.5789e-02,\n",
       "                        1.8531e-02, -1.1453e-02,  2.1218e-02,  1.8626e-02,  1.3585e-02,\n",
       "                       -3.0026e-02,  1.2386e-02, -9.9208e-03, -2.6795e-04, -8.1980e-03,\n",
       "                       -1.3025e-02, -1.7465e-02,  3.8352e-04, -2.6250e-02, -3.8193e-02,\n",
       "                        1.8636e-02, -7.6045e-03, -3.9300e-02,  1.3399e-03,  1.3233e-02,\n",
       "                        1.9639e-02, -1.1317e-02, -1.9422e-02, -3.2577e-02,  5.8234e-02],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.4.edge_encoder.1.running_var',\n",
       "               tensor([0.0007, 0.0011, 0.0017, 0.0010, 0.0004, 0.0005, 0.0011, 0.0008, 0.0008,\n",
       "                       0.0006, 0.0011, 0.0012, 0.0004, 0.0011, 0.0017, 0.0008, 0.0009, 0.0008,\n",
       "                       0.0008, 0.0017, 0.0010, 0.0005, 0.0005, 0.0005, 0.0007, 0.0009, 0.0004,\n",
       "                       0.0016, 0.0005, 0.0014, 0.0013, 0.0005, 0.0005, 0.0010, 0.0009, 0.0005,\n",
       "                       0.0009, 0.0014, 0.0012, 0.0007, 0.0004, 0.0008, 0.0005, 0.0008, 0.0010,\n",
       "                       0.0010, 0.0010, 0.0012, 0.0016, 0.0011, 0.0004, 0.0004, 0.0009, 0.0014,\n",
       "                       0.0009, 0.0013, 0.0004, 0.0005, 0.0009, 0.0005, 0.0003, 0.0009, 0.0005,\n",
       "                       0.0007, 0.0009, 0.0004, 0.0008, 0.0009, 0.0006, 0.0004, 0.0013, 0.0007,\n",
       "                       0.0007, 0.0006, 0.0007, 0.0004, 0.0007, 0.0007, 0.0007, 0.0003, 0.0020,\n",
       "                       0.0011, 0.0006, 0.0004, 0.0010, 0.0019, 0.0012, 0.0007, 0.0005, 0.0004,\n",
       "                       0.0005, 0.0009, 0.0012, 0.0007, 0.0007, 0.0014, 0.0015, 0.0009, 0.0009,\n",
       "                       0.0006, 0.0004, 0.0006, 0.0008, 0.0008, 0.0012, 0.0005, 0.0013, 0.0009,\n",
       "                       0.0006, 0.0015, 0.0007, 0.0006, 0.0007, 0.0010, 0.0010, 0.0010, 0.0005,\n",
       "                       0.0006, 0.0006, 0.0005, 0.0003, 0.0008, 0.0007, 0.0010, 0.0008, 0.0009,\n",
       "                       0.0008, 0.0012, 0.0011, 0.0014, 0.0014, 0.0012, 0.0019, 0.0012, 0.0016,\n",
       "                       0.0008, 0.0008, 0.0006, 0.0006, 0.0012, 0.0004, 0.0006, 0.0020, 0.0009,\n",
       "                       0.0004, 0.0004, 0.0010, 0.0010, 0.0006, 0.0004, 0.0008, 0.0006, 0.0010,\n",
       "                       0.0016, 0.0006, 0.0004, 0.0010, 0.0015, 0.0007, 0.0009, 0.0008, 0.0008,\n",
       "                       0.0005, 0.0006, 0.0010, 0.0003, 0.0010, 0.0007, 0.0005, 0.0007, 0.0007,\n",
       "                       0.0008, 0.0009, 0.0022, 0.0009, 0.0007, 0.0006, 0.0006, 0.0006, 0.0014,\n",
       "                       0.0004, 0.0004, 0.0003, 0.0004, 0.0008, 0.0010, 0.0010, 0.0010, 0.0016,\n",
       "                       0.0016, 0.0008, 0.0008, 0.0017, 0.0004, 0.0013, 0.0004, 0.0015, 0.0007,\n",
       "                       0.0011, 0.0009], device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.4.edge_encoder.1.num_batches_tracked',\n",
       "               tensor(318750, device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.4.edge_encoder.3.weight',\n",
       "               tensor([[-0.0193, -0.0094, -0.0241,  ...,  0.0122, -0.0301, -0.0028],\n",
       "                       [ 0.0069,  0.0188,  0.0111,  ..., -0.0008, -0.0141,  0.0301],\n",
       "                       [ 0.0371, -0.0236, -0.0005,  ..., -0.0178,  0.0145,  0.0044],\n",
       "                       ...,\n",
       "                       [ 0.0266,  0.0113,  0.0204,  ..., -0.0058,  0.0168, -0.0279],\n",
       "                       [ 0.0263, -0.0120,  0.0145,  ..., -0.0088,  0.0285, -0.0355],\n",
       "                       [ 0.0217,  0.0041,  0.0519,  ...,  0.0308, -0.0709, -0.0156]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.4.edge_encoder.3.bias',\n",
       "               tensor([-2.3653e-03, -5.7033e-03,  2.7150e-03,  1.7915e-03, -1.3082e-03,\n",
       "                       -3.1844e-04,  8.8534e-04, -5.2766e-03,  1.3499e-03,  4.7690e-03,\n",
       "                       -4.6336e-03,  1.4850e-03, -3.2236e-03,  3.7453e-03, -8.5289e-03,\n",
       "                        7.5043e-03,  5.8532e-03,  2.3962e-04, -5.7625e-04,  5.2903e-04,\n",
       "                       -1.7449e-03,  5.2435e-03,  2.9055e-03, -4.1971e-03, -5.6767e-03,\n",
       "                       -4.0691e-03, -1.4285e-03,  5.0252e-03, -1.9099e-03,  1.1951e-03,\n",
       "                        2.1446e-03, -2.3171e-03,  5.1971e-03,  1.3342e-03, -6.3974e-03,\n",
       "                        7.7394e-04, -5.0417e-03, -4.6538e-04,  8.4626e-03, -4.4000e-04,\n",
       "                       -7.0619e-04,  4.7418e-03, -5.4846e-03, -5.1588e-03, -7.3695e-03,\n",
       "                       -9.4579e-03,  4.9077e-03, -5.9823e-03,  1.0702e-03, -2.1661e-03,\n",
       "                        1.0390e-03,  1.1983e-03, -4.2399e-03, -1.2942e-03, -7.8520e-03,\n",
       "                       -3.5293e-03, -1.0280e-02,  3.5102e-04,  3.8343e-03, -1.2780e-03,\n",
       "                        4.5618e-04,  3.8666e-03,  1.8226e-03,  4.2149e-03, -7.9116e-03,\n",
       "                       -6.3569e-03,  7.4834e-04,  4.8660e-04, -3.4787e-03, -3.4874e-03,\n",
       "                       -2.9350e-03,  6.0196e-03,  2.0707e-03,  6.1710e-03, -2.5195e-04,\n",
       "                        2.7551e-03, -3.0170e-03, -3.2106e-03, -5.5723e-05,  5.0233e-03,\n",
       "                       -5.5378e-03, -8.5195e-03,  2.5666e-03, -1.8356e-03,  1.2716e-03,\n",
       "                       -1.2945e-03,  1.9425e-03,  8.8292e-04,  2.0636e-03,  1.4934e-03,\n",
       "                       -1.9848e-03,  9.8496e-03, -2.1664e-03,  1.9293e-03, -3.8735e-03,\n",
       "                       -5.7664e-03,  3.7731e-03, -2.0194e-03,  5.2783e-03,  3.5625e-03,\n",
       "                       -4.3390e-03, -4.5637e-03,  6.6010e-03,  3.1173e-03,  4.0452e-03,\n",
       "                       -2.6583e-03,  4.5262e-03, -1.5825e-03, -4.2482e-03, -3.4520e-03,\n",
       "                        2.3763e-03,  3.6228e-03,  1.7307e-03,  1.0506e-03,  4.2683e-03,\n",
       "                       -3.5708e-04, -2.0222e-03, -1.5319e-03,  4.2033e-03, -6.7279e-03,\n",
       "                        1.4046e-03,  2.9070e-03,  3.6665e-03,  1.5358e-03,  2.2912e-03,\n",
       "                        1.5417e-03, -5.5028e-03,  1.9160e-03, -3.6478e-03, -3.0722e-03,\n",
       "                       -6.0849e-04,  4.6370e-03,  1.5033e-03,  7.6505e-03,  1.1843e-03,\n",
       "                       -2.6880e-03, -7.3885e-04, -1.9909e-03, -4.8474e-03,  7.0672e-03,\n",
       "                        7.6360e-03, -5.4759e-03, -6.0674e-03, -1.4287e-03,  1.6351e-03,\n",
       "                        4.7338e-03, -4.7588e-03, -5.5839e-03,  1.8682e-03, -1.0032e-03,\n",
       "                       -1.1349e-04,  6.5163e-03,  7.6160e-04,  6.0492e-03,  2.1817e-03,\n",
       "                        5.5140e-04, -5.6854e-03,  2.1677e-04,  1.8623e-03,  1.7347e-03,\n",
       "                       -3.2468e-03,  2.5972e-03, -1.4406e-03, -4.4453e-03, -6.4311e-03,\n",
       "                       -3.7272e-03,  2.8988e-03, -3.4194e-03,  8.8222e-04,  3.5037e-03,\n",
       "                        4.3227e-04, -1.8212e-03,  1.9136e-03, -3.1052e-03, -5.8780e-03,\n",
       "                       -9.3809e-04,  2.1546e-03, -5.0847e-03, -5.3777e-03, -3.2735e-03,\n",
       "                        1.7199e-04, -1.1658e-03,  3.6198e-03,  4.1820e-03,  1.1943e-04,\n",
       "                       -1.7642e-03,  4.1916e-03,  8.8105e-04, -6.2575e-03,  6.1010e-03,\n",
       "                       -4.3334e-04,  1.6691e-03,  8.9472e-06,  5.3347e-03,  4.1516e-03,\n",
       "                        4.4639e-03,  4.7324e-03, -6.6560e-04, -5.5783e-03,  1.1676e-03],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.4.linear_key.weight',\n",
       "               tensor([[-0.0174, -0.0075, -0.0178,  ...,  0.0331,  0.0086,  0.0188],\n",
       "                       [-0.0261,  0.0199,  0.0184,  ...,  0.0088,  0.0205,  0.0070],\n",
       "                       [-0.0167, -0.0150, -0.0182,  ..., -0.0140, -0.0180,  0.0003],\n",
       "                       ...,\n",
       "                       [-0.0484,  0.0122,  0.0207,  ..., -0.0159,  0.0132, -0.0069],\n",
       "                       [ 0.0055,  0.0027,  0.0291,  ..., -0.0143,  0.0007, -0.0397],\n",
       "                       [ 0.0263, -0.0147,  0.0306,  ...,  0.0006, -0.0084,  0.0151]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.4.linear_key.bias',\n",
       "               tensor([-2.0361e-02, -1.3585e-02,  1.6256e-02, -1.9488e-02,  1.8675e-02,\n",
       "                        9.7456e-03, -2.1691e-03, -2.1546e-03, -1.7278e-02,  6.7567e-03,\n",
       "                       -2.3131e-03, -2.4437e-02, -3.5201e-02, -1.9527e-02,  1.7901e-02,\n",
       "                       -2.1086e-02,  1.8843e-02, -2.8507e-02,  3.1116e-02, -1.4423e-02,\n",
       "                       -4.4986e-02, -9.9926e-03, -1.0158e-02,  1.6467e-02,  1.8762e-02,\n",
       "                       -5.3391e-03, -1.4838e-02,  1.2698e-02, -2.9353e-02, -1.7169e-02,\n",
       "                        1.0275e-02,  3.0359e-02,  9.6568e-03, -3.1193e-02, -7.0709e-04,\n",
       "                       -2.0554e-02, -1.4149e-02, -1.8807e-02,  2.8204e-02,  8.2927e-03,\n",
       "                       -1.0176e-02, -3.4930e-03,  2.7666e-02,  7.9554e-03, -1.1180e-02,\n",
       "                       -1.0738e-02,  1.0681e-02, -1.1160e-02,  1.7261e-02,  3.0824e-03,\n",
       "                       -1.3169e-02, -2.4229e-03,  1.2116e-02, -2.4050e-03,  4.8218e-04,\n",
       "                        2.8070e-02,  3.0176e-03, -7.6056e-03,  2.1462e-03,  2.4011e-02,\n",
       "                       -8.7551e-03,  1.1112e-03,  8.2797e-03,  3.2275e-03, -8.5847e-03,\n",
       "                        2.7811e-02,  1.4373e-02, -3.9583e-03, -1.7444e-02,  5.3861e-03,\n",
       "                        1.0021e-03, -6.5996e-04,  9.4627e-03,  1.6703e-02, -9.3798e-03,\n",
       "                        1.3695e-02,  6.3828e-03,  6.1141e-03, -1.1883e-02, -2.4466e-02,\n",
       "                       -1.5600e-02, -8.4963e-05,  1.1245e-02, -9.5523e-03,  1.0915e-02,\n",
       "                        1.9887e-03,  1.1448e-03,  5.9110e-03,  1.2738e-02, -7.8768e-03,\n",
       "                        1.7390e-03, -1.0120e-02, -1.7310e-02,  6.8927e-03, -2.7884e-03,\n",
       "                       -1.2022e-04,  9.6144e-03, -1.1217e-03, -5.1758e-04,  7.8154e-03,\n",
       "                       -2.6472e-02,  1.0558e-02, -2.0036e-02,  8.2444e-03, -2.1908e-02,\n",
       "                       -1.0068e-02,  3.9347e-03, -1.2443e-02, -1.4185e-02, -1.5558e-02,\n",
       "                       -2.7794e-03, -7.3212e-04,  2.5161e-02,  1.1396e-02,  1.8585e-02,\n",
       "                        3.1850e-02,  3.5856e-03,  7.1022e-03, -1.3033e-02, -6.4599e-03,\n",
       "                       -5.1281e-04,  1.8632e-03, -1.3350e-02,  9.8378e-03,  1.3703e-02,\n",
       "                        2.4600e-02, -1.2608e-02, -9.4540e-03,  1.0820e-02,  6.8718e-03,\n",
       "                        2.7586e-02, -1.6604e-02, -1.0196e-02, -5.2672e-03,  3.9570e-04,\n",
       "                        4.7798e-03,  7.3857e-03,  1.2877e-02, -1.9195e-02, -2.7407e-02,\n",
       "                       -1.3817e-02,  6.8572e-03,  9.1689e-04,  1.2197e-02, -2.1288e-02,\n",
       "                       -5.9910e-03,  7.2908e-03, -7.3262e-03,  2.3270e-02,  6.1475e-03,\n",
       "                        3.1430e-03, -1.5719e-03, -8.6737e-03,  2.8269e-03,  5.8124e-03,\n",
       "                       -1.1925e-03,  6.0953e-03, -9.4999e-03, -2.5553e-03, -7.3679e-03,\n",
       "                       -1.8339e-02,  7.6487e-03, -2.9845e-03, -2.4019e-02,  4.9802e-03,\n",
       "                        3.6179e-03,  1.1267e-02,  1.0451e-04,  5.4782e-03, -4.0756e-02,\n",
       "                        1.1025e-02,  2.0049e-02,  1.1878e-02, -9.1809e-03, -1.9087e-02,\n",
       "                       -2.2857e-02,  1.8188e-03, -5.3641e-03, -2.9514e-02, -2.0174e-02,\n",
       "                       -1.7496e-02, -2.9632e-03,  4.9012e-03,  1.1587e-02, -1.3219e-02,\n",
       "                        1.0501e-02,  1.2119e-02,  1.4126e-02, -5.3790e-03, -1.8683e-03,\n",
       "                        1.8508e-03, -2.2378e-02, -3.9305e-02, -7.8273e-03,  1.7121e-02,\n",
       "                       -3.2266e-03, -1.1195e-02, -1.5430e-02, -1.0927e-02,  1.5571e-02],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.4.linear_msg.weight',\n",
       "               tensor([[-0.0041,  0.0235,  0.0409,  ..., -0.0254, -0.0332, -0.0167],\n",
       "                       [ 0.0129,  0.0383, -0.0074,  ...,  0.0034, -0.0177, -0.0132],\n",
       "                       [-0.0087,  0.0068, -0.0015,  ...,  0.0168,  0.0425, -0.0039],\n",
       "                       ...,\n",
       "                       [-0.0378,  0.0039, -0.0179,  ...,  0.0036, -0.0505,  0.0058],\n",
       "                       [ 0.0091,  0.0134,  0.0077,  ..., -0.0127,  0.0168, -0.0122],\n",
       "                       [ 0.0011, -0.0541, -0.0143,  ...,  0.0086,  0.0173,  0.0168]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.4.linear_msg.bias',\n",
       "               tensor([ 1.2442e-02,  4.8924e-03, -6.7801e-03, -2.8757e-02, -1.0203e-02,\n",
       "                        4.1644e-03, -1.0881e-02,  9.8595e-03,  1.2610e-02, -1.1174e-02,\n",
       "                       -2.6269e-03,  2.1854e-03,  5.8973e-03,  1.5072e-03, -1.6198e-02,\n",
       "                        5.4929e-03,  1.3514e-02, -5.4019e-03,  8.4693e-03, -5.9947e-03,\n",
       "                       -1.3583e-02, -1.0126e-02, -1.4251e-02,  4.9310e-03, -2.2384e-03,\n",
       "                       -2.0614e-04,  6.5417e-03, -3.1551e-03, -9.5498e-03, -1.0863e-02,\n",
       "                        6.6747e-03, -1.9492e-02, -1.5803e-02, -4.9199e-03, -1.3338e-02,\n",
       "                       -1.7072e-02,  1.5511e-03,  1.4419e-02, -5.2024e-03,  1.4456e-02,\n",
       "                        8.7422e-03,  2.2308e-02, -3.6750e-04,  5.9243e-03,  1.0451e-02,\n",
       "                        9.7118e-03, -1.3962e-02,  5.0843e-03,  5.7733e-03,  1.2407e-02,\n",
       "                        1.6830e-03, -7.5544e-03, -1.6936e-02,  4.6087e-03, -1.4313e-02,\n",
       "                       -1.6295e-03,  1.2602e-02,  3.0640e-03, -6.6388e-03,  5.0650e-03,\n",
       "                       -3.8087e-03,  5.7915e-03, -2.5066e-03,  9.4404e-03,  4.3008e-03,\n",
       "                        7.9756e-03,  9.1158e-03,  3.4974e-03,  9.3498e-03,  1.1780e-02,\n",
       "                       -1.7039e-03, -2.8936e-03,  8.5089e-03,  3.2079e-03, -9.6781e-03,\n",
       "                       -2.6276e-03,  3.2281e-03,  7.7788e-03, -1.3112e-02,  3.4701e-04,\n",
       "                        1.5125e-03,  5.2154e-03, -1.1769e-02,  1.4585e-03, -2.5928e-04,\n",
       "                       -8.5234e-03, -7.7187e-03, -1.6995e-03, -2.0239e-03,  2.6604e-03,\n",
       "                       -4.5600e-03, -8.2359e-03, -1.2275e-02,  9.0281e-03, -2.6951e-03,\n",
       "                        6.0572e-03,  1.5126e-03,  4.7947e-03,  5.3855e-03,  1.0448e-03,\n",
       "                        6.6057e-03,  2.1415e-03, -7.6484e-03, -1.4576e-02, -1.0022e-02,\n",
       "                       -5.5040e-03, -1.2196e-02,  3.2215e-03,  3.7692e-03,  2.4948e-03,\n",
       "                       -1.0413e-02, -1.4503e-02,  3.8385e-03, -7.4219e-03, -1.0020e-02,\n",
       "                       -1.3047e-02, -1.0260e-02, -6.5911e-03, -8.6348e-03,  1.4301e-02,\n",
       "                       -5.8031e-03,  5.6790e-03,  7.0032e-03, -1.1155e-02,  4.9011e-03,\n",
       "                        7.0283e-03,  7.7470e-03,  3.9127e-03,  1.0379e-02,  1.8425e-02,\n",
       "                        2.4067e-03, -2.6343e-03, -9.7246e-03,  1.1727e-02,  1.0557e-02,\n",
       "                       -1.2934e-02,  1.6646e-02, -4.7960e-03, -1.3211e-02,  1.0016e-02,\n",
       "                        1.6051e-03,  3.9610e-05, -2.0523e-02, -1.2591e-02, -8.2880e-03,\n",
       "                       -1.1374e-02, -1.1965e-03,  1.2223e-02,  1.0554e-02,  9.2184e-03,\n",
       "                       -1.1696e-02,  1.5214e-02, -9.2984e-03,  4.2283e-03, -1.3728e-02,\n",
       "                        1.4412e-02,  3.4406e-03, -1.2315e-02,  9.0081e-03,  9.5337e-03,\n",
       "                       -8.2127e-03,  7.4159e-03,  4.9165e-03, -8.3669e-03,  9.4977e-03,\n",
       "                        2.7518e-03, -1.5290e-02, -1.8555e-03, -8.0448e-03,  1.0223e-02,\n",
       "                       -1.7026e-02,  1.6674e-02, -7.7872e-03,  6.2059e-03, -1.2881e-02,\n",
       "                        6.6564e-03, -2.8725e-03,  7.3827e-04, -1.8740e-03, -1.2649e-02,\n",
       "                        3.6008e-03, -4.1453e-03,  5.4938e-03, -1.4690e-02,  1.2408e-02,\n",
       "                        5.5852e-05, -3.4460e-03,  1.5828e-02,  1.1501e-02, -8.7758e-03,\n",
       "                       -5.6332e-03, -2.1626e-03, -1.4659e-02, -2.8180e-04, -1.2896e-02,\n",
       "                       -9.6095e-04, -2.7637e-02,  8.1085e-03,  1.4464e-02, -6.3184e-03],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.4.linear_query.weight',\n",
       "               tensor([[-0.0046, -0.0097,  0.0040,  ...,  0.0188,  0.0484, -0.0526],\n",
       "                       [-0.0360, -0.0169,  0.0037,  ...,  0.0326, -0.0742,  0.0037],\n",
       "                       [ 0.0070, -0.0385,  0.0151,  ...,  0.0042,  0.0177,  0.0019],\n",
       "                       ...,\n",
       "                       [-0.0364, -0.0103, -0.0292,  ..., -0.0248, -0.0434, -0.0132],\n",
       "                       [-0.0111,  0.0103,  0.0170,  ..., -0.0106, -0.0581,  0.0430],\n",
       "                       [ 0.0042, -0.0129, -0.0043,  ..., -0.0099,  0.0152, -0.0169]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.4.linear_query.bias',\n",
       "               tensor([ 0.0074,  0.0010,  0.0765,  0.0100,  0.0526, -0.0535, -0.0513,  0.0762,\n",
       "                        0.0834,  0.0339,  0.0918,  0.0072,  0.0204,  0.0784,  0.0124, -0.0718,\n",
       "                       -0.0159, -0.0679, -0.0117, -0.0502,  0.0010,  0.0165,  0.0038, -0.0516,\n",
       "                       -0.0342, -0.0643,  0.0063, -0.0142, -0.0203,  0.0132, -0.0984,  0.0427,\n",
       "                        0.0051, -0.0405,  0.0460,  0.0083, -0.0198, -0.0063,  0.0062,  0.0171,\n",
       "                       -0.0055, -0.0190,  0.0157, -0.0001, -0.0126, -0.0609,  0.0243,  0.0203,\n",
       "                       -0.0311,  0.0468,  0.0333, -0.0130, -0.0205,  0.0114,  0.0210, -0.0251,\n",
       "                        0.0131, -0.0092,  0.0164, -0.0172,  0.0087, -0.0247, -0.0353, -0.0099,\n",
       "                       -0.0042, -0.0204,  0.0180,  0.0147,  0.0112, -0.0054, -0.0130,  0.0311,\n",
       "                       -0.0165, -0.0261, -0.0126, -0.0314,  0.0114, -0.0124,  0.0125, -0.0015,\n",
       "                        0.0345,  0.0039, -0.0125, -0.0191, -0.0109,  0.0054, -0.0012,  0.0142,\n",
       "                        0.0030,  0.0152,  0.0140,  0.0008,  0.0026, -0.0170,  0.0281, -0.0074,\n",
       "                        0.0267,  0.0201,  0.0096, -0.0160,  0.0375,  0.0261, -0.0112, -0.0456,\n",
       "                        0.0171, -0.0098, -0.0305, -0.0225,  0.0026, -0.0222, -0.0124,  0.0150,\n",
       "                       -0.0157,  0.0196,  0.0021,  0.0080, -0.0308, -0.0393,  0.0018,  0.0240,\n",
       "                       -0.0058, -0.0176,  0.0447,  0.0302,  0.0346,  0.0112, -0.0404,  0.0059,\n",
       "                       -0.0287, -0.0056,  0.0261,  0.0543, -0.0152, -0.0160,  0.0296,  0.0347,\n",
       "                        0.0167,  0.0339,  0.0412,  0.0344,  0.0316, -0.0309,  0.0696, -0.0322,\n",
       "                        0.0325, -0.0271, -0.0243, -0.0130, -0.0119,  0.0198,  0.0276, -0.0144,\n",
       "                        0.0286,  0.0036, -0.0108, -0.0189, -0.0044, -0.0044, -0.0128, -0.0121,\n",
       "                        0.0258,  0.0195, -0.0122,  0.0236,  0.0429, -0.0405,  0.0393,  0.0062,\n",
       "                       -0.0152,  0.0080,  0.0262,  0.0190, -0.0450, -0.0290,  0.0048, -0.0201,\n",
       "                        0.0107, -0.0135,  0.0355, -0.0357,  0.0425, -0.0210, -0.0307, -0.0401,\n",
       "                        0.0274,  0.0224,  0.0358,  0.0152,  0.0239,  0.0151,  0.0030, -0.0057,\n",
       "                        0.0288, -0.0051,  0.0076,  0.0328,  0.0034, -0.0147,  0.0136, -0.0136],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.4.mlp.0.weight',\n",
       "               tensor([[-0.0244,  0.0305, -0.0129,  ...,  0.0408, -0.0125, -0.0051],\n",
       "                       [ 0.0227, -0.0006, -0.0284,  ..., -0.0175,  0.0043,  0.0367],\n",
       "                       [ 0.0150,  0.0075,  0.0265,  ...,  0.0045,  0.0048,  0.0049],\n",
       "                       ...,\n",
       "                       [-0.0354, -0.0473,  0.0028,  ..., -0.0065, -0.0305, -0.0211],\n",
       "                       [-0.0204,  0.0090,  0.0053,  ...,  0.0068, -0.0061, -0.0120],\n",
       "                       [-0.0300, -0.0406,  0.0169,  ..., -0.0193,  0.0028, -0.0157]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.4.mlp.0.bias',\n",
       "               tensor([ 1.7723e-03, -8.0581e-03, -8.4324e-03,  3.8911e-03, -7.6187e-03,\n",
       "                       -1.1040e-03, -3.0838e-02, -1.8247e-02,  9.5199e-03, -2.4542e-02,\n",
       "                       -5.3477e-03, -6.5162e-04, -1.6652e-02,  2.0782e-02, -8.8935e-03,\n",
       "                        8.3297e-03, -7.8489e-03,  1.1371e-02, -2.9585e-03,  2.1292e-02,\n",
       "                        1.2796e-02,  1.1311e-02,  4.5516e-03,  8.9223e-03,  2.2118e-03,\n",
       "                       -1.8560e-02,  6.7927e-03,  1.3853e-02,  5.3808e-03,  1.5878e-02,\n",
       "                        1.5200e-02, -1.3353e-03, -9.4384e-03, -9.9985e-03, -1.0995e-02,\n",
       "                        9.2708e-05, -6.8756e-03, -2.4241e-02,  3.3530e-04,  6.8398e-03,\n",
       "                        1.9197e-02,  1.6381e-03,  7.7485e-03, -9.2184e-03,  9.4985e-03,\n",
       "                       -1.0998e-02, -1.0769e-02,  1.2858e-02, -6.2528e-03,  1.7754e-03,\n",
       "                        8.9856e-03,  5.2955e-03, -2.4900e-03,  2.6524e-02, -1.6341e-02,\n",
       "                       -9.1020e-03,  1.2982e-03,  6.5825e-03, -6.5489e-03,  4.1733e-03,\n",
       "                        1.3398e-02, -1.2815e-02,  1.6642e-02, -1.1174e-03, -1.5330e-03,\n",
       "                       -1.3162e-02,  2.3943e-03,  1.6264e-02,  7.1581e-03,  1.0813e-03,\n",
       "                       -1.0454e-02, -1.3002e-02,  1.7860e-02,  3.5738e-03, -1.0436e-02,\n",
       "                       -7.9428e-03, -3.2996e-03,  7.3987e-03, -5.1484e-03, -3.7118e-03,\n",
       "                       -3.5453e-03, -9.7824e-03, -1.3506e-02,  7.7681e-04, -1.0009e-02,\n",
       "                        8.5434e-03,  2.1498e-02, -8.0956e-03,  3.3482e-03,  2.4708e-03,\n",
       "                       -1.1433e-02,  1.0781e-04,  1.1791e-02, -1.3782e-03,  2.3815e-02,\n",
       "                        1.1653e-02, -9.2652e-03, -6.1863e-03, -1.7914e-03, -4.0729e-03,\n",
       "                        1.1394e-02, -6.9447e-03, -7.4795e-03, -9.6668e-03, -1.5188e-02,\n",
       "                       -1.2623e-02, -1.6171e-02,  8.2952e-03,  5.3782e-05,  5.9452e-03,\n",
       "                        2.7058e-03, -2.0280e-02, -7.3605e-03, -4.0344e-03,  3.4852e-03,\n",
       "                        1.9317e-02,  7.5723e-03,  5.0640e-03, -6.5346e-03,  1.2736e-02,\n",
       "                        6.7081e-03, -1.8434e-03, -6.8924e-03,  5.2425e-03,  5.4509e-03,\n",
       "                       -1.1523e-02, -5.4539e-03, -1.5934e-03,  3.5740e-03, -3.7478e-03,\n",
       "                       -6.3377e-03,  4.4551e-03,  2.2175e-03, -2.7778e-03, -3.1217e-03,\n",
       "                       -1.4234e-02,  1.5164e-02,  1.4276e-02,  2.6822e-03,  4.0435e-03,\n",
       "                       -7.4622e-03,  1.8131e-02, -1.2433e-02,  2.8663e-05, -9.6471e-03,\n",
       "                        1.0495e-02, -4.6454e-03, -1.0160e-02,  6.8711e-05, -6.3252e-03,\n",
       "                        1.1808e-02, -8.2546e-03,  2.1070e-02,  1.1196e-02,  7.8041e-03,\n",
       "                       -8.2639e-03, -8.6976e-03, -1.4557e-02,  9.5425e-03,  8.7781e-04,\n",
       "                       -5.4977e-03,  2.3918e-02, -7.6626e-03,  1.9184e-03, -1.5916e-02,\n",
       "                       -4.4888e-03,  2.0113e-03, -7.3335e-04, -8.6441e-04,  4.8871e-04,\n",
       "                       -7.7835e-03, -6.7740e-03, -7.6888e-03,  1.9638e-04, -2.2392e-02,\n",
       "                        1.4653e-02,  1.7290e-02,  1.0615e-02,  1.0641e-03,  1.3589e-02,\n",
       "                       -5.9152e-03, -2.4870e-03, -6.7936e-03,  2.5456e-04, -1.0163e-02,\n",
       "                        1.1128e-03, -1.6892e-02, -9.1984e-04,  1.5823e-02,  1.8909e-02,\n",
       "                        9.5387e-04,  2.1333e-03,  2.8511e-03,  2.8004e-03, -1.4528e-02,\n",
       "                       -1.7816e-02,  1.4489e-02,  7.7663e-03, -6.4066e-03, -1.2064e-02],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.4.mlp.1.weight',\n",
       "               tensor([0.9748, 1.0059, 0.9868, 0.9906, 1.0220, 0.9865, 0.9977, 0.9904, 0.9951,\n",
       "                       0.9989, 0.9815, 0.9899, 0.9821, 1.0025, 0.9967, 0.9892, 0.9921, 0.9737,\n",
       "                       0.9932, 0.9863, 0.9938, 0.9605, 0.9825, 1.0054, 0.9919, 0.9912, 1.0175,\n",
       "                       0.9658, 0.9979, 0.9857, 1.0050, 0.9859, 0.9880, 0.9776, 0.9995, 0.9847,\n",
       "                       0.9933, 0.9722, 0.9919, 0.9894, 0.9853, 0.9902, 0.9990, 0.9739, 0.9856,\n",
       "                       0.9982, 1.0022, 0.9980, 0.9996, 0.9925, 1.0035, 0.9864, 0.9997, 0.9899,\n",
       "                       0.9829, 0.9933, 0.9950, 0.9923, 0.9891, 0.9802, 0.9970, 0.9661, 0.9693,\n",
       "                       0.9751, 0.9950, 0.9892, 0.9815, 0.9809, 0.9953, 0.9863, 0.9792, 1.0047,\n",
       "                       1.0000, 0.9865, 0.9827, 0.9957, 0.9778, 0.9775, 0.9834, 0.9848, 1.0061,\n",
       "                       0.9824, 0.9954, 1.0073, 0.9932, 0.9702, 1.0210, 0.9820, 0.9926, 0.9905,\n",
       "                       0.9882, 0.9803, 0.9988, 0.9932, 0.9870, 1.0031, 0.9984, 1.0116, 1.0000,\n",
       "                       0.9864, 0.9659, 0.9827, 1.0054, 0.9861, 0.9823, 0.9919, 0.9873, 0.9983,\n",
       "                       0.9770, 0.9899, 0.9937, 0.9836, 1.0190, 0.9868, 1.0198, 1.0087, 0.9903,\n",
       "                       0.9900, 0.9917, 1.0179, 0.9911, 0.9943, 0.9808, 0.9900, 0.9978, 0.9840,\n",
       "                       0.9956, 0.9840, 0.9908, 0.9708, 1.0012, 0.9822, 1.0043, 0.9780, 0.9841,\n",
       "                       0.9727, 0.9846, 0.9860, 1.0030, 0.9860, 0.9914, 0.9861, 0.9880, 0.9881,\n",
       "                       0.9950, 0.9886, 0.9887, 0.9888, 0.9898, 0.9962, 1.0099, 1.0018, 0.9766,\n",
       "                       0.9870, 0.9788, 0.9805, 0.9786, 0.9920, 0.9867, 1.0068, 0.9903, 0.9757,\n",
       "                       0.9904, 1.0103, 0.9543, 1.0227, 0.9894, 0.9690, 0.9936, 0.9908, 0.9723,\n",
       "                       1.0150, 0.9728, 0.9832, 0.9876, 0.9943, 0.9778, 0.9939, 0.9977, 0.9842,\n",
       "                       0.9629, 1.0038, 0.9895, 0.9897, 0.9900, 0.9795, 0.9780, 0.9882, 1.0098,\n",
       "                       0.9751, 1.0073, 1.0116, 1.0021, 0.9931, 0.9779, 0.9905, 1.0282, 0.9880,\n",
       "                       0.9905, 0.9769], device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.4.mlp.1.bias',\n",
       "               tensor([ 9.1144e-03,  2.3036e-02,  2.5051e-02,  1.7860e-02,  4.6584e-02,\n",
       "                        1.0837e-02,  2.9614e-02,  6.1200e-02,  2.0035e-02,  4.1005e-02,\n",
       "                        4.4914e-02,  4.4072e-02, -4.3799e-05,  5.1718e-02,  7.7372e-03,\n",
       "                        5.0975e-02,  3.4104e-02, -5.8003e-03,  1.0667e-03,  6.8821e-03,\n",
       "                        3.2256e-02, -1.3321e-02, -6.7061e-03,  4.4515e-02, -4.9935e-03,\n",
       "                        3.9886e-02,  4.4992e-02,  2.4499e-02,  3.3165e-02,  3.7948e-02,\n",
       "                        3.7886e-02,  8.6660e-03,  3.5780e-02,  3.7567e-02,  2.6683e-02,\n",
       "                        1.0698e-02,  1.2588e-02,  2.1237e-02,  4.6880e-02,  4.9736e-02,\n",
       "                        2.9394e-02,  6.5428e-02,  2.4822e-02,  1.6440e-02,  1.4933e-02,\n",
       "                        5.0627e-02,  3.5569e-02,  2.3301e-02,  3.8033e-02,  4.0211e-02,\n",
       "                        3.0821e-02,  2.2420e-02,  5.7201e-02,  2.9452e-02,  1.8346e-02,\n",
       "                        3.3162e-02,  3.5542e-02,  3.5699e-03,  2.4598e-02,  3.9075e-02,\n",
       "                       -3.2049e-02, -8.0434e-03,  3.7551e-02,  1.6566e-02,  2.4491e-02,\n",
       "                       -1.9893e-02, -1.3724e-02,  2.4593e-02,  2.0270e-02,  6.2828e-02,\n",
       "                       -7.7718e-03,  1.4831e-02,  2.7815e-02,  3.9034e-02, -3.8826e-03,\n",
       "                        2.5541e-03, -3.3562e-03,  7.6241e-03,  1.5228e-02, -6.5595e-05,\n",
       "                        4.2414e-02,  2.0456e-02,  2.9060e-02,  2.9228e-02,  5.3783e-02,\n",
       "                       -5.9626e-03,  4.4118e-02,  2.8179e-02,  3.6203e-02,  4.6755e-02,\n",
       "                        3.4746e-02,  2.7119e-02,  2.5116e-02,  3.9205e-02,  5.3738e-02,\n",
       "                        3.2470e-02,  2.9157e-02,  3.9538e-02,  2.7400e-02,  1.2318e-02,\n",
       "                        1.8757e-02,  2.4371e-02, -1.8302e-02,  1.9274e-04,  4.8579e-02,\n",
       "                        3.0513e-03,  2.1456e-02,  1.7016e-02, -4.6695e-02,  4.0277e-02,\n",
       "                        3.0549e-02,  5.1475e-02,  3.2844e-02,  4.7479e-02,  4.5704e-02,\n",
       "                        3.5715e-02,  1.8459e-02,  3.9666e-02, -8.0942e-03,  2.5035e-02,\n",
       "                        3.3544e-02,  6.0938e-04, -1.8602e-03,  3.3142e-02,  4.6477e-02,\n",
       "                        2.7378e-02,  3.0696e-02,  4.4820e-02,  4.7289e-02, -2.8671e-02,\n",
       "                        4.0005e-02,  2.3096e-02,  5.0933e-02, -2.6024e-02,  3.8376e-02,\n",
       "                        4.1520e-02,  3.3534e-02,  2.6101e-02,  3.6449e-02,  3.3659e-02,\n",
       "                        7.3448e-03,  3.6479e-02,  4.7592e-02,  1.4866e-03,  4.8326e-02,\n",
       "                        4.7011e-02,  5.4118e-02,  1.9781e-02,  1.7012e-02,  4.8792e-02,\n",
       "                        3.8374e-02,  4.6182e-02, -5.1413e-03,  2.2638e-02,  2.2920e-02,\n",
       "                        1.5218e-03, -1.4581e-02,  3.3110e-02,  5.3986e-03,  3.0704e-02,\n",
       "                        2.2323e-02, -1.3037e-02, -2.1907e-03,  4.1294e-02,  9.8522e-03,\n",
       "                        4.7524e-02, -3.6157e-03, -8.8695e-04,  4.0165e-02,  3.0214e-02,\n",
       "                       -1.8135e-03, -1.2214e-02,  1.3240e-02,  1.6268e-02,  7.7919e-03,\n",
       "                        4.5434e-02,  2.9261e-02,  3.8585e-02,  5.7343e-02, -1.6358e-02,\n",
       "                       -1.3366e-02,  2.9236e-02,  3.6800e-02, -7.7143e-04, -3.8666e-02,\n",
       "                        3.5712e-02, -1.8820e-02,  3.5487e-02,  2.6146e-02,  2.7139e-02,\n",
       "                        5.8467e-02,  4.9917e-02,  2.1414e-02,  3.4388e-03,  2.9890e-02,\n",
       "                       -3.0237e-02,  3.2285e-03,  3.5778e-02,  1.8103e-03,  3.1428e-02],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.4.mlp.1.running_mean',\n",
       "               tensor([-0.4704,  0.1439, -0.5756, -0.9538, -1.3238,  0.6071, -1.1246, -2.3151,\n",
       "                       -0.2901, -1.6952,  0.3737, -1.5740,  2.1225,  0.0904,  0.0144, -2.3206,\n",
       "                       -1.1758,  1.4706, -1.9722,  2.4214, -1.3488,  2.1326, -0.3683, -1.9080,\n",
       "                       -0.6780, -1.3888, -1.4815, -0.2718, -1.9541, -0.8932, -2.0013, -1.6640,\n",
       "                       -0.8851, -0.1301, -0.5850, -1.1617, -1.0159, -1.4498, -1.5228, -2.1235,\n",
       "                       -0.9520, -2.2645, -0.8018,  0.2853,  0.1724, -3.1177, -0.9083, -0.1814,\n",
       "                       -1.3251, -1.2177, -1.8630, -0.8361, -1.5624, -0.7311, -1.3353, -1.0596,\n",
       "                        0.8768,  0.7143, -0.3542, -0.2062,  1.9061,  1.3504,  1.1250, -1.1094,\n",
       "                       -1.5470,  1.8960,  2.2640, -0.6072, -0.9374, -2.4442,  2.0916, -1.0602,\n",
       "                       -1.4889, -0.0894,  0.1269,  0.0428, -0.2788,  2.0339,  1.6138,  2.1878,\n",
       "                       -0.5444,  1.8535, -0.6408, -1.5707, -2.0088,  2.3007, -1.3821,  1.0888,\n",
       "                       -0.7927,  0.5722,  1.7719, -0.9994, -0.8480, -0.6958, -1.4512, -1.1176,\n",
       "                       -0.7695, -2.0758, -0.9757,  2.4927,  1.9409,  0.0225, -0.4559,  1.8387,\n",
       "                       -0.0271, -0.1564, -0.9407, -0.2957,  1.4932, -1.4896, -0.9964,  0.6032,\n",
       "                       -2.1913, -2.0698, -2.5471, -1.2780, -0.5511, -1.5638, -0.5770, -0.4726,\n",
       "                       -1.6748, -1.2667,  0.4771, -0.7031, -1.6362, -1.7247, -0.8176, -2.1795,\n",
       "                       -1.5265,  2.8345, -1.4912,  1.1319, -0.5410,  2.4697, -1.1564,  1.1106,\n",
       "                       -2.2175, -0.9262, -1.8355,  0.0135,  1.7986, -1.6795, -1.2308,  2.1179,\n",
       "                       -1.9221, -0.7297, -1.8696, -0.3779, -0.3793, -1.3039, -2.0817, -1.4192,\n",
       "                        0.8556, -0.3803,  0.0302,  0.7626,  2.3251, -0.7047,  1.7637, -1.0334,\n",
       "                       -1.4603,  2.5834,  0.1677, -1.8634, -3.7227, -2.0274, -1.0314, -0.5973,\n",
       "                       -1.5782,  0.8455, -0.4778, -0.6696,  2.1344, -0.1912,  2.2490,  1.2983,\n",
       "                        0.5600, -0.9783, -2.3109,  2.2546,  1.6433, -0.9423, -1.5223,  1.8917,\n",
       "                       -0.1671,  0.8546,  1.9776,  1.3216, -2.8552, -0.4215, -0.1540, -1.6873,\n",
       "                       -0.0943, -1.0286, -0.3902,  3.4064, -0.1886, -1.9594, -1.6942, -2.1144],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.4.mlp.1.running_var',\n",
       "               tensor([ 2.6265,  2.3953,  3.1615,  4.4254, 10.4687,  4.0983,  4.7825, 12.4127,\n",
       "                        3.8447,  9.0646,  2.7454,  5.9090,  8.0723,  6.1882,  2.3662,  9.2179,\n",
       "                        8.8872,  6.1261,  6.2550, 11.0235,  6.2006,  8.2412,  1.0746, 11.0937,\n",
       "                        3.2472,  4.3764, 10.5114,  6.0757,  7.4415,  4.6825, 11.3090,  6.0523,\n",
       "                        6.4619,  3.9657,  3.3328,  2.7106,  2.8356,  4.3206,  5.8920, 10.7993,\n",
       "                        5.4706,  8.9799,  1.8469,  3.1471,  4.1903, 20.0857,  5.0142,  3.3180,\n",
       "                        8.0434,  4.6777,  7.5208,  3.0434,  6.4238,  3.8849,  3.9639,  8.5117,\n",
       "                        7.6095,  4.8251,  3.7263,  2.3576,  7.7566,  5.4677,  5.3179,  4.3316,\n",
       "                        5.5102,  7.7869,  9.7740,  4.2848,  2.3964, 11.4945,  6.4344,  4.8472,\n",
       "                        9.6086,  3.1576,  4.7375,  6.5360,  4.2862,  7.6604,  6.4368,  9.5182,\n",
       "                        3.3015,  7.3941,  2.7510,  6.0976,  8.4066,  9.7497,  9.9356,  4.0898,\n",
       "                        4.2117,  5.9925,  8.0087,  5.6267,  3.2922,  2.1109,  5.2325,  4.4581,\n",
       "                        4.0080,  8.4052,  5.0727, 10.9550,  9.2362,  5.9725,  3.5535,  8.8939,\n",
       "                        2.8450,  2.9760,  5.5547,  2.7751,  4.2451,  6.1425,  3.8869,  4.2421,\n",
       "                       10.8928,  7.8134, 12.2599,  6.2793,  3.1658,  4.8814,  6.1802,  2.2854,\n",
       "                        5.0489,  4.1533,  5.7911,  5.3038,  7.2883,  5.6526,  5.1174,  8.8240,\n",
       "                        4.6686, 14.4173,  5.9908,  6.1411,  3.2739, 12.5399,  4.8538,  8.2288,\n",
       "                       10.4822,  5.7071,  5.9760,  3.1413,  6.7250,  5.1272,  3.4034,  8.0522,\n",
       "                        7.9516,  4.2757,  9.0109,  4.2508,  3.0696,  4.6845,  8.9174,  9.8298,\n",
       "                        2.7405,  3.9592,  4.6253,  3.0837, 10.2556,  3.7100, 11.7673,  4.0416,\n",
       "                        4.3553, 12.2904,  3.9919, 10.1785, 20.4027,  8.1441,  3.3032,  7.9648,\n",
       "                        4.7412,  4.4267,  1.7531,  4.0688, 10.4883,  3.3528, 10.7375,  8.3600,\n",
       "                        4.6241,  5.7216, 12.6800,  9.1414,  5.1478,  3.8733,  5.5500,  6.9363,\n",
       "                        3.0920,  4.6733,  8.4911,  5.9085, 17.3483,  2.1800,  8.0849, 11.1852,\n",
       "                        2.5341,  2.5084,  3.7282, 17.0970,  3.9878,  7.7971,  5.5913,  9.6299],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.4.mlp.1.num_batches_tracked',\n",
       "               tensor(63750, device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.4.mlp.3.weight',\n",
       "               tensor([[-0.0219, -0.0602,  0.0174,  ...,  0.0129, -0.0316,  0.0316],\n",
       "                       [-0.0068, -0.0086,  0.0086,  ..., -0.0123,  0.0238, -0.0158],\n",
       "                       [-0.0178, -0.0058,  0.0144,  ...,  0.0269,  0.0005,  0.0143],\n",
       "                       ...,\n",
       "                       [ 0.0166, -0.0270,  0.0032,  ..., -0.0029,  0.0021,  0.0430],\n",
       "                       [ 0.0093, -0.0320,  0.0152,  ...,  0.0206,  0.0231,  0.0411],\n",
       "                       [-0.0076,  0.0234,  0.0004,  ..., -0.0229,  0.0067, -0.0254]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.gnn_layers.4.mlp.3.bias',\n",
       "               tensor([ 0.0248,  0.0321,  0.0189,  0.0099,  0.0209,  0.0338,  0.0076,  0.0157,\n",
       "                       -0.0162,  0.0374,  0.0225, -0.0116,  0.0178,  0.0173,  0.0136,  0.0194,\n",
       "                        0.0186,  0.0134,  0.0450, -0.0176,  0.0178,  0.0063,  0.0324,  0.0170,\n",
       "                        0.0254,  0.0210, -0.0056, -0.0024, -0.0049,  0.0283,  0.0252,  0.0310,\n",
       "                        0.0127,  0.0384,  0.0178,  0.0045,  0.0270, -0.0063,  0.0262,  0.0337,\n",
       "                        0.0440,  0.0076,  0.0058,  0.0141, -0.0016,  0.0294,  0.0125,  0.0181,\n",
       "                        0.0312, -0.0110,  0.0376,  0.0136,  0.0129, -0.0057,  0.0208,  0.0206,\n",
       "                        0.0064,  0.0133,  0.0179,  0.0187,  0.0384,  0.0359,  0.0043,  0.0105,\n",
       "                        0.0322,  0.0347,  0.0121,  0.0045,  0.0247,  0.0202,  0.0173,  0.0302,\n",
       "                        0.0317,  0.0046,  0.0386, -0.0019,  0.0074,  0.0296,  0.0285,  0.0166,\n",
       "                        0.0134, -0.0043,  0.0216,  0.0252,  0.0044,  0.0165,  0.0212, -0.0045,\n",
       "                        0.0154, -0.0014,  0.0306,  0.0196,  0.0282,  0.0267,  0.0415, -0.0021,\n",
       "                        0.0220,  0.0334,  0.0380,  0.0325, -0.0121,  0.0053,  0.0047,  0.0173,\n",
       "                        0.0102,  0.0085,  0.0275, -0.0019,  0.0201,  0.0104,  0.0242,  0.0311,\n",
       "                        0.0102, -0.0218, -0.0082,  0.0166,  0.0232,  0.0123,  0.0246,  0.0204,\n",
       "                        0.0248,  0.0172,  0.0325,  0.0131,  0.0196,  0.0012,  0.0189, -0.0040,\n",
       "                        0.0059, -0.0077,  0.0125,  0.0204,  0.0333,  0.0276,  0.0260,  0.0040,\n",
       "                        0.0324,  0.0224,  0.0039,  0.0045, -0.0191,  0.0382,  0.0290,  0.0413,\n",
       "                        0.0057,  0.0218,  0.0238,  0.0241,  0.0399,  0.0187,  0.0316,  0.0246,\n",
       "                       -0.0132,  0.0250,  0.0125,  0.0278,  0.0274,  0.0202,  0.0237,  0.0197,\n",
       "                        0.0327, -0.0014,  0.0141,  0.0066,  0.0404,  0.0126,  0.0310,  0.0036,\n",
       "                        0.0301,  0.0328,  0.0081,  0.0218,  0.0139, -0.0130,  0.0027,  0.0342,\n",
       "                        0.0212, -0.0206,  0.0130,  0.0193,  0.0130,  0.0274,  0.0029,  0.0208,\n",
       "                        0.0165,  0.0085,  0.0216, -0.0105,  0.0175,  0.0019,  0.0103,  0.0042,\n",
       "                       -0.0215,  0.0011,  0.0198,  0.0113,  0.0415,  0.0464,  0.0372,  0.0139],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.Vh.weight',\n",
       "               tensor([[ 2.0592e-02, -2.3823e-02,  3.2955e-02,  ..., -5.4625e-03,\n",
       "                         1.4741e-02, -4.5238e-03],\n",
       "                       [-2.6099e-02,  2.2891e-02,  5.3131e-02,  ...,  4.5356e-02,\n",
       "                        -1.1540e-03, -2.5901e-03],\n",
       "                       [ 3.7625e-02,  1.5886e-02,  3.3226e-02,  ...,  2.5338e-02,\n",
       "                        -3.2735e-03,  1.1722e-02],\n",
       "                       ...,\n",
       "                       [-4.3598e-02, -3.2153e-03, -1.8577e-02,  ..., -9.1293e-03,\n",
       "                         2.5321e-02,  2.1771e-02],\n",
       "                       [ 1.3392e-02,  1.1763e-02,  2.1900e-02,  ...,  9.2063e-05,\n",
       "                        -6.6513e-03,  3.0935e-02],\n",
       "                       [ 1.4348e-02, -2.2150e-02,  7.8168e-03,  ...,  9.8906e-03,\n",
       "                         2.9652e-02, -2.2663e-03]], device='cuda:0')),\n",
       "              ('decoder.gnn.Vh.bias',\n",
       "               tensor([ 0.0307,  0.0101, -0.0029,  0.0112,  0.0042,  0.0037,  0.0071,  0.0183,\n",
       "                        0.0098,  0.0035,  0.0051,  0.0146,  0.0012,  0.0244,  0.0096, -0.0001,\n",
       "                        0.0293,  0.0026,  0.0080,  0.0062, -0.0037,  0.0104,  0.0169,  0.0186,\n",
       "                        0.0070,  0.0120,  0.0196,  0.0018,  0.0146,  0.0203,  0.0041,  0.0301,\n",
       "                        0.0302,  0.0037,  0.0054, -0.0025,  0.0044,  0.0025,  0.0198, -0.0018,\n",
       "                        0.0250,  0.0076,  0.0087,  0.0118, -0.0029,  0.0003,  0.0156,  0.0037,\n",
       "                        0.0050,  0.0077,  0.0232,  0.0183, -0.0022,  0.0184,  0.0046,  0.0245,\n",
       "                        0.0116,  0.0202,  0.0062,  0.0155,  0.0167,  0.0145,  0.0161,  0.0178,\n",
       "                        0.0124,  0.0164,  0.0255,  0.0281,  0.0231,  0.0167,  0.0065,  0.0129,\n",
       "                        0.0133,  0.0205,  0.0242,  0.0031,  0.0108, -0.0169,  0.0017,  0.0023,\n",
       "                        0.0221,  0.0234,  0.0059,  0.0146,  0.0047,  0.0166,  0.0212,  0.0007,\n",
       "                        0.0116,  0.0076,  0.0075,  0.0252,  0.0124,  0.0193,  0.0057,  0.0023,\n",
       "                        0.0032,  0.0178, -0.0005,  0.0170,  0.0083, -0.0012,  0.0096,  0.0055,\n",
       "                        0.0049, -0.0033,  0.0020,  0.0087,  0.0075,  0.0017,  0.0134,  0.0127,\n",
       "                        0.0125,  0.0137, -0.0016,  0.0054,  0.0168,  0.0137,  0.0159,  0.0215,\n",
       "                        0.0081,  0.0105,  0.0082,  0.0212,  0.0102,  0.0177, -0.0047,  0.0115,\n",
       "                        0.0042,  0.0075,  0.0161,  0.0126,  0.0102,  0.0214,  0.0143,  0.0118,\n",
       "                       -0.0163,  0.0002,  0.0097,  0.0065,  0.0092,  0.0253,  0.0146, -0.0013,\n",
       "                        0.0029, -0.0052,  0.0271,  0.0018,  0.0033, -0.0068,  0.0116,  0.0043,\n",
       "                        0.0042,  0.0123,  0.0143,  0.0060,  0.0094,  0.0264,  0.0092, -0.0006,\n",
       "                        0.0225,  0.0100,  0.0123,  0.0131,  0.0123,  0.0174,  0.0225,  0.0080,\n",
       "                        0.0027,  0.0020,  0.0176,  0.0149, -0.0027,  0.0225,  0.0234,  0.0145,\n",
       "                        0.0140,  0.0223,  0.0097,  0.0174,  0.0045,  0.0170,  0.0134,  0.0121,\n",
       "                       -0.0165,  0.0090,  0.0153,  0.0048,  0.0048,  0.0086,  0.0187,  0.0092,\n",
       "                       -0.0032,  0.0077,  0.0136,  0.0042,  0.0135, -0.0066, -0.0003,  0.0157],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.Vx.weight',\n",
       "               tensor([[-0.0057, -0.0202,  0.0017,  ...,  0.0064, -0.0478, -0.0082],\n",
       "                       [ 0.0082,  0.0013,  0.0364,  ...,  0.0260,  0.0173, -0.0087],\n",
       "                       [-0.0079,  0.0101, -0.0334,  ...,  0.0113, -0.0038,  0.0059],\n",
       "                       ...,\n",
       "                       [-0.0017,  0.0015, -0.0342,  ..., -0.0187,  0.0012, -0.0175],\n",
       "                       [-0.0177,  0.0345, -0.0263,  ..., -0.0382,  0.0057,  0.0386],\n",
       "                       [ 0.0257, -0.0437,  0.0090,  ...,  0.0549,  0.0189, -0.0430]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.gnn.Vx.bias',\n",
       "               tensor([ 0.0307,  0.0101, -0.0029,  0.0112,  0.0042,  0.0037,  0.0071,  0.0183,\n",
       "                        0.0098,  0.0035,  0.0051,  0.0146,  0.0012,  0.0244,  0.0096, -0.0001,\n",
       "                        0.0293,  0.0026,  0.0080,  0.0062, -0.0037,  0.0104,  0.0169,  0.0186,\n",
       "                        0.0070,  0.0120,  0.0196,  0.0018,  0.0146,  0.0203,  0.0041,  0.0301,\n",
       "                        0.0302,  0.0037,  0.0054, -0.0025,  0.0044,  0.0025,  0.0198, -0.0018,\n",
       "                        0.0250,  0.0076,  0.0087,  0.0118, -0.0029,  0.0003,  0.0156,  0.0037,\n",
       "                        0.0050,  0.0077,  0.0232,  0.0183, -0.0022,  0.0184,  0.0046,  0.0245,\n",
       "                        0.0116,  0.0202,  0.0062,  0.0155,  0.0167,  0.0145,  0.0161,  0.0178,\n",
       "                        0.0124,  0.0164,  0.0255,  0.0281,  0.0231,  0.0167,  0.0065,  0.0129,\n",
       "                        0.0133,  0.0205,  0.0242,  0.0031,  0.0108, -0.0169,  0.0017,  0.0023,\n",
       "                        0.0221,  0.0234,  0.0059,  0.0146,  0.0047,  0.0166,  0.0212,  0.0007,\n",
       "                        0.0116,  0.0076,  0.0075,  0.0252,  0.0124,  0.0193,  0.0057,  0.0023,\n",
       "                        0.0032,  0.0178, -0.0005,  0.0170,  0.0083, -0.0012,  0.0096,  0.0055,\n",
       "                        0.0049, -0.0033,  0.0020,  0.0087,  0.0075,  0.0017,  0.0134,  0.0127,\n",
       "                        0.0125,  0.0137, -0.0016,  0.0054,  0.0168,  0.0137,  0.0159,  0.0215,\n",
       "                        0.0081,  0.0105,  0.0082,  0.0212,  0.0102,  0.0177, -0.0047,  0.0115,\n",
       "                        0.0042,  0.0075,  0.0161,  0.0126,  0.0102,  0.0214,  0.0143,  0.0118,\n",
       "                       -0.0163,  0.0002,  0.0097,  0.0065,  0.0092,  0.0253,  0.0146, -0.0013,\n",
       "                        0.0029, -0.0052,  0.0271,  0.0018,  0.0033, -0.0068,  0.0116,  0.0043,\n",
       "                        0.0042,  0.0123,  0.0143,  0.0060,  0.0094,  0.0264,  0.0092, -0.0006,\n",
       "                        0.0225,  0.0100,  0.0123,  0.0131,  0.0123,  0.0174,  0.0225,  0.0080,\n",
       "                        0.0027,  0.0020,  0.0176,  0.0149, -0.0027,  0.0225,  0.0234,  0.0145,\n",
       "                        0.0140,  0.0223,  0.0097,  0.0174,  0.0045,  0.0170,  0.0134,  0.0121,\n",
       "                       -0.0165,  0.0090,  0.0153,  0.0048,  0.0048,  0.0086,  0.0187,  0.0092,\n",
       "                       -0.0032,  0.0077,  0.0136,  0.0042,  0.0135, -0.0066, -0.0003,  0.0157],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.pooler.w_qs.weight',\n",
       "               tensor([[ 0.0221,  0.0366,  0.0087,  ..., -0.0128, -0.0015,  0.0041],\n",
       "                       [-0.0193,  0.0071,  0.0523,  ..., -0.0419,  0.0009,  0.0035],\n",
       "                       [-0.0166,  0.0053,  0.0379,  ..., -0.0155, -0.0213,  0.0221],\n",
       "                       ...,\n",
       "                       [-0.0160,  0.0052, -0.0089,  ...,  0.0344,  0.0672, -0.0023],\n",
       "                       [ 0.0353, -0.0232,  0.0159,  ...,  0.0081, -0.0227,  0.0085],\n",
       "                       [-0.0218, -0.0007,  0.0091,  ...,  0.0102, -0.0093, -0.0087]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.pooler.w_qs.bias',\n",
       "               tensor([-0.0213,  0.0094,  0.0341,  0.0101,  0.0004, -0.0261, -0.0296,  0.0019,\n",
       "                       -0.0152, -0.0252, -0.0014,  0.0044,  0.0186,  0.0007, -0.0164, -0.0118,\n",
       "                       -0.0220,  0.0005,  0.0065, -0.0091,  0.0013, -0.0149,  0.0484, -0.0173,\n",
       "                       -0.0361,  0.0237, -0.0395,  0.0147,  0.0021, -0.0207,  0.0017, -0.0074,\n",
       "                        0.0102, -0.0121, -0.0097, -0.0065,  0.0297, -0.0330,  0.0206, -0.0032,\n",
       "                        0.0386, -0.0288,  0.0142, -0.0081, -0.0066, -0.0336,  0.0299,  0.0132,\n",
       "                        0.0174, -0.0016,  0.0265, -0.0155, -0.0002,  0.0220,  0.0359, -0.0174,\n",
       "                        0.0336,  0.0377, -0.0477, -0.0106,  0.0402,  0.0281, -0.0033, -0.0104,\n",
       "                        0.0234,  0.0302, -0.0031,  0.0309, -0.0247,  0.0060, -0.0015, -0.0037,\n",
       "                       -0.0242, -0.0216, -0.0060,  0.0108,  0.0119,  0.0242,  0.0016, -0.0021,\n",
       "                        0.0407, -0.0119,  0.0249, -0.0072,  0.0033, -0.0095,  0.0082, -0.0107,\n",
       "                       -0.0482, -0.0394, -0.0038,  0.0021,  0.0080, -0.0094,  0.0104, -0.0318,\n",
       "                        0.0375, -0.0181,  0.0284,  0.0226,  0.0052,  0.0276,  0.0018, -0.0155,\n",
       "                       -0.0181, -0.0312, -0.0102,  0.0120, -0.0309,  0.0060, -0.0068,  0.0154,\n",
       "                       -0.0118,  0.0246,  0.0139, -0.0205,  0.0057, -0.0133,  0.0240,  0.0003,\n",
       "                        0.0033,  0.0106,  0.0221, -0.0175,  0.0081, -0.0023,  0.0046,  0.0219,\n",
       "                       -0.0352,  0.0164,  0.0037,  0.0301,  0.0017,  0.0133,  0.0218, -0.0022,\n",
       "                       -0.0036, -0.0091,  0.0087,  0.0100,  0.0309, -0.0252, -0.0254,  0.0274,\n",
       "                        0.0249, -0.0251,  0.0056,  0.0008,  0.0239, -0.0082, -0.0051,  0.0095,\n",
       "                       -0.0001,  0.0003,  0.0069, -0.0352,  0.0301,  0.0221,  0.0019, -0.0280,\n",
       "                        0.0070,  0.0082,  0.0222,  0.0227, -0.0110, -0.0211, -0.0061, -0.0349,\n",
       "                       -0.0100,  0.0044,  0.0162, -0.0122,  0.0016,  0.0067,  0.0072,  0.0037,\n",
       "                       -0.0070,  0.0111, -0.0300,  0.0050, -0.0010,  0.0017,  0.0218,  0.0111,\n",
       "                       -0.0142, -0.0064,  0.0066, -0.0108, -0.0221,  0.0002, -0.0061,  0.0009,\n",
       "                       -0.0322,  0.0191, -0.0091,  0.0010, -0.0282,  0.0119, -0.0055,  0.0169],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.pooler.w_ks.weight',\n",
       "               tensor([[ 0.0079,  0.0384,  0.0091,  ...,  0.0086,  0.0039,  0.0255],\n",
       "                       [-0.0711,  0.0020, -0.0033,  ..., -0.0250,  0.0143,  0.0367],\n",
       "                       [-0.0043, -0.0111, -0.0333,  ..., -0.0174, -0.0448, -0.0213],\n",
       "                       ...,\n",
       "                       [-0.0518,  0.0154,  0.0149,  ..., -0.0309,  0.0058, -0.0205],\n",
       "                       [-0.0143,  0.0291, -0.0414,  ...,  0.0062,  0.0209, -0.0316],\n",
       "                       [-0.0257, -0.0189,  0.0011,  ..., -0.0054,  0.0052,  0.0146]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.pooler.w_ks.bias',\n",
       "               tensor([-1.9664e-02,  1.7479e-02,  5.2928e-03,  9.6509e-03,  1.0743e-02,\n",
       "                       -2.7423e-03, -1.5878e-02, -1.6436e-02, -3.6621e-02, -5.1174e-03,\n",
       "                        1.4945e-02,  1.8737e-02,  6.8475e-03,  3.5718e-02, -2.1124e-02,\n",
       "                       -9.5675e-03,  6.9860e-03, -1.2971e-02,  1.4654e-02, -3.8565e-02,\n",
       "                        7.8800e-04,  3.4210e-03, -1.7265e-03, -1.4978e-02,  2.8272e-02,\n",
       "                        1.1322e-02, -1.7928e-02,  5.6820e-03,  5.3999e-03, -8.2937e-03,\n",
       "                       -1.4712e-04, -1.5900e-03,  9.4883e-03,  6.6784e-03, -6.2532e-03,\n",
       "                        1.2846e-02,  7.2549e-03, -1.8513e-02,  7.2822e-03, -4.7121e-02,\n",
       "                        5.2682e-03, -1.9938e-02,  7.5845e-03, -1.1435e-02, -3.5611e-02,\n",
       "                       -3.7717e-03, -6.8872e-03,  3.8281e-03, -4.1188e-03,  8.8976e-03,\n",
       "                        5.7601e-03, -3.9799e-04,  1.4714e-02, -9.4127e-03, -6.4002e-03,\n",
       "                       -1.4528e-02,  4.8491e-02,  1.9781e-02, -9.5523e-03, -6.1105e-04,\n",
       "                       -1.3485e-03,  1.4100e-03,  8.6614e-03,  1.3366e-02, -2.7513e-04,\n",
       "                       -8.2332e-04, -1.5373e-02,  9.9849e-03,  5.6509e-03,  7.4003e-03,\n",
       "                       -3.4258e-03,  5.2728e-03,  1.3238e-02, -1.0042e-05, -1.4742e-02,\n",
       "                       -3.8617e-03,  3.7665e-02,  5.9734e-03, -1.1515e-03, -3.4238e-02,\n",
       "                       -1.1436e-02,  1.4635e-02,  1.6605e-02, -1.0365e-02,  1.8738e-02,\n",
       "                       -2.0084e-03, -3.1932e-02,  2.6127e-03,  8.9033e-03, -1.9522e-02,\n",
       "                        3.4640e-02, -2.0440e-02, -7.9607e-03, -5.4781e-03,  1.7056e-02,\n",
       "                       -1.1164e-02,  7.9136e-03,  5.4821e-03,  2.4587e-03,  1.2098e-02,\n",
       "                        8.6946e-03,  2.0298e-02,  1.5115e-02, -1.9044e-03,  1.8861e-03,\n",
       "                       -9.8950e-03, -2.0724e-02, -1.3893e-03,  8.1729e-03, -2.5186e-04,\n",
       "                        3.1287e-03,  4.5192e-03, -6.9016e-04,  2.1956e-02,  8.7605e-03,\n",
       "                       -2.2504e-03,  1.8298e-02, -2.2341e-02,  5.5835e-03, -2.4234e-03,\n",
       "                        4.2521e-03,  8.8197e-03,  2.6943e-02, -1.0409e-02, -5.2599e-03,\n",
       "                        6.0183e-03,  6.8180e-04,  1.7468e-02, -2.4718e-02,  1.2513e-02,\n",
       "                       -1.0106e-03,  1.5881e-02, -3.3562e-03,  1.0636e-02,  1.7606e-02,\n",
       "                       -2.3189e-03,  9.9795e-03,  1.0741e-02,  1.9087e-02,  3.0245e-03,\n",
       "                        2.3470e-02, -1.9124e-02, -2.0035e-02,  8.5978e-03,  3.5819e-03,\n",
       "                       -1.0993e-03, -1.5789e-03,  3.7089e-04,  1.5847e-03, -4.2344e-03,\n",
       "                       -9.3803e-03, -2.8323e-03, -1.6243e-03, -1.8687e-02,  1.2605e-02,\n",
       "                       -6.4970e-03,  1.4118e-02,  2.0684e-02,  2.2582e-02, -5.5743e-03,\n",
       "                       -3.0696e-04,  2.1501e-02,  8.3338e-03,  1.5549e-03, -5.6198e-04,\n",
       "                        5.7049e-03, -1.0853e-03, -1.7157e-02, -8.0673e-05,  2.0039e-02,\n",
       "                        9.6533e-03, -1.6486e-02, -1.4573e-03, -2.0078e-02,  2.6200e-04,\n",
       "                        2.2603e-03,  1.1083e-03,  7.7040e-03, -1.7498e-02,  5.0111e-03,\n",
       "                       -1.0049e-02,  3.1715e-03,  1.5583e-02,  4.8026e-03, -1.0210e-02,\n",
       "                       -7.8279e-03, -1.3173e-02,  2.1026e-03, -1.4846e-02, -2.4753e-03,\n",
       "                        1.4841e-04,  1.2020e-02, -1.3507e-03,  2.1637e-02, -1.2646e-02,\n",
       "                        2.7922e-02, -1.7643e-02, -1.1698e-03, -1.1762e-02,  1.3403e-02],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.pooler.w_vs.weight',\n",
       "               tensor([[ 0.0528, -0.0178,  0.0046,  ..., -0.0175, -0.0197, -0.0136],\n",
       "                       [-0.0015,  0.0090,  0.0217,  ..., -0.0002,  0.0126,  0.0190],\n",
       "                       [-0.0033,  0.0003,  0.0397,  ...,  0.0122, -0.0019, -0.0052],\n",
       "                       ...,\n",
       "                       [ 0.0047,  0.0137,  0.0007,  ..., -0.0215,  0.0176, -0.0488],\n",
       "                       [-0.0037,  0.0391, -0.0354,  ..., -0.0267,  0.0535,  0.0073],\n",
       "                       [-0.0144,  0.0094,  0.0158,  ...,  0.0235, -0.0247,  0.0060]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.pooler.w_vs.bias',\n",
       "               tensor([-1.4504e-04,  1.7025e-03, -8.5591e-04,  8.4043e-03, -6.3569e-03,\n",
       "                        5.7008e-03,  1.8634e-03, -5.8425e-03, -2.8923e-03,  5.8822e-03,\n",
       "                        9.3323e-03,  5.6292e-03,  5.6848e-04, -7.4868e-03, -1.8633e-02,\n",
       "                       -2.1228e-02,  1.4955e-03, -4.1497e-03,  1.3225e-02,  7.4926e-03,\n",
       "                       -1.2036e-02, -1.1458e-02, -1.4202e-02, -5.3754e-03, -4.2175e-03,\n",
       "                       -1.2016e-03, -2.6656e-03, -5.4835e-03,  6.9702e-03, -6.7281e-03,\n",
       "                       -3.0543e-02,  3.5690e-03,  4.6939e-03,  1.3834e-02,  3.3755e-04,\n",
       "                       -3.5269e-03, -6.6742e-03,  5.8014e-03,  7.8975e-03, -2.8101e-03,\n",
       "                        5.4092e-03,  4.4680e-03, -2.7645e-02,  2.0798e-03, -2.2563e-03,\n",
       "                       -1.6441e-03,  1.0718e-02,  6.0132e-03, -1.7017e-02, -1.2712e-03,\n",
       "                       -7.5271e-03, -1.7181e-03, -4.0349e-03, -1.8836e-03, -1.5459e-03,\n",
       "                        1.8250e-03,  2.2274e-03,  4.1021e-03, -3.4261e-03, -1.6093e-02,\n",
       "                       -1.0155e-03,  1.0049e-02, -2.7185e-03, -1.1158e-02, -1.6999e-02,\n",
       "                        4.0282e-03,  1.1986e-02,  5.7665e-03, -1.1235e-02,  2.6585e-02,\n",
       "                       -1.2759e-02, -5.6945e-03, -4.2574e-04, -4.8654e-03,  3.4534e-03,\n",
       "                       -1.6053e-02,  7.1331e-03,  4.7426e-03,  1.6950e-03, -1.8264e-02,\n",
       "                        1.0236e-02,  1.2899e-02, -7.4479e-03,  3.7305e-03, -1.4385e-02,\n",
       "                       -1.2487e-02,  8.9648e-03, -9.5717e-03, -3.2726e-03,  1.5158e-02,\n",
       "                       -4.6572e-03, -5.2325e-03,  1.1334e-02, -1.5465e-02,  2.0992e-03,\n",
       "                       -3.4045e-03,  1.2270e-02, -1.2159e-02, -5.9814e-03, -1.2645e-02,\n",
       "                       -6.9660e-03,  2.0114e-03,  6.9886e-03, -4.4433e-03, -1.4196e-02,\n",
       "                        4.0298e-04,  7.7373e-03, -6.6523e-04,  2.2869e-02, -5.9456e-03,\n",
       "                       -3.3398e-03,  1.6669e-02, -9.1825e-03, -4.9488e-03,  9.2270e-03,\n",
       "                       -5.9997e-03, -4.5469e-03, -1.1728e-03,  4.9569e-03, -5.9868e-03,\n",
       "                        1.4031e-03,  1.4683e-02,  2.7520e-03, -3.8295e-03, -4.6931e-03,\n",
       "                        1.7838e-02, -8.8332e-03,  8.7202e-03,  8.9118e-03,  1.8928e-02,\n",
       "                       -8.1677e-03,  1.1778e-03, -4.7602e-03, -1.7902e-02, -7.2256e-04,\n",
       "                        1.1453e-02, -5.7434e-03,  6.9815e-03,  3.1859e-04, -6.2239e-03,\n",
       "                       -5.4810e-04,  9.1531e-04,  4.5137e-03, -1.8574e-03, -6.1261e-03,\n",
       "                       -1.6914e-05, -1.8939e-04,  1.1845e-02,  3.4999e-03,  5.2336e-03,\n",
       "                       -5.3663e-03, -7.4145e-03, -5.4144e-03, -6.1006e-04,  4.7093e-03,\n",
       "                       -4.1778e-03, -4.7151e-03, -1.5464e-03,  4.7098e-03,  6.6070e-03,\n",
       "                       -6.2587e-03, -1.1099e-02,  6.9957e-04,  1.3100e-02,  3.1013e-03,\n",
       "                       -2.5731e-03, -6.4687e-04,  6.4057e-03, -3.7085e-03,  9.9097e-03,\n",
       "                        2.0033e-02, -1.8866e-03, -5.3962e-03,  5.8916e-03,  6.1145e-03,\n",
       "                        1.1642e-04,  3.6246e-03, -7.8148e-03, -3.4589e-03,  6.2773e-03,\n",
       "                        7.2706e-03, -5.2979e-03, -6.7265e-04, -8.9096e-03, -4.0736e-03,\n",
       "                       -4.9350e-03, -6.8013e-03,  5.4620e-03, -1.3328e-02,  4.6304e-03,\n",
       "                        9.5784e-03,  6.5432e-03, -6.2536e-03, -1.4449e-03,  5.7473e-04,\n",
       "                       -1.2056e-02,  1.9061e-03,  1.7261e-02,  1.9932e-02, -5.7366e-03],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.fc.layers.0-Linear.weight',\n",
       "               tensor([[-0.0015, -0.0259, -0.0048,  ...,  0.0115,  0.0152, -0.0272]],\n",
       "                      device='cuda:0')),\n",
       "              ('decoder.fc.layers.0-Linear.bias',\n",
       "               tensor([-0.0115], device='cuda:0'))]),\n",
       " Namespace(att_head_num=2, batch_size=64, cuda=True, dataset='csqa', debug=False, decoder_lr=0.001, dev_adj='data/csqa/graph/dev.graph.adj.pk', dev_statements='data/csqa/statement/dev.statement.jsonl', drop_partial_batch=False, dropoutf=0.2, dropoutg=0.2, dropouti=0.2, encoder='FacebookAI/roberta-large', encoder_layer=-1, encoder_lr=1e-05, ent_emb=['tzw'], ent_emb_paths=['data/cpnet/tzw.ent.npy'], eval_batch_size=2, fc_dim=200, fc_layer_num=0, fill_partial_batch=False, fp16=True, freeze_ent_emb=True, gnn_dim=200, inhouse=True, inhouse_train_qids='data/csqa/inhouse_split_qids.txt', init_range=0.02, k=5, load_model_path=None, log_interval=10, loss='cross_entropy', lr_schedule='fixed', max_epochs_before_stop=10, max_grad_norm=1.0, max_node_num=200, max_seq_len=100, mini_batch_size=2, mode='train', n_epochs=15, num_relation=38, optim='radam', refreeze_epoch=10000, save_dir='saved_models/csqa/enc-FacebookAI/roberta-large__k5__gnndim200__bs64__seed0__20240320_173213', save_model=True, seed=0, simple=False, subsample=1.0, test_adj='data/csqa/graph/test.graph.adj.pk', test_statements='data/csqa/statement/test.statement.jsonl', train_adj='data/csqa/graph/train.graph.adj.pk', train_statements='data/csqa/statement/train.statement.jsonl', unfreeze_epoch=4, use_cache=True, warmup_steps=150, weight_decay=0.01)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36c8c312-d4c4-4481-b9ae-001b503b49ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "030ad4ef-e386-4ea6-8bb9-2458af1ca641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('encoder.module.embeddings.word_embeddings.weight',\n",
       "              tensor([[-0.1402, -0.0094,  0.0387,  ...,  0.0506, -0.0055, -0.0362],\n",
       "                      [ 0.0078, -0.0156,  0.0156,  ..., -0.0156,  0.0231,  0.0156],\n",
       "                      [-0.0830, -0.0004, -0.1170,  ...,  0.1088,  0.0691, -0.0357],\n",
       "                      ...,\n",
       "                      [ 0.0393,  0.0031,  0.0465,  ..., -0.0240, -0.0505,  0.0342],\n",
       "                      [ 0.0499,  0.0272,  0.0413,  ..., -0.0370, -0.0100,  0.0071],\n",
       "                      [-0.0149, -0.0114, -0.0222,  ...,  0.0441,  0.0116, -0.0330]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.embeddings.position_embeddings.weight',\n",
       "              tensor([[-0.0038,  0.0253, -0.0092,  ...,  0.0177,  0.0062, -0.0162],\n",
       "                      [ 0.0117, -0.0019, -0.0267,  ...,  0.0062, -0.0193,  0.0263],\n",
       "                      [ 0.0319,  0.0150, -0.0553,  ..., -0.0719, -0.0456,  0.0466],\n",
       "                      ...,\n",
       "                      [-0.0209, -0.0052,  0.0484,  ..., -0.0394,  0.0463,  0.0537],\n",
       "                      [-0.0274,  0.1172,  0.0470,  ...,  0.0169, -0.1204,  0.0525],\n",
       "                      [ 0.0969, -0.0729,  0.0558,  ..., -0.1204, -0.1075,  0.0489]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.embeddings.token_type_embeddings.weight',\n",
       "              tensor([[-1.0618e-05,  2.8758e-05, -3.0997e-04,  ..., -3.2288e-05,\n",
       "                       -9.2162e-05,  2.4317e-04]], device='cuda:0')),\n",
       "             ('encoder.module.embeddings.LayerNorm.weight',\n",
       "              tensor([0.9345, 0.9233, 0.9123,  ..., 0.9408, 0.9148, 0.9019], device='cuda:0')),\n",
       "             ('encoder.module.embeddings.LayerNorm.bias',\n",
       "              tensor([ 0.0314,  0.0421,  0.1922,  ..., -0.2254, -0.0895,  0.1252],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.0.attention.self.query.weight',\n",
       "              tensor([[-0.0035,  0.0343, -0.0013,  ...,  0.0033,  0.0593, -0.0433],\n",
       "                      [-0.0244,  0.0518, -0.0165,  ..., -0.0310, -0.0134,  0.0099],\n",
       "                      [ 0.0037,  0.0732, -0.0307,  ...,  0.0802,  0.0114, -0.0114],\n",
       "                      ...,\n",
       "                      [-0.0586,  0.0189, -0.0421,  ..., -0.0325,  0.0046,  0.0688],\n",
       "                      [ 0.0418,  0.0229, -0.0642,  ..., -0.0528, -0.0167,  0.0189],\n",
       "                      [-0.0199, -0.0427, -0.0099,  ...,  0.0460,  0.0245, -0.0176]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.0.attention.self.query.bias',\n",
       "              tensor([ 0.3103,  0.0555, -0.0737,  ..., -0.0701, -0.0528, -0.0658],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.0.attention.self.key.weight',\n",
       "              tensor([[-0.0045, -0.0172, -0.0130,  ..., -0.0044,  0.0072, -0.0139],\n",
       "                      [-0.0238, -0.0003,  0.0267,  ...,  0.0390,  0.0427, -0.0212],\n",
       "                      [-0.0287, -0.0528, -0.0136,  ..., -0.0341,  0.0068,  0.0191],\n",
       "                      ...,\n",
       "                      [-0.0704, -0.0227, -0.0193,  ..., -0.0186,  0.0133,  0.1045],\n",
       "                      [ 0.0148,  0.0054, -0.0194,  ..., -0.0014, -0.0083,  0.0437],\n",
       "                      [-0.0076, -0.0644,  0.0450,  ...,  0.0460,  0.0174, -0.0477]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.0.attention.self.key.bias',\n",
       "              tensor([-0.0039, -0.0033, -0.0011,  ...,  0.0014,  0.0016,  0.0019],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.0.attention.self.value.weight',\n",
       "              tensor([[ 0.0326,  0.0017, -0.0227,  ..., -0.0245,  0.0013,  0.0220],\n",
       "                      [ 0.0568,  0.0460,  0.0025,  ..., -0.0176,  0.0915, -0.0176],\n",
       "                      [-0.0168, -0.0435,  0.0110,  ..., -0.0510,  0.0006,  0.0638],\n",
       "                      ...,\n",
       "                      [-0.0100,  0.0080, -0.0122,  ...,  0.0355,  0.0262,  0.0146],\n",
       "                      [-0.0038, -0.0113, -0.0569,  ...,  0.0372, -0.0323,  0.0305],\n",
       "                      [ 0.0024, -0.0069, -0.0114,  ..., -0.0242,  0.0885, -0.0161]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.0.attention.self.value.bias',\n",
       "              tensor([-0.0015,  0.0012, -0.0092,  ..., -0.0235, -0.0204, -0.0351],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.0.attention.output.dense.weight',\n",
       "              tensor([[ 0.0037,  0.0409, -0.0174,  ..., -0.0164, -0.0334, -0.0146],\n",
       "                      [-0.0360,  0.0116, -0.0144,  ...,  0.0334, -0.0053,  0.0270],\n",
       "                      [ 0.0270, -0.0738,  0.0180,  ..., -0.0318, -0.0049,  0.0995],\n",
       "                      ...,\n",
       "                      [ 0.0258,  0.0024,  0.0231,  ...,  0.0139, -0.0109, -0.0401],\n",
       "                      [-0.0061,  0.0525, -0.0469,  ...,  0.0420,  0.0255, -0.0173],\n",
       "                      [ 0.0478,  0.0247,  0.0921,  ...,  0.0261,  0.0095,  0.0082]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.0.attention.output.dense.bias',\n",
       "              tensor([-0.0140,  0.0290,  0.0845,  ...,  0.0737, -0.0088,  0.0105],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.0.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9801, 0.9888, 0.9740,  ..., 0.9834, 0.9908, 0.9955], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.0.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.4313,  0.2762, -0.0082,  ...,  0.0119,  0.3295, -0.2980],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.0.intermediate.dense.weight',\n",
       "              tensor([[ 0.0577, -0.0650, -0.0921,  ...,  0.0056,  0.0177, -0.0157],\n",
       "                      [ 0.0162, -0.0287,  0.0204,  ...,  0.0148, -0.0403,  0.1210],\n",
       "                      [ 0.0370, -0.0655, -0.0023,  ...,  0.0306, -0.0267, -0.0214],\n",
       "                      ...,\n",
       "                      [ 0.0160, -0.0911,  0.0038,  ...,  0.0337, -0.0487,  0.0007],\n",
       "                      [ 0.1340,  0.0506, -0.1338,  ..., -0.1487, -0.0339,  0.0232],\n",
       "                      [ 0.0707, -0.0305, -0.0604,  ...,  0.0107, -0.0559, -0.0312]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.0.intermediate.dense.bias',\n",
       "              tensor([-0.0955, -0.0762, -0.0829,  ..., -0.1065, -0.0703, -0.0931],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.0.output.dense.weight',\n",
       "              tensor([[ 0.0440,  0.1033,  0.0296,  ..., -0.0544,  0.0583,  0.0658],\n",
       "                      [ 0.0181,  0.0091, -0.0102,  ..., -0.0043,  0.0201, -0.0115],\n",
       "                      [ 0.0274, -0.0708,  0.0514,  ..., -0.0398, -0.0097,  0.0031],\n",
       "                      ...,\n",
       "                      [-0.0144, -0.0045,  0.0531,  ...,  0.0100, -0.0610,  0.0133],\n",
       "                      [-0.0500,  0.0326, -0.0726,  ...,  0.0563, -0.0353, -0.0029],\n",
       "                      [-0.0944, -0.0434, -0.0970,  ..., -0.0545,  0.0548, -0.0317]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.0.output.dense.bias',\n",
       "              tensor([ 0.0637, -0.0392,  0.0423,  ...,  0.0081, -0.0957,  0.0558],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.0.output.LayerNorm.weight',\n",
       "              tensor([0.9693, 0.9603, 0.9665,  ..., 0.9714, 0.9695, 0.9492], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.0.output.LayerNorm.bias',\n",
       "              tensor([ 0.3963, -0.1877,  0.0424,  ..., -0.0483, -0.2742,  0.2006],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.1.attention.self.query.weight',\n",
       "              tensor([[ 0.0213, -0.1125,  0.0191,  ..., -0.0657, -0.0288, -0.0350],\n",
       "                      [ 0.0322, -0.0090,  0.0987,  ..., -0.0253,  0.0251,  0.1673],\n",
       "                      [ 0.0102, -0.0432,  0.0326,  ...,  0.0083,  0.0004, -0.0043],\n",
       "                      ...,\n",
       "                      [ 0.0163,  0.0324,  0.0658,  ...,  0.0452, -0.0525,  0.1040],\n",
       "                      [-0.1168,  0.0718,  0.0684,  ..., -0.0135, -0.0762,  0.0614],\n",
       "                      [ 0.0294, -0.0692,  0.0241,  ...,  0.0651,  0.0013,  0.0046]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.1.attention.self.query.bias',\n",
       "              tensor([ 0.0741,  0.0509, -0.0696,  ...,  0.0822,  0.0454, -0.0778],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.1.attention.self.key.weight',\n",
       "              tensor([[-0.0101,  0.0598, -0.0090,  ..., -0.0296,  0.0141, -0.0163],\n",
       "                      [-0.0195, -0.0880, -0.0577,  ...,  0.0531, -0.0386,  0.0150],\n",
       "                      [-0.0130,  0.0401,  0.0355,  ...,  0.0066,  0.0013, -0.0113],\n",
       "                      ...,\n",
       "                      [-0.0619, -0.0674,  0.0816,  ...,  0.0227,  0.0218,  0.0022],\n",
       "                      [ 0.0472, -0.0481,  0.0354,  ...,  0.0481,  0.0382, -0.0329],\n",
       "                      [ 0.0616,  0.0385,  0.0560,  ...,  0.0918,  0.0252,  0.0010]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.1.attention.self.key.bias',\n",
       "              tensor([ 1.5260e-03, -8.1243e-04, -7.9964e-04,  ...,  2.8900e-04,\n",
       "                      -5.8891e-05,  9.3044e-04], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.1.attention.self.value.weight',\n",
       "              tensor([[-0.0651,  0.0028, -0.0267,  ..., -0.0064,  0.0536,  0.0284],\n",
       "                      [-0.0196,  0.0350, -0.0340,  ..., -0.0098,  0.0327, -0.0211],\n",
       "                      [ 0.0019,  0.0369,  0.0038,  ...,  0.0248,  0.0853, -0.0175],\n",
       "                      ...,\n",
       "                      [-0.0039, -0.0807, -0.0334,  ..., -0.0223,  0.0369,  0.0237],\n",
       "                      [-0.0613,  0.0684, -0.0166,  ..., -0.0053,  0.0229, -0.0134],\n",
       "                      [ 0.0363,  0.0348,  0.0144,  ...,  0.0116,  0.0311, -0.0158]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.1.attention.self.value.bias',\n",
       "              tensor([ 0.0067,  0.0036,  0.0057,  ...,  0.0012, -0.0547, -0.0021],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.1.attention.output.dense.weight',\n",
       "              tensor([[-0.0384, -0.0116,  0.0060,  ..., -0.0720, -0.0308,  0.0185],\n",
       "                      [ 0.0016, -0.0531, -0.0047,  ..., -0.0744, -0.0386,  0.0060],\n",
       "                      [ 0.0435,  0.0116, -0.0226,  ..., -0.0307,  0.0177,  0.0337],\n",
       "                      ...,\n",
       "                      [-0.0066, -0.0177,  0.0368,  ...,  0.0223, -0.0257,  0.0481],\n",
       "                      [-0.0194,  0.0105,  0.0087,  ..., -0.0492, -0.0399, -0.0518],\n",
       "                      [ 0.0052, -0.0219,  0.0423,  ...,  0.0079, -0.0465,  0.0257]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.1.attention.output.dense.bias',\n",
       "              tensor([-0.2173,  0.0390, -0.0820,  ..., -0.0753,  0.2331,  0.0729],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.1.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9831, 0.9999, 0.9579,  ..., 0.9794, 0.9882, 0.9729], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.1.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.3297,  0.1810, -0.0329,  ..., -0.0727,  0.2494, -0.2292],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.1.intermediate.dense.weight',\n",
       "              tensor([[ 0.0285, -0.0341, -0.0020,  ..., -0.0203,  0.1008,  0.0514],\n",
       "                      [-0.0029, -0.0696, -0.0298,  ...,  0.0348, -0.0021, -0.0550],\n",
       "                      [-0.0044,  0.0846,  0.0727,  ...,  0.0144,  0.0216, -0.0072],\n",
       "                      ...,\n",
       "                      [-0.0392, -0.0434,  0.1242,  ...,  0.0005,  0.0130, -0.0307],\n",
       "                      [ 0.0744, -0.0583, -0.1045,  ..., -0.0316,  0.0243, -0.0830],\n",
       "                      [ 0.0011,  0.0746,  0.0947,  ..., -0.0187, -0.0265,  0.0313]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.1.intermediate.dense.bias',\n",
       "              tensor([ 0.0960, -0.0533, -0.0538,  ..., -0.0873, -0.0856, -0.0858],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.1.output.dense.weight',\n",
       "              tensor([[-0.0209, -0.0180,  0.0632,  ..., -0.0227, -0.0908,  0.0513],\n",
       "                      [ 0.0459, -0.0187, -0.0137,  ..., -0.0317, -0.0057, -0.0449],\n",
       "                      [ 0.0414,  0.0374,  0.0648,  ..., -0.0265, -0.0519,  0.0961],\n",
       "                      ...,\n",
       "                      [ 0.0416, -0.0619, -0.0756,  ..., -0.0404,  0.0235,  0.0344],\n",
       "                      [ 0.0095,  0.0857,  0.1109,  ...,  0.0651, -0.0422, -0.0220],\n",
       "                      [-0.0650,  0.0733,  0.0051,  ..., -0.0345,  0.0692,  0.0394]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.1.output.dense.bias',\n",
       "              tensor([ 0.0100,  0.0058,  0.0672,  ...,  0.0119, -0.0484,  0.0130],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.1.output.LayerNorm.weight',\n",
       "              tensor([0.9591, 0.9943, 0.9396,  ..., 0.9688, 0.9669, 0.9388], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.1.output.LayerNorm.bias',\n",
       "              tensor([ 0.1891, -0.1931, -0.0495,  ..., -0.0135, -0.2732,  0.1576],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.2.attention.self.query.weight',\n",
       "              tensor([[ 0.0039, -0.0496,  0.0445,  ..., -0.0288, -0.0679, -0.0151],\n",
       "                      [-0.0826, -0.0900,  0.0350,  ..., -0.0250,  0.0030,  0.0135],\n",
       "                      [-0.0214, -0.0071, -0.0401,  ..., -0.0336, -0.0133, -0.0217],\n",
       "                      ...,\n",
       "                      [ 0.0205, -0.0192, -0.0119,  ..., -0.0352,  0.0825, -0.0730],\n",
       "                      [ 0.0316, -0.0969, -0.0500,  ..., -0.0463, -0.0011,  0.0119],\n",
       "                      [ 0.0207, -0.0244, -0.0707,  ...,  0.0729, -0.0066,  0.0467]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.2.attention.self.query.bias',\n",
       "              tensor([-0.0627,  0.1263,  0.1138,  ..., -0.1519,  0.0648, -0.1616],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.2.attention.self.key.weight',\n",
       "              tensor([[ 0.0138,  0.1364,  0.0391,  ...,  0.0353,  0.0184, -0.0570],\n",
       "                      [-0.0002,  0.0156, -0.0160,  ..., -0.0302, -0.0384,  0.0428],\n",
       "                      [ 0.0658, -0.0082,  0.0020,  ..., -0.0537,  0.0267, -0.0464],\n",
       "                      ...,\n",
       "                      [-0.0028, -0.0351, -0.0346,  ..., -0.0019, -0.0546, -0.0682],\n",
       "                      [-0.0551, -0.0334,  0.0353,  ...,  0.0027, -0.0500,  0.0193],\n",
       "                      [ 0.0320,  0.0149, -0.0258,  ...,  0.0672,  0.0113,  0.0533]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.2.attention.self.key.bias',\n",
       "              tensor([-9.1236e-04, -2.6559e-03, -1.1033e-03,  ...,  4.9065e-05,\n",
       "                      -6.6379e-04, -9.1310e-04], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.2.attention.self.value.weight',\n",
       "              tensor([[-0.0059,  0.0502,  0.0218,  ...,  0.0288,  0.0287,  0.0007],\n",
       "                      [-0.0005,  0.0914, -0.0207,  ..., -0.0035, -0.0302, -0.0043],\n",
       "                      [ 0.0204,  0.0468,  0.0072,  ...,  0.0364,  0.0283, -0.0200],\n",
       "                      ...,\n",
       "                      [-0.0115,  0.0285, -0.0110,  ..., -0.0393, -0.0268,  0.0396],\n",
       "                      [ 0.0609,  0.0396, -0.0402,  ..., -0.0240,  0.0644,  0.0300],\n",
       "                      [-0.0240, -0.0091,  0.0009,  ..., -0.0115,  0.0123,  0.0530]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.2.attention.self.value.bias',\n",
       "              tensor([-0.0299,  0.0157,  0.0105,  ..., -0.0050,  0.0107, -0.0050],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.2.attention.output.dense.weight',\n",
       "              tensor([[-1.3482e-02, -1.6333e-02,  2.1289e-02,  ..., -5.4758e-03,\n",
       "                       -1.1926e-02,  2.3625e-02],\n",
       "                      [ 3.1707e-03,  1.6660e-02, -1.4398e-02,  ..., -4.6522e-02,\n",
       "                       -1.2077e-02, -2.8264e-03],\n",
       "                      [ 6.0994e-03,  4.0657e-02, -7.1024e-02,  ..., -1.2754e-02,\n",
       "                       -1.3767e-02, -1.5191e-02],\n",
       "                      ...,\n",
       "                      [-3.0070e-02, -7.1995e-03,  4.8884e-02,  ..., -3.0136e-03,\n",
       "                        9.1774e-03, -1.2675e-02],\n",
       "                      [-8.0736e-02, -2.0098e-05,  3.2670e-03,  ...,  4.3712e-02,\n",
       "                        1.9678e-02, -8.8421e-03],\n",
       "                      [ 5.4194e-02,  4.8298e-02,  6.4266e-05,  ...,  4.8767e-03,\n",
       "                        5.4590e-02,  2.6172e-02]], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.2.attention.output.dense.bias',\n",
       "              tensor([ 0.0609, -0.0594,  0.0323,  ...,  0.0803, -0.0397,  0.0737],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.2.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9813, 0.9851, 0.9860,  ..., 0.9628, 0.9561, 0.9711], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.2.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.0941, -0.0032, -0.3413,  ..., -0.0276, -0.0715,  0.2152],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.2.intermediate.dense.weight',\n",
       "              tensor([[ 0.0228,  0.0860,  0.0685,  ..., -0.0477, -0.0158, -0.0440],\n",
       "                      [-0.0248, -0.0678,  0.0926,  ..., -0.0752,  0.0543, -0.0043],\n",
       "                      [-0.0730,  0.0045,  0.0926,  ...,  0.0138,  0.0224,  0.0031],\n",
       "                      ...,\n",
       "                      [-0.0364, -0.0123,  0.0055,  ...,  0.0065, -0.0011,  0.0199],\n",
       "                      [-0.0674,  0.0101, -0.0131,  ..., -0.0002,  0.0338, -0.0952],\n",
       "                      [ 0.0008,  0.0221,  0.0189,  ..., -0.0159, -0.0528, -0.1006]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.2.intermediate.dense.bias',\n",
       "              tensor([-0.0233, -0.0801, -0.0688,  ...,  0.0582, -0.0866, -0.0891],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.2.output.dense.weight',\n",
       "              tensor([[-0.0241,  0.0824,  0.0166,  ..., -0.0397, -0.1089,  0.0008],\n",
       "                      [-0.0072,  0.0175, -0.0628,  ...,  0.0476, -0.0254, -0.0119],\n",
       "                      [ 0.0537, -0.0567,  0.0586,  ...,  0.0124, -0.0475, -0.0761],\n",
       "                      ...,\n",
       "                      [ 0.0061, -0.0443,  0.0690,  ...,  0.0143,  0.1029,  0.0017],\n",
       "                      [ 0.0487, -0.0090, -0.0308,  ...,  0.0113, -0.0955, -0.0088],\n",
       "                      [ 0.0311, -0.0490, -0.0231,  ..., -0.0424,  0.0165,  0.0011]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.2.output.dense.bias',\n",
       "              tensor([-0.0089, -0.0411,  0.0116,  ...,  0.0297,  0.0136,  0.0442],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.2.output.LayerNorm.weight',\n",
       "              tensor([0.9654, 0.9686, 0.9535,  ..., 0.9730, 0.9769, 0.9592], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.2.output.LayerNorm.bias',\n",
       "              tensor([-0.0324, -0.1077,  0.2081,  ..., -0.0504, -0.0277, -0.2035],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.3.attention.self.query.weight',\n",
       "              tensor([[-0.0715,  0.0100,  0.0374,  ...,  0.0288,  0.0525, -0.0108],\n",
       "                      [-0.0187, -0.0765, -0.0403,  ...,  0.0358, -0.0141,  0.0315],\n",
       "                      [-0.0206, -0.0179,  0.0800,  ...,  0.0355, -0.0197,  0.0060],\n",
       "                      ...,\n",
       "                      [-0.0568, -0.0124, -0.0112,  ...,  0.0377,  0.0884, -0.0206],\n",
       "                      [ 0.0692, -0.0346,  0.0424,  ..., -0.0892,  0.0267, -0.0357],\n",
       "                      [ 0.0320,  0.0647, -0.0204,  ..., -0.0421, -0.0323,  0.0206]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.3.attention.self.query.bias',\n",
       "              tensor([-0.0245, -0.0527,  0.0306,  ...,  0.0132,  0.1152, -0.0827],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.3.attention.self.key.weight',\n",
       "              tensor([[-0.1327, -0.0380,  0.0013,  ...,  0.0233,  0.0478, -0.0255],\n",
       "                      [ 0.0243,  0.1003,  0.0936,  ..., -0.0250,  0.0848, -0.0455],\n",
       "                      [ 0.0056, -0.0404,  0.0914,  ..., -0.0175,  0.0154, -0.0207],\n",
       "                      ...,\n",
       "                      [-0.0248, -0.0049, -0.0034,  ...,  0.0737, -0.0610, -0.0407],\n",
       "                      [ 0.0021, -0.0245, -0.0065,  ...,  0.0403, -0.0319,  0.0083],\n",
       "                      [ 0.0313,  0.0118,  0.0217,  ...,  0.0154, -0.0308, -0.0182]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.3.attention.self.key.bias',\n",
       "              tensor([ 2.7646e-05,  1.1264e-03,  1.7614e-04,  ...,  1.3361e-03,\n",
       "                      -8.6365e-04,  4.9541e-04], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.3.attention.self.value.weight',\n",
       "              tensor([[ 0.0118, -0.0319, -0.0748,  ...,  0.0303,  0.0971,  0.0226],\n",
       "                      [-0.0173,  0.0381,  0.0468,  ..., -0.0292,  0.0076, -0.0065],\n",
       "                      [ 0.0397,  0.0377, -0.0703,  ..., -0.0517,  0.0276,  0.0236],\n",
       "                      ...,\n",
       "                      [ 0.0722,  0.0009,  0.0130,  ...,  0.0227,  0.0312,  0.0434],\n",
       "                      [-0.0226,  0.0503, -0.0326,  ..., -0.0040, -0.1066, -0.0126],\n",
       "                      [ 0.0266, -0.0087, -0.0443,  ..., -0.0314, -0.0028, -0.0478]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.3.attention.self.value.bias',\n",
       "              tensor([-0.0183, -0.0084, -0.0073,  ...,  0.0066,  0.0060, -0.0011],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.3.attention.output.dense.weight',\n",
       "              tensor([[-0.0004,  0.0027,  0.0343,  ...,  0.0009, -0.0267, -0.0284],\n",
       "                      [ 0.0108, -0.0084,  0.0408,  ...,  0.0132, -0.0189,  0.0139],\n",
       "                      [-0.0789,  0.0120, -0.0064,  ..., -0.0124,  0.0572, -0.0048],\n",
       "                      ...,\n",
       "                      [ 0.0211, -0.0009, -0.0218,  ...,  0.0220, -0.0327,  0.0140],\n",
       "                      [ 0.0129,  0.0421,  0.0025,  ..., -0.0075, -0.0125, -0.0087],\n",
       "                      [-0.0284, -0.0182,  0.0179,  ..., -0.0088,  0.0168,  0.0359]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.3.attention.output.dense.bias',\n",
       "              tensor([ 0.0423, -0.0197, -0.0265,  ..., -0.0228,  0.0345, -0.0205],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.3.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9866, 0.9823, 0.9769,  ..., 0.9864, 0.9784, 0.9661], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.3.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1803, -0.1192, -0.3015,  ..., -0.0454,  0.1130,  0.0350],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.3.intermediate.dense.weight',\n",
       "              tensor([[ 0.0116,  0.0397, -0.0336,  ..., -0.0524, -0.0227, -0.0354],\n",
       "                      [ 0.0370,  0.0314,  0.0163,  ...,  0.0232, -0.0439, -0.0148],\n",
       "                      [ 0.0341, -0.0616, -0.0168,  ...,  0.0668, -0.1823,  0.0079],\n",
       "                      ...,\n",
       "                      [-0.0285, -0.0329, -0.0361,  ...,  0.0337, -0.0248, -0.0534],\n",
       "                      [ 0.0301, -0.0594, -0.0384,  ..., -0.0018,  0.0214, -0.0295],\n",
       "                      [ 0.0002,  0.0048, -0.0462,  ...,  0.0120, -0.0645, -0.0449]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.3.intermediate.dense.bias',\n",
       "              tensor([-0.0912, -0.1102, -0.0566,  ..., -0.1007, -0.0188, -0.0873],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.3.output.dense.weight',\n",
       "              tensor([[-0.0193, -0.0332, -0.0233,  ...,  0.0202, -0.0676, -0.0083],\n",
       "                      [ 0.0242, -0.0141, -0.0245,  ..., -0.0045, -0.0456, -0.0677],\n",
       "                      [-0.0763, -0.0783,  0.0211,  ...,  0.0563, -0.0287, -0.0015],\n",
       "                      ...,\n",
       "                      [ 0.0082,  0.0291,  0.0779,  ..., -0.0534, -0.0733,  0.0006],\n",
       "                      [-0.0966, -0.0811, -0.0590,  ..., -0.0209, -0.0069, -0.1064],\n",
       "                      [ 0.1377,  0.0522, -0.0634,  ...,  0.0482, -0.0441,  0.0301]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.3.output.dense.bias',\n",
       "              tensor([-0.0872,  0.0331,  0.0637,  ...,  0.0406, -0.0829,  0.2712],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.3.output.LayerNorm.weight',\n",
       "              tensor([0.9753, 0.9917, 0.9679,  ..., 0.9714, 0.9672, 0.9497], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.3.output.LayerNorm.bias',\n",
       "              tensor([ 0.0134, -0.0074,  0.1964,  ..., -0.0254, -0.1183, -0.0805],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.4.attention.self.query.weight',\n",
       "              tensor([[-0.0063, -0.0137, -0.0589,  ..., -0.0077, -0.0344, -0.0073],\n",
       "                      [-0.0024,  0.0018,  0.0431,  ..., -0.0606, -0.0116,  0.0691],\n",
       "                      [-0.0847,  0.0070,  0.0155,  ..., -0.0648, -0.0117,  0.0285],\n",
       "                      ...,\n",
       "                      [ 0.0164,  0.0070, -0.0130,  ...,  0.0210,  0.0043,  0.0016],\n",
       "                      [ 0.0172, -0.0275,  0.0376,  ..., -0.0104, -0.0284,  0.0164],\n",
       "                      [ 0.0352, -0.1014, -0.0187,  ..., -0.0377, -0.0363, -0.1452]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.4.attention.self.query.bias',\n",
       "              tensor([ 0.2099,  0.0040,  0.2280,  ..., -0.2532, -0.1884,  0.2033],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.4.attention.self.key.weight',\n",
       "              tensor([[-0.0186, -0.0762, -0.0492,  ..., -0.0070, -0.0442,  0.0077],\n",
       "                      [-0.0532, -0.0106,  0.0206,  ...,  0.0042, -0.0242,  0.0125],\n",
       "                      [ 0.0139,  0.0292,  0.0413,  ...,  0.0327,  0.0659, -0.0061],\n",
       "                      ...,\n",
       "                      [ 0.0371,  0.0803,  0.0373,  ...,  0.0556,  0.0096,  0.0901],\n",
       "                      [-0.0151, -0.0257, -0.0283,  ..., -0.0180, -0.0420,  0.0626],\n",
       "                      [ 0.0043,  0.0279, -0.0063,  ...,  0.0267, -0.0332,  0.0235]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.4.attention.self.key.bias',\n",
       "              tensor([ 0.0006, -0.0002,  0.0003,  ..., -0.0005, -0.0002, -0.0002],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.4.attention.self.value.weight',\n",
       "              tensor([[-0.0094,  0.0010,  0.0084,  ...,  0.0207,  0.0029,  0.0478],\n",
       "                      [ 0.0199,  0.0609, -0.0225,  ...,  0.0637, -0.0176, -0.0740],\n",
       "                      [ 0.0368,  0.0162,  0.0247,  ...,  0.0519, -0.0345,  0.0642],\n",
       "                      ...,\n",
       "                      [ 0.0117,  0.0652,  0.0219,  ...,  0.0489, -0.0018,  0.0250],\n",
       "                      [ 0.0274,  0.0077,  0.0162,  ...,  0.0291, -0.0030,  0.0633],\n",
       "                      [ 0.0086, -0.1033, -0.0014,  ..., -0.0403,  0.0335,  0.0074]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.4.attention.self.value.bias',\n",
       "              tensor([-0.0094, -0.0033,  0.0089,  ..., -0.0075,  0.0025, -0.0005],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.4.attention.output.dense.weight',\n",
       "              tensor([[-0.0334, -0.0706, -0.0206,  ..., -0.0066, -0.0078,  0.0661],\n",
       "                      [-0.0453, -0.0165, -0.0117,  ...,  0.0457,  0.0283,  0.0089],\n",
       "                      [ 0.0060,  0.0090, -0.0099,  ..., -0.0415,  0.0451, -0.0116],\n",
       "                      ...,\n",
       "                      [ 0.0044,  0.0053,  0.0072,  ...,  0.0125,  0.0027, -0.0156],\n",
       "                      [-0.0023,  0.0141, -0.0295,  ...,  0.0535,  0.0048, -0.0254],\n",
       "                      [ 0.0173,  0.0456, -0.0143,  ..., -0.0102, -0.0274,  0.0094]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.4.attention.output.dense.bias',\n",
       "              tensor([-0.0073, -0.0125, -0.0086,  ...,  0.0167, -0.0641, -0.0042],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.4.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9904, 0.9983, 0.9867,  ..., 0.9873, 0.9975, 0.9586], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.4.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1679,  0.0776, -0.2974,  ...,  0.0608,  0.0174,  0.2049],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.4.intermediate.dense.weight',\n",
       "              tensor([[ 0.0025,  0.0551, -0.0333,  ..., -0.0766,  0.0540,  0.0405],\n",
       "                      [-0.0144, -0.0164, -0.0074,  ..., -0.0157, -0.0173, -0.0903],\n",
       "                      [-0.0326,  0.0143,  0.0496,  ..., -0.0940,  0.0211, -0.0463],\n",
       "                      ...,\n",
       "                      [-0.0589, -0.0233,  0.0650,  ...,  0.1269,  0.0421, -0.0711],\n",
       "                      [-0.0040, -0.0810, -0.0883,  ..., -0.0558, -0.0258,  0.0620],\n",
       "                      [-0.0365, -0.0229,  0.0063,  ...,  0.0205,  0.0368, -0.0449]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.4.intermediate.dense.bias',\n",
       "              tensor([-0.0894, -0.0796, -0.0722,  ..., -0.0708, -0.0520, -0.0546],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.4.output.dense.weight',\n",
       "              tensor([[-0.0204,  0.0603,  0.0072,  ...,  0.0362, -0.0110, -0.0280],\n",
       "                      [-0.0465, -0.0276, -0.0511,  ...,  0.0357, -0.0569,  0.0018],\n",
       "                      [ 0.0150,  0.0825,  0.1045,  ...,  0.0022,  0.0528, -0.0289],\n",
       "                      ...,\n",
       "                      [-0.0351, -0.0456, -0.0653,  ...,  0.1405, -0.0656,  0.0144],\n",
       "                      [ 0.0388, -0.0213,  0.0319,  ...,  0.1022, -0.0142,  0.0146],\n",
       "                      [ 0.0074, -0.0455, -0.0988,  ..., -0.0382,  0.0641, -0.0394]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.4.output.dense.bias',\n",
       "              tensor([-0.0843, -0.0168,  0.1403,  ...,  0.0093, -0.1006,  0.1652],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.4.output.LayerNorm.weight',\n",
       "              tensor([0.9729, 0.9961, 0.9750,  ..., 0.9770, 0.9965, 0.9674], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.4.output.LayerNorm.bias',\n",
       "              tensor([ 0.0116, -0.1011,  0.2787,  ..., -0.1055, -0.1017, -0.1644],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.5.attention.self.query.weight',\n",
       "              tensor([[ 0.0700, -0.0118,  0.0258,  ..., -0.0179,  0.0206,  0.0343],\n",
       "                      [ 0.0536, -0.0120,  0.0065,  ...,  0.0029,  0.0462, -0.1405],\n",
       "                      [-0.0546, -0.0125, -0.0211,  ...,  0.0232, -0.0477, -0.0022],\n",
       "                      ...,\n",
       "                      [-0.0178, -0.0199, -0.0732,  ..., -0.0314,  0.0172,  0.0018],\n",
       "                      [ 0.0474, -0.0839,  0.0218,  ...,  0.0348,  0.0220, -0.0326],\n",
       "                      [-0.0076,  0.0275,  0.0586,  ...,  0.0085,  0.0673,  0.0537]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.5.attention.self.query.bias',\n",
       "              tensor([ 0.0330, -0.0289, -0.0239,  ...,  0.0297,  0.1256, -0.1331],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.5.attention.self.key.weight',\n",
       "              tensor([[ 2.0024e-03,  6.4798e-02, -9.3016e-03,  ..., -4.0371e-02,\n",
       "                        5.8995e-03, -1.4847e-02],\n",
       "                      [ 3.8978e-02, -2.1360e-02, -3.8421e-02,  ...,  3.6202e-02,\n",
       "                        3.1528e-02, -3.7590e-02],\n",
       "                      [ 3.5582e-02, -1.6480e-02, -3.2980e-02,  ..., -1.1358e-01,\n",
       "                        4.2403e-02,  3.2613e-02],\n",
       "                      ...,\n",
       "                      [ 2.7950e-02,  5.7143e-05, -4.7798e-03,  ...,  2.7696e-02,\n",
       "                        6.5372e-02,  4.1512e-02],\n",
       "                      [ 1.7674e-02,  7.0106e-03, -1.3185e-02,  ...,  1.6778e-02,\n",
       "                       -1.5144e-02,  1.0560e-02],\n",
       "                      [-7.3066e-02,  1.2416e-03,  5.9495e-02,  ..., -5.3007e-02,\n",
       "                        1.7157e-02,  3.3654e-03]], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.5.attention.self.key.bias',\n",
       "              tensor([ 0.0008, -0.0002, -0.0002,  ...,  0.0018,  0.0009,  0.0005],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.5.attention.self.value.weight',\n",
       "              tensor([[-0.0212,  0.0520,  0.0126,  ..., -0.0003, -0.0068,  0.0516],\n",
       "                      [-0.0671, -0.0655, -0.0130,  ...,  0.0227, -0.0432, -0.0596],\n",
       "                      [ 0.0387, -0.0426, -0.0291,  ..., -0.0003, -0.0125,  0.0323],\n",
       "                      ...,\n",
       "                      [ 0.0302, -0.0207, -0.0139,  ..., -0.0306, -0.0094, -0.0315],\n",
       "                      [ 0.0561,  0.0271, -0.0972,  ...,  0.0122, -0.0089,  0.0470],\n",
       "                      [-0.0355,  0.0701, -0.0230,  ..., -0.0224, -0.0215,  0.0236]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.5.attention.self.value.bias',\n",
       "              tensor([ 0.0020, -0.0050, -0.0023,  ...,  0.0085, -0.0056, -0.0094],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.5.attention.output.dense.weight',\n",
       "              tensor([[ 0.0298, -0.0095, -0.0192,  ...,  0.0245,  0.0241, -0.0229],\n",
       "                      [-0.0986,  0.0298,  0.0095,  ..., -0.0521, -0.0189,  0.0467],\n",
       "                      [ 0.0651, -0.0071,  0.0426,  ..., -0.0187, -0.0406, -0.0307],\n",
       "                      ...,\n",
       "                      [-0.0108, -0.0525, -0.0141,  ..., -0.0065,  0.0209, -0.0371],\n",
       "                      [ 0.0010,  0.0128,  0.0365,  ...,  0.0085, -0.0688, -0.0014],\n",
       "                      [ 0.0070,  0.0254,  0.0213,  ...,  0.0340, -0.0079, -0.0044]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.5.attention.output.dense.bias',\n",
       "              tensor([ 0.0058,  0.0078, -0.0753,  ..., -0.0274, -0.0630, -0.0143],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.5.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9914, 0.9988, 0.9986,  ..., 0.9788, 0.9925, 0.9698], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.5.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1208,  0.0556, -0.2698,  ...,  0.0015, -0.0934,  0.0926],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.5.intermediate.dense.weight',\n",
       "              tensor([[-0.0017, -0.0376, -0.0314,  ..., -0.0090, -0.0048, -0.0247],\n",
       "                      [-0.0046, -0.0437, -0.0200,  ..., -0.0161,  0.0678, -0.0435],\n",
       "                      [ 0.0645,  0.0491,  0.0060,  ..., -0.0124, -0.0359,  0.0523],\n",
       "                      ...,\n",
       "                      [-0.0156, -0.0546, -0.0125,  ...,  0.0600,  0.0030, -0.0714],\n",
       "                      [-0.0238, -0.1218,  0.0010,  ...,  0.0287,  0.0660, -0.0308],\n",
       "                      [-0.0576,  0.0428,  0.0489,  ...,  0.0289, -0.0008,  0.0442]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.5.intermediate.dense.bias',\n",
       "              tensor([-0.0727, -0.1106, -0.1094,  ..., -0.0520, -0.1169, -0.1059],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.5.output.dense.weight',\n",
       "              tensor([[-0.0309,  0.0612,  0.0031,  ..., -0.0152, -0.0379,  0.0261],\n",
       "                      [ 0.0446, -0.0577,  0.0644,  ..., -0.0438, -0.0211, -0.0806],\n",
       "                      [ 0.0063,  0.0121, -0.0138,  ..., -0.0324, -0.0124, -0.0699],\n",
       "                      ...,\n",
       "                      [-0.0677, -0.0647, -0.0335,  ...,  0.0011,  0.1031, -0.0220],\n",
       "                      [-0.0118,  0.0196, -0.0772,  ..., -0.0258, -0.0109, -0.0043],\n",
       "                      [ 0.0015, -0.0225,  0.0842,  ..., -0.0507,  0.0294, -0.0353]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.5.output.dense.bias',\n",
       "              tensor([-0.1073,  0.0105,  0.1376,  ..., -0.0012, -0.0590,  0.1447],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.5.output.LayerNorm.weight',\n",
       "              tensor([0.9725, 0.9938, 0.9904,  ..., 0.9754, 0.9918, 0.9571], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.5.output.LayerNorm.bias',\n",
       "              tensor([-0.0165, -0.1135,  0.2715,  ..., -0.1173, -0.0456, -0.1471],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.6.attention.self.query.weight',\n",
       "              tensor([[ 0.0196, -0.0262,  0.0548,  ...,  0.0419,  0.0496,  0.0079],\n",
       "                      [-0.0054, -0.0329, -0.0064,  ..., -0.0063, -0.0499, -0.0331],\n",
       "                      [ 0.0380,  0.1499,  0.0873,  ...,  0.0484,  0.0453,  0.0364],\n",
       "                      ...,\n",
       "                      [ 0.0096, -0.0026, -0.1047,  ...,  0.0315,  0.0681,  0.0648],\n",
       "                      [ 0.0259,  0.0189,  0.0191,  ...,  0.0054,  0.0270,  0.0863],\n",
       "                      [-0.0396, -0.0008,  0.0403,  ..., -0.0430,  0.0341, -0.0310]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.6.attention.self.query.bias',\n",
       "              tensor([-0.3070,  0.0543, -0.3075,  ..., -0.0908,  0.0279,  0.0038],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.6.attention.self.key.weight',\n",
       "              tensor([[ 2.7794e-02, -3.0469e-02,  6.7685e-02,  ..., -1.1314e-02,\n",
       "                       -2.7330e-02, -6.8249e-04],\n",
       "                      [-1.6221e-02,  3.0847e-02,  1.9335e-02,  ...,  9.9139e-02,\n",
       "                        7.6029e-02,  1.5817e-02],\n",
       "                      [ 5.5143e-02,  6.2480e-05,  1.8972e-02,  ..., -1.4660e-02,\n",
       "                       -3.5012e-02, -4.0957e-02],\n",
       "                      ...,\n",
       "                      [-1.8491e-02,  1.6199e-02,  3.6844e-03,  ..., -3.3738e-02,\n",
       "                        1.3604e-02, -6.4020e-05],\n",
       "                      [-7.4941e-02, -6.2888e-02, -1.0905e-03,  ...,  4.5084e-02,\n",
       "                        3.7688e-02, -6.9551e-03],\n",
       "                      [ 9.9136e-03,  3.3959e-02,  9.2323e-05,  ...,  5.8859e-02,\n",
       "                        3.0609e-02, -9.0229e-03]], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.6.attention.self.key.bias',\n",
       "              tensor([ 7.7416e-04, -6.6255e-04,  1.7531e-04,  ..., -7.8539e-05,\n",
       "                       7.7771e-05,  3.3924e-04], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.6.attention.self.value.weight',\n",
       "              tensor([[ 0.0128,  0.0158, -0.0072,  ..., -0.0311, -0.0133, -0.0016],\n",
       "                      [-0.0024,  0.0396,  0.0185,  ..., -0.0564,  0.0383,  0.0133],\n",
       "                      [-0.0173, -0.0563,  0.0531,  ...,  0.0453, -0.0023,  0.0233],\n",
       "                      ...,\n",
       "                      [ 0.0149,  0.0407,  0.0010,  ...,  0.0473, -0.0586,  0.0014],\n",
       "                      [ 0.0094, -0.0157, -0.0046,  ..., -0.0296,  0.0175, -0.0146],\n",
       "                      [ 0.0117,  0.0239,  0.0226,  ..., -0.0345,  0.1073,  0.0264]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.6.attention.self.value.bias',\n",
       "              tensor([-0.0072, -0.0077, -0.0015,  ..., -0.0179, -0.0082, -0.0027],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.6.attention.output.dense.weight',\n",
       "              tensor([[-0.0386,  0.0046, -0.0161,  ...,  0.0405, -0.0315, -0.0049],\n",
       "                      [ 0.0188, -0.0355, -0.0399,  ...,  0.0210,  0.0384, -0.0200],\n",
       "                      [ 0.0493, -0.0577, -0.0384,  ...,  0.0265,  0.0671, -0.0364],\n",
       "                      ...,\n",
       "                      [-0.0168,  0.0494,  0.0012,  ..., -0.0426,  0.0060,  0.0211],\n",
       "                      [-0.0267,  0.0231,  0.0434,  ...,  0.0247, -0.0197, -0.0410],\n",
       "                      [-0.0220,  0.0472,  0.0231,  ...,  0.0603,  0.0046,  0.0188]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.6.attention.output.dense.bias',\n",
       "              tensor([ 7.2820e-03, -1.1136e-02,  3.1680e-02,  ...,  6.8015e-05,\n",
       "                      -6.6930e-02,  8.7634e-03], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.6.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9850, 0.9996, 0.9997,  ..., 0.9824, 0.9801, 0.9517], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.6.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1210,  0.0572, -0.2836,  ..., -0.0225, -0.1026,  0.1006],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.6.intermediate.dense.weight',\n",
       "              tensor([[-0.0049, -0.0055, -0.0124,  ..., -0.0033,  0.0405,  0.0701],\n",
       "                      [ 0.0059,  0.0058, -0.0010,  ..., -0.0272,  0.0210, -0.0421],\n",
       "                      [-0.0606, -0.0774, -0.0482,  ...,  0.0749, -0.0169, -0.0796],\n",
       "                      ...,\n",
       "                      [-0.0475, -0.0407,  0.0061,  ..., -0.0117,  0.0809, -0.0509],\n",
       "                      [ 0.0039,  0.0025,  0.0085,  ...,  0.0126,  0.0112,  0.0075],\n",
       "                      [-0.0101, -0.0606,  0.0461,  ..., -0.0201,  0.0190, -0.1269]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.6.intermediate.dense.bias',\n",
       "              tensor([-0.0800, -0.0928, -0.1035,  ..., -0.0771, -0.0703, -0.1737],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.6.output.dense.weight',\n",
       "              tensor([[ 0.0272, -0.0351, -0.0201,  ...,  0.0352,  0.0233, -0.0080],\n",
       "                      [ 0.0100, -0.0430, -0.0086,  ..., -0.0072,  0.0349,  0.0114],\n",
       "                      [ 0.0245, -0.0135, -0.0904,  ...,  0.0430, -0.0433,  0.0378],\n",
       "                      ...,\n",
       "                      [ 0.0093, -0.0625,  0.0094,  ..., -0.0169,  0.0571, -0.0456],\n",
       "                      [ 0.0281,  0.0008, -0.1135,  ..., -0.0174, -0.0273,  0.0639],\n",
       "                      [ 0.0405,  0.0090,  0.0191,  ..., -0.0306,  0.0257, -0.0177]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.6.output.dense.bias',\n",
       "              tensor([-0.0681,  0.0310,  0.0668,  ..., -0.0088, -0.0556,  0.0709],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.6.output.LayerNorm.weight',\n",
       "              tensor([0.9826, 0.9898, 1.0000,  ..., 0.9792, 0.9755, 0.9611], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.6.output.LayerNorm.bias',\n",
       "              tensor([-0.0242, -0.1124,  0.1121,  ..., -0.0807, -0.0280, -0.1336],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.7.attention.self.query.weight',\n",
       "              tensor([[ 0.0189, -0.0202,  0.0036,  ...,  0.0258, -0.0392, -0.1074],\n",
       "                      [ 0.0567, -0.0802, -0.0153,  ...,  0.0166, -0.0427,  0.0196],\n",
       "                      [-0.1335,  0.0187,  0.0228,  ...,  0.0098,  0.0817,  0.0018],\n",
       "                      ...,\n",
       "                      [-0.0297,  0.1953,  0.0427,  ...,  0.0570,  0.0103,  0.1292],\n",
       "                      [ 0.0085,  0.0252, -0.0313,  ...,  0.0126,  0.0743,  0.1002],\n",
       "                      [ 0.0170,  0.0126,  0.0277,  ...,  0.0942,  0.1176,  0.0466]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.7.attention.self.query.bias',\n",
       "              tensor([ 0.0159,  0.0130, -0.0539,  ..., -0.2545,  0.1263, -0.2625],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.7.attention.self.key.weight',\n",
       "              tensor([[ 0.0044, -0.0022, -0.0544,  ..., -0.0081, -0.0031,  0.0631],\n",
       "                      [ 0.0124,  0.0054,  0.0236,  ...,  0.0236, -0.0455,  0.0065],\n",
       "                      [-0.0079, -0.0427, -0.0183,  ...,  0.0219, -0.0369,  0.0292],\n",
       "                      ...,\n",
       "                      [-0.0245,  0.0017,  0.0287,  ..., -0.0510, -0.0771, -0.0423],\n",
       "                      [-0.0697,  0.0383,  0.0179,  ..., -0.0069, -0.0242,  0.0808],\n",
       "                      [ 0.0222,  0.0233,  0.0276,  ...,  0.0108, -0.0107, -0.0332]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.7.attention.self.key.bias',\n",
       "              tensor([-3.1071e-04, -8.7827e-04, -9.8964e-05,  ...,  3.7811e-04,\n",
       "                       6.2051e-04,  3.3757e-04], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.7.attention.self.value.weight',\n",
       "              tensor([[ 0.0065, -0.0216,  0.0022,  ...,  0.0201, -0.0024, -0.0427],\n",
       "                      [-0.0115, -0.0296, -0.0225,  ..., -0.0176, -0.0343, -0.0479],\n",
       "                      [ 0.0236, -0.0200,  0.0250,  ..., -0.0146,  0.0223,  0.0083],\n",
       "                      ...,\n",
       "                      [-0.0020, -0.0426,  0.0138,  ...,  0.0235,  0.0379,  0.0100],\n",
       "                      [-0.0549, -0.0563, -0.0036,  ...,  0.0457,  0.0207,  0.0210],\n",
       "                      [ 0.0357, -0.0014, -0.0254,  ...,  0.0328, -0.0364, -0.0162]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.7.attention.self.value.bias',\n",
       "              tensor([ 0.0012,  0.0337, -0.0517,  ...,  0.0140,  0.0036,  0.0048],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.7.attention.output.dense.weight',\n",
       "              tensor([[ 0.0013, -0.0077,  0.0298,  ...,  0.0086,  0.0639, -0.0320],\n",
       "                      [-0.0392,  0.0027,  0.0162,  ...,  0.0410, -0.0791,  0.0256],\n",
       "                      [-0.0340, -0.0198,  0.0132,  ...,  0.0439,  0.0380,  0.0345],\n",
       "                      ...,\n",
       "                      [ 0.0448,  0.0032,  0.0524,  ...,  0.0072, -0.0658, -0.0062],\n",
       "                      [ 0.0110,  0.0139,  0.0117,  ..., -0.0084,  0.0159,  0.0333],\n",
       "                      [-0.0120, -0.0280, -0.0094,  ..., -0.0520, -0.0143,  0.0465]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.7.attention.output.dense.bias',\n",
       "              tensor([-0.0172,  0.0162, -0.0390,  ..., -0.0470, -0.0039,  0.0278],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.7.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9910, 0.9864, 0.9999,  ..., 0.9805, 0.9598, 0.9747], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.7.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.0919,  0.0109, -0.4246,  ..., -0.0742, -0.1016, -0.0008],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.7.intermediate.dense.weight',\n",
       "              tensor([[-0.0649,  0.0356,  0.0165,  ...,  0.0629,  0.0046,  0.0348],\n",
       "                      [ 0.0648,  0.0383, -0.0084,  ..., -0.0020, -0.0383, -0.0372],\n",
       "                      [-0.0375, -0.0248, -0.0008,  ...,  0.0163,  0.0164,  0.0334],\n",
       "                      ...,\n",
       "                      [ 0.0060,  0.0325,  0.0043,  ..., -0.0391, -0.0228,  0.0072],\n",
       "                      [-0.0333, -0.1084,  0.0162,  ..., -0.0868, -0.0081, -0.0115],\n",
       "                      [-0.0504, -0.0502,  0.0032,  ...,  0.0442, -0.0249,  0.0339]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.7.intermediate.dense.bias',\n",
       "              tensor([-0.0924, -0.0911, -0.0114,  ...,  0.0073, -0.0845, -0.0317],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.7.output.dense.weight',\n",
       "              tensor([[-0.0116,  0.0720, -0.0146,  ...,  0.0152, -0.1039, -0.0401],\n",
       "                      [ 0.0330,  0.0777,  0.0048,  ..., -0.0379, -0.0641,  0.0317],\n",
       "                      [-0.0133, -0.0086, -0.0086,  ...,  0.0290,  0.0141,  0.0066],\n",
       "                      ...,\n",
       "                      [-0.0593,  0.0384, -0.0252,  ...,  0.0267, -0.0118,  0.0272],\n",
       "                      [-0.0096, -0.0016, -0.0243,  ...,  0.0291,  0.0201,  0.0133],\n",
       "                      [ 0.0689, -0.0198,  0.0120,  ..., -0.0292,  0.0173, -0.0433]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.7.output.dense.bias',\n",
       "              tensor([-0.1937,  0.0498,  0.1158,  ..., -0.0160, -0.0424,  0.0587],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.7.output.LayerNorm.weight',\n",
       "              tensor([0.9892, 0.9893, 0.9990,  ..., 0.9805, 0.9774, 0.9516], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.7.output.LayerNorm.bias',\n",
       "              tensor([-0.0313, -0.0963, -0.0034,  ..., -0.0475, -0.0410, -0.1096],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.8.attention.self.query.weight',\n",
       "              tensor([[ 0.0358,  0.0331,  0.0311,  ...,  0.0218,  0.0173,  0.0115],\n",
       "                      [-0.0904, -0.0679,  0.0669,  ..., -0.0369,  0.0025,  0.0109],\n",
       "                      [-0.0667,  0.1055, -0.0310,  ...,  0.0427,  0.0672, -0.0033],\n",
       "                      ...,\n",
       "                      [ 0.0616,  0.0421, -0.0026,  ..., -0.0072,  0.0861, -0.0056],\n",
       "                      [ 0.0114,  0.0807, -0.0314,  ..., -0.1259,  0.0415,  0.0285],\n",
       "                      [-0.0275, -0.0795,  0.0003,  ...,  0.0057, -0.0169, -0.0442]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.8.attention.self.query.bias',\n",
       "              tensor([-0.0948,  0.1278,  0.0216,  ..., -0.1389, -0.0547,  0.0569],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.8.attention.self.key.weight',\n",
       "              tensor([[-0.0710,  0.0463,  0.0003,  ..., -0.1572,  0.0552, -0.0123],\n",
       "                      [-0.0544, -0.0026,  0.1166,  ...,  0.0146,  0.0182, -0.0305],\n",
       "                      [ 0.0419, -0.0373, -0.0595,  ..., -0.0314,  0.1134, -0.0309],\n",
       "                      ...,\n",
       "                      [-0.0084,  0.0541, -0.0413,  ...,  0.0566,  0.0012,  0.0333],\n",
       "                      [-0.0787,  0.0296, -0.0481,  ...,  0.0119,  0.0417, -0.0280],\n",
       "                      [-0.0111, -0.0857,  0.0332,  ...,  0.0145,  0.0086, -0.0653]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.8.attention.self.key.bias',\n",
       "              tensor([ 5.7599e-05,  2.1966e-04, -2.7304e-04,  ...,  3.6880e-05,\n",
       "                      -5.2950e-05,  1.5549e-04], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.8.attention.self.value.weight',\n",
       "              tensor([[ 0.0439,  0.0023, -0.0153,  ..., -0.0456,  0.0317,  0.0349],\n",
       "                      [-0.0498, -0.0349, -0.0010,  ...,  0.0655,  0.0012,  0.0494],\n",
       "                      [ 0.0018, -0.0060,  0.0048,  ..., -0.0010, -0.0085, -0.0674],\n",
       "                      ...,\n",
       "                      [ 0.0030,  0.0341,  0.0177,  ..., -0.0221, -0.0396, -0.0317],\n",
       "                      [ 0.0523, -0.0485,  0.0015,  ..., -0.0060, -0.0176, -0.0135],\n",
       "                      [-0.0276, -0.0153,  0.0039,  ...,  0.0417, -0.0164, -0.0403]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.8.attention.self.value.bias',\n",
       "              tensor([-0.0069, -0.0148,  0.0093,  ..., -0.0142, -0.0056, -0.0037],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.8.attention.output.dense.weight',\n",
       "              tensor([[ 0.0287, -0.0025, -0.0088,  ..., -0.0007,  0.0061, -0.0011],\n",
       "                      [ 0.0024, -0.0160,  0.0281,  ..., -0.0005,  0.0400,  0.0616],\n",
       "                      [ 0.0499, -0.0381,  0.0264,  ...,  0.0437, -0.0358,  0.0063],\n",
       "                      ...,\n",
       "                      [-0.0340,  0.0262, -0.0164,  ...,  0.0362, -0.0339, -0.0307],\n",
       "                      [-0.0473,  0.0049, -0.0263,  ...,  0.0026,  0.0016,  0.0064],\n",
       "                      [ 0.0270, -0.0116,  0.0306,  ...,  0.0233,  0.0035,  0.0472]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.8.attention.output.dense.bias',\n",
       "              tensor([-0.0504,  0.0051,  0.0043,  ...,  0.0091, -0.0962,  0.0549],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.8.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9887, 0.9956, 1.0000,  ..., 0.9886, 0.9953, 0.9737], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.8.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1705,  0.0123, -0.4999,  ..., -0.0113, -0.1094, -0.0146],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.8.intermediate.dense.weight',\n",
       "              tensor([[-0.0093, -0.0013,  0.0191,  ..., -0.0639,  0.0098, -0.0767],\n",
       "                      [ 0.0293, -0.0720,  0.0390,  ..., -0.1106,  0.0509, -0.0231],\n",
       "                      [ 0.0318,  0.0975,  0.0396,  ...,  0.0278,  0.0105,  0.0159],\n",
       "                      ...,\n",
       "                      [ 0.0444, -0.0180,  0.0362,  ..., -0.0200, -0.0170,  0.0366],\n",
       "                      [ 0.0873,  0.0202,  0.0094,  ...,  0.0160,  0.0524, -0.0739],\n",
       "                      [ 0.0361,  0.0054,  0.0192,  ..., -0.0242, -0.0673, -0.0163]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.8.intermediate.dense.bias',\n",
       "              tensor([-0.0612, -0.0999, -0.0531,  ..., -0.0758, -0.0579, -0.0349],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.8.output.dense.weight',\n",
       "              tensor([[ 0.0065,  0.0090,  0.0101,  ..., -0.0303,  0.0685,  0.0162],\n",
       "                      [-0.0350,  0.0173,  0.0659,  ...,  0.0196,  0.0093,  0.0270],\n",
       "                      [ 0.0370, -0.0163,  0.0182,  ...,  0.0376, -0.0040, -0.0028],\n",
       "                      ...,\n",
       "                      [ 0.0695, -0.0602,  0.0319,  ...,  0.0520, -0.0109,  0.0215],\n",
       "                      [-0.0157, -0.0060,  0.0141,  ..., -0.0643, -0.0102, -0.0052],\n",
       "                      [ 0.0210,  0.0234,  0.0252,  ...,  0.0253,  0.0079,  0.0249]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.8.output.dense.bias',\n",
       "              tensor([-0.1677,  0.0009,  0.0616,  ..., -0.0411, -0.0503, -0.0571],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.8.output.LayerNorm.weight',\n",
       "              tensor([0.9752, 0.9947, 1.0002,  ..., 0.9768, 0.9800, 0.9543], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.8.output.LayerNorm.bias',\n",
       "              tensor([ 0.0215, -0.1106, -0.0194,  ..., -0.0839, -0.0250, -0.0838],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.9.attention.self.query.weight',\n",
       "              tensor([[ 0.0094, -0.0838, -0.0360,  ..., -0.0320,  0.0669, -0.0665],\n",
       "                      [ 0.0207, -0.0312, -0.0086,  ..., -0.0323,  0.0509,  0.0566],\n",
       "                      [ 0.0205,  0.0260,  0.0154,  ..., -0.0404,  0.0147, -0.0259],\n",
       "                      ...,\n",
       "                      [ 0.0584, -0.0264, -0.0013,  ..., -0.0135, -0.0661, -0.0124],\n",
       "                      [ 0.0454,  0.0059, -0.0797,  ...,  0.0384,  0.0273,  0.0223],\n",
       "                      [-0.0214, -0.0197, -0.0416,  ..., -0.0469, -0.0362, -0.0465]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.9.attention.self.query.bias',\n",
       "              tensor([-0.0133, -0.0314, -0.0593,  ...,  0.0044, -0.0582,  0.0745],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.9.attention.self.key.weight',\n",
       "              tensor([[-3.5470e-02,  5.0172e-02,  8.2295e-06,  ..., -1.2851e-02,\n",
       "                       -3.0647e-02, -3.7194e-02],\n",
       "                      [ 3.7715e-02, -7.4924e-03, -3.5996e-03,  ..., -3.5361e-02,\n",
       "                       -1.9228e-02, -4.1577e-02],\n",
       "                      [ 3.7180e-02, -5.0020e-02,  6.9988e-02,  ..., -6.7592e-02,\n",
       "                       -2.6847e-02,  1.3417e-02],\n",
       "                      ...,\n",
       "                      [-1.0913e-02,  1.1511e-02,  2.2165e-03,  ...,  8.2961e-03,\n",
       "                        5.4171e-02,  7.3049e-03],\n",
       "                      [ 4.3057e-02,  3.5284e-02, -1.0992e-02,  ...,  1.4433e-02,\n",
       "                        2.8832e-02,  1.0114e-02],\n",
       "                      [-4.1063e-02,  9.8135e-03, -3.0008e-02,  ...,  8.5773e-02,\n",
       "                       -3.2332e-03,  1.0221e-01]], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.9.attention.self.key.bias',\n",
       "              tensor([-1.0146e-04, -5.6505e-06,  2.3852e-04,  ...,  1.9571e-04,\n",
       "                       3.1929e-04,  1.5910e-04], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.9.attention.self.value.weight',\n",
       "              tensor([[-0.0242,  0.0028,  0.0105,  ..., -0.0260, -0.0557,  0.0287],\n",
       "                      [-0.0215, -0.0320, -0.0010,  ..., -0.0535, -0.0039,  0.0557],\n",
       "                      [ 0.0002,  0.0535,  0.0108,  ...,  0.0214,  0.0262,  0.0112],\n",
       "                      ...,\n",
       "                      [-0.0540,  0.0350,  0.0133,  ...,  0.0558,  0.0596, -0.0052],\n",
       "                      [ 0.0541,  0.0144, -0.0109,  ..., -0.0322, -0.0370, -0.0333],\n",
       "                      [-0.0349,  0.0136,  0.0082,  ...,  0.0209,  0.0060, -0.0190]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.9.attention.self.value.bias',\n",
       "              tensor([ 0.0012, -0.0072,  0.0014,  ...,  0.0322, -0.0014,  0.0013],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.9.attention.output.dense.weight',\n",
       "              tensor([[-0.0177, -0.0263,  0.0085,  ...,  0.0192, -0.0104, -0.0194],\n",
       "                      [ 0.0031, -0.0422,  0.0037,  ..., -0.0460,  0.0173,  0.0207],\n",
       "                      [ 0.0342, -0.0673, -0.0011,  ..., -0.0131,  0.0403,  0.0015],\n",
       "                      ...,\n",
       "                      [ 0.0023,  0.0129,  0.0324,  ..., -0.0186,  0.0040,  0.0018],\n",
       "                      [-0.0167, -0.0069, -0.0078,  ..., -0.0810, -0.0195,  0.0549],\n",
       "                      [ 0.0272,  0.0133,  0.0288,  ..., -0.0129, -0.0120, -0.0040]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.9.attention.output.dense.bias',\n",
       "              tensor([ 0.0464,  0.0031, -0.1743,  ...,  0.0535, -0.0486,  0.0044],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.9.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9843, 0.9919, 0.9997,  ..., 0.9841, 0.9932, 0.9871], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.9.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1782, -0.0276, -0.4653,  ..., -0.0479, -0.1164, -0.0285],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.9.intermediate.dense.weight',\n",
       "              tensor([[ 0.0256,  0.0056, -0.0159,  ...,  0.0243,  0.0214,  0.0019],\n",
       "                      [ 0.0072, -0.0008,  0.0153,  ...,  0.0828,  0.0250,  0.0138],\n",
       "                      [ 0.0491, -0.0505,  0.0141,  ...,  0.0634, -0.0778,  0.0660],\n",
       "                      ...,\n",
       "                      [ 0.0073, -0.0351,  0.0135,  ...,  0.0732,  0.0060, -0.0192],\n",
       "                      [ 0.0139, -0.0574,  0.0069,  ...,  0.0001, -0.0117, -0.0104],\n",
       "                      [-0.0203, -0.0327,  0.0111,  ...,  0.0093,  0.0479,  0.0183]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.9.intermediate.dense.bias',\n",
       "              tensor([-0.0534, -0.0802, -0.0251,  ..., -0.0479, -0.0425, -0.1010],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.9.output.dense.weight',\n",
       "              tensor([[-0.0031,  0.0216, -0.0172,  ..., -0.0070,  0.0221,  0.0035],\n",
       "                      [ 0.0335,  0.0771, -0.0187,  ..., -0.0196, -0.0086, -0.0116],\n",
       "                      [ 0.0113,  0.0048,  0.0168,  ...,  0.0128, -0.0050, -0.0018],\n",
       "                      ...,\n",
       "                      [ 0.0139,  0.0928, -0.0512,  ..., -0.0506,  0.0201,  0.0168],\n",
       "                      [ 0.0313,  0.0484, -0.0488,  ...,  0.0433,  0.0332, -0.0015],\n",
       "                      [-0.0399, -0.0262, -0.0483,  ..., -0.0113,  0.0224,  0.0052]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.9.output.dense.bias',\n",
       "              tensor([-0.1372,  0.0675, -0.0874,  ..., -0.0444, -0.0780, -0.0239],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.9.output.LayerNorm.weight',\n",
       "              tensor([0.9759, 0.9884, 0.9987,  ..., 0.9716, 0.9816, 0.9732], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.9.output.LayerNorm.bias',\n",
       "              tensor([ 0.0327, -0.0622, -0.2096,  ..., -0.0588, -0.0126, -0.0454],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.10.attention.self.query.weight',\n",
       "              tensor([[ 0.0669,  0.0395, -0.0003,  ..., -0.1473,  0.0458,  0.0172],\n",
       "                      [ 0.0665, -0.1064, -0.0106,  ...,  0.0778,  0.0037, -0.0292],\n",
       "                      [-0.0308, -0.0115, -0.0377,  ...,  0.0798,  0.0949, -0.0405],\n",
       "                      ...,\n",
       "                      [ 0.0374,  0.0346,  0.2359,  ...,  0.0903, -0.0641,  0.0620],\n",
       "                      [ 0.0183,  0.0181,  0.0624,  ...,  0.1151,  0.0489, -0.0498],\n",
       "                      [ 0.0310, -0.0190,  0.0493,  ...,  0.0546,  0.0594, -0.0204]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.10.attention.self.query.bias',\n",
       "              tensor([ 0.0239,  0.0314, -0.0162,  ...,  0.0301,  0.0554,  0.0012],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.10.attention.self.key.weight',\n",
       "              tensor([[-0.0111,  0.0409,  0.0550,  ..., -0.0202, -0.0262, -0.0489],\n",
       "                      [-0.0969, -0.0963,  0.0256,  ..., -0.0674,  0.0010, -0.0060],\n",
       "                      [-0.0313,  0.0766, -0.0067,  ..., -0.1060,  0.0009, -0.0567],\n",
       "                      ...,\n",
       "                      [ 0.0190, -0.0087,  0.2555,  ..., -0.0731, -0.0286,  0.0291],\n",
       "                      [ 0.0112, -0.0092,  0.0811,  ..., -0.0077, -0.0020, -0.0161],\n",
       "                      [-0.0285, -0.0460,  0.0271,  ...,  0.0624, -0.0078, -0.0247]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.10.attention.self.key.bias',\n",
       "              tensor([-0.0006, -0.0009,  0.0005,  ...,  0.0004,  0.0004, -0.0005],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.10.attention.self.value.weight',\n",
       "              tensor([[ 0.0108,  0.0441,  0.0096,  ..., -0.0033, -0.0261, -0.0305],\n",
       "                      [ 0.0251, -0.0050, -0.0098,  ..., -0.0135, -0.0031, -0.0182],\n",
       "                      [ 0.0359,  0.0510,  0.0037,  ..., -0.0012,  0.0291, -0.0191],\n",
       "                      ...,\n",
       "                      [-0.0182,  0.0052, -0.0025,  ...,  0.0021,  0.0065, -0.0429],\n",
       "                      [ 0.0130,  0.0162, -0.0080,  ...,  0.0188, -0.0391,  0.0120],\n",
       "                      [-0.0269, -0.0149, -0.0153,  ..., -0.0253,  0.0117, -0.0155]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.10.attention.self.value.bias',\n",
       "              tensor([ 0.0219,  0.0104, -0.0333,  ...,  0.0204, -0.0136,  0.0498],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.10.attention.output.dense.weight',\n",
       "              tensor([[ 0.0085,  0.0544, -0.0078,  ...,  0.0126,  0.0358,  0.0216],\n",
       "                      [-0.0179, -0.0061, -0.0152,  ..., -0.0445,  0.0249, -0.0142],\n",
       "                      [ 0.0311,  0.0227, -0.1381,  ..., -0.0696, -0.0630, -0.0113],\n",
       "                      ...,\n",
       "                      [ 0.0055, -0.0079, -0.0362,  ..., -0.0076, -0.0065, -0.0199],\n",
       "                      [ 0.0296, -0.0010,  0.0470,  ..., -0.0180,  0.0013,  0.0158],\n",
       "                      [ 0.0530, -0.0038,  0.0056,  ..., -0.0050, -0.0115, -0.0268]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.10.attention.output.dense.bias',\n",
       "              tensor([-0.0046,  0.0635,  0.0535,  ...,  0.0353, -0.0607,  0.0743],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.10.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9741, 0.9900, 1.0001,  ..., 0.9890, 0.9916, 0.9870], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.10.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1806, -0.0025, -0.4714,  ..., -0.0686, -0.1522, -0.0407],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.10.intermediate.dense.weight',\n",
       "              tensor([[-0.0175, -0.0042,  0.0075,  ..., -0.0173, -0.0134, -0.0763],\n",
       "                      [ 0.0041,  0.0207,  0.0338,  ...,  0.0525,  0.0372, -0.0061],\n",
       "                      [-0.0011, -0.0164,  0.0281,  ...,  0.0292,  0.0336,  0.0027],\n",
       "                      ...,\n",
       "                      [ 0.0204,  0.0229,  0.0230,  ...,  0.0715, -0.0365,  0.0041],\n",
       "                      [ 0.0517, -0.0171,  0.0032,  ...,  0.0350,  0.0612, -0.0301],\n",
       "                      [-0.0087, -0.0186, -0.0078,  ...,  0.0173,  0.0034, -0.0229]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.10.intermediate.dense.bias',\n",
       "              tensor([-0.0571, -0.0502, -0.0152,  ..., -0.0922, -0.0903, -0.0147],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.10.output.dense.weight',\n",
       "              tensor([[-0.0174,  0.0023, -0.0023,  ...,  0.0587,  0.0150, -0.0558],\n",
       "                      [-0.0336,  0.0102,  0.0008,  ...,  0.0141, -0.0239, -0.0470],\n",
       "                      [ 0.0063, -0.0063,  0.0108,  ..., -0.0007, -0.0114,  0.0006],\n",
       "                      ...,\n",
       "                      [ 0.0103, -0.0144, -0.0114,  ...,  0.0235, -0.0048, -0.0066],\n",
       "                      [-0.0193, -0.0944, -0.0459,  ...,  0.0258,  0.0092, -0.0486],\n",
       "                      [-0.0254, -0.0002, -0.0444,  ...,  0.0069,  0.0239,  0.0106]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.10.output.dense.bias',\n",
       "              tensor([-0.2128,  0.0545,  0.0879,  ..., -0.0425,  0.0073, -0.1136],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.10.output.LayerNorm.weight',\n",
       "              tensor([0.9779, 0.9874, 0.9999,  ..., 0.9785, 0.9776, 0.9861], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.10.output.LayerNorm.bias',\n",
       "              tensor([ 0.0441, -0.0730, -0.2016,  ..., -0.0414,  0.0385, -0.0470],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.11.attention.self.query.weight',\n",
       "              tensor([[ 0.0356, -0.0109,  0.0256,  ...,  0.0181,  0.0850,  0.0366],\n",
       "                      [ 0.0721, -0.0424, -0.0022,  ..., -0.0238,  0.0123,  0.0318],\n",
       "                      [ 0.0529, -0.0496, -0.2163,  ...,  0.0503,  0.0724, -0.0327],\n",
       "                      ...,\n",
       "                      [ 0.0940, -0.0229,  0.0825,  ..., -0.0424,  0.0633, -0.0683],\n",
       "                      [-0.0685, -0.0217, -0.0633,  ..., -0.0205, -0.0343, -0.0838],\n",
       "                      [ 0.0379,  0.0065, -0.0362,  ..., -0.0496, -0.0955, -0.0480]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.11.attention.self.query.bias',\n",
       "              tensor([0.0106, 0.0283, 0.0473,  ..., 0.1027, 0.0180, 0.0222], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.11.attention.self.key.weight',\n",
       "              tensor([[-0.0863, -0.0035,  0.0745,  ...,  0.0059, -0.0251, -0.0131],\n",
       "                      [-0.0621, -0.0168, -0.0321,  ...,  0.0193, -0.0277,  0.0740],\n",
       "                      [-0.1178,  0.0090, -0.2359,  ..., -0.0570, -0.0031,  0.0054],\n",
       "                      ...,\n",
       "                      [-0.0393, -0.0319,  0.1112,  ..., -0.0796, -0.0347, -0.0251],\n",
       "                      [-0.0140,  0.0091, -0.0642,  ..., -0.1068,  0.0082,  0.0109],\n",
       "                      [ 0.0100, -0.0780, -0.0353,  ..., -0.0435, -0.0185, -0.0165]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.11.attention.self.key.bias',\n",
       "              tensor([ 5.8434e-04, -2.9706e-05, -2.1220e-05,  ..., -1.6546e-04,\n",
       "                      -6.0570e-06,  5.2048e-05], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.11.attention.self.value.weight',\n",
       "              tensor([[ 0.0101, -0.0316,  0.0028,  ...,  0.0624,  0.0035, -0.0001],\n",
       "                      [ 0.0254, -0.0347, -0.0042,  ..., -0.0777, -0.0298,  0.0399],\n",
       "                      [-0.0457, -0.0106,  0.0268,  ..., -0.0849, -0.0282,  0.0196],\n",
       "                      ...,\n",
       "                      [-0.0057,  0.0450, -0.0015,  ...,  0.0015, -0.0457, -0.0011],\n",
       "                      [ 0.0418,  0.0283,  0.0013,  ...,  0.0478,  0.0339, -0.0786],\n",
       "                      [-0.0132,  0.0007,  0.0017,  ..., -0.0461,  0.0339, -0.0238]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.11.attention.self.value.bias',\n",
       "              tensor([-0.0098,  0.0112,  0.0058,  ..., -0.0280,  0.0112, -0.0346],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.11.attention.output.dense.weight',\n",
       "              tensor([[-0.0066, -0.0249,  0.0218,  ...,  0.0061,  0.0042, -0.0243],\n",
       "                      [ 0.0449,  0.0072,  0.0231,  ...,  0.0076, -0.0024,  0.0315],\n",
       "                      [-0.0249,  0.0068, -0.0320,  ...,  0.0077,  0.0179, -0.0202],\n",
       "                      ...,\n",
       "                      [-0.0110,  0.0026,  0.0653,  ...,  0.0226,  0.0247, -0.0174],\n",
       "                      [ 0.0071,  0.0193,  0.0347,  ...,  0.0112,  0.0299, -0.0063],\n",
       "                      [ 0.0245, -0.0564, -0.0037,  ..., -0.0197, -0.0256, -0.0252]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.11.attention.output.dense.bias',\n",
       "              tensor([-0.0511,  0.1448, -0.1547,  ...,  0.0590, -0.0474,  0.0369],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.11.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9817, 0.9929, 0.9997,  ..., 0.9932, 0.9956, 0.9810], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.11.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.2123,  0.0090, -0.3471,  ..., -0.0617, -0.0711, -0.0355],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.11.intermediate.dense.weight',\n",
       "              tensor([[ 0.0070, -0.0359, -0.0075,  ...,  0.0530,  0.0283,  0.0410],\n",
       "                      [ 0.1040,  0.0581,  0.0037,  ...,  0.0586,  0.0348, -0.0855],\n",
       "                      [ 0.0036,  0.0460, -0.0063,  ...,  0.0400,  0.0088, -0.0368],\n",
       "                      ...,\n",
       "                      [ 0.0613,  0.0114,  0.0082,  ..., -0.0027,  0.0500, -0.1040],\n",
       "                      [ 0.0511,  0.0047,  0.0145,  ...,  0.0647, -0.0277,  0.0378],\n",
       "                      [ 0.0696,  0.0207,  0.0362,  ...,  0.0150,  0.0020,  0.0121]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.11.intermediate.dense.bias',\n",
       "              tensor([ 0.0239, -0.0455, -0.0557,  ..., -0.0536, -0.0638,  0.0378],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.11.output.dense.weight',\n",
       "              tensor([[ 0.0086,  0.0324, -0.0032,  ...,  0.0088,  0.0267, -0.0502],\n",
       "                      [ 0.0177,  0.0425,  0.0047,  ..., -0.0198,  0.0452,  0.0061],\n",
       "                      [-0.0153,  0.0214, -0.0083,  ..., -0.0046, -0.0069, -0.0026],\n",
       "                      ...,\n",
       "                      [ 0.0509, -0.0554,  0.0636,  ..., -0.0223, -0.0164, -0.0122],\n",
       "                      [ 0.0130,  0.0297, -0.0422,  ...,  0.0131, -0.0343,  0.0144],\n",
       "                      [ 0.0262, -0.0403,  0.0013,  ..., -0.0314, -0.0599, -0.0132]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.11.output.dense.bias',\n",
       "              tensor([-0.1759, -0.0093, -0.0050,  ..., -0.0141, -0.0839, -0.1054],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.11.output.LayerNorm.weight',\n",
       "              tensor([0.9867, 0.9904, 0.9997,  ..., 0.9784, 0.9824, 0.9908], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.11.output.LayerNorm.bias',\n",
       "              tensor([ 0.0854, -0.0873,  0.1802,  ..., -0.0374, -0.0192, -0.0719],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.12.attention.self.query.weight',\n",
       "              tensor([[-4.8801e-02, -2.4072e-02,  8.8054e-02,  ...,  2.6472e-03,\n",
       "                        5.3192e-02,  5.9305e-02],\n",
       "                      [-2.3200e-02,  6.8120e-03,  1.3998e-02,  ..., -8.0420e-02,\n",
       "                       -6.4488e-02,  5.5517e-02],\n",
       "                      [-5.6253e-02,  3.9899e-02, -1.3430e-01,  ...,  5.5875e-02,\n",
       "                        3.0077e-02,  5.0069e-02],\n",
       "                      ...,\n",
       "                      [ 2.6300e-02,  2.1235e-02,  2.8901e-01,  ..., -1.4791e-02,\n",
       "                        9.4844e-02, -2.3197e-02],\n",
       "                      [-8.4691e-02,  1.3762e-02, -1.0885e-01,  ..., -3.3938e-02,\n",
       "                        1.3628e-02, -2.3983e-02],\n",
       "                      [-2.6341e-04, -4.2995e-03, -3.1212e-02,  ..., -9.0760e-02,\n",
       "                       -4.2664e-03, -7.9350e-02]], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.12.attention.self.query.bias',\n",
       "              tensor([ 0.0043, -0.0059,  0.0022,  ..., -0.2385, -0.0193, -0.0036],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.12.attention.self.key.weight',\n",
       "              tensor([[-2.5527e-02, -1.2586e-01,  7.4955e-02,  ...,  3.8491e-02,\n",
       "                       -1.8016e-02,  6.6667e-02],\n",
       "                      [ 1.2175e-01,  2.3826e-02, -7.6932e-02,  ...,  1.4100e-04,\n",
       "                       -2.6859e-02, -1.7448e-02],\n",
       "                      [-4.3746e-02,  3.1089e-02, -1.0856e-01,  ..., -7.8189e-02,\n",
       "                       -4.5242e-02,  3.4632e-03],\n",
       "                      ...,\n",
       "                      [-3.1230e-03,  1.6832e-02, -3.7097e-01,  ...,  5.7401e-02,\n",
       "                       -7.1693e-03, -9.3028e-03],\n",
       "                      [ 2.4365e-02, -5.5965e-03, -1.9452e-01,  ..., -3.5051e-02,\n",
       "                        8.0228e-03,  5.6383e-02],\n",
       "                      [ 3.5171e-03, -3.9062e-02, -9.6139e-02,  ...,  3.8449e-02,\n",
       "                        9.7325e-03,  9.7846e-03]], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.12.attention.self.key.bias',\n",
       "              tensor([ 4.7666e-05, -1.0270e-04,  1.3898e-05,  ..., -1.7913e-02,\n",
       "                       5.9356e-04, -1.9250e-04], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.12.attention.self.value.weight',\n",
       "              tensor([[-0.0893, -0.0027,  0.0088,  ...,  0.0459, -0.0019, -0.0060],\n",
       "                      [ 0.0316,  0.0998, -0.0115,  ..., -0.0075,  0.0305,  0.0838],\n",
       "                      [ 0.0155,  0.0042, -0.0011,  ..., -0.0360, -0.0432,  0.0351],\n",
       "                      ...,\n",
       "                      [-0.0187, -0.0378, -0.0148,  ..., -0.0055, -0.0146,  0.0627],\n",
       "                      [-0.0360, -0.0446,  0.0239,  ..., -0.0140, -0.0368,  0.0622],\n",
       "                      [ 0.0018, -0.0307,  0.0002,  ..., -0.0338,  0.0363,  0.0228]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.12.attention.self.value.bias',\n",
       "              tensor([ 0.0050, -0.0075,  0.0003,  ...,  0.0298,  0.0153,  0.0310],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.12.attention.output.dense.weight',\n",
       "              tensor([[-0.0449, -0.0198, -0.0211,  ...,  0.0201,  0.0005,  0.0008],\n",
       "                      [-0.0476,  0.0174, -0.0386,  ..., -0.0312,  0.0039,  0.0174],\n",
       "                      [-0.0411, -0.0196,  0.0288,  ...,  0.0136,  0.0363,  0.0014],\n",
       "                      ...,\n",
       "                      [ 0.0178, -0.0133, -0.0403,  ..., -0.0140,  0.0114,  0.0297],\n",
       "                      [ 0.0017, -0.0273,  0.0171,  ..., -0.0172,  0.0194, -0.0215],\n",
       "                      [ 0.0053,  0.0382,  0.0408,  ..., -0.0110, -0.0290, -0.0254]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.12.attention.output.dense.bias',\n",
       "              tensor([ 0.0293, -0.0018,  0.0631,  ..., -0.0135, -0.0418, -0.0079],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.12.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9920, 0.9810, 1.0002,  ..., 0.9884, 0.9839, 0.9876], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.12.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1647,  0.0042, -0.3015,  ..., -0.0278, -0.1446, -0.0364],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.12.intermediate.dense.weight',\n",
       "              tensor([[ 0.0728, -0.0337,  0.0158,  ..., -0.0143, -0.0046,  0.0081],\n",
       "                      [-0.0168, -0.0274,  0.0180,  ..., -0.0484, -0.0393, -0.0167],\n",
       "                      [-0.0388, -0.0446,  0.0778,  ..., -0.0025, -0.0160, -0.0243],\n",
       "                      ...,\n",
       "                      [ 0.0209, -0.0464,  0.0278,  ..., -0.1238, -0.0197, -0.0035],\n",
       "                      [ 0.0128, -0.0499,  0.0155,  ..., -0.0497, -0.0163,  0.0440],\n",
       "                      [ 0.0182,  0.0055, -0.0061,  ...,  0.0152, -0.0276, -0.0090]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.12.intermediate.dense.bias',\n",
       "              tensor([-0.1074, -0.0404, -0.0113,  ..., -0.1226, -0.0860, -0.1047],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.12.output.dense.weight',\n",
       "              tensor([[ 0.0305, -0.0028, -0.0675,  ...,  0.0266,  0.0262, -0.0147],\n",
       "                      [-0.0146,  0.0205,  0.0110,  ..., -0.0289,  0.0097, -0.0360],\n",
       "                      [ 0.0003,  0.0010, -0.0148,  ..., -0.0016, -0.0285, -0.0023],\n",
       "                      ...,\n",
       "                      [-0.0097, -0.0116,  0.0155,  ..., -0.0420, -0.0118, -0.0244],\n",
       "                      [-0.0179, -0.0111, -0.0235,  ..., -0.0114, -0.0246,  0.0201],\n",
       "                      [-0.0544, -0.0361,  0.0324,  ...,  0.0057, -0.0026, -0.0106]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.12.output.dense.bias',\n",
       "              tensor([-0.2180,  0.1670, -0.0793,  ..., -0.0087, -0.0804, -0.1233],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.12.output.LayerNorm.weight',\n",
       "              tensor([0.9877, 0.9905, 0.9963,  ..., 0.9903, 0.9831, 0.9911], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.12.output.LayerNorm.bias',\n",
       "              tensor([ 0.0085, -0.0779,  0.0869,  ..., -0.0695, -0.0121, -0.0617],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.13.attention.self.query.weight',\n",
       "              tensor([[ 0.0448,  0.0473, -0.0504,  ..., -0.0472,  0.0426, -0.0586],\n",
       "                      [-0.0264, -0.0095,  0.0493,  ...,  0.0335,  0.0293,  0.0587],\n",
       "                      [-0.0053, -0.0268,  0.0018,  ..., -0.0378, -0.0804, -0.0144],\n",
       "                      ...,\n",
       "                      [ 0.0633, -0.0096,  0.0292,  ...,  0.0067, -0.0203, -0.0164],\n",
       "                      [-0.0053, -0.0269, -0.1436,  ...,  0.0454,  0.0224, -0.0244],\n",
       "                      [ 0.0501,  0.0561, -0.1591,  ...,  0.0247,  0.0381,  0.0658]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.13.attention.self.query.bias',\n",
       "              tensor([-0.0478,  0.0438,  0.0065,  ...,  0.0428,  0.1791,  0.0484],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.13.attention.self.key.weight',\n",
       "              tensor([[ 0.0267,  0.0612, -0.0415,  ..., -0.0176,  0.0262, -0.0715],\n",
       "                      [ 0.0543, -0.0048,  0.0743,  ..., -0.0335, -0.0022, -0.0320],\n",
       "                      [ 0.0189,  0.0648, -0.0433,  ...,  0.1567,  0.0242, -0.0780],\n",
       "                      ...,\n",
       "                      [-0.0468, -0.0479, -0.0111,  ..., -0.0245,  0.0126, -0.0224],\n",
       "                      [ 0.0217,  0.0325, -0.2133,  ..., -0.0188, -0.0205,  0.0022],\n",
       "                      [-0.0433,  0.0463, -0.1319,  ...,  0.0231,  0.0087,  0.0320]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.13.attention.self.key.bias',\n",
       "              tensor([-3.8081e-05, -6.7709e-05, -2.4498e-04,  ...,  1.8495e-04,\n",
       "                       5.4848e-04, -3.5835e-04], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.13.attention.self.value.weight',\n",
       "              tensor([[ 5.4093e-02,  6.5674e-02, -1.5529e-02,  ...,  3.9786e-02,\n",
       "                        5.9725e-03,  3.8671e-02],\n",
       "                      [ 1.4891e-02,  5.4602e-02,  6.9210e-03,  ..., -3.4420e-02,\n",
       "                       -2.1761e-02,  2.2652e-02],\n",
       "                      [-3.8045e-03,  5.0695e-02,  9.8608e-04,  ..., -2.2995e-02,\n",
       "                       -5.5622e-02,  3.9144e-02],\n",
       "                      ...,\n",
       "                      [ 4.1323e-02, -7.2542e-02,  1.9550e-02,  ..., -3.6455e-04,\n",
       "                       -1.5171e-02, -2.3390e-02],\n",
       "                      [-1.0871e-03,  8.9378e-04, -3.9205e-02,  ...,  7.6769e-03,\n",
       "                       -1.1067e-01, -9.2029e-03],\n",
       "                      [-4.1449e-02, -9.0341e-02,  2.5514e-02,  ..., -9.4621e-05,\n",
       "                       -7.6007e-03, -1.8495e-02]], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.13.attention.self.value.bias',\n",
       "              tensor([ 0.0120,  0.0079,  0.0063,  ..., -0.0072, -0.0073, -0.0008],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.13.attention.output.dense.weight',\n",
       "              tensor([[ 0.0018, -0.0391,  0.0306,  ..., -0.0514, -0.0004,  0.1053],\n",
       "                      [ 0.0090,  0.0064, -0.0079,  ...,  0.0097, -0.0632,  0.0405],\n",
       "                      [-0.0028, -0.0099, -0.0161,  ...,  0.0143, -0.0198, -0.0009],\n",
       "                      ...,\n",
       "                      [-0.0380, -0.0049, -0.0470,  ...,  0.0013, -0.0425,  0.0174],\n",
       "                      [-0.0428,  0.0573, -0.0023,  ...,  0.0163,  0.0800, -0.0292],\n",
       "                      [-0.0013,  0.0023,  0.0138,  ...,  0.0204,  0.0361,  0.0530]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.13.attention.output.dense.bias',\n",
       "              tensor([-0.0423,  0.0429, -0.0923,  ...,  0.0384, -0.0336,  0.0341],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.13.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9803, 0.9892, 0.9997,  ..., 0.9911, 0.9855, 0.9798], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.13.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1781,  0.0721, -0.2694,  ..., -0.0585, -0.1191, -0.0615],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.13.intermediate.dense.weight',\n",
       "              tensor([[ 0.0205, -0.0218,  0.0199,  ..., -0.0340, -0.0568, -0.0415],\n",
       "                      [ 0.0354,  0.0090,  0.0101,  ...,  0.0516,  0.0217, -0.0007],\n",
       "                      [ 0.0594, -0.0431,  0.0545,  ...,  0.1132, -0.0105, -0.0641],\n",
       "                      ...,\n",
       "                      [ 0.0296, -0.0114, -0.0061,  ..., -0.0107,  0.0371,  0.0057],\n",
       "                      [ 0.0095,  0.0431,  0.0935,  ...,  0.0424,  0.0410, -0.0324],\n",
       "                      [ 0.0344, -0.1294,  0.0409,  ...,  0.0058,  0.0022, -0.0757]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.13.intermediate.dense.bias',\n",
       "              tensor([-0.1378, -0.0528, -0.0889,  ..., -0.1026, -0.0329, -0.0373],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.13.output.dense.weight',\n",
       "              tensor([[ 0.0634, -0.0330, -0.0446,  ..., -0.0347,  0.0098, -0.0065],\n",
       "                      [-0.0084,  0.0005, -0.0564,  ...,  0.0087,  0.0215, -0.0255],\n",
       "                      [ 0.0146,  0.0071,  0.0031,  ..., -0.0014,  0.0066, -0.0031],\n",
       "                      ...,\n",
       "                      [-0.0298,  0.0344,  0.0009,  ..., -0.0324,  0.0107,  0.0349],\n",
       "                      [-0.0873, -0.0238,  0.0315,  ..., -0.0197,  0.0595,  0.0162],\n",
       "                      [-0.0277, -0.0034, -0.0283,  ..., -0.0250, -0.0015, -0.0440]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.13.output.dense.bias',\n",
       "              tensor([-0.1067,  0.0574, -0.0723,  ..., -0.0241, -0.0499, -0.0874],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.13.output.LayerNorm.weight',\n",
       "              tensor([0.9857, 0.9919, 0.9975,  ..., 0.9896, 0.9884, 0.9940], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.13.output.LayerNorm.bias',\n",
       "              tensor([ 0.0679, -0.1159,  0.2406,  ..., -0.0530, -0.0041, -0.0440],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.14.attention.self.query.weight',\n",
       "              tensor([[-0.0415, -0.0574,  0.0110,  ..., -0.1231, -0.0240, -0.1601],\n",
       "                      [-0.0686,  0.0300, -0.0958,  ...,  0.0300, -0.0204, -0.0346],\n",
       "                      [-0.0060, -0.0323,  0.1081,  ..., -0.0077, -0.0609,  0.0326],\n",
       "                      ...,\n",
       "                      [ 0.0635,  0.0023,  0.0228,  ..., -0.0388, -0.0702,  0.0419],\n",
       "                      [-0.0177,  0.0402, -0.0162,  ..., -0.0931, -0.0313,  0.0583],\n",
       "                      [-0.0709,  0.0261,  0.0084,  ...,  0.0572,  0.0292,  0.0414]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.14.attention.self.query.bias',\n",
       "              tensor([ 0.1925,  0.1407, -0.1232,  ...,  0.2324, -0.1197,  0.0184],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.14.attention.self.key.weight',\n",
       "              tensor([[ 0.0361,  0.0813,  0.0729,  ...,  0.0074,  0.0034, -0.0071],\n",
       "                      [-0.0668, -0.0047, -0.1240,  ..., -0.0121,  0.0115,  0.0430],\n",
       "                      [-0.0207,  0.0271,  0.0475,  ...,  0.0238, -0.1161,  0.0600],\n",
       "                      ...,\n",
       "                      [ 0.0782, -0.0605,  0.0650,  ..., -0.0999, -0.0444, -0.0249],\n",
       "                      [ 0.0456,  0.0767,  0.0443,  ..., -0.0771,  0.0683,  0.0377],\n",
       "                      [-0.0682, -0.0025,  0.0571,  ..., -0.0072, -0.0541, -0.0274]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.14.attention.self.key.bias',\n",
       "              tensor([ 2.5960e-04, -6.5786e-05, -1.5482e-04,  ..., -1.6639e-04,\n",
       "                       6.5704e-05,  1.5342e-04], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.14.attention.self.value.weight',\n",
       "              tensor([[-0.0428,  0.0019,  0.0434,  ..., -0.0437, -0.0048, -0.0064],\n",
       "                      [-0.0023, -0.0698, -0.0089,  ...,  0.0601,  0.0618, -0.0541],\n",
       "                      [ 0.0274, -0.0341, -0.0241,  ..., -0.0638,  0.0103,  0.0177],\n",
       "                      ...,\n",
       "                      [ 0.0815,  0.0247, -0.0177,  ...,  0.0245, -0.0284, -0.0344],\n",
       "                      [ 0.0718,  0.0167, -0.0145,  ..., -0.0028, -0.0221,  0.0307],\n",
       "                      [-0.0726, -0.0347, -0.0240,  ..., -0.0011,  0.0484, -0.1314]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.14.attention.self.value.bias',\n",
       "              tensor([-6.7340e-05,  5.9770e-03, -1.2090e-02,  ...,  1.1727e-04,\n",
       "                       4.8451e-03,  1.3237e-02], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.14.attention.output.dense.weight',\n",
       "              tensor([[-0.0125, -0.0239,  0.0356,  ..., -0.0439, -0.0008,  0.0847],\n",
       "                      [ 0.0157, -0.0406,  0.0493,  ..., -0.0698, -0.0414, -0.0060],\n",
       "                      [ 0.0408, -0.0356,  0.0162,  ...,  0.0048,  0.0070, -0.0233],\n",
       "                      ...,\n",
       "                      [ 0.0661, -0.0342,  0.0695,  ...,  0.0084, -0.0049, -0.0084],\n",
       "                      [-0.0059, -0.0630, -0.0203,  ...,  0.0260,  0.0086, -0.0088],\n",
       "                      [-0.0120, -0.0312,  0.0251,  ...,  0.0648,  0.0188,  0.0692]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.14.attention.output.dense.bias',\n",
       "              tensor([-0.0237,  0.0020,  0.0311,  ...,  0.0651, -0.0414, -0.0050],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.14.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9979, 0.9837, 0.9994,  ..., 0.9899, 0.9909, 0.9893], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.14.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.0863, -0.0134, -0.1951,  ..., -0.0626, -0.1386, -0.0531],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.14.intermediate.dense.weight',\n",
       "              tensor([[-0.0087, -0.0012,  0.0394,  ...,  0.0003, -0.0169,  0.0385],\n",
       "                      [ 0.0129, -0.0519, -0.0091,  ...,  0.0624, -0.0237,  0.0486],\n",
       "                      [ 0.0453, -0.0666,  0.0101,  ...,  0.0640,  0.0665, -0.0525],\n",
       "                      ...,\n",
       "                      [ 0.0743, -0.0388,  0.0085,  ...,  0.0079, -0.0062, -0.0341],\n",
       "                      [-0.0352, -0.0586, -0.0118,  ...,  0.0300,  0.0121,  0.0184],\n",
       "                      [ 0.0354, -0.0426, -0.0663,  ...,  0.0372, -0.0153,  0.0054]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.14.intermediate.dense.bias',\n",
       "              tensor([-0.1081, -0.1092, -0.1115,  ..., -0.0580, -0.0804, -0.0826],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.14.output.dense.weight',\n",
       "              tensor([[-0.0196,  0.0288,  0.0082,  ...,  0.0272,  0.0085, -0.0655],\n",
       "                      [ 0.0077, -0.0103, -0.0870,  ..., -0.0096,  0.0156, -0.0647],\n",
       "                      [-0.0105, -0.0182,  0.0368,  ...,  0.0098,  0.0054,  0.0125],\n",
       "                      ...,\n",
       "                      [ 0.0606,  0.0087,  0.0067,  ..., -0.0465,  0.0367, -0.0312],\n",
       "                      [-0.0510,  0.0130,  0.0244,  ...,  0.0446,  0.0018, -0.0314],\n",
       "                      [ 0.0270,  0.0106, -0.0592,  ..., -0.0044, -0.0201, -0.0694]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.14.output.dense.bias',\n",
       "              tensor([-0.1094,  0.0496, -0.1960,  ..., -0.0112, -0.1291, -0.0688],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.14.output.LayerNorm.weight',\n",
       "              tensor([0.9907, 0.9935, 0.9980,  ..., 0.9915, 0.9905, 0.9935], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.14.output.LayerNorm.bias',\n",
       "              tensor([-0.0244, -0.1100,  0.2496,  ..., -0.0509, -0.0146, -0.0587],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.15.attention.self.query.weight',\n",
       "              tensor([[ 0.0602,  0.0549, -0.1355,  ..., -0.0178,  0.0381,  0.0186],\n",
       "                      [-0.0217,  0.0184,  0.0861,  ...,  0.0862, -0.0278, -0.0231],\n",
       "                      [-0.0031, -0.0200, -0.0308,  ..., -0.0582,  0.0586, -0.0830],\n",
       "                      ...,\n",
       "                      [ 0.0501,  0.1160, -0.0245,  ...,  0.0255, -0.0174,  0.0139],\n",
       "                      [-0.0178,  0.0906,  0.0348,  ..., -0.0046, -0.0625,  0.0392],\n",
       "                      [-0.0552, -0.0342,  0.0114,  ..., -0.0129,  0.0937, -0.0541]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.15.attention.self.query.bias',\n",
       "              tensor([-0.0122, -0.0729, -0.0247,  ..., -0.1174, -0.0878, -0.0033],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.15.attention.self.key.weight',\n",
       "              tensor([[-0.0437,  0.0160, -0.2183,  ..., -0.0841, -0.0103, -0.0082],\n",
       "                      [ 0.0627, -0.0182, -0.0566,  ..., -0.0116,  0.0013, -0.0230],\n",
       "                      [-0.0313,  0.0872, -0.0740,  ..., -0.0446, -0.0619, -0.0167],\n",
       "                      ...,\n",
       "                      [ 0.0160,  0.0140, -0.0534,  ..., -0.1037,  0.0359, -0.0165],\n",
       "                      [-0.0982, -0.0158, -0.0395,  ..., -0.0039,  0.0132,  0.0328],\n",
       "                      [ 0.0532, -0.0452,  0.0258,  ..., -0.0333,  0.0473,  0.0601]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.15.attention.self.key.bias',\n",
       "              tensor([ 1.2952e-04, -3.9652e-05,  2.7541e-04,  ...,  4.8910e-04,\n",
       "                       1.9019e-04, -2.0512e-04], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.15.attention.self.value.weight',\n",
       "              tensor([[-6.7444e-02,  4.6222e-02,  5.8268e-03,  ...,  1.0668e-03,\n",
       "                       -2.4784e-02,  6.5475e-02],\n",
       "                      [-1.3486e-02, -2.9810e-02, -3.1635e-02,  ..., -3.9141e-02,\n",
       "                        3.7655e-02, -6.6108e-02],\n",
       "                      [ 7.3940e-05, -9.1596e-03,  3.6369e-03,  ..., -1.0545e-01,\n",
       "                        1.0470e-01,  9.7701e-02],\n",
       "                      ...,\n",
       "                      [ 1.6463e-02, -5.8153e-02,  3.1320e-04,  ...,  3.6566e-02,\n",
       "                       -8.1827e-03,  7.6367e-02],\n",
       "                      [-4.7229e-02, -8.6532e-02,  5.1329e-03,  ...,  6.1005e-02,\n",
       "                        1.6789e-02,  1.3355e-02],\n",
       "                      [-6.3939e-02,  4.3613e-03, -1.3436e-02,  ..., -6.5099e-02,\n",
       "                       -1.0760e-01,  2.1085e-03]], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.15.attention.self.value.bias',\n",
       "              tensor([-0.0045,  0.0053,  0.0015,  ...,  0.0030, -0.0046, -0.0215],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.15.attention.output.dense.weight',\n",
       "              tensor([[ 0.0145,  0.0039, -0.0207,  ..., -0.0355, -0.0311,  0.0244],\n",
       "                      [ 0.0098,  0.0242, -0.0344,  ..., -0.0031,  0.0479, -0.0246],\n",
       "                      [-0.0272, -0.0384,  0.0716,  ..., -0.0159, -0.0166, -0.0120],\n",
       "                      ...,\n",
       "                      [-0.0027,  0.0526,  0.0168,  ..., -0.0369, -0.0088,  0.0223],\n",
       "                      [-0.0600,  0.0955,  0.0484,  ..., -0.0035,  0.0194,  0.0878],\n",
       "                      [ 0.0254, -0.0558,  0.0104,  ..., -0.0112, -0.0378, -0.0204]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.15.attention.output.dense.bias',\n",
       "              tensor([-0.0165,  0.0167,  0.0532,  ...,  0.0020, -0.0478, -0.0281],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.15.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9910, 0.9904, 0.9995,  ..., 0.9915, 0.9915, 0.9859], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.15.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1105, -0.0167, -0.1705,  ..., -0.0920, -0.0813, -0.1239],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.15.intermediate.dense.weight',\n",
       "              tensor([[-0.0215, -0.0179,  0.0236,  ...,  0.0113,  0.0506, -0.0314],\n",
       "                      [ 0.0532, -0.0539,  0.0043,  ..., -0.0226, -0.0464, -0.0110],\n",
       "                      [-0.0259,  0.0529,  0.0247,  ...,  0.0951,  0.0065,  0.0232],\n",
       "                      ...,\n",
       "                      [-0.0404, -0.0329,  0.0204,  ...,  0.0804,  0.0416,  0.0258],\n",
       "                      [-0.0416,  0.0694,  0.0569,  ..., -0.0117,  0.0223, -0.0107],\n",
       "                      [ 0.0672,  0.0077,  0.0062,  ...,  0.0436,  0.0705,  0.0231]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.15.intermediate.dense.bias',\n",
       "              tensor([-0.0443, -0.1070, -0.0776,  ..., -0.0345,  0.0107, -0.0831],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.15.output.dense.weight',\n",
       "              tensor([[-0.0235,  0.0637, -0.0439,  ..., -0.0001,  0.0174, -0.0094],\n",
       "                      [-0.0220,  0.0113, -0.0343,  ..., -0.0554, -0.0027, -0.0036],\n",
       "                      [-0.0171, -0.0077, -0.0258,  ..., -0.0026,  0.0165,  0.0142],\n",
       "                      ...,\n",
       "                      [ 0.0047,  0.0237,  0.0552,  ..., -0.0088,  0.0034, -0.0013],\n",
       "                      [-0.0018, -0.0083,  0.0666,  ..., -0.0425, -0.0172,  0.0012],\n",
       "                      [-0.0458,  0.0186,  0.0200,  ...,  0.0322, -0.0091,  0.0380]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.15.output.dense.bias',\n",
       "              tensor([-0.1302,  0.0302, -0.2485,  ..., -0.0317, -0.0861, -0.0998],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.15.output.LayerNorm.weight',\n",
       "              tensor([0.9884, 0.9861, 0.9983,  ..., 0.9864, 0.9959, 0.9868], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.15.output.LayerNorm.bias',\n",
       "              tensor([-0.0083, -0.0669,  0.1742,  ..., -0.0156, -0.0312, -0.0161],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.16.attention.self.query.weight',\n",
       "              tensor([[-0.0178,  0.0010, -0.0399,  ..., -0.0123,  0.0901,  0.0356],\n",
       "                      [-0.0467, -0.0655, -0.0256,  ...,  0.0127, -0.0201, -0.0383],\n",
       "                      [ 0.0019, -0.0054,  0.0839,  ..., -0.0682, -0.0602, -0.0079],\n",
       "                      ...,\n",
       "                      [ 0.0706, -0.0923, -0.0288,  ..., -0.0144,  0.0361,  0.0214],\n",
       "                      [-0.0500,  0.0419,  0.0564,  ..., -0.0885,  0.0312, -0.1165],\n",
       "                      [ 0.0141,  0.0082,  0.0344,  ..., -0.0358, -0.0882, -0.0328]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.16.attention.self.query.bias',\n",
       "              tensor([-0.0090, -0.0675,  0.0129,  ..., -0.0052,  0.0856,  0.0127],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.16.attention.self.key.weight',\n",
       "              tensor([[-0.0549, -0.0115, -0.0310,  ...,  0.0776, -0.0133, -0.0555],\n",
       "                      [ 0.0520, -0.0135, -0.0301,  ...,  0.0747, -0.0465, -0.0283],\n",
       "                      [-0.0175,  0.0691,  0.0812,  ..., -0.0364, -0.0604,  0.0315],\n",
       "                      ...,\n",
       "                      [ 0.0493,  0.0355,  0.0024,  ..., -0.0698, -0.0159, -0.0027],\n",
       "                      [ 0.0018,  0.0830,  0.0184,  ..., -0.0272,  0.0515,  0.0041],\n",
       "                      [ 0.0490, -0.0263,  0.0753,  ..., -0.0916, -0.0372,  0.0445]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.16.attention.self.key.bias',\n",
       "              tensor([-0.0002, -0.0004,  0.0004,  ..., -0.0002, -0.0004,  0.0001],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.16.attention.self.value.weight',\n",
       "              tensor([[ 0.0402, -0.0019,  0.0107,  ...,  0.0371, -0.0579,  0.0565],\n",
       "                      [ 0.0256,  0.0590, -0.0328,  ...,  0.0014,  0.0237,  0.0849],\n",
       "                      [ 0.0106,  0.0055, -0.0078,  ..., -0.0432, -0.0562,  0.0284],\n",
       "                      ...,\n",
       "                      [-0.0578, -0.1274,  0.0225,  ..., -0.0893, -0.0107,  0.0547],\n",
       "                      [-0.0025, -0.0322, -0.0334,  ..., -0.0223,  0.0054,  0.1260],\n",
       "                      [ 0.0401,  0.1230, -0.0010,  ..., -0.0211,  0.0103, -0.0254]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.16.attention.self.value.bias',\n",
       "              tensor([-0.0094,  0.0054,  0.0030,  ..., -0.0103, -0.0152, -0.0091],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.16.attention.output.dense.weight',\n",
       "              tensor([[ 0.0401, -0.0426, -0.0121,  ..., -0.0008, -0.0207,  0.0090],\n",
       "                      [ 0.0032,  0.0201,  0.0106,  ...,  0.0354, -0.0656, -0.0212],\n",
       "                      [ 0.0537, -0.0718,  0.0200,  ..., -0.0151, -0.0269,  0.0380],\n",
       "                      ...,\n",
       "                      [ 0.0194,  0.0083, -0.0578,  ...,  0.0841,  0.0392,  0.0029],\n",
       "                      [-0.0482, -0.0360, -0.0249,  ...,  0.0191, -0.0723,  0.0361],\n",
       "                      [ 0.0031, -0.0149, -0.0031,  ..., -0.0693, -0.0658, -0.0380]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.16.attention.output.dense.bias',\n",
       "              tensor([-0.0022, -0.0225,  0.0808,  ..., -0.0592,  0.0308, -0.0680],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.16.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9977, 0.9945, 0.9986,  ..., 0.9932, 0.9969, 0.9982], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.16.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.0785, -0.0414, -0.2097,  ..., -0.0618, -0.0683, -0.0664],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.16.intermediate.dense.weight',\n",
       "              tensor([[ 0.0746, -0.0217,  0.0455,  ...,  0.0472,  0.0110, -0.0304],\n",
       "                      [ 0.0129,  0.0432,  0.0237,  ...,  0.0627, -0.0745, -0.0008],\n",
       "                      [ 0.0124,  0.0171, -0.0133,  ...,  0.1303, -0.0051, -0.0166],\n",
       "                      ...,\n",
       "                      [-0.0783, -0.0630,  0.0141,  ...,  0.0246,  0.0261, -0.0214],\n",
       "                      [-0.0371, -0.0232,  0.0402,  ...,  0.0068, -0.0493, -0.0476],\n",
       "                      [-0.0146, -0.0863,  0.0382,  ...,  0.0241, -0.0492,  0.0310]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.16.intermediate.dense.bias',\n",
       "              tensor([-0.0784, -0.0589, -0.0988,  ..., -0.0642, -0.0775, -0.0862],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.16.output.dense.weight',\n",
       "              tensor([[ 0.0125,  0.0352,  0.0682,  ..., -0.0133, -0.0018,  0.0059],\n",
       "                      [-0.0152, -0.0019,  0.0128,  ..., -0.0334, -0.0683, -0.0234],\n",
       "                      [ 0.0067, -0.0022, -0.0163,  ...,  0.0018,  0.0004,  0.0070],\n",
       "                      ...,\n",
       "                      [-0.0156,  0.0419,  0.0055,  ...,  0.0060, -0.0326, -0.0576],\n",
       "                      [-0.0546, -0.0406,  0.0455,  ..., -0.0061, -0.0310,  0.0173],\n",
       "                      [-0.0046,  0.0193, -0.0110,  ..., -0.0394,  0.0101,  0.0364]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.16.output.dense.bias',\n",
       "              tensor([-0.0816,  0.0123, -0.2006,  ..., -0.0394, -0.0640, -0.1035],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.16.output.LayerNorm.weight',\n",
       "              tensor([0.9805, 0.9965, 0.9975,  ..., 0.9756, 0.9913, 0.9874], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.16.output.LayerNorm.bias',\n",
       "              tensor([-0.0194, -0.0471,  0.1807,  ..., -0.0244, -0.0307, -0.0294],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.17.attention.self.query.weight',\n",
       "              tensor([[-0.0059, -0.0175,  0.0622,  ...,  0.0437, -0.0281,  0.0619],\n",
       "                      [ 0.0308,  0.0173, -0.0222,  ...,  0.0891, -0.0317,  0.0482],\n",
       "                      [ 0.1371,  0.0720,  0.0295,  ..., -0.0814, -0.0424, -0.0062],\n",
       "                      ...,\n",
       "                      [-0.0277, -0.0425,  0.0739,  ..., -0.1263,  0.0552, -0.0763],\n",
       "                      [ 0.0474, -0.0099,  0.0442,  ...,  0.0012, -0.0467,  0.0321],\n",
       "                      [ 0.0127,  0.0891, -0.0297,  ...,  0.0012,  0.0176, -0.0198]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.17.attention.self.query.bias',\n",
       "              tensor([-0.1753,  0.0583,  0.0230,  ..., -0.0484,  0.0412,  0.0124],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.17.attention.self.key.weight',\n",
       "              tensor([[ 0.0272, -0.0098,  0.0549,  ..., -0.0642,  0.0378,  0.0313],\n",
       "                      [ 0.0472,  0.0105,  0.0325,  ...,  0.0894, -0.0343,  0.0201],\n",
       "                      [ 0.0125,  0.0306, -0.0354,  ..., -0.0664,  0.0821,  0.0042],\n",
       "                      ...,\n",
       "                      [ 0.0195,  0.0560,  0.0246,  ...,  0.0182,  0.0391, -0.0757],\n",
       "                      [ 0.0324,  0.0487,  0.0486,  ...,  0.0555,  0.0231,  0.0185],\n",
       "                      [-0.0881, -0.0012, -0.0290,  ...,  0.0581,  0.0087,  0.0656]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.17.attention.self.key.bias',\n",
       "              tensor([ 2.4357e-03, -1.9340e-05,  8.2812e-05,  ..., -9.4199e-06,\n",
       "                       3.9316e-04,  2.2320e-04], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.17.attention.self.value.weight',\n",
       "              tensor([[-0.0168,  0.0040, -0.0070,  ...,  0.0123,  0.0022,  0.0050],\n",
       "                      [-0.0183,  0.0201, -0.0101,  ...,  0.0223,  0.0118,  0.0255],\n",
       "                      [ 0.0074,  0.0112, -0.0096,  ...,  0.0174, -0.0016, -0.0740],\n",
       "                      ...,\n",
       "                      [-0.0251,  0.0310,  0.0057,  ..., -0.0274, -0.0804, -0.1123],\n",
       "                      [ 0.0160, -0.0989, -0.0300,  ...,  0.0028, -0.0297,  0.0954],\n",
       "                      [ 0.0591, -0.0673,  0.0101,  ..., -0.1133,  0.0468, -0.0467]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.17.attention.self.value.bias',\n",
       "              tensor([ 0.0079, -0.0015, -0.0010,  ...,  0.0012,  0.0090,  0.0051],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.17.attention.output.dense.weight',\n",
       "              tensor([[ 0.0001, -0.0224, -0.0162,  ..., -0.0210, -0.0318,  0.0524],\n",
       "                      [ 0.0259,  0.0084,  0.0125,  ...,  0.0758, -0.0500,  0.0667],\n",
       "                      [ 0.0009,  0.0085, -0.0030,  ...,  0.0149, -0.0295, -0.0059],\n",
       "                      ...,\n",
       "                      [ 0.0318,  0.0098, -0.0394,  ...,  0.0292,  0.0297,  0.0220],\n",
       "                      [-0.0284,  0.0254, -0.0095,  ..., -0.0473,  0.0638, -0.0307],\n",
       "                      [ 0.0260, -0.0276, -0.0557,  ..., -0.0025, -0.0308,  0.0152]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.17.attention.output.dense.bias',\n",
       "              tensor([-0.0234,  0.0375,  0.0295,  ..., -0.0088, -0.0498, -0.0184],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.17.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9903, 0.9981, 0.9986,  ..., 0.9852, 0.9885, 0.9865], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.17.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.0950, -0.0614, -0.2155,  ..., -0.0824, -0.0679, -0.0850],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.17.intermediate.dense.weight',\n",
       "              tensor([[ 0.0056, -0.0428,  0.0231,  ..., -0.0517, -0.0381, -0.0282],\n",
       "                      [ 0.0824, -0.0310,  0.0201,  ...,  0.0233, -0.0604, -0.0038],\n",
       "                      [-0.0048,  0.0129,  0.0115,  ...,  0.0317,  0.0271,  0.0142],\n",
       "                      ...,\n",
       "                      [ 0.0736, -0.0577, -0.0373,  ..., -0.0065,  0.0344,  0.0078],\n",
       "                      [-0.0062,  0.0937,  0.0127,  ..., -0.0513, -0.0673,  0.0136],\n",
       "                      [-0.0542, -0.0242, -0.0050,  ..., -0.0253, -0.0026,  0.0256]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.17.intermediate.dense.bias',\n",
       "              tensor([-0.0443, -0.0903, -0.0246,  ...,  0.0193, -0.1121, -0.0450],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.17.output.dense.weight',\n",
       "              tensor([[ 0.0275,  0.0672, -0.0155,  ...,  0.0049, -0.0236, -0.0566],\n",
       "                      [ 0.0071, -0.0059,  0.0216,  ...,  0.0035,  0.0031, -0.0068],\n",
       "                      [-0.0173, -0.0251, -0.0005,  ...,  0.0136,  0.0318, -0.0158],\n",
       "                      ...,\n",
       "                      [ 0.0088,  0.0985, -0.0154,  ...,  0.0209, -0.0335,  0.0018],\n",
       "                      [ 0.0117,  0.0120, -0.0232,  ...,  0.0182,  0.0373, -0.0013],\n",
       "                      [-0.0269, -0.0364, -0.0153,  ...,  0.0102, -0.0190,  0.0144]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.17.output.dense.bias',\n",
       "              tensor([-0.0693,  0.0154, -0.1523,  ..., -0.0159, -0.0878, -0.0514],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.17.output.LayerNorm.weight',\n",
       "              tensor([0.9882, 0.9918, 0.9971,  ..., 0.9848, 0.9878, 0.9863], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.17.output.LayerNorm.bias',\n",
       "              tensor([-0.0038, -0.0266,  0.1263,  ..., -0.0133, -0.0372, -0.0074],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.18.attention.self.query.weight',\n",
       "              tensor([[ 3.6751e-02, -3.3289e-05,  1.3821e-01,  ...,  2.5397e-02,\n",
       "                        6.5598e-02, -2.4664e-02],\n",
       "                      [ 3.3232e-02,  1.9245e-02,  1.2652e-02,  ..., -1.4206e-01,\n",
       "                       -4.8007e-02, -3.9465e-02],\n",
       "                      [-5.0668e-02,  5.6206e-02,  1.8897e-01,  ...,  4.4060e-02,\n",
       "                       -2.4586e-02, -2.6627e-02],\n",
       "                      ...,\n",
       "                      [-5.1486e-02, -2.8011e-03, -2.8190e-02,  ...,  2.0182e-02,\n",
       "                       -1.5861e-02, -3.2911e-02],\n",
       "                      [-5.7257e-02,  4.2928e-02, -1.1736e-02,  ...,  1.1981e-02,\n",
       "                        5.1345e-02,  1.1053e-01],\n",
       "                      [-1.7415e-02,  4.0345e-02,  1.4265e-01,  ..., -3.0697e-02,\n",
       "                        1.2528e-02, -5.4152e-02]], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.18.attention.self.query.bias',\n",
       "              tensor([-0.2755, -0.0112, -0.1426,  ...,  0.0097, -0.0073,  0.0218],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.18.attention.self.key.weight',\n",
       "              tensor([[-0.0606, -0.0173,  0.0531,  ...,  0.0107, -0.0087,  0.0467],\n",
       "                      [-0.0250,  0.0826,  0.1168,  ..., -0.0194, -0.0075, -0.0566],\n",
       "                      [ 0.0664,  0.0492,  0.2589,  ..., -0.0252,  0.0011,  0.0091],\n",
       "                      ...,\n",
       "                      [-0.0554, -0.0358, -0.0143,  ..., -0.0323,  0.0620,  0.0246],\n",
       "                      [ 0.0641, -0.0268, -0.0223,  ..., -0.0104, -0.0416, -0.0051],\n",
       "                      [-0.0155, -0.0172,  0.1423,  ...,  0.0383, -0.0085,  0.0757]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.18.attention.self.key.bias',\n",
       "              tensor([-7.0144e-04,  1.4384e-04, -1.4243e-04,  ...,  4.6404e-06,\n",
       "                       1.2977e-05,  2.5628e-04], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.18.attention.self.value.weight',\n",
       "              tensor([[ 0.0269,  0.0191, -0.0016,  ...,  0.0166,  0.0020,  0.0064],\n",
       "                      [-0.0377,  0.0597,  0.0153,  ...,  0.0075,  0.0042,  0.0263],\n",
       "                      [ 0.0105, -0.0388, -0.0325,  ...,  0.1059, -0.0258,  0.0040],\n",
       "                      ...,\n",
       "                      [ 0.0076, -0.0008,  0.0203,  ...,  0.0249, -0.0216, -0.0367],\n",
       "                      [ 0.0381, -0.0024, -0.0427,  ...,  0.0069,  0.0326,  0.0053],\n",
       "                      [ 0.0254,  0.0679, -0.0172,  ..., -0.0476,  0.0170,  0.0042]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.18.attention.self.value.bias',\n",
       "              tensor([-0.0073,  0.0054, -0.0178,  ..., -0.0077,  0.0028, -0.0113],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.18.attention.output.dense.weight',\n",
       "              tensor([[-0.0349, -0.0207, -0.0622,  ..., -0.0273, -0.0066, -0.0412],\n",
       "                      [-0.0215,  0.0689, -0.0525,  ...,  0.0043, -0.0256,  0.0205],\n",
       "                      [-0.0428,  0.0151, -0.0095,  ...,  0.0121, -0.0245, -0.0008],\n",
       "                      ...,\n",
       "                      [ 0.0320,  0.0092,  0.0669,  ..., -0.0082,  0.0231,  0.0183],\n",
       "                      [-0.0066,  0.0198,  0.0187,  ..., -0.0183, -0.0009,  0.0152],\n",
       "                      [-0.0059,  0.0056, -0.0078,  ..., -0.0034,  0.0282,  0.0216]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.18.attention.output.dense.bias',\n",
       "              tensor([-0.0148,  0.0795,  0.0279,  ...,  0.0720,  0.0369,  0.0007],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.18.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9885, 0.9853, 0.9983,  ..., 0.9906, 0.9804, 0.9896], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.18.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.0946, -0.0219, -0.2505,  ..., -0.0717, -0.0624, -0.0678],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.18.intermediate.dense.weight',\n",
       "              tensor([[ 0.0497, -0.0259,  0.0311,  ...,  0.0203,  0.0042, -0.0250],\n",
       "                      [ 0.0612, -0.0435,  0.0091,  ..., -0.0145, -0.0016, -0.0470],\n",
       "                      [ 0.0256, -0.0304, -0.0301,  ..., -0.0364,  0.0078, -0.0315],\n",
       "                      ...,\n",
       "                      [ 0.0179,  0.0679,  0.0402,  ...,  0.0306,  0.0313,  0.0073],\n",
       "                      [-0.0307, -0.0509,  0.0054,  ...,  0.0419, -0.0238,  0.0076],\n",
       "                      [ 0.0402,  0.0605, -0.0644,  ...,  0.0037,  0.0113, -0.0084]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.18.intermediate.dense.bias',\n",
       "              tensor([-0.0716, -0.1016, -0.0044,  ..., -0.0477, -0.0969, -0.0804],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.18.output.dense.weight',\n",
       "              tensor([[-3.9529e-02,  3.2429e-05,  1.7672e-02,  ...,  2.1361e-02,\n",
       "                       -2.9729e-02, -3.2711e-02],\n",
       "                      [-3.6445e-02, -3.8090e-02, -1.8349e-02,  ...,  4.3578e-02,\n",
       "                       -2.9701e-02, -5.8972e-03],\n",
       "                      [ 1.6083e-02, -3.6531e-03, -5.4671e-03,  ..., -1.1584e-02,\n",
       "                       -6.1758e-03, -1.6010e-02],\n",
       "                      ...,\n",
       "                      [ 1.9981e-02,  1.7714e-02,  4.1006e-02,  ..., -3.1077e-03,\n",
       "                       -1.4521e-03, -8.1402e-03],\n",
       "                      [-9.2505e-03, -1.3867e-02,  4.3788e-04,  ..., -4.6812e-03,\n",
       "                        5.0823e-02,  1.2591e-02],\n",
       "                      [-2.7757e-02, -1.3849e-02,  4.4082e-02,  ...,  3.1692e-03,\n",
       "                       -5.6854e-02, -2.2744e-02]], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.18.output.dense.bias',\n",
       "              tensor([-0.0766,  0.0012, -0.1594,  ...,  0.0426, -0.0416, -0.0424],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.18.output.LayerNorm.weight',\n",
       "              tensor([0.9839, 0.9973, 0.9984,  ..., 0.9809, 0.9888, 0.9825], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.18.output.LayerNorm.bias',\n",
       "              tensor([-0.0068, -0.0484,  0.1254,  ..., -0.0183, -0.0274, -0.0289],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.19.attention.self.query.weight',\n",
       "              tensor([[-0.0485, -0.0313, -0.0166,  ..., -0.0709,  0.0614, -0.1430],\n",
       "                      [ 0.0287,  0.0149, -0.1316,  ...,  0.0347,  0.0423,  0.0795],\n",
       "                      [-0.0311, -0.0197,  0.0465,  ..., -0.0590, -0.0814,  0.0176],\n",
       "                      ...,\n",
       "                      [-0.0050, -0.0108, -0.1974,  ...,  0.0872, -0.0064, -0.0345],\n",
       "                      [-0.1271,  0.0599,  0.0545,  ..., -0.0125,  0.0566, -0.0852],\n",
       "                      [-0.0272,  0.0588,  0.0604,  ...,  0.0970,  0.0690, -0.0209]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.19.attention.self.query.bias',\n",
       "              tensor([-0.0139, -0.0616, -0.0124,  ..., -0.0221,  0.0376, -0.0224],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.19.attention.self.key.weight',\n",
       "              tensor([[-0.0189,  0.0068, -0.0008,  ...,  0.0456, -0.0926, -0.0129],\n",
       "                      [ 0.0638,  0.0658, -0.0974,  ...,  0.0578, -0.0419,  0.0628],\n",
       "                      [-0.0588, -0.0167,  0.0368,  ...,  0.0193,  0.1104, -0.0434],\n",
       "                      ...,\n",
       "                      [-0.0803, -0.0242, -0.2640,  ...,  0.0136,  0.0649,  0.0287],\n",
       "                      [-0.0139,  0.0079,  0.1634,  ...,  0.0251,  0.0857,  0.0182],\n",
       "                      [ 0.0186, -0.0762,  0.1227,  ..., -0.0472, -0.0180,  0.0720]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.19.attention.self.key.bias',\n",
       "              tensor([-8.2632e-05, -1.3315e-04,  1.7966e-04,  ..., -5.9897e-05,\n",
       "                       1.4607e-03, -1.3739e-05], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.19.attention.self.value.weight',\n",
       "              tensor([[ 0.0266,  0.0119,  0.0285,  ...,  0.0282,  0.0206,  0.0257],\n",
       "                      [-0.0065,  0.0101, -0.0031,  ...,  0.0341,  0.0252, -0.0187],\n",
       "                      [-0.0347, -0.0132,  0.0149,  ...,  0.0355, -0.0211, -0.0324],\n",
       "                      ...,\n",
       "                      [ 0.0186,  0.0173,  0.0135,  ..., -0.0196, -0.0152, -0.0179],\n",
       "                      [ 0.0231,  0.0260, -0.0368,  ...,  0.0291, -0.0189, -0.0462],\n",
       "                      [-0.0176,  0.0598, -0.0252,  ...,  0.0375,  0.0248, -0.0033]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.19.attention.self.value.bias',\n",
       "              tensor([ 0.0033,  0.0725, -0.0001,  ..., -0.0049,  0.0002, -0.0173],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.19.attention.output.dense.weight',\n",
       "              tensor([[ 0.0013,  0.0280, -0.0179,  ...,  0.0274,  0.0127, -0.0046],\n",
       "                      [ 0.0063, -0.0304, -0.0474,  ..., -0.0030,  0.0365,  0.0051],\n",
       "                      [ 0.0014, -0.0487, -0.0238,  ...,  0.0409, -0.0234,  0.0151],\n",
       "                      ...,\n",
       "                      [-0.0631, -0.0612, -0.0297,  ...,  0.0025, -0.0005,  0.0137],\n",
       "                      [-0.0164,  0.0463,  0.0093,  ...,  0.0112,  0.0181, -0.0089],\n",
       "                      [-0.0191, -0.0373,  0.0031,  ..., -0.0118, -0.0235, -0.0472]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.19.attention.output.dense.bias',\n",
       "              tensor([ 0.0043,  0.0610,  0.0789,  ..., -0.0016,  0.0254,  0.0067],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.19.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9800, 0.9890, 0.9985,  ..., 0.9726, 0.9882, 0.9948], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.19.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.0797, -0.0365, -0.2133,  ..., -0.0627, -0.0840, -0.0623],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.19.intermediate.dense.weight',\n",
       "              tensor([[ 0.0427, -0.0420,  0.0148,  ...,  0.0872,  0.0761,  0.1549],\n",
       "                      [ 0.0501, -0.0103,  0.0539,  ...,  0.0198,  0.0287,  0.0301],\n",
       "                      [ 0.0196,  0.0075,  0.0389,  ..., -0.0204, -0.0055,  0.0091],\n",
       "                      ...,\n",
       "                      [ 0.0753, -0.0251,  0.0214,  ..., -0.0025, -0.0522,  0.0382],\n",
       "                      [ 0.0289, -0.0084, -0.0386,  ..., -0.0151,  0.0328, -0.0840],\n",
       "                      [ 0.0146,  0.0445,  0.0356,  ..., -0.0370, -0.0110,  0.0347]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.19.intermediate.dense.bias',\n",
       "              tensor([-0.1024,  0.0125, -0.0424,  ..., -0.1168,  0.0036, -0.0176],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.19.output.dense.weight',\n",
       "              tensor([[ 0.0118, -0.0163, -0.0197,  ..., -0.0422, -0.0091,  0.0072],\n",
       "                      [-0.0581, -0.0388,  0.0081,  ...,  0.0529, -0.0177,  0.0203],\n",
       "                      [ 0.0136, -0.0144, -0.0004,  ..., -0.0156,  0.0088, -0.0013],\n",
       "                      ...,\n",
       "                      [ 0.0103, -0.0086,  0.0301,  ..., -0.0457,  0.0122,  0.0234],\n",
       "                      [ 0.0284, -0.0090, -0.0316,  ..., -0.0178, -0.0080, -0.0094],\n",
       "                      [ 0.0078,  0.0138, -0.0028,  ...,  0.0416,  0.0414,  0.0316]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.19.output.dense.bias',\n",
       "              tensor([-0.0388,  0.0273, -0.0501,  ...,  0.1111, -0.0572,  0.0031],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.19.output.LayerNorm.weight',\n",
       "              tensor([0.9639, 0.9944, 0.9965,  ..., 0.9763, 0.9912, 0.9857], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.19.output.LayerNorm.bias',\n",
       "              tensor([-0.0106, -0.0327,  0.0787,  ..., -0.0203, -0.0165, -0.0065],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.20.attention.self.query.weight',\n",
       "              tensor([[-0.0147,  0.0174, -0.0110,  ...,  0.0012, -0.0577,  0.0194],\n",
       "                      [-0.0724, -0.0724,  0.0294,  ..., -0.0305, -0.0394, -0.0035],\n",
       "                      [-0.0188, -0.0296, -0.0005,  ...,  0.0300,  0.0462, -0.0053],\n",
       "                      ...,\n",
       "                      [ 0.0955, -0.0104, -0.0276,  ...,  0.0713, -0.0226,  0.0173],\n",
       "                      [-0.0014, -0.0016,  0.1986,  ..., -0.0232,  0.0237,  0.0017],\n",
       "                      [-0.0252,  0.0132, -0.1223,  ..., -0.0457, -0.0356, -0.0504]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.20.attention.self.query.bias',\n",
       "              tensor([-0.0272,  0.0251,  0.0127,  ...,  0.0903, -0.0333,  0.0521],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.20.attention.self.key.weight',\n",
       "              tensor([[ 0.0151, -0.0673, -0.0259,  ..., -0.1064, -0.0147, -0.0858],\n",
       "                      [-0.0145, -0.0050,  0.0354,  ..., -0.0162, -0.0012, -0.0034],\n",
       "                      [ 0.0272,  0.0473, -0.0871,  ...,  0.1048,  0.0214,  0.0366],\n",
       "                      ...,\n",
       "                      [-0.0373, -0.0532, -0.1084,  ..., -0.0246, -0.0156,  0.0287],\n",
       "                      [-0.0327,  0.0546,  0.2247,  ...,  0.0259, -0.0634,  0.0284],\n",
       "                      [-0.0195,  0.0242, -0.0454,  ..., -0.0933, -0.0159,  0.0171]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.20.attention.self.key.bias',\n",
       "              tensor([ 3.1508e-04,  1.9668e-04,  3.1824e-04,  ...,  1.7927e-04,\n",
       "                      -2.9245e-05,  1.0939e-04], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.20.attention.self.value.weight',\n",
       "              tensor([[-0.0486, -0.0088,  0.0261,  ..., -0.0251, -0.0009,  0.0608],\n",
       "                      [-0.0186,  0.0013, -0.0165,  ..., -0.0243,  0.1045,  0.0206],\n",
       "                      [ 0.0051,  0.0316, -0.0122,  ..., -0.0674, -0.0781,  0.0165],\n",
       "                      ...,\n",
       "                      [-0.0650,  0.0293,  0.0203,  ...,  0.0661,  0.0087,  0.0175],\n",
       "                      [ 0.0918,  0.0099,  0.0630,  ..., -0.0055,  0.0164, -0.0505],\n",
       "                      [ 0.0217,  0.0426, -0.0116,  ..., -0.0255, -0.0091, -0.0743]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.20.attention.self.value.bias',\n",
       "              tensor([-0.0003,  0.0056,  0.0192,  ...,  0.0027,  0.0030, -0.0059],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.20.attention.output.dense.weight',\n",
       "              tensor([[ 0.0096, -0.0653, -0.0505,  ...,  0.0568, -0.0547, -0.0164],\n",
       "                      [ 0.0132,  0.0436,  0.0166,  ..., -0.0144, -0.0153, -0.0552],\n",
       "                      [ 0.0262,  0.0096,  0.0100,  ..., -0.0174, -0.0530, -0.0049],\n",
       "                      ...,\n",
       "                      [ 0.0437, -0.0266, -0.0440,  ..., -0.0725, -0.0224,  0.0398],\n",
       "                      [ 0.0205,  0.0002,  0.0085,  ..., -0.0204, -0.0123,  0.0301],\n",
       "                      [ 0.0086,  0.0065, -0.0167,  ...,  0.0238,  0.0123,  0.0371]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.20.attention.output.dense.bias',\n",
       "              tensor([-0.0102,  0.0781,  0.0602,  ...,  0.0719,  0.0868,  0.0220],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.20.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9723, 0.9950, 0.9993,  ..., 0.9795, 0.9858, 0.9953], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.20.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.0296, -0.0330, -0.1557,  ..., -0.0448, -0.0895, -0.0459],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.20.intermediate.dense.weight',\n",
       "              tensor([[ 0.0062, -0.0099,  0.0590,  ...,  0.0059,  0.0104,  0.0130],\n",
       "                      [ 0.0207, -0.0087,  0.0044,  ...,  0.0079, -0.0651,  0.0704],\n",
       "                      [-0.0160, -0.0145, -0.0554,  ..., -0.0223, -0.0313, -0.0315],\n",
       "                      ...,\n",
       "                      [ 0.0009, -0.0304,  0.0034,  ...,  0.0399,  0.0904,  0.0201],\n",
       "                      [ 0.0592,  0.0491,  0.0600,  ..., -0.0512, -0.0089, -0.0289],\n",
       "                      [-0.0175, -0.0421,  0.0497,  ..., -0.0107,  0.0012, -0.0069]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.20.intermediate.dense.bias',\n",
       "              tensor([-0.0226, -0.0381, -0.0478,  ..., -0.0260, -0.0179, -0.0257],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.20.output.dense.weight',\n",
       "              tensor([[-0.0169,  0.0672,  0.0131,  ...,  0.0582, -0.0088, -0.0173],\n",
       "                      [ 0.0103,  0.0308,  0.0499,  ...,  0.0042,  0.0151, -0.0400],\n",
       "                      [-0.0119, -0.0021, -0.0031,  ..., -0.0085, -0.0095, -0.0122],\n",
       "                      ...,\n",
       "                      [ 0.0138,  0.0070,  0.0452,  ..., -0.0166,  0.0146, -0.0031],\n",
       "                      [-0.0199, -0.0457,  0.0213,  ...,  0.0315,  0.0596,  0.0219],\n",
       "                      [-0.0337,  0.0024,  0.0384,  ...,  0.0212,  0.0382, -0.0062]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.20.output.dense.bias',\n",
       "              tensor([-0.0564,  0.0041, -0.0086,  ...,  0.0620, -0.0943,  0.0493],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.20.output.LayerNorm.weight',\n",
       "              tensor([0.9663, 0.9921, 0.9977,  ..., 0.9803, 0.9841, 0.9801], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.20.output.LayerNorm.bias',\n",
       "              tensor([-0.0310, -0.0306,  0.0812,  ..., -0.0303, -0.0235, -0.0134],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.21.attention.self.query.weight',\n",
       "              tensor([[ 0.0294, -0.0809, -0.2133,  ..., -0.0181, -0.0100, -0.0440],\n",
       "                      [-0.0245, -0.0810,  0.0545,  ..., -0.0246,  0.0212,  0.0030],\n",
       "                      [ 0.0550,  0.0398,  0.0605,  ...,  0.0321, -0.0400, -0.0779],\n",
       "                      ...,\n",
       "                      [ 0.0016,  0.0144, -0.1501,  ...,  0.0744,  0.0648,  0.0554],\n",
       "                      [-0.0580,  0.0106,  0.0361,  ...,  0.0062,  0.0064,  0.0055],\n",
       "                      [-0.0480, -0.0429,  0.0472,  ...,  0.0163, -0.0200,  0.0679]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.21.attention.self.query.bias',\n",
       "              tensor([ 0.1657, -0.0315, -0.0174,  ..., -0.0690,  0.0409, -0.0460],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.21.attention.self.key.weight',\n",
       "              tensor([[ 0.0106,  0.0486, -0.1590,  ...,  0.0698,  0.0304,  0.0119],\n",
       "                      [ 0.0435,  0.0443,  0.0703,  ...,  0.0068,  0.1318, -0.0435],\n",
       "                      [-0.0005,  0.0016, -0.0024,  ..., -0.0806,  0.0139, -0.0116],\n",
       "                      ...,\n",
       "                      [-0.0567, -0.0455, -0.1240,  ...,  0.0280, -0.0530,  0.0310],\n",
       "                      [ 0.0887, -0.0140,  0.0698,  ..., -0.0936,  0.0291, -0.0110],\n",
       "                      [-0.0311,  0.0130,  0.0787,  ..., -0.0392,  0.0150, -0.0053]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.21.attention.self.key.bias',\n",
       "              tensor([-5.0854e-02, -5.5043e-05,  7.1470e-04,  ...,  3.9272e-03,\n",
       "                      -3.3241e-04,  1.0085e-02], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.21.attention.self.value.weight',\n",
       "              tensor([[ 0.0289, -0.0319, -0.0536,  ..., -0.0363,  0.0161, -0.0274],\n",
       "                      [ 0.0426, -0.0498, -0.0003,  ...,  0.0232, -0.0507,  0.0682],\n",
       "                      [ 0.0166, -0.0406, -0.0112,  ...,  0.0032, -0.0379,  0.0264],\n",
       "                      ...,\n",
       "                      [ 0.0200, -0.0725, -0.0099,  ..., -0.0241, -0.0741, -0.0296],\n",
       "                      [ 0.0280, -0.0294, -0.0437,  ...,  0.0672, -0.0155,  0.0250],\n",
       "                      [-0.0202, -0.0031,  0.0946,  ..., -0.0343, -0.0219,  0.0221]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.21.attention.self.value.bias',\n",
       "              tensor([ 0.0075, -0.0017, -0.0012,  ..., -0.0112, -0.0260, -0.0125],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.21.attention.output.dense.weight',\n",
       "              tensor([[-0.0024,  0.0444, -0.0341,  ..., -0.0173,  0.0066,  0.0372],\n",
       "                      [ 0.0342,  0.0149, -0.0343,  ...,  0.0047,  0.0279, -0.0189],\n",
       "                      [ 0.0103, -0.0402, -0.0076,  ..., -0.0139,  0.0143, -0.0396],\n",
       "                      ...,\n",
       "                      [ 0.0197,  0.0446, -0.0042,  ...,  0.0199, -0.0221,  0.0489],\n",
       "                      [-0.0538,  0.0704, -0.0665,  ...,  0.0016, -0.0416, -0.0162],\n",
       "                      [ 0.0158,  0.0136, -0.0549,  ...,  0.0509, -0.0234, -0.0266]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.21.attention.output.dense.bias',\n",
       "              tensor([-0.0267,  0.0898,  0.0438,  ...,  0.0352,  0.1779,  0.0309],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.21.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9710, 0.9920, 1.0003,  ..., 0.9794, 0.9911, 0.9923], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.21.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.0457, -0.0584, -0.1334,  ..., -0.0504, -0.1017, -0.0347],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.21.intermediate.dense.weight',\n",
       "              tensor([[-0.0169, -0.0317,  0.0370,  ...,  0.0542,  0.0235, -0.0262],\n",
       "                      [ 0.0016,  0.0004, -0.0736,  ...,  0.0261,  0.0011,  0.0592],\n",
       "                      [ 0.0018,  0.0369, -0.0441,  ..., -0.0049,  0.0096,  0.0010],\n",
       "                      ...,\n",
       "                      [-0.0091, -0.0185,  0.0261,  ..., -0.0239, -0.0733, -0.0231],\n",
       "                      [ 0.0130, -0.0698,  0.0180,  ..., -0.0241,  0.0056, -0.0255],\n",
       "                      [ 0.0037,  0.0034,  0.0191,  ..., -0.0111,  0.0282,  0.0382]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.21.intermediate.dense.bias',\n",
       "              tensor([-0.0255, -0.0450,  0.0188,  ..., -0.0301, -0.0034, -0.0151],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.21.output.dense.weight',\n",
       "              tensor([[-0.0118,  0.0005, -0.0038,  ...,  0.0360, -0.0205, -0.0351],\n",
       "                      [ 0.0025,  0.0127, -0.0347,  ...,  0.0152, -0.0354,  0.0513],\n",
       "                      [-0.0182,  0.0002,  0.0019,  ...,  0.0121,  0.0048,  0.0123],\n",
       "                      ...,\n",
       "                      [-0.0311,  0.0123,  0.0245,  ..., -0.0185, -0.0135, -0.0044],\n",
       "                      [-0.0340,  0.0021, -0.0369,  ..., -0.0359, -0.1036,  0.0085],\n",
       "                      [-0.0080, -0.0055,  0.0025,  ..., -0.0032, -0.0314,  0.0014]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.21.output.dense.bias',\n",
       "              tensor([-0.0102,  0.0067, -0.0726,  ...,  0.0921, -0.1209,  0.0154],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.21.output.LayerNorm.weight',\n",
       "              tensor([0.9694, 0.9909, 0.9962,  ..., 0.9832, 0.9863, 0.9964], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.21.output.LayerNorm.bias',\n",
       "              tensor([-0.0435, -0.0139,  0.0397,  ..., -0.0393, -0.0567, -0.0170],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.22.attention.self.query.weight',\n",
       "              tensor([[ 0.0033,  0.0378,  0.0876,  ...,  0.0187,  0.0169,  0.0582],\n",
       "                      [ 0.0182, -0.0408,  0.0043,  ..., -0.1017,  0.0531,  0.0099],\n",
       "                      [ 0.0975, -0.0285,  0.1844,  ...,  0.0121,  0.0569, -0.0078],\n",
       "                      ...,\n",
       "                      [-0.0079, -0.0129, -0.0795,  ..., -0.0675, -0.0028,  0.0724],\n",
       "                      [-0.0413,  0.0721, -0.0110,  ...,  0.0608, -0.0370, -0.0324],\n",
       "                      [ 0.0365,  0.0596,  0.0999,  ...,  0.0263, -0.0223, -0.0810]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.22.attention.self.query.bias',\n",
       "              tensor([-0.0049,  0.0072,  0.1515,  ...,  0.0021,  0.0991, -0.0555],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.22.attention.self.key.weight',\n",
       "              tensor([[-0.0665, -0.0530,  0.0720,  ...,  0.0042, -0.0582,  0.0475],\n",
       "                      [ 0.0304, -0.0271,  0.0238,  ...,  0.0317, -0.0107,  0.0133],\n",
       "                      [ 0.0019,  0.0328,  0.0956,  ...,  0.0177, -0.0129,  0.0159],\n",
       "                      ...,\n",
       "                      [ 0.0752,  0.0003, -0.0992,  ..., -0.0611, -0.0546, -0.0923],\n",
       "                      [ 0.0232,  0.0672, -0.0535,  ...,  0.0362,  0.0366, -0.0388],\n",
       "                      [-0.0530,  0.0173, -0.0274,  ..., -0.0099,  0.0197, -0.0084]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.22.attention.self.key.bias',\n",
       "              tensor([-9.2472e-06, -1.5771e-04,  4.3453e-04,  ..., -1.6064e-04,\n",
       "                      -6.7599e-04, -7.0374e-04], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.22.attention.self.value.weight',\n",
       "              tensor([[ 0.0256,  0.0333,  0.0429,  ...,  0.0434, -0.0222,  0.0517],\n",
       "                      [-0.0441, -0.0137, -0.0154,  ...,  0.0525, -0.0724,  0.0560],\n",
       "                      [-0.0191,  0.0347,  0.0061,  ..., -0.0043, -0.0187,  0.0227],\n",
       "                      ...,\n",
       "                      [-0.0414,  0.0006, -0.0150,  ..., -0.0331,  0.0289, -0.0466],\n",
       "                      [ 0.0183,  0.0147,  0.0360,  ...,  0.0060,  0.0050, -0.0354],\n",
       "                      [-0.0229, -0.0195, -0.0385,  ..., -0.0249,  0.0118,  0.0233]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.22.attention.self.value.bias',\n",
       "              tensor([ 0.0077, -0.0129,  0.0142,  ..., -0.0118, -0.0047, -0.0074],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.22.attention.output.dense.weight',\n",
       "              tensor([[ 0.0415,  0.0489, -0.0050,  ..., -0.0355, -0.0328, -0.0120],\n",
       "                      [ 0.0092,  0.0243,  0.0287,  ..., -0.0476,  0.0069,  0.0275],\n",
       "                      [ 0.0179,  0.0051, -0.0263,  ..., -0.0232,  0.0505, -0.0038],\n",
       "                      ...,\n",
       "                      [ 0.0328,  0.0276, -0.0225,  ...,  0.0104, -0.0218, -0.0118],\n",
       "                      [ 0.0428, -0.0164,  0.0173,  ..., -0.0158, -0.0070, -0.0430],\n",
       "                      [ 0.0328,  0.0400,  0.0391,  ..., -0.0347,  0.0057, -0.0029]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.22.attention.output.dense.bias',\n",
       "              tensor([ 0.0767,  0.0950,  0.0674,  ...,  0.0083,  0.1465, -0.0306],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.22.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9539, 0.9882, 0.9968,  ..., 0.9750, 0.9965, 0.9874], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.22.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.0478, -0.0131, -0.1199,  ..., -0.0383, -0.1028,  0.0335],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.22.intermediate.dense.weight',\n",
       "              tensor([[-0.0016, -0.0680, -0.0492,  ..., -0.0091,  0.0079,  0.0769],\n",
       "                      [-0.0169, -0.0196,  0.0643,  ...,  0.0032,  0.0457, -0.0019],\n",
       "                      [-0.0291, -0.0688,  0.0752,  ...,  0.0112, -0.0122, -0.0462],\n",
       "                      ...,\n",
       "                      [-0.0327,  0.0271,  0.0451,  ...,  0.0470,  0.0082,  0.0374],\n",
       "                      [ 0.0629,  0.0207,  0.0444,  ...,  0.0230, -0.0062,  0.0043],\n",
       "                      [ 0.0038, -0.0734, -0.0578,  ..., -0.0045,  0.0220, -0.0506]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.22.intermediate.dense.bias',\n",
       "              tensor([ 0.0177, -0.0076, -0.0130,  ..., -0.0444,  0.0148, -0.0282],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.22.output.dense.weight',\n",
       "              tensor([[-0.0260,  0.0399, -0.0240,  ...,  0.0071, -0.0063, -0.0860],\n",
       "                      [ 0.0119, -0.0277,  0.0234,  ..., -0.0092, -0.0304,  0.0135],\n",
       "                      [-0.0164, -0.0118, -0.0041,  ...,  0.0016, -0.0002,  0.0110],\n",
       "                      ...,\n",
       "                      [-0.0133, -0.0314,  0.0101,  ..., -0.0212, -0.0067,  0.0565],\n",
       "                      [ 0.0158, -0.0375,  0.0406,  ..., -0.0081, -0.0247, -0.0256],\n",
       "                      [-0.0079,  0.0707,  0.0313,  ..., -0.0225,  0.0065, -0.0239]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.22.output.dense.bias',\n",
       "              tensor([ 0.0236,  0.0464, -0.0756,  ...,  0.0239, -0.1325,  0.0456],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.22.output.LayerNorm.weight',\n",
       "              tensor([0.9558, 0.9937, 0.9971,  ..., 0.9825, 0.9913, 0.9834], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.22.output.LayerNorm.bias',\n",
       "              tensor([-0.0229,  0.0381,  0.0502,  ..., -0.0329, -0.0121,  0.0167],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.23.attention.self.query.weight',\n",
       "              tensor([[-0.0343,  0.0237,  0.0925,  ..., -0.0896,  0.0877,  0.0667],\n",
       "                      [-0.0428,  0.0212,  0.1017,  ..., -0.0057, -0.0134, -0.0046],\n",
       "                      [ 0.0349,  0.0420,  0.0307,  ..., -0.0086, -0.0894, -0.0342],\n",
       "                      ...,\n",
       "                      [ 0.1001, -0.0529,  0.1248,  ..., -0.0051, -0.0110,  0.0664],\n",
       "                      [-0.0477,  0.0011, -0.0024,  ..., -0.0515, -0.0170, -0.0157],\n",
       "                      [-0.0128, -0.0463, -0.0592,  ...,  0.0460, -0.0669,  0.0150]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.23.attention.self.query.bias',\n",
       "              tensor([ 0.0779,  0.2723,  0.0302,  ..., -0.2013,  0.1131,  0.0774],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.23.attention.self.key.weight',\n",
       "              tensor([[ 0.0584, -0.0311,  0.2180,  ..., -0.0164,  0.0305,  0.0213],\n",
       "                      [ 0.0737, -0.0645,  0.0659,  ...,  0.0123, -0.0494,  0.0070],\n",
       "                      [-0.1160, -0.0252, -0.0379,  ..., -0.1287,  0.0430, -0.0249],\n",
       "                      ...,\n",
       "                      [ 0.0535,  0.0074,  0.0699,  ..., -0.0457,  0.0010,  0.0545],\n",
       "                      [ 0.0201, -0.0007, -0.0654,  ..., -0.0272,  0.0350,  0.0346],\n",
       "                      [-0.0144, -0.0170, -0.0170,  ...,  0.1073,  0.0039,  0.0636]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.23.attention.self.key.bias',\n",
       "              tensor([ 7.4651e-06, -9.8145e-05,  4.8232e-05,  ...,  6.2495e-02,\n",
       "                      -9.5109e-05, -1.1840e-04], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.23.attention.self.value.weight',\n",
       "              tensor([[-0.0673, -0.0674, -0.0099,  ..., -0.0340,  0.0020,  0.0078],\n",
       "                      [ 0.0229,  0.0074,  0.0389,  ..., -0.0287,  0.0032, -0.0462],\n",
       "                      [-0.0406,  0.0639, -0.0136,  ...,  0.0078, -0.0465, -0.0100],\n",
       "                      ...,\n",
       "                      [ 0.0502,  0.0295, -0.0295,  ..., -0.0130, -0.0232,  0.0162],\n",
       "                      [ 0.0026, -0.0350,  0.0274,  ..., -0.0147, -0.0005,  0.0129],\n",
       "                      [ 0.0114, -0.0210,  0.0245,  ..., -0.0007,  0.0173,  0.0144]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.23.attention.self.value.bias',\n",
       "              tensor([-0.0153,  0.0179,  0.0118,  ...,  0.0076,  0.0071,  0.0132],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.23.attention.output.dense.weight',\n",
       "              tensor([[-0.0207, -0.0079, -0.0011,  ...,  0.0385, -0.0317,  0.0332],\n",
       "                      [-0.0365, -0.0048,  0.0260,  ...,  0.0547, -0.0097, -0.0484],\n",
       "                      [-0.0257,  0.0097,  0.0089,  ..., -0.0102,  0.0159, -0.0319],\n",
       "                      ...,\n",
       "                      [-0.0018, -0.0468, -0.0107,  ..., -0.0216, -0.0017, -0.0087],\n",
       "                      [ 0.0171,  0.0433,  0.0164,  ...,  0.0116,  0.0042,  0.0044],\n",
       "                      [ 0.0381, -0.0133, -0.0239,  ..., -0.0107,  0.0135,  0.0136]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.23.attention.output.dense.bias',\n",
       "              tensor([ 0.0641,  0.0725, -0.0045,  ...,  0.0315,  0.0211,  0.1619],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.23.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9619, 0.9805, 0.9935,  ..., 0.9814, 0.9922, 0.9647], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.23.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1348,  0.0311, -0.1584,  ..., -0.0664, -0.1432, -0.0919],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.23.intermediate.dense.weight',\n",
       "              tensor([[-0.0111, -0.0868, -0.0142,  ..., -0.0097,  0.0167, -0.0259],\n",
       "                      [-0.0144, -0.0238, -0.0115,  ..., -0.0120,  0.0176, -0.0640],\n",
       "                      [ 0.0009, -0.0922, -0.0031,  ...,  0.0325,  0.0341, -0.0215],\n",
       "                      ...,\n",
       "                      [-0.0411,  0.0268,  0.0117,  ..., -0.0028, -0.0404, -0.0078],\n",
       "                      [ 0.0433,  0.0024, -0.0067,  ..., -0.0123,  0.0637,  0.0382],\n",
       "                      [ 0.0346, -0.0150, -0.0294,  ...,  0.0524,  0.0292,  0.0393]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.23.intermediate.dense.bias',\n",
       "              tensor([ 0.0086, -0.0688, -0.1255,  ..., -0.0401, -0.0952, -0.0114],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.23.output.dense.weight',\n",
       "              tensor([[ 0.0228, -0.0394, -0.0190,  ...,  0.0182,  0.0234, -0.0076],\n",
       "                      [ 0.0121,  0.0641, -0.0238,  ..., -0.0137, -0.0393,  0.0269],\n",
       "                      [-0.0031, -0.0097,  0.0092,  ...,  0.0128, -0.0260, -0.0145],\n",
       "                      ...,\n",
       "                      [ 0.0150, -0.0354,  0.0848,  ...,  0.0315, -0.0137,  0.0416],\n",
       "                      [ 0.0081, -0.0174,  0.0471,  ...,  0.0078,  0.0257, -0.0065],\n",
       "                      [-0.0393,  0.0068,  0.0054,  ...,  0.0364,  0.0075, -0.0130]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.23.output.dense.bias',\n",
       "              tensor([-0.0758, -0.0242, -0.0956,  ...,  0.0764, -0.1582,  0.0786],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.23.output.LayerNorm.weight',\n",
       "              tensor([0.9783, 0.9947, 0.9975,  ..., 0.9821, 1.0003, 0.9883], device='cuda:0')),\n",
       "             ('encoder.module.encoder.layer.23.output.LayerNorm.bias',\n",
       "              tensor([-0.0241, -0.0407, -0.0133,  ..., -0.0476,  0.0083, -0.0058],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.pooler.dense.weight',\n",
       "              tensor([[-0.0222, -0.0229, -0.0050,  ...,  0.0107,  0.0221, -0.0344],\n",
       "                      [-0.0213, -0.0027, -0.0135,  ..., -0.0073, -0.0328,  0.0215],\n",
       "                      [ 0.0131,  0.0175,  0.0092,  ..., -0.0129, -0.0239, -0.0167],\n",
       "                      ...,\n",
       "                      [ 0.0016, -0.0032, -0.0192,  ..., -0.0037,  0.0279, -0.0231],\n",
       "                      [-0.0006, -0.0131, -0.0080,  ..., -0.0057, -0.0309,  0.0086],\n",
       "                      [ 0.0056, -0.0014, -0.0067,  ...,  0.0188, -0.0101,  0.0110]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder.module.pooler.dense.bias',\n",
       "              tensor([-1.0914e-04, -5.6884e-06, -7.3462e-05,  ..., -1.0166e-05,\n",
       "                       1.0752e-05, -1.1368e-04], device='cuda:0')),\n",
       "             ('decoder.concept_emb.emb.weight',\n",
       "              tensor([[-0.0021, -0.0093, -0.0035,  ...,  0.0264,  0.0093, -0.0249],\n",
       "                      [ 0.0110,  0.0315, -0.0124,  ..., -0.0238, -0.0061,  0.0199],\n",
       "                      [-0.0049, -0.0213, -0.0010,  ..., -0.0176, -0.0216,  0.0018],\n",
       "                      ...,\n",
       "                      [-0.0336,  0.0151,  0.0169,  ..., -0.0195, -0.0170, -0.0008],\n",
       "                      [-0.0311, -0.0065,  0.0086,  ...,  0.0026,  0.0236,  0.0275],\n",
       "                      [-0.0059,  0.0217,  0.0035,  ...,  0.0066,  0.0229,  0.0052]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.concept_emb.cpt_transform.weight',\n",
       "              tensor([[-0.0261, -0.0223, -0.0787,  ...,  0.0410,  0.0095, -0.0131],\n",
       "                      [ 0.0326, -0.0123, -0.0152,  ...,  0.0176,  0.0356, -0.0404],\n",
       "                      [ 0.0368, -0.0123,  0.0049,  ...,  0.0246,  0.0120,  0.0077],\n",
       "                      ...,\n",
       "                      [ 0.0575, -0.0335,  0.0465,  ...,  0.0244, -0.0145,  0.0293],\n",
       "                      [-0.0065,  0.0155,  0.0200,  ..., -0.0192, -0.0238,  0.0177],\n",
       "                      [ 0.0008,  0.0556,  0.0587,  ..., -0.0066,  0.0120,  0.0017]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.concept_emb.cpt_transform.bias',\n",
       "              tensor([-1.4412e-04, -1.3455e-03, -1.5558e-03,  3.5151e-03,  1.4187e-03,\n",
       "                      -2.8012e-03,  9.1978e-04, -8.8056e-03,  5.0289e-03,  4.6891e-03,\n",
       "                       4.8367e-03,  2.3062e-03, -9.3638e-04, -8.0265e-03,  5.6711e-04,\n",
       "                      -1.3954e-03,  3.0733e-03, -5.1915e-04,  1.7739e-04,  4.7920e-03,\n",
       "                      -6.4800e-03,  1.4314e-03, -8.5851e-03, -2.0884e-03,  1.7184e-03,\n",
       "                       4.3466e-03,  9.5161e-04, -4.7719e-04,  1.2588e-03,  4.5807e-03,\n",
       "                       3.4654e-03,  5.6649e-03,  3.4984e-03,  8.0474e-03,  8.2014e-04,\n",
       "                      -1.3068e-04,  4.1048e-03, -6.6709e-03,  2.5043e-03,  3.5412e-03,\n",
       "                       6.1462e-03,  1.1376e-02, -4.0413e-03,  4.2803e-03, -1.7503e-03,\n",
       "                       1.5077e-03,  3.5865e-03, -5.8945e-03, -2.5768e-03,  4.2645e-03,\n",
       "                       1.4766e-03,  5.8837e-03,  3.9391e-03, -5.5847e-04,  5.7460e-03,\n",
       "                       1.0291e-02,  1.3220e-03,  1.5369e-03,  4.4432e-03,  7.5385e-03,\n",
       "                      -3.3466e-04, -2.5860e-03,  9.7495e-03,  7.9255e-03,  7.2938e-03,\n",
       "                       3.1890e-03, -7.1955e-03, -2.9941e-03,  3.3290e-04,  4.2594e-03,\n",
       "                      -3.3322e-03,  4.0706e-03,  2.6884e-03,  3.9320e-03,  8.9764e-03,\n",
       "                      -4.0281e-03, -3.3583e-03,  5.5277e-04, -4.7081e-03, -6.6360e-03,\n",
       "                      -3.4894e-03, -3.4223e-03,  4.1334e-03,  3.9148e-03,  1.3284e-03,\n",
       "                      -5.1087e-03,  1.6737e-03,  3.3628e-03,  7.0820e-04,  2.0758e-03,\n",
       "                       6.9778e-03,  5.9217e-03,  4.5069e-03, -2.5562e-03, -4.9841e-03,\n",
       "                      -9.8979e-04,  6.8510e-03,  8.1777e-03, -6.4643e-03,  2.9687e-03,\n",
       "                       1.4244e-03, -8.1463e-04,  5.8132e-03,  5.3942e-03, -2.2554e-03,\n",
       "                       1.2681e-03,  1.8258e-03,  2.5328e-03,  1.7381e-03, -3.4727e-03,\n",
       "                       3.9319e-03, -5.1496e-03, -2.8889e-03,  2.8870e-03,  1.0129e-02,\n",
       "                      -5.6224e-04, -1.2436e-03, -6.7372e-03,  3.9395e-03,  6.2165e-04,\n",
       "                      -3.5744e-03,  3.4591e-03, -7.5553e-03,  6.2993e-03, -2.4101e-03,\n",
       "                       1.0683e-03, -5.2048e-03, -5.0791e-03,  4.2002e-03,  5.4582e-04,\n",
       "                       2.5689e-03,  7.7316e-03,  4.3836e-03, -2.6434e-04,  3.4999e-03,\n",
       "                      -9.0906e-04,  3.2814e-03,  4.2027e-03,  7.8210e-05,  8.3546e-03,\n",
       "                      -3.0505e-03, -5.2401e-03, -9.1293e-04,  1.6463e-03,  4.7031e-03,\n",
       "                      -6.3057e-03,  2.1843e-04,  3.3019e-03,  2.5109e-03, -4.3105e-03,\n",
       "                      -6.9763e-03,  2.7634e-03,  3.6391e-03, -4.5386e-03, -4.5071e-03,\n",
       "                       7.1755e-03, -7.0795e-04,  4.8503e-03, -4.2110e-03, -1.5914e-03,\n",
       "                      -5.4100e-04,  4.4430e-03,  7.3457e-03,  1.1669e-02,  2.8427e-03,\n",
       "                      -1.5164e-04, -2.8106e-04, -8.0606e-03,  1.5429e-03,  1.3314e-03,\n",
       "                       1.0562e-03,  1.9810e-03, -1.3426e-03,  1.4027e-03,  3.7663e-03,\n",
       "                       8.7385e-04,  5.0410e-03,  3.8163e-03,  7.2394e-04,  4.9438e-03,\n",
       "                      -1.5160e-03, -1.0695e-03, -7.5346e-03, -2.1936e-03, -3.0228e-04,\n",
       "                      -1.9483e-03,  8.4731e-03,  6.9126e-03,  1.0584e-04, -1.7135e-03,\n",
       "                       1.3586e-03, -1.2804e-03,  4.5278e-03,  2.4855e-03, -1.7020e-03,\n",
       "                       5.4938e-03, -1.4628e-03, -2.9341e-03, -4.4272e-03,  1.5379e-03],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.svec2nvec.weight',\n",
       "              tensor([[-0.0099,  0.0258, -0.0242,  ...,  0.0048,  0.0278,  0.0114],\n",
       "                      [ 0.0036,  0.0189, -0.0037,  ...,  0.0122,  0.0289,  0.0073],\n",
       "                      [-0.0451, -0.0067,  0.0235,  ..., -0.0122,  0.0139,  0.0152],\n",
       "                      ...,\n",
       "                      [-0.0122, -0.0294,  0.0005,  ...,  0.0206, -0.0134,  0.0174],\n",
       "                      [-0.0230,  0.0245, -0.0122,  ..., -0.0002,  0.0092, -0.0127],\n",
       "                      [ 0.0054,  0.0229,  0.0269,  ..., -0.0247, -0.0009, -0.0030]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.svec2nvec.bias',\n",
       "              tensor([-0.0092, -0.0039,  0.0008, -0.0112, -0.0080, -0.0027, -0.0099,  0.0023,\n",
       "                      -0.0189, -0.0061, -0.0183, -0.0234, -0.0128, -0.0042, -0.0044, -0.0075,\n",
       "                      -0.0042, -0.0027, -0.0018, -0.0039, -0.0031, -0.0103, -0.0005, -0.0107,\n",
       "                      -0.0078, -0.0166, -0.0167,  0.0054, -0.0106, -0.0154, -0.0031, -0.0090,\n",
       "                       0.0014, -0.0151, -0.0053, -0.0138, -0.0193,  0.0064, -0.0078, -0.0081,\n",
       "                      -0.0083, -0.0142, -0.0046, -0.0106, -0.0097, -0.0118, -0.0018,  0.0071,\n",
       "                      -0.0030, -0.0029, -0.0125, -0.0193, -0.0144, -0.0026, -0.0042, -0.0180,\n",
       "                      -0.0068, -0.0145, -0.0042, -0.0109, -0.0020, -0.0108, -0.0136, -0.0081,\n",
       "                      -0.0066, -0.0066,  0.0003, -0.0157, -0.0166, -0.0023,  0.0001, -0.0060,\n",
       "                      -0.0091, -0.0118, -0.0034, -0.0018, -0.0014, -0.0043,  0.0080, -0.0014,\n",
       "                      -0.0029,  0.0019, -0.0030, -0.0046, -0.0069, -0.0034, -0.0147, -0.0033,\n",
       "                      -0.0063, -0.0006, -0.0156, -0.0037, -0.0135, -0.0119, -0.0126, -0.0129,\n",
       "                      -0.0153, -0.0149,  0.0072, -0.0032, -0.0236, -0.0001, -0.0093, -0.0096,\n",
       "                      -0.0221, -0.0044, -0.0090, -0.0032, -0.0189, -0.0015, -0.0109,  0.0020,\n",
       "                      -0.0075,  0.0016, -0.0189, -0.0143, -0.0071, -0.0028, -0.0154, -0.0094,\n",
       "                       0.0002, -0.0016,  0.0013, -0.0123,  0.0037,  0.0088,  0.0012, -0.0008,\n",
       "                      -0.0198, -0.0181, -0.0144, -0.0096, -0.0087, -0.0043, -0.0041, -0.0108,\n",
       "                      -0.0172, -0.0060,  0.0065, -0.0168,  0.0041, -0.0157,  0.0017, -0.0015,\n",
       "                      -0.0009, -0.0038,  0.0052, -0.0119, -0.0138,  0.0005, -0.0032, -0.0046,\n",
       "                      -0.0171, -0.0022, -0.0103, -0.0119,  0.0027, -0.0014, -0.0122, -0.0050,\n",
       "                      -0.0072, -0.0013, -0.0125, -0.0086, -0.0129, -0.0160, -0.0052, -0.0092,\n",
       "                      -0.0067, -0.0018, -0.0173, -0.0087, -0.0160, -0.0007, -0.0165,  0.0023,\n",
       "                      -0.0127, -0.0114, -0.0025, -0.0024, -0.0058, -0.0058,  0.0003, -0.0018,\n",
       "                      -0.0063, -0.0053, -0.0066, -0.0178, -0.0112, -0.0052, -0.0155, -0.0033,\n",
       "                      -0.0106, -0.0108, -0.0002, -0.0153, -0.0053, -0.0042, -0.0015, -0.0032],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.emb_node_type.weight',\n",
       "              tensor([[-0.0575,  0.0560, -0.0019, -0.0095],\n",
       "                      [ 0.0643, -0.0029, -0.0709, -0.0031],\n",
       "                      [ 0.0582, -0.0688, -0.0201, -0.0214],\n",
       "                      [ 0.0586,  0.0015, -0.0386, -0.0172],\n",
       "                      [-0.0405,  0.1053, -0.0176,  0.0871],\n",
       "                      [ 0.0403, -0.0954,  0.0321, -0.0297],\n",
       "                      [-0.0319, -0.0305,  0.0462, -0.0109],\n",
       "                      [ 0.0652, -0.0594,  0.0503, -0.0361],\n",
       "                      [-0.0601,  0.0368,  0.0201, -0.0218],\n",
       "                      [ 0.0985,  0.0199, -0.0333, -0.0168],\n",
       "                      [-0.0591,  0.0487, -0.0400,  0.0215],\n",
       "                      [-0.1078, -0.0320,  0.0111, -0.0211],\n",
       "                      [ 0.0329, -0.0985,  0.0194, -0.0714],\n",
       "                      [-0.0518,  0.0117,  0.0422, -0.0438],\n",
       "                      [-0.0312,  0.0416, -0.0349,  0.0011],\n",
       "                      [ 0.0742, -0.0559, -0.0106,  0.0307],\n",
       "                      [ 0.0453, -0.0738,  0.0489, -0.0298],\n",
       "                      [-0.0516,  0.1062, -0.0013, -0.0002],\n",
       "                      [ 0.0200, -0.0390,  0.0522, -0.0051],\n",
       "                      [-0.0318,  0.0552, -0.0061, -0.0373],\n",
       "                      [ 0.0315, -0.0781,  0.0033,  0.0307],\n",
       "                      [ 0.0812, -0.0301,  0.0448, -0.0093],\n",
       "                      [-0.0371,  0.0669, -0.0382,  0.0126],\n",
       "                      [ 0.0581, -0.0410,  0.0483,  0.0090],\n",
       "                      [-0.0009, -0.0713,  0.0010, -0.0091],\n",
       "                      [-0.0352,  0.0898, -0.0175,  0.0594],\n",
       "                      [-0.0427,  0.0357, -0.0555,  0.0136],\n",
       "                      [-0.0576,  0.0303,  0.0128,  0.0316],\n",
       "                      [ 0.0314,  0.0329, -0.0014,  0.0130],\n",
       "                      [ 0.0312, -0.0009, -0.0530,  0.0359],\n",
       "                      [-0.0558,  0.0342, -0.0138,  0.0044],\n",
       "                      [ 0.0983, -0.0707,  0.0061, -0.0555],\n",
       "                      [ 0.0278, -0.1175,  0.0065,  0.0051],\n",
       "                      [ 0.0845, -0.0536, -0.0268, -0.0037],\n",
       "                      [ 0.0392,  0.0255, -0.0550,  0.0435],\n",
       "                      [-0.0422,  0.1056, -0.0068, -0.0335],\n",
       "                      [-0.0102,  0.0794,  0.0307,  0.0191],\n",
       "                      [ 0.0495,  0.0582, -0.0199,  0.0284],\n",
       "                      [ 0.0998, -0.0417, -0.0194,  0.0244],\n",
       "                      [-0.0489, -0.0505,  0.0262, -0.0151],\n",
       "                      [ 0.0458, -0.0675, -0.0020,  0.0730],\n",
       "                      [-0.0475,  0.0474,  0.0299, -0.0071],\n",
       "                      [ 0.0132,  0.0074, -0.0393,  0.0200],\n",
       "                      [-0.1036,  0.0546, -0.0100, -0.0172],\n",
       "                      [ 0.0637, -0.0708,  0.0423, -0.0043],\n",
       "                      [ 0.1023, -0.0521, -0.0199,  0.0192],\n",
       "                      [-0.0542,  0.0978, -0.0141,  0.0174],\n",
       "                      [ 0.0603, -0.0510,  0.0359, -0.0110],\n",
       "                      [ 0.0519, -0.0794,  0.0269, -0.0175],\n",
       "                      [ 0.0732,  0.0493, -0.0213,  0.0116],\n",
       "                      [ 0.0200,  0.0678, -0.0200,  0.0700],\n",
       "                      [-0.0631,  0.0953, -0.0081,  0.0691],\n",
       "                      [ 0.0470, -0.0454,  0.0385, -0.0217],\n",
       "                      [-0.0405,  0.0771, -0.0166,  0.0252],\n",
       "                      [-0.0696,  0.0661, -0.0047,  0.0479],\n",
       "                      [-0.0332,  0.0315,  0.0552,  0.0106],\n",
       "                      [-0.0044,  0.0766,  0.0054,  0.0026],\n",
       "                      [ 0.0700,  0.0096, -0.0435,  0.0041],\n",
       "                      [-0.0894,  0.0464,  0.0585,  0.0120],\n",
       "                      [ 0.0456, -0.0812,  0.0093,  0.0281],\n",
       "                      [-0.0708,  0.0756,  0.0061,  0.0641],\n",
       "                      [ 0.0477, -0.0745,  0.0394, -0.0960],\n",
       "                      [-0.0435,  0.0259,  0.0139,  0.0286],\n",
       "                      [ 0.0686, -0.0703,  0.0099, -0.0640],\n",
       "                      [ 0.0749, -0.0070, -0.0133, -0.0014],\n",
       "                      [-0.0708,  0.0422, -0.0194,  0.0221],\n",
       "                      [ 0.0583, -0.0594, -0.0440, -0.0235],\n",
       "                      [-0.0340, -0.0214,  0.0223,  0.0540],\n",
       "                      [ 0.0335, -0.0326,  0.0576, -0.0074],\n",
       "                      [ 0.0652,  0.0652, -0.0326,  0.0102],\n",
       "                      [-0.0395,  0.0915, -0.0074,  0.0595],\n",
       "                      [ 0.0615, -0.0214,  0.0112,  0.0073],\n",
       "                      [-0.0255,  0.1036, -0.0221,  0.0484],\n",
       "                      [-0.0219,  0.0730, -0.0367,  0.0257],\n",
       "                      [-0.0437,  0.1042,  0.0075,  0.0546],\n",
       "                      [ 0.0164, -0.0056,  0.0151,  0.0640],\n",
       "                      [ 0.0403,  0.0096, -0.0567, -0.0024],\n",
       "                      [ 0.0739, -0.0493,  0.0054,  0.0136],\n",
       "                      [-0.0536,  0.0741, -0.0107,  0.0479],\n",
       "                      [-0.0382,  0.0521,  0.0286, -0.0134],\n",
       "                      [ 0.0615, -0.0552, -0.0510,  0.0121],\n",
       "                      [ 0.0150, -0.0645, -0.0089,  0.0755],\n",
       "                      [-0.0325, -0.0463,  0.0474, -0.0469],\n",
       "                      [ 0.0666, -0.0282, -0.0364, -0.0006],\n",
       "                      [ 0.0398, -0.1003,  0.0226, -0.0189],\n",
       "                      [ 0.0293, -0.0486, -0.0192, -0.0063],\n",
       "                      [-0.0563,  0.0310,  0.0438,  0.0302],\n",
       "                      [ 0.0285, -0.0293, -0.0141, -0.0750],\n",
       "                      [ 0.0422, -0.0142, -0.0498,  0.0265],\n",
       "                      [-0.0510,  0.0242,  0.0479, -0.0352],\n",
       "                      [-0.1082,  0.0565,  0.0082, -0.0190],\n",
       "                      [ 0.0277,  0.0151,  0.0483, -0.0021],\n",
       "                      [ 0.0773,  0.0175,  0.0170,  0.0418],\n",
       "                      [-0.0170,  0.0829, -0.1047,  0.0285],\n",
       "                      [-0.0294,  0.1167, -0.0176,  0.0352],\n",
       "                      [-0.0655,  0.0648,  0.0341,  0.0008],\n",
       "                      [ 0.0469,  0.0051,  0.0879,  0.0075],\n",
       "                      [-0.0893,  0.0766, -0.0138, -0.0110],\n",
       "                      [ 0.0438, -0.0599, -0.0076, -0.0132],\n",
       "                      [ 0.0698, -0.0293,  0.0246,  0.0009]], device='cuda:0')),\n",
       "             ('decoder.gnn.emb_node_type.bias',\n",
       "              tensor([-1.7244e-03, -1.2611e-02, -6.3562e-03, -3.4311e-03,  1.1325e-02,\n",
       "                       2.0210e-03,  1.1851e-02,  2.5032e-02, -2.0607e-04,  5.1416e-03,\n",
       "                      -2.1123e-02, -9.2990e-03, -1.4026e-03,  3.2679e-04, -8.6463e-03,\n",
       "                       4.0055e-03,  1.5199e-02,  5.1943e-03,  2.4899e-02, -3.6126e-03,\n",
       "                      -6.6937e-04,  3.3157e-02, -5.5833e-03,  3.2293e-02, -4.7288e-03,\n",
       "                       1.0243e-02, -2.1952e-02, -8.3966e-05,  2.2345e-03, -8.5305e-03,\n",
       "                      -9.5624e-03,  1.0917e-03,  3.3697e-03,  7.7774e-03, -1.0185e-02,\n",
       "                       2.0124e-03,  1.8276e-02,  1.0287e-02,  9.6984e-03, -2.8847e-04,\n",
       "                       4.3604e-03,  9.0700e-03, -6.5484e-03, -7.0139e-03,  1.0808e-02,\n",
       "                       4.8732e-03,  1.3507e-03,  2.1852e-02,  6.9488e-03,  5.7913e-03,\n",
       "                       9.0181e-03,  5.7041e-03,  2.4900e-02,  5.5354e-03,  3.0704e-03,\n",
       "                       1.9322e-02,  7.0766e-03, -8.4721e-04,  1.5402e-02,  2.5136e-03,\n",
       "                       6.5178e-03,  1.3641e-02,  4.3347e-03,  4.2477e-03,  4.1811e-03,\n",
       "                      -4.3966e-03, -1.5422e-02,  6.7477e-03,  2.4053e-02,  9.9347e-03,\n",
       "                       6.8836e-03,  1.7362e-02,  8.6351e-03, -3.6376e-03,  1.4597e-02,\n",
       "                       2.1104e-02, -8.3994e-03,  1.7945e-02,  6.4021e-03,  1.1530e-02,\n",
       "                      -1.0867e-02, -2.9725e-03,  3.3500e-03,  2.7570e-04,  2.1235e-03,\n",
       "                      -1.2688e-02,  1.2620e-02, -1.0303e-02, -9.8016e-03,  1.9308e-02,\n",
       "                      -4.2995e-03,  2.4803e-02,  1.8347e-02, -1.2493e-02,  8.6543e-03,\n",
       "                       1.2488e-02,  3.4106e-02, -6.2364e-03, -5.3477e-03,  2.2741e-02],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.emb_score.weight',\n",
       "              tensor([[ 0.0078, -0.0042, -0.0100,  ..., -0.0720,  0.0973, -0.0618],\n",
       "                      [-0.0088, -0.0530, -0.0431,  ..., -0.0236, -0.0097, -0.0369],\n",
       "                      [-0.0213,  0.0119,  0.0003,  ...,  0.0503,  0.0331,  0.0095],\n",
       "                      ...,\n",
       "                      [ 0.0475,  0.0317,  0.0337,  ..., -0.0036,  0.0375,  0.0161],\n",
       "                      [ 0.0533,  0.0819,  0.0611,  ..., -0.0545,  0.0780, -0.0234],\n",
       "                      [-0.0191,  0.0348, -0.0284,  ...,  0.0231,  0.0246, -0.0444]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.emb_score.bias',\n",
       "              tensor([-0.0170,  0.0160,  0.0384,  0.0003,  0.0312,  0.0157,  0.0198,  0.0045,\n",
       "                       0.0458, -0.0108,  0.0094,  0.0111,  0.0003,  0.0087,  0.0200,  0.0117,\n",
       "                       0.0396,  0.0177,  0.0109,  0.0510,  0.0196, -0.0052,  0.0072,  0.0250,\n",
       "                       0.0058,  0.0036,  0.0225,  0.0172, -0.0016,  0.0303,  0.0265,  0.0007,\n",
       "                      -0.0036,  0.0227,  0.0041, -0.0048,  0.0063,  0.0421,  0.0133, -0.0047,\n",
       "                       0.0083,  0.0087,  0.0072,  0.0302,  0.0101, -0.0021,  0.0525,  0.0520,\n",
       "                      -0.0023,  0.0138,  0.0110,  0.0279,  0.0045,  0.0111,  0.0158,  0.0146,\n",
       "                       0.0064,  0.0159, -0.0005,  0.0028,  0.0062,  0.0118, -0.0010, -0.0058,\n",
       "                       0.0277,  0.0265,  0.0182,  0.0133,  0.0133, -0.0014,  0.0417,  0.0171,\n",
       "                       0.0314,  0.0230,  0.0494,  0.0091,  0.0222,  0.0009,  0.0185,  0.0354,\n",
       "                       0.0074, -0.0031, -0.0010,  0.0177,  0.0460, -0.0056,  0.0126,  0.0119,\n",
       "                       0.0203, -0.0103,  0.0235,  0.0160,  0.0184, -0.0099,  0.0226,  0.0253,\n",
       "                      -0.0006,  0.0175,  0.0085, -0.0090], device='cuda:0')),\n",
       "             ('decoder.gnn.edge_encoder.0.weight',\n",
       "              tensor([[ 0.0306, -0.0353,  0.0325,  ..., -0.0054, -0.0064, -0.0239],\n",
       "                      [ 0.0247,  0.0387,  0.0236,  ...,  0.0328,  0.0120, -0.0459],\n",
       "                      [ 0.0180, -0.0081, -0.0130,  ..., -0.0158,  0.0251,  0.0164],\n",
       "                      ...,\n",
       "                      [ 0.0070,  0.0437, -0.0125,  ..., -0.0002, -0.0051, -0.0569],\n",
       "                      [ 0.0213,  0.0714,  0.0441,  ..., -0.0479,  0.0109, -0.0085],\n",
       "                      [ 0.0176, -0.0074, -0.0351,  ..., -0.0420,  0.0276, -0.0018]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.edge_encoder.0.bias',\n",
       "              tensor([ 0.0077,  0.0119,  0.0017, -0.0190, -0.0046,  0.0056,  0.0168,  0.0094,\n",
       "                      -0.0051,  0.0039, -0.0029,  0.0186, -0.0180,  0.0189,  0.0191, -0.0094,\n",
       "                       0.0084,  0.0184, -0.0068, -0.0066, -0.0126, -0.0144,  0.0322,  0.0054,\n",
       "                       0.0056, -0.0084,  0.0076,  0.0117, -0.0092, -0.0210,  0.0302,  0.0111,\n",
       "                       0.0049,  0.0133,  0.0009,  0.0033,  0.0078, -0.0005,  0.0011,  0.0380,\n",
       "                       0.0042, -0.0085, -0.0131, -0.0191, -0.0132, -0.0132,  0.0060,  0.0126,\n",
       "                       0.0204, -0.0218, -0.0039,  0.0289,  0.0030,  0.0034,  0.0042,  0.0069,\n",
       "                       0.0276,  0.0014,  0.0052, -0.0010,  0.0165, -0.0045, -0.0037,  0.0045,\n",
       "                       0.0175, -0.0177, -0.0008,  0.0173, -0.0091,  0.0122, -0.0022, -0.0185,\n",
       "                      -0.0071, -0.0143,  0.0194,  0.0052,  0.0028,  0.0003, -0.0044,  0.0021,\n",
       "                      -0.0239, -0.0257,  0.0002,  0.0104,  0.0085,  0.0029,  0.0085,  0.0186,\n",
       "                       0.0136, -0.0184,  0.0170,  0.0219,  0.0114,  0.0373, -0.0013, -0.0081,\n",
       "                       0.0079,  0.0001,  0.0129, -0.0018,  0.0132,  0.0188,  0.0141, -0.0070,\n",
       "                       0.0138,  0.0063, -0.0268, -0.0065,  0.0113,  0.0060,  0.0369,  0.0077,\n",
       "                       0.0054, -0.0095, -0.0127, -0.0155, -0.0099, -0.0243, -0.0093,  0.0114,\n",
       "                      -0.0292, -0.0092, -0.0165,  0.0360, -0.0180,  0.0009, -0.0012, -0.0136,\n",
       "                      -0.0028, -0.0299, -0.0139,  0.0060, -0.0042,  0.0075, -0.0028,  0.0032,\n",
       "                       0.0168, -0.0089,  0.0203,  0.0222,  0.0033, -0.0214,  0.0055, -0.0004,\n",
       "                      -0.0070, -0.0103,  0.0122,  0.0016,  0.0049,  0.0059,  0.0101, -0.0175,\n",
       "                      -0.0075,  0.0347, -0.0166,  0.0217,  0.0009, -0.0263,  0.0026,  0.0296,\n",
       "                       0.0109,  0.0100, -0.0139, -0.0151,  0.0139,  0.0117,  0.0224,  0.0200,\n",
       "                       0.0159,  0.0146, -0.0090,  0.0056,  0.0198, -0.0114,  0.0122, -0.0099,\n",
       "                      -0.0116,  0.0004, -0.0143, -0.0011,  0.0056,  0.0021,  0.0154, -0.0226,\n",
       "                      -0.0033, -0.0069, -0.0072, -0.0033, -0.0062, -0.0068, -0.0164,  0.0153,\n",
       "                      -0.0333,  0.0075, -0.0050, -0.0042, -0.0204,  0.0111, -0.0367,  0.0139],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.edge_encoder.1.weight',\n",
       "              tensor([0.9628, 0.9829, 0.9672, 0.9673, 0.9706, 0.9835, 0.9779, 0.9585, 0.9801,\n",
       "                      1.0104, 0.9749, 0.9749, 0.9704, 0.9653, 0.9617, 0.9588, 0.9810, 0.9747,\n",
       "                      0.9706, 0.9653, 0.9548, 0.9736, 0.9918, 0.9715, 0.9768, 0.9686, 0.9768,\n",
       "                      0.9644, 0.9705, 0.9647, 0.9775, 0.9654, 0.9791, 0.9719, 0.9689, 1.0024,\n",
       "                      0.9714, 0.9612, 0.9602, 0.9835, 0.9716, 0.9771, 0.9913, 0.9704, 0.9972,\n",
       "                      0.9774, 0.9673, 0.9556, 0.9649, 0.9712, 0.9714, 0.9532, 0.9586, 0.9630,\n",
       "                      0.9654, 0.9569, 0.9866, 0.9909, 0.9710, 0.9789, 0.9821, 0.9766, 0.9629,\n",
       "                      1.0112, 0.9736, 1.0307, 0.9648, 0.9848, 0.9644, 0.9779, 0.9688, 0.9556,\n",
       "                      0.9911, 0.9716, 0.9692, 0.9976, 0.9801, 0.9737, 0.9750, 1.0032, 0.9712,\n",
       "                      0.9831, 0.9793, 1.0119, 0.9947, 0.9525, 0.9689, 1.0086, 0.9671, 0.9862,\n",
       "                      0.9723, 0.9898, 0.9515, 0.9780, 0.9625, 0.9707, 0.9851, 0.9711, 0.9946,\n",
       "                      0.9929, 1.0127, 0.9705, 0.9535, 0.9593, 0.9769, 0.9911, 0.9627, 0.9748,\n",
       "                      0.9724, 0.9391, 0.9803, 0.9876, 0.9843, 0.9748, 0.9582, 0.9636, 0.9737,\n",
       "                      0.9705, 0.9908, 0.9860, 0.9873, 0.9901, 0.9624, 0.9739, 0.9752, 0.9613,\n",
       "                      0.9775, 0.9644, 0.9877, 0.9880, 0.9751, 0.9752, 0.9599, 0.9629, 0.9751,\n",
       "                      0.9859, 0.9705, 0.9769, 0.9848, 0.9831, 0.9677, 1.0146, 0.9704, 0.9786,\n",
       "                      0.9771, 0.9810, 0.9668, 0.9568, 0.9419, 0.9776, 0.9674, 0.9866, 0.9767,\n",
       "                      0.9543, 0.9812, 1.0107, 0.9792, 0.9727, 0.9707, 0.9655, 0.9763, 0.9820,\n",
       "                      0.9982, 0.9833, 0.9660, 1.0028, 0.9630, 0.9713, 1.0131, 0.9784, 0.9664,\n",
       "                      0.9688, 0.9602, 0.9605, 0.9668, 0.9759, 0.9633, 0.9736, 0.9751, 0.9571,\n",
       "                      0.9551, 0.9673, 0.9850, 0.9753, 0.9827, 0.9796, 0.9681, 0.9709, 0.9784,\n",
       "                      0.9611, 0.9603, 0.9895, 0.9809, 0.9890, 0.9777, 0.9484, 0.9913, 0.9686,\n",
       "                      1.0060, 0.9723], device='cuda:0')),\n",
       "             ('decoder.gnn.edge_encoder.1.bias',\n",
       "              tensor([-2.5693e-02, -9.7445e-03, -1.3280e-02, -1.4876e-02, -1.3010e-02,\n",
       "                      -2.8902e-02, -1.5408e-02, -1.3348e-02, -7.5672e-03,  1.6497e-03,\n",
       "                      -7.8495e-03, -9.1716e-03, -2.0961e-02, -2.2757e-02, -2.0028e-02,\n",
       "                      -1.7987e-02, -7.9770e-03, -1.8736e-03, -5.3145e-03, -3.8504e-03,\n",
       "                      -1.5113e-02, -2.7974e-02,  2.6333e-03, -8.1461e-03, -1.9291e-02,\n",
       "                      -1.5892e-03,  1.6622e-04, -1.8932e-02, -1.3259e-02, -2.7374e-02,\n",
       "                      -1.4522e-02, -1.6898e-02, -8.0646e-03, -1.0664e-02, -1.0739e-02,\n",
       "                      -1.7976e-03, -1.9121e-02, -1.7618e-02, -1.1595e-02, -8.5707e-03,\n",
       "                      -1.0648e-02, -1.1552e-02, -1.4868e-02, -9.6961e-03, -2.4517e-02,\n",
       "                      -7.4088e-03,  7.0666e-03, -1.7505e-02, -1.4665e-02, -2.4669e-02,\n",
       "                      -2.5899e-02, -3.7980e-02, -2.2516e-02, -3.0423e-03, -9.7302e-03,\n",
       "                      -2.5835e-02, -2.2611e-03, -4.0520e-03, -6.8373e-03, -1.9277e-02,\n",
       "                      -8.0628e-03, -1.8217e-02, -1.6750e-02, -1.5095e-02, -1.4788e-03,\n",
       "                      -3.7971e-02, -1.9556e-02,  1.5557e-04, -7.2736e-03, -3.9847e-03,\n",
       "                      -1.2300e-02, -1.9903e-02, -1.9171e-02, -9.9416e-03, -5.3805e-03,\n",
       "                       1.5913e-03, -7.6342e-03, -3.3007e-03, -6.2690e-03, -1.4096e-05,\n",
       "                      -1.5686e-02, -6.8913e-03, -1.7321e-02, -2.5634e-02, -1.4783e-02,\n",
       "                      -2.4108e-02, -1.3706e-02, -2.0894e-02, -2.0094e-02, -6.5898e-03,\n",
       "                      -1.2185e-02, -6.1023e-03, -2.7504e-02, -2.4717e-02, -2.5939e-02,\n",
       "                      -1.5674e-02, -5.1389e-03, -7.2659e-03,  4.9414e-03, -1.5022e-03,\n",
       "                      -1.3755e-02, -2.0142e-02, -2.5539e-02, -3.3021e-02, -1.7456e-02,\n",
       "                      -7.0987e-03, -1.8066e-02, -7.1374e-03, -9.0562e-03, -4.0189e-02,\n",
       "                      -4.1441e-03, -9.2944e-03, -8.8290e-03, -1.3431e-02, -1.1504e-02,\n",
       "                      -2.5691e-02, -1.5559e-02, -2.4027e-02, -1.8737e-02, -6.9398e-03,\n",
       "                      -1.3982e-02, -9.3979e-03, -2.2429e-02, -1.6925e-02, -1.1936e-02,\n",
       "                      -2.2714e-02, -8.0626e-03, -2.0102e-02, -1.1027e-02, -1.1894e-02,\n",
       "                      -2.9027e-02, -1.0246e-02, -2.0020e-02, -2.4571e-02,  1.9411e-03,\n",
       "                      -2.1970e-02, -1.8667e-02, -1.4658e-02, -3.9352e-03, -1.8957e-02,\n",
       "                      -9.4686e-03, -2.8255e-02,  5.2848e-04,  7.7191e-03, -1.7395e-02,\n",
       "                      -1.0582e-02, -1.7854e-02, -2.6494e-02, -3.3694e-02, -2.2807e-02,\n",
       "                      -2.3661e-02, -5.3341e-03, -7.3770e-03, -3.4522e-02, -2.7705e-02,\n",
       "                      -7.6568e-03, -5.1986e-03,  6.7720e-03, -2.3240e-02, -3.5141e-02,\n",
       "                      -1.3055e-02, -8.6289e-03, -2.5888e-02, -1.1771e-02, -1.2512e-02,\n",
       "                      -1.8411e-02, -3.3645e-02, -7.4316e-03, -1.2644e-02, -7.5547e-03,\n",
       "                      -1.6641e-02, -1.9724e-02, -2.6223e-02, -1.5339e-02, -6.3751e-03,\n",
       "                      -5.5682e-03, -2.3769e-02, -8.3162e-03, -7.2813e-03, -3.8014e-02,\n",
       "                      -2.6523e-02, -2.3696e-02, -9.4407e-03, -1.6965e-02, -1.8803e-02,\n",
       "                       4.4039e-03, -1.6914e-02, -1.6613e-02,  7.9222e-03, -2.1573e-02,\n",
       "                      -5.3399e-03, -1.7694e-02, -4.4106e-03, -3.1973e-03, -3.3638e-03,\n",
       "                      -3.0254e-02,  3.6135e-03, -1.7349e-02,  2.9815e-03, -8.8753e-03],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.edge_encoder.1.running_mean',\n",
       "              tensor([ 2.7008e-02,  1.6912e-03,  1.5797e-02, -6.7778e-02,  2.0418e-02,\n",
       "                      -1.1173e-02,  1.5179e-02,  2.4307e-02,  1.2653e-02,  4.6869e-03,\n",
       "                      -1.0762e-02, -1.9674e-03, -1.3291e-02,  3.0813e-02, -1.3610e-03,\n",
       "                       4.5526e-03,  2.5402e-02,  2.0468e-02,  1.6868e-02,  1.5769e-02,\n",
       "                      -3.7985e-03, -2.9739e-02,  3.6873e-02, -1.5693e-03, -2.0923e-02,\n",
       "                       4.5054e-02,  3.2104e-02, -3.1810e-03,  5.9307e-03, -2.4748e-03,\n",
       "                       2.8697e-02,  2.8321e-03,  4.0958e-02,  2.8253e-02,  3.6128e-02,\n",
       "                      -1.6234e-02,  1.5718e-02,  2.1499e-02,  3.2818e-02,  4.5780e-02,\n",
       "                       1.8265e-02, -2.2358e-02,  1.0330e-02, -8.1752e-03, -7.3849e-02,\n",
       "                      -7.7433e-02, -9.5062e-03,  5.6934e-02,  2.9798e-02, -5.6704e-02,\n",
       "                      -2.8998e-04,  3.8911e-02,  7.1862e-02,  2.8319e-02, -1.3835e-03,\n",
       "                       2.4380e-02,  4.7917e-02, -7.5812e-03,  4.3195e-02, -8.7772e-03,\n",
       "                       3.0336e-02, -2.1767e-02, -2.0313e-02, -5.7155e-02,  2.2238e-02,\n",
       "                      -1.7876e-02,  7.2475e-03,  5.9072e-02,  1.7254e-02,  3.5640e-02,\n",
       "                      -5.3690e-02,  3.1887e-02, -6.1408e-02,  1.1748e-02, -2.8399e-02,\n",
       "                       3.6311e-02,  3.8973e-02,  6.4906e-02,  7.8385e-03, -2.0935e-02,\n",
       "                      -5.8416e-02, -2.0047e-02, -3.1496e-02,  2.9189e-02, -3.4504e-02,\n",
       "                      -2.7514e-02,  6.8505e-02,  2.8062e-03,  1.8849e-05, -1.3774e-02,\n",
       "                       9.2343e-03,  3.7521e-02,  4.5121e-02,  1.4074e-02, -1.8121e-04,\n",
       "                      -4.0558e-02, -3.7644e-03,  1.6923e-02,  2.7104e-02, -1.5634e-02,\n",
       "                      -4.1377e-03,  9.3574e-03,  1.9628e-02,  5.6155e-02,  5.2343e-02,\n",
       "                       8.2967e-03, -3.7830e-03, -4.8709e-03, -8.8138e-03,  5.4959e-02,\n",
       "                       9.5033e-02, -8.7470e-03, -2.1711e-03, -2.7213e-02,  2.7870e-02,\n",
       "                      -6.4279e-02, -1.5909e-02, -4.3667e-02, -1.5132e-02, -9.5939e-03,\n",
       "                      -1.8963e-02, -6.7713e-03, -5.5545e-02, -1.0497e-02, -3.9040e-02,\n",
       "                      -4.8672e-03,  1.1762e-02, -1.5282e-02, -4.3349e-02, -5.3518e-02,\n",
       "                       4.6776e-03, -4.4651e-02, -4.5448e-02, -1.2307e-02,  1.7775e-02,\n",
       "                      -4.1911e-03,  2.1014e-02, -4.3004e-03,  2.7901e-02,  1.0977e-02,\n",
       "                      -7.3112e-03, -3.7840e-02, -1.7166e-03,  1.3762e-02, -2.5244e-02,\n",
       "                       1.1566e-02,  7.3994e-02, -4.3874e-03,  4.3512e-02, -4.0878e-02,\n",
       "                       1.8922e-03, -1.0121e-02, -2.9110e-02,  2.4583e-02, -4.8153e-02,\n",
       "                       2.5973e-02, -2.9922e-03, -2.0870e-02, -2.2877e-02, -1.4993e-03,\n",
       "                      -5.9943e-03, -7.2241e-03, -2.0146e-02,  1.2459e-02, -3.8290e-03,\n",
       "                      -2.0011e-02,  3.9809e-02,  1.3255e-02, -4.2352e-04,  1.7046e-02,\n",
       "                      -6.5159e-03,  1.2209e-02,  6.6373e-02, -1.1389e-02,  5.5789e-02,\n",
       "                       1.8531e-02, -1.1453e-02,  2.1218e-02,  1.8626e-02,  1.3585e-02,\n",
       "                      -3.0026e-02,  1.2386e-02, -9.9208e-03, -2.6795e-04, -8.1980e-03,\n",
       "                      -1.3025e-02, -1.7465e-02,  3.8352e-04, -2.6250e-02, -3.8193e-02,\n",
       "                       1.8636e-02, -7.6045e-03, -3.9300e-02,  1.3399e-03,  1.3233e-02,\n",
       "                       1.9639e-02, -1.1317e-02, -1.9422e-02, -3.2577e-02,  5.8234e-02],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.edge_encoder.1.running_var',\n",
       "              tensor([0.0007, 0.0011, 0.0017, 0.0010, 0.0004, 0.0005, 0.0011, 0.0008, 0.0008,\n",
       "                      0.0006, 0.0011, 0.0012, 0.0004, 0.0011, 0.0017, 0.0008, 0.0009, 0.0008,\n",
       "                      0.0008, 0.0017, 0.0010, 0.0005, 0.0005, 0.0005, 0.0007, 0.0009, 0.0004,\n",
       "                      0.0016, 0.0005, 0.0014, 0.0013, 0.0005, 0.0005, 0.0010, 0.0009, 0.0005,\n",
       "                      0.0009, 0.0014, 0.0012, 0.0007, 0.0004, 0.0008, 0.0005, 0.0008, 0.0010,\n",
       "                      0.0010, 0.0010, 0.0012, 0.0016, 0.0011, 0.0004, 0.0004, 0.0009, 0.0014,\n",
       "                      0.0009, 0.0013, 0.0004, 0.0005, 0.0009, 0.0005, 0.0003, 0.0009, 0.0005,\n",
       "                      0.0007, 0.0009, 0.0004, 0.0008, 0.0009, 0.0006, 0.0004, 0.0013, 0.0007,\n",
       "                      0.0007, 0.0006, 0.0007, 0.0004, 0.0007, 0.0007, 0.0007, 0.0003, 0.0020,\n",
       "                      0.0011, 0.0006, 0.0004, 0.0010, 0.0019, 0.0012, 0.0007, 0.0005, 0.0004,\n",
       "                      0.0005, 0.0009, 0.0012, 0.0007, 0.0007, 0.0014, 0.0015, 0.0009, 0.0009,\n",
       "                      0.0006, 0.0004, 0.0006, 0.0008, 0.0008, 0.0012, 0.0005, 0.0013, 0.0009,\n",
       "                      0.0006, 0.0015, 0.0007, 0.0006, 0.0007, 0.0010, 0.0010, 0.0010, 0.0005,\n",
       "                      0.0006, 0.0006, 0.0005, 0.0003, 0.0008, 0.0007, 0.0010, 0.0008, 0.0009,\n",
       "                      0.0008, 0.0012, 0.0011, 0.0014, 0.0014, 0.0012, 0.0019, 0.0012, 0.0016,\n",
       "                      0.0008, 0.0008, 0.0006, 0.0006, 0.0012, 0.0004, 0.0006, 0.0020, 0.0009,\n",
       "                      0.0004, 0.0004, 0.0010, 0.0010, 0.0006, 0.0004, 0.0008, 0.0006, 0.0010,\n",
       "                      0.0016, 0.0006, 0.0004, 0.0010, 0.0015, 0.0007, 0.0009, 0.0008, 0.0008,\n",
       "                      0.0005, 0.0006, 0.0010, 0.0003, 0.0010, 0.0007, 0.0005, 0.0007, 0.0007,\n",
       "                      0.0008, 0.0009, 0.0022, 0.0009, 0.0007, 0.0006, 0.0006, 0.0006, 0.0014,\n",
       "                      0.0004, 0.0004, 0.0003, 0.0004, 0.0008, 0.0010, 0.0010, 0.0010, 0.0016,\n",
       "                      0.0016, 0.0008, 0.0008, 0.0017, 0.0004, 0.0013, 0.0004, 0.0015, 0.0007,\n",
       "                      0.0011, 0.0009], device='cuda:0')),\n",
       "             ('decoder.gnn.edge_encoder.1.num_batches_tracked',\n",
       "              tensor(318750, device='cuda:0')),\n",
       "             ('decoder.gnn.edge_encoder.3.weight',\n",
       "              tensor([[-0.0193, -0.0094, -0.0241,  ...,  0.0122, -0.0301, -0.0028],\n",
       "                      [ 0.0069,  0.0188,  0.0111,  ..., -0.0008, -0.0141,  0.0301],\n",
       "                      [ 0.0371, -0.0236, -0.0005,  ..., -0.0178,  0.0145,  0.0044],\n",
       "                      ...,\n",
       "                      [ 0.0266,  0.0113,  0.0204,  ..., -0.0058,  0.0168, -0.0279],\n",
       "                      [ 0.0263, -0.0120,  0.0145,  ..., -0.0088,  0.0285, -0.0355],\n",
       "                      [ 0.0217,  0.0041,  0.0519,  ...,  0.0308, -0.0709, -0.0156]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.edge_encoder.3.bias',\n",
       "              tensor([-2.3653e-03, -5.7033e-03,  2.7150e-03,  1.7915e-03, -1.3082e-03,\n",
       "                      -3.1844e-04,  8.8534e-04, -5.2766e-03,  1.3499e-03,  4.7690e-03,\n",
       "                      -4.6336e-03,  1.4850e-03, -3.2236e-03,  3.7453e-03, -8.5289e-03,\n",
       "                       7.5043e-03,  5.8532e-03,  2.3962e-04, -5.7625e-04,  5.2903e-04,\n",
       "                      -1.7449e-03,  5.2435e-03,  2.9055e-03, -4.1971e-03, -5.6767e-03,\n",
       "                      -4.0691e-03, -1.4285e-03,  5.0252e-03, -1.9099e-03,  1.1951e-03,\n",
       "                       2.1446e-03, -2.3171e-03,  5.1971e-03,  1.3342e-03, -6.3974e-03,\n",
       "                       7.7394e-04, -5.0417e-03, -4.6538e-04,  8.4626e-03, -4.4000e-04,\n",
       "                      -7.0619e-04,  4.7418e-03, -5.4846e-03, -5.1588e-03, -7.3695e-03,\n",
       "                      -9.4579e-03,  4.9077e-03, -5.9823e-03,  1.0702e-03, -2.1661e-03,\n",
       "                       1.0390e-03,  1.1983e-03, -4.2399e-03, -1.2942e-03, -7.8520e-03,\n",
       "                      -3.5293e-03, -1.0280e-02,  3.5102e-04,  3.8343e-03, -1.2780e-03,\n",
       "                       4.5618e-04,  3.8666e-03,  1.8226e-03,  4.2149e-03, -7.9116e-03,\n",
       "                      -6.3569e-03,  7.4834e-04,  4.8660e-04, -3.4787e-03, -3.4874e-03,\n",
       "                      -2.9350e-03,  6.0196e-03,  2.0707e-03,  6.1710e-03, -2.5195e-04,\n",
       "                       2.7551e-03, -3.0170e-03, -3.2106e-03, -5.5723e-05,  5.0233e-03,\n",
       "                      -5.5378e-03, -8.5195e-03,  2.5666e-03, -1.8356e-03,  1.2716e-03,\n",
       "                      -1.2945e-03,  1.9425e-03,  8.8292e-04,  2.0636e-03,  1.4934e-03,\n",
       "                      -1.9848e-03,  9.8496e-03, -2.1664e-03,  1.9293e-03, -3.8735e-03,\n",
       "                      -5.7664e-03,  3.7731e-03, -2.0194e-03,  5.2783e-03,  3.5625e-03,\n",
       "                      -4.3390e-03, -4.5637e-03,  6.6010e-03,  3.1173e-03,  4.0452e-03,\n",
       "                      -2.6583e-03,  4.5262e-03, -1.5825e-03, -4.2482e-03, -3.4520e-03,\n",
       "                       2.3763e-03,  3.6228e-03,  1.7307e-03,  1.0506e-03,  4.2683e-03,\n",
       "                      -3.5708e-04, -2.0222e-03, -1.5319e-03,  4.2033e-03, -6.7279e-03,\n",
       "                       1.4046e-03,  2.9070e-03,  3.6665e-03,  1.5358e-03,  2.2912e-03,\n",
       "                       1.5417e-03, -5.5028e-03,  1.9160e-03, -3.6478e-03, -3.0722e-03,\n",
       "                      -6.0849e-04,  4.6370e-03,  1.5033e-03,  7.6505e-03,  1.1843e-03,\n",
       "                      -2.6880e-03, -7.3885e-04, -1.9909e-03, -4.8474e-03,  7.0672e-03,\n",
       "                       7.6360e-03, -5.4759e-03, -6.0674e-03, -1.4287e-03,  1.6351e-03,\n",
       "                       4.7338e-03, -4.7588e-03, -5.5839e-03,  1.8682e-03, -1.0032e-03,\n",
       "                      -1.1349e-04,  6.5163e-03,  7.6160e-04,  6.0492e-03,  2.1817e-03,\n",
       "                       5.5140e-04, -5.6854e-03,  2.1677e-04,  1.8623e-03,  1.7347e-03,\n",
       "                      -3.2468e-03,  2.5972e-03, -1.4406e-03, -4.4453e-03, -6.4311e-03,\n",
       "                      -3.7272e-03,  2.8988e-03, -3.4194e-03,  8.8222e-04,  3.5037e-03,\n",
       "                       4.3227e-04, -1.8212e-03,  1.9136e-03, -3.1052e-03, -5.8780e-03,\n",
       "                      -9.3809e-04,  2.1546e-03, -5.0847e-03, -5.3777e-03, -3.2735e-03,\n",
       "                       1.7199e-04, -1.1658e-03,  3.6198e-03,  4.1820e-03,  1.1943e-04,\n",
       "                      -1.7642e-03,  4.1916e-03,  8.8105e-04, -6.2575e-03,  6.1010e-03,\n",
       "                      -4.3334e-04,  1.6691e-03,  8.9472e-06,  5.3347e-03,  4.1516e-03,\n",
       "                       4.4639e-03,  4.7324e-03, -6.6560e-04, -5.5783e-03,  1.1676e-03],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.0.edge_encoder.0.weight',\n",
       "              tensor([[ 0.0306, -0.0353,  0.0325,  ..., -0.0054, -0.0064, -0.0239],\n",
       "                      [ 0.0247,  0.0387,  0.0236,  ...,  0.0328,  0.0120, -0.0459],\n",
       "                      [ 0.0180, -0.0081, -0.0130,  ..., -0.0158,  0.0251,  0.0164],\n",
       "                      ...,\n",
       "                      [ 0.0070,  0.0437, -0.0125,  ..., -0.0002, -0.0051, -0.0569],\n",
       "                      [ 0.0213,  0.0714,  0.0441,  ..., -0.0479,  0.0109, -0.0085],\n",
       "                      [ 0.0176, -0.0074, -0.0351,  ..., -0.0420,  0.0276, -0.0018]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.0.edge_encoder.0.bias',\n",
       "              tensor([ 0.0077,  0.0119,  0.0017, -0.0190, -0.0046,  0.0056,  0.0168,  0.0094,\n",
       "                      -0.0051,  0.0039, -0.0029,  0.0186, -0.0180,  0.0189,  0.0191, -0.0094,\n",
       "                       0.0084,  0.0184, -0.0068, -0.0066, -0.0126, -0.0144,  0.0322,  0.0054,\n",
       "                       0.0056, -0.0084,  0.0076,  0.0117, -0.0092, -0.0210,  0.0302,  0.0111,\n",
       "                       0.0049,  0.0133,  0.0009,  0.0033,  0.0078, -0.0005,  0.0011,  0.0380,\n",
       "                       0.0042, -0.0085, -0.0131, -0.0191, -0.0132, -0.0132,  0.0060,  0.0126,\n",
       "                       0.0204, -0.0218, -0.0039,  0.0289,  0.0030,  0.0034,  0.0042,  0.0069,\n",
       "                       0.0276,  0.0014,  0.0052, -0.0010,  0.0165, -0.0045, -0.0037,  0.0045,\n",
       "                       0.0175, -0.0177, -0.0008,  0.0173, -0.0091,  0.0122, -0.0022, -0.0185,\n",
       "                      -0.0071, -0.0143,  0.0194,  0.0052,  0.0028,  0.0003, -0.0044,  0.0021,\n",
       "                      -0.0239, -0.0257,  0.0002,  0.0104,  0.0085,  0.0029,  0.0085,  0.0186,\n",
       "                       0.0136, -0.0184,  0.0170,  0.0219,  0.0114,  0.0373, -0.0013, -0.0081,\n",
       "                       0.0079,  0.0001,  0.0129, -0.0018,  0.0132,  0.0188,  0.0141, -0.0070,\n",
       "                       0.0138,  0.0063, -0.0268, -0.0065,  0.0113,  0.0060,  0.0369,  0.0077,\n",
       "                       0.0054, -0.0095, -0.0127, -0.0155, -0.0099, -0.0243, -0.0093,  0.0114,\n",
       "                      -0.0292, -0.0092, -0.0165,  0.0360, -0.0180,  0.0009, -0.0012, -0.0136,\n",
       "                      -0.0028, -0.0299, -0.0139,  0.0060, -0.0042,  0.0075, -0.0028,  0.0032,\n",
       "                       0.0168, -0.0089,  0.0203,  0.0222,  0.0033, -0.0214,  0.0055, -0.0004,\n",
       "                      -0.0070, -0.0103,  0.0122,  0.0016,  0.0049,  0.0059,  0.0101, -0.0175,\n",
       "                      -0.0075,  0.0347, -0.0166,  0.0217,  0.0009, -0.0263,  0.0026,  0.0296,\n",
       "                       0.0109,  0.0100, -0.0139, -0.0151,  0.0139,  0.0117,  0.0224,  0.0200,\n",
       "                       0.0159,  0.0146, -0.0090,  0.0056,  0.0198, -0.0114,  0.0122, -0.0099,\n",
       "                      -0.0116,  0.0004, -0.0143, -0.0011,  0.0056,  0.0021,  0.0154, -0.0226,\n",
       "                      -0.0033, -0.0069, -0.0072, -0.0033, -0.0062, -0.0068, -0.0164,  0.0153,\n",
       "                      -0.0333,  0.0075, -0.0050, -0.0042, -0.0204,  0.0111, -0.0367,  0.0139],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.0.edge_encoder.1.weight',\n",
       "              tensor([0.9628, 0.9829, 0.9672, 0.9673, 0.9706, 0.9835, 0.9779, 0.9585, 0.9801,\n",
       "                      1.0104, 0.9749, 0.9749, 0.9704, 0.9653, 0.9617, 0.9588, 0.9810, 0.9747,\n",
       "                      0.9706, 0.9653, 0.9548, 0.9736, 0.9918, 0.9715, 0.9768, 0.9686, 0.9768,\n",
       "                      0.9644, 0.9705, 0.9647, 0.9775, 0.9654, 0.9791, 0.9719, 0.9689, 1.0024,\n",
       "                      0.9714, 0.9612, 0.9602, 0.9835, 0.9716, 0.9771, 0.9913, 0.9704, 0.9972,\n",
       "                      0.9774, 0.9673, 0.9556, 0.9649, 0.9712, 0.9714, 0.9532, 0.9586, 0.9630,\n",
       "                      0.9654, 0.9569, 0.9866, 0.9909, 0.9710, 0.9789, 0.9821, 0.9766, 0.9629,\n",
       "                      1.0112, 0.9736, 1.0307, 0.9648, 0.9848, 0.9644, 0.9779, 0.9688, 0.9556,\n",
       "                      0.9911, 0.9716, 0.9692, 0.9976, 0.9801, 0.9737, 0.9750, 1.0032, 0.9712,\n",
       "                      0.9831, 0.9793, 1.0119, 0.9947, 0.9525, 0.9689, 1.0086, 0.9671, 0.9862,\n",
       "                      0.9723, 0.9898, 0.9515, 0.9780, 0.9625, 0.9707, 0.9851, 0.9711, 0.9946,\n",
       "                      0.9929, 1.0127, 0.9705, 0.9535, 0.9593, 0.9769, 0.9911, 0.9627, 0.9748,\n",
       "                      0.9724, 0.9391, 0.9803, 0.9876, 0.9843, 0.9748, 0.9582, 0.9636, 0.9737,\n",
       "                      0.9705, 0.9908, 0.9860, 0.9873, 0.9901, 0.9624, 0.9739, 0.9752, 0.9613,\n",
       "                      0.9775, 0.9644, 0.9877, 0.9880, 0.9751, 0.9752, 0.9599, 0.9629, 0.9751,\n",
       "                      0.9859, 0.9705, 0.9769, 0.9848, 0.9831, 0.9677, 1.0146, 0.9704, 0.9786,\n",
       "                      0.9771, 0.9810, 0.9668, 0.9568, 0.9419, 0.9776, 0.9674, 0.9866, 0.9767,\n",
       "                      0.9543, 0.9812, 1.0107, 0.9792, 0.9727, 0.9707, 0.9655, 0.9763, 0.9820,\n",
       "                      0.9982, 0.9833, 0.9660, 1.0028, 0.9630, 0.9713, 1.0131, 0.9784, 0.9664,\n",
       "                      0.9688, 0.9602, 0.9605, 0.9668, 0.9759, 0.9633, 0.9736, 0.9751, 0.9571,\n",
       "                      0.9551, 0.9673, 0.9850, 0.9753, 0.9827, 0.9796, 0.9681, 0.9709, 0.9784,\n",
       "                      0.9611, 0.9603, 0.9895, 0.9809, 0.9890, 0.9777, 0.9484, 0.9913, 0.9686,\n",
       "                      1.0060, 0.9723], device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.0.edge_encoder.1.bias',\n",
       "              tensor([-2.5693e-02, -9.7445e-03, -1.3280e-02, -1.4876e-02, -1.3010e-02,\n",
       "                      -2.8902e-02, -1.5408e-02, -1.3348e-02, -7.5672e-03,  1.6497e-03,\n",
       "                      -7.8495e-03, -9.1716e-03, -2.0961e-02, -2.2757e-02, -2.0028e-02,\n",
       "                      -1.7987e-02, -7.9770e-03, -1.8736e-03, -5.3145e-03, -3.8504e-03,\n",
       "                      -1.5113e-02, -2.7974e-02,  2.6333e-03, -8.1461e-03, -1.9291e-02,\n",
       "                      -1.5892e-03,  1.6622e-04, -1.8932e-02, -1.3259e-02, -2.7374e-02,\n",
       "                      -1.4522e-02, -1.6898e-02, -8.0646e-03, -1.0664e-02, -1.0739e-02,\n",
       "                      -1.7976e-03, -1.9121e-02, -1.7618e-02, -1.1595e-02, -8.5707e-03,\n",
       "                      -1.0648e-02, -1.1552e-02, -1.4868e-02, -9.6961e-03, -2.4517e-02,\n",
       "                      -7.4088e-03,  7.0666e-03, -1.7505e-02, -1.4665e-02, -2.4669e-02,\n",
       "                      -2.5899e-02, -3.7980e-02, -2.2516e-02, -3.0423e-03, -9.7302e-03,\n",
       "                      -2.5835e-02, -2.2611e-03, -4.0520e-03, -6.8373e-03, -1.9277e-02,\n",
       "                      -8.0628e-03, -1.8217e-02, -1.6750e-02, -1.5095e-02, -1.4788e-03,\n",
       "                      -3.7971e-02, -1.9556e-02,  1.5557e-04, -7.2736e-03, -3.9847e-03,\n",
       "                      -1.2300e-02, -1.9903e-02, -1.9171e-02, -9.9416e-03, -5.3805e-03,\n",
       "                       1.5913e-03, -7.6342e-03, -3.3007e-03, -6.2690e-03, -1.4096e-05,\n",
       "                      -1.5686e-02, -6.8913e-03, -1.7321e-02, -2.5634e-02, -1.4783e-02,\n",
       "                      -2.4108e-02, -1.3706e-02, -2.0894e-02, -2.0094e-02, -6.5898e-03,\n",
       "                      -1.2185e-02, -6.1023e-03, -2.7504e-02, -2.4717e-02, -2.5939e-02,\n",
       "                      -1.5674e-02, -5.1389e-03, -7.2659e-03,  4.9414e-03, -1.5022e-03,\n",
       "                      -1.3755e-02, -2.0142e-02, -2.5539e-02, -3.3021e-02, -1.7456e-02,\n",
       "                      -7.0987e-03, -1.8066e-02, -7.1374e-03, -9.0562e-03, -4.0189e-02,\n",
       "                      -4.1441e-03, -9.2944e-03, -8.8290e-03, -1.3431e-02, -1.1504e-02,\n",
       "                      -2.5691e-02, -1.5559e-02, -2.4027e-02, -1.8737e-02, -6.9398e-03,\n",
       "                      -1.3982e-02, -9.3979e-03, -2.2429e-02, -1.6925e-02, -1.1936e-02,\n",
       "                      -2.2714e-02, -8.0626e-03, -2.0102e-02, -1.1027e-02, -1.1894e-02,\n",
       "                      -2.9027e-02, -1.0246e-02, -2.0020e-02, -2.4571e-02,  1.9411e-03,\n",
       "                      -2.1970e-02, -1.8667e-02, -1.4658e-02, -3.9352e-03, -1.8957e-02,\n",
       "                      -9.4686e-03, -2.8255e-02,  5.2848e-04,  7.7191e-03, -1.7395e-02,\n",
       "                      -1.0582e-02, -1.7854e-02, -2.6494e-02, -3.3694e-02, -2.2807e-02,\n",
       "                      -2.3661e-02, -5.3341e-03, -7.3770e-03, -3.4522e-02, -2.7705e-02,\n",
       "                      -7.6568e-03, -5.1986e-03,  6.7720e-03, -2.3240e-02, -3.5141e-02,\n",
       "                      -1.3055e-02, -8.6289e-03, -2.5888e-02, -1.1771e-02, -1.2512e-02,\n",
       "                      -1.8411e-02, -3.3645e-02, -7.4316e-03, -1.2644e-02, -7.5547e-03,\n",
       "                      -1.6641e-02, -1.9724e-02, -2.6223e-02, -1.5339e-02, -6.3751e-03,\n",
       "                      -5.5682e-03, -2.3769e-02, -8.3162e-03, -7.2813e-03, -3.8014e-02,\n",
       "                      -2.6523e-02, -2.3696e-02, -9.4407e-03, -1.6965e-02, -1.8803e-02,\n",
       "                       4.4039e-03, -1.6914e-02, -1.6613e-02,  7.9222e-03, -2.1573e-02,\n",
       "                      -5.3399e-03, -1.7694e-02, -4.4106e-03, -3.1973e-03, -3.3638e-03,\n",
       "                      -3.0254e-02,  3.6135e-03, -1.7349e-02,  2.9815e-03, -8.8753e-03],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.0.edge_encoder.1.running_mean',\n",
       "              tensor([ 2.7008e-02,  1.6912e-03,  1.5797e-02, -6.7778e-02,  2.0418e-02,\n",
       "                      -1.1173e-02,  1.5179e-02,  2.4307e-02,  1.2653e-02,  4.6869e-03,\n",
       "                      -1.0762e-02, -1.9674e-03, -1.3291e-02,  3.0813e-02, -1.3610e-03,\n",
       "                       4.5526e-03,  2.5402e-02,  2.0468e-02,  1.6868e-02,  1.5769e-02,\n",
       "                      -3.7985e-03, -2.9739e-02,  3.6873e-02, -1.5693e-03, -2.0923e-02,\n",
       "                       4.5054e-02,  3.2104e-02, -3.1810e-03,  5.9307e-03, -2.4748e-03,\n",
       "                       2.8697e-02,  2.8321e-03,  4.0958e-02,  2.8253e-02,  3.6128e-02,\n",
       "                      -1.6234e-02,  1.5718e-02,  2.1499e-02,  3.2818e-02,  4.5780e-02,\n",
       "                       1.8265e-02, -2.2358e-02,  1.0330e-02, -8.1752e-03, -7.3849e-02,\n",
       "                      -7.7433e-02, -9.5062e-03,  5.6934e-02,  2.9798e-02, -5.6704e-02,\n",
       "                      -2.8998e-04,  3.8911e-02,  7.1862e-02,  2.8319e-02, -1.3835e-03,\n",
       "                       2.4380e-02,  4.7917e-02, -7.5812e-03,  4.3195e-02, -8.7772e-03,\n",
       "                       3.0336e-02, -2.1767e-02, -2.0313e-02, -5.7155e-02,  2.2238e-02,\n",
       "                      -1.7876e-02,  7.2475e-03,  5.9072e-02,  1.7254e-02,  3.5640e-02,\n",
       "                      -5.3690e-02,  3.1887e-02, -6.1408e-02,  1.1748e-02, -2.8399e-02,\n",
       "                       3.6311e-02,  3.8973e-02,  6.4906e-02,  7.8385e-03, -2.0935e-02,\n",
       "                      -5.8416e-02, -2.0047e-02, -3.1496e-02,  2.9189e-02, -3.4504e-02,\n",
       "                      -2.7514e-02,  6.8505e-02,  2.8062e-03,  1.8849e-05, -1.3774e-02,\n",
       "                       9.2343e-03,  3.7521e-02,  4.5121e-02,  1.4074e-02, -1.8121e-04,\n",
       "                      -4.0558e-02, -3.7644e-03,  1.6923e-02,  2.7104e-02, -1.5634e-02,\n",
       "                      -4.1377e-03,  9.3574e-03,  1.9628e-02,  5.6155e-02,  5.2343e-02,\n",
       "                       8.2967e-03, -3.7830e-03, -4.8709e-03, -8.8138e-03,  5.4959e-02,\n",
       "                       9.5033e-02, -8.7470e-03, -2.1711e-03, -2.7213e-02,  2.7870e-02,\n",
       "                      -6.4279e-02, -1.5909e-02, -4.3667e-02, -1.5132e-02, -9.5939e-03,\n",
       "                      -1.8963e-02, -6.7713e-03, -5.5545e-02, -1.0497e-02, -3.9040e-02,\n",
       "                      -4.8672e-03,  1.1762e-02, -1.5282e-02, -4.3349e-02, -5.3518e-02,\n",
       "                       4.6776e-03, -4.4651e-02, -4.5448e-02, -1.2307e-02,  1.7775e-02,\n",
       "                      -4.1911e-03,  2.1014e-02, -4.3004e-03,  2.7901e-02,  1.0977e-02,\n",
       "                      -7.3112e-03, -3.7840e-02, -1.7166e-03,  1.3762e-02, -2.5244e-02,\n",
       "                       1.1566e-02,  7.3994e-02, -4.3874e-03,  4.3512e-02, -4.0878e-02,\n",
       "                       1.8922e-03, -1.0121e-02, -2.9110e-02,  2.4583e-02, -4.8153e-02,\n",
       "                       2.5973e-02, -2.9922e-03, -2.0870e-02, -2.2877e-02, -1.4993e-03,\n",
       "                      -5.9943e-03, -7.2241e-03, -2.0146e-02,  1.2459e-02, -3.8290e-03,\n",
       "                      -2.0011e-02,  3.9809e-02,  1.3255e-02, -4.2352e-04,  1.7046e-02,\n",
       "                      -6.5159e-03,  1.2209e-02,  6.6373e-02, -1.1389e-02,  5.5789e-02,\n",
       "                       1.8531e-02, -1.1453e-02,  2.1218e-02,  1.8626e-02,  1.3585e-02,\n",
       "                      -3.0026e-02,  1.2386e-02, -9.9208e-03, -2.6795e-04, -8.1980e-03,\n",
       "                      -1.3025e-02, -1.7465e-02,  3.8352e-04, -2.6250e-02, -3.8193e-02,\n",
       "                       1.8636e-02, -7.6045e-03, -3.9300e-02,  1.3399e-03,  1.3233e-02,\n",
       "                       1.9639e-02, -1.1317e-02, -1.9422e-02, -3.2577e-02,  5.8234e-02],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.0.edge_encoder.1.running_var',\n",
       "              tensor([0.0007, 0.0011, 0.0017, 0.0010, 0.0004, 0.0005, 0.0011, 0.0008, 0.0008,\n",
       "                      0.0006, 0.0011, 0.0012, 0.0004, 0.0011, 0.0017, 0.0008, 0.0009, 0.0008,\n",
       "                      0.0008, 0.0017, 0.0010, 0.0005, 0.0005, 0.0005, 0.0007, 0.0009, 0.0004,\n",
       "                      0.0016, 0.0005, 0.0014, 0.0013, 0.0005, 0.0005, 0.0010, 0.0009, 0.0005,\n",
       "                      0.0009, 0.0014, 0.0012, 0.0007, 0.0004, 0.0008, 0.0005, 0.0008, 0.0010,\n",
       "                      0.0010, 0.0010, 0.0012, 0.0016, 0.0011, 0.0004, 0.0004, 0.0009, 0.0014,\n",
       "                      0.0009, 0.0013, 0.0004, 0.0005, 0.0009, 0.0005, 0.0003, 0.0009, 0.0005,\n",
       "                      0.0007, 0.0009, 0.0004, 0.0008, 0.0009, 0.0006, 0.0004, 0.0013, 0.0007,\n",
       "                      0.0007, 0.0006, 0.0007, 0.0004, 0.0007, 0.0007, 0.0007, 0.0003, 0.0020,\n",
       "                      0.0011, 0.0006, 0.0004, 0.0010, 0.0019, 0.0012, 0.0007, 0.0005, 0.0004,\n",
       "                      0.0005, 0.0009, 0.0012, 0.0007, 0.0007, 0.0014, 0.0015, 0.0009, 0.0009,\n",
       "                      0.0006, 0.0004, 0.0006, 0.0008, 0.0008, 0.0012, 0.0005, 0.0013, 0.0009,\n",
       "                      0.0006, 0.0015, 0.0007, 0.0006, 0.0007, 0.0010, 0.0010, 0.0010, 0.0005,\n",
       "                      0.0006, 0.0006, 0.0005, 0.0003, 0.0008, 0.0007, 0.0010, 0.0008, 0.0009,\n",
       "                      0.0008, 0.0012, 0.0011, 0.0014, 0.0014, 0.0012, 0.0019, 0.0012, 0.0016,\n",
       "                      0.0008, 0.0008, 0.0006, 0.0006, 0.0012, 0.0004, 0.0006, 0.0020, 0.0009,\n",
       "                      0.0004, 0.0004, 0.0010, 0.0010, 0.0006, 0.0004, 0.0008, 0.0006, 0.0010,\n",
       "                      0.0016, 0.0006, 0.0004, 0.0010, 0.0015, 0.0007, 0.0009, 0.0008, 0.0008,\n",
       "                      0.0005, 0.0006, 0.0010, 0.0003, 0.0010, 0.0007, 0.0005, 0.0007, 0.0007,\n",
       "                      0.0008, 0.0009, 0.0022, 0.0009, 0.0007, 0.0006, 0.0006, 0.0006, 0.0014,\n",
       "                      0.0004, 0.0004, 0.0003, 0.0004, 0.0008, 0.0010, 0.0010, 0.0010, 0.0016,\n",
       "                      0.0016, 0.0008, 0.0008, 0.0017, 0.0004, 0.0013, 0.0004, 0.0015, 0.0007,\n",
       "                      0.0011, 0.0009], device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.0.edge_encoder.1.num_batches_tracked',\n",
       "              tensor(318750, device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.0.edge_encoder.3.weight',\n",
       "              tensor([[-0.0193, -0.0094, -0.0241,  ...,  0.0122, -0.0301, -0.0028],\n",
       "                      [ 0.0069,  0.0188,  0.0111,  ..., -0.0008, -0.0141,  0.0301],\n",
       "                      [ 0.0371, -0.0236, -0.0005,  ..., -0.0178,  0.0145,  0.0044],\n",
       "                      ...,\n",
       "                      [ 0.0266,  0.0113,  0.0204,  ..., -0.0058,  0.0168, -0.0279],\n",
       "                      [ 0.0263, -0.0120,  0.0145,  ..., -0.0088,  0.0285, -0.0355],\n",
       "                      [ 0.0217,  0.0041,  0.0519,  ...,  0.0308, -0.0709, -0.0156]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.0.edge_encoder.3.bias',\n",
       "              tensor([-2.3653e-03, -5.7033e-03,  2.7150e-03,  1.7915e-03, -1.3082e-03,\n",
       "                      -3.1844e-04,  8.8534e-04, -5.2766e-03,  1.3499e-03,  4.7690e-03,\n",
       "                      -4.6336e-03,  1.4850e-03, -3.2236e-03,  3.7453e-03, -8.5289e-03,\n",
       "                       7.5043e-03,  5.8532e-03,  2.3962e-04, -5.7625e-04,  5.2903e-04,\n",
       "                      -1.7449e-03,  5.2435e-03,  2.9055e-03, -4.1971e-03, -5.6767e-03,\n",
       "                      -4.0691e-03, -1.4285e-03,  5.0252e-03, -1.9099e-03,  1.1951e-03,\n",
       "                       2.1446e-03, -2.3171e-03,  5.1971e-03,  1.3342e-03, -6.3974e-03,\n",
       "                       7.7394e-04, -5.0417e-03, -4.6538e-04,  8.4626e-03, -4.4000e-04,\n",
       "                      -7.0619e-04,  4.7418e-03, -5.4846e-03, -5.1588e-03, -7.3695e-03,\n",
       "                      -9.4579e-03,  4.9077e-03, -5.9823e-03,  1.0702e-03, -2.1661e-03,\n",
       "                       1.0390e-03,  1.1983e-03, -4.2399e-03, -1.2942e-03, -7.8520e-03,\n",
       "                      -3.5293e-03, -1.0280e-02,  3.5102e-04,  3.8343e-03, -1.2780e-03,\n",
       "                       4.5618e-04,  3.8666e-03,  1.8226e-03,  4.2149e-03, -7.9116e-03,\n",
       "                      -6.3569e-03,  7.4834e-04,  4.8660e-04, -3.4787e-03, -3.4874e-03,\n",
       "                      -2.9350e-03,  6.0196e-03,  2.0707e-03,  6.1710e-03, -2.5195e-04,\n",
       "                       2.7551e-03, -3.0170e-03, -3.2106e-03, -5.5723e-05,  5.0233e-03,\n",
       "                      -5.5378e-03, -8.5195e-03,  2.5666e-03, -1.8356e-03,  1.2716e-03,\n",
       "                      -1.2945e-03,  1.9425e-03,  8.8292e-04,  2.0636e-03,  1.4934e-03,\n",
       "                      -1.9848e-03,  9.8496e-03, -2.1664e-03,  1.9293e-03, -3.8735e-03,\n",
       "                      -5.7664e-03,  3.7731e-03, -2.0194e-03,  5.2783e-03,  3.5625e-03,\n",
       "                      -4.3390e-03, -4.5637e-03,  6.6010e-03,  3.1173e-03,  4.0452e-03,\n",
       "                      -2.6583e-03,  4.5262e-03, -1.5825e-03, -4.2482e-03, -3.4520e-03,\n",
       "                       2.3763e-03,  3.6228e-03,  1.7307e-03,  1.0506e-03,  4.2683e-03,\n",
       "                      -3.5708e-04, -2.0222e-03, -1.5319e-03,  4.2033e-03, -6.7279e-03,\n",
       "                       1.4046e-03,  2.9070e-03,  3.6665e-03,  1.5358e-03,  2.2912e-03,\n",
       "                       1.5417e-03, -5.5028e-03,  1.9160e-03, -3.6478e-03, -3.0722e-03,\n",
       "                      -6.0849e-04,  4.6370e-03,  1.5033e-03,  7.6505e-03,  1.1843e-03,\n",
       "                      -2.6880e-03, -7.3885e-04, -1.9909e-03, -4.8474e-03,  7.0672e-03,\n",
       "                       7.6360e-03, -5.4759e-03, -6.0674e-03, -1.4287e-03,  1.6351e-03,\n",
       "                       4.7338e-03, -4.7588e-03, -5.5839e-03,  1.8682e-03, -1.0032e-03,\n",
       "                      -1.1349e-04,  6.5163e-03,  7.6160e-04,  6.0492e-03,  2.1817e-03,\n",
       "                       5.5140e-04, -5.6854e-03,  2.1677e-04,  1.8623e-03,  1.7347e-03,\n",
       "                      -3.2468e-03,  2.5972e-03, -1.4406e-03, -4.4453e-03, -6.4311e-03,\n",
       "                      -3.7272e-03,  2.8988e-03, -3.4194e-03,  8.8222e-04,  3.5037e-03,\n",
       "                       4.3227e-04, -1.8212e-03,  1.9136e-03, -3.1052e-03, -5.8780e-03,\n",
       "                      -9.3809e-04,  2.1546e-03, -5.0847e-03, -5.3777e-03, -3.2735e-03,\n",
       "                       1.7199e-04, -1.1658e-03,  3.6198e-03,  4.1820e-03,  1.1943e-04,\n",
       "                      -1.7642e-03,  4.1916e-03,  8.8105e-04, -6.2575e-03,  6.1010e-03,\n",
       "                      -4.3334e-04,  1.6691e-03,  8.9472e-06,  5.3347e-03,  4.1516e-03,\n",
       "                       4.4639e-03,  4.7324e-03, -6.6560e-04, -5.5783e-03,  1.1676e-03],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.0.linear_key.weight',\n",
       "              tensor([[-0.0106, -0.0202,  0.0185,  ...,  0.0253,  0.0045,  0.0275],\n",
       "                      [-0.0210,  0.0047, -0.0176,  ..., -0.0228, -0.0010,  0.0040],\n",
       "                      [-0.0289, -0.0460,  0.0422,  ..., -0.0065,  0.0403, -0.0174],\n",
       "                      ...,\n",
       "                      [ 0.0261, -0.0126,  0.0230,  ..., -0.0217, -0.0105, -0.0238],\n",
       "                      [ 0.0208, -0.0345,  0.0073,  ...,  0.0367,  0.0091, -0.0063],\n",
       "                      [ 0.0282, -0.0078,  0.0024,  ...,  0.0098,  0.0292, -0.0101]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.0.linear_key.bias',\n",
       "              tensor([ 0.0062, -0.0041, -0.0065, -0.0044,  0.0086, -0.0033, -0.0039,  0.0073,\n",
       "                       0.0069, -0.0070, -0.0016, -0.0057,  0.0053, -0.0058,  0.0021,  0.0104,\n",
       "                      -0.0075,  0.0005, -0.0076, -0.0022, -0.0096, -0.0102,  0.0071, -0.0090,\n",
       "                       0.0084,  0.0051,  0.0006,  0.0091, -0.0088, -0.0021,  0.0104, -0.0083,\n",
       "                       0.0028,  0.0077,  0.0064,  0.0041, -0.0031,  0.0082,  0.0040,  0.0100,\n",
       "                      -0.0019, -0.0126, -0.0043, -0.0051,  0.0089,  0.0056, -0.0024,  0.0069,\n",
       "                      -0.0074, -0.0072, -0.0112, -0.0041,  0.0057, -0.0042, -0.0093,  0.0038,\n",
       "                      -0.0053,  0.0095,  0.0034, -0.0016,  0.0031,  0.0016,  0.0073, -0.0068,\n",
       "                       0.0007, -0.0001, -0.0089, -0.0075, -0.0041,  0.0040, -0.0031,  0.0062,\n",
       "                       0.0051, -0.0042, -0.0060, -0.0027, -0.0070,  0.0045,  0.0074, -0.0039,\n",
       "                      -0.0030, -0.0042, -0.0005,  0.0041, -0.0031,  0.0040, -0.0049, -0.0022,\n",
       "                       0.0077, -0.0033,  0.0015, -0.0066, -0.0086,  0.0092, -0.0035,  0.0047,\n",
       "                       0.0052, -0.0002, -0.0043,  0.0080,  0.0057,  0.0029, -0.0151,  0.0078,\n",
       "                       0.0008,  0.0150,  0.0152, -0.0022,  0.0164, -0.0047, -0.0060, -0.0075,\n",
       "                       0.0022, -0.0127, -0.0057,  0.0104,  0.0111, -0.0102,  0.0073,  0.0035,\n",
       "                       0.0109,  0.0078,  0.0123,  0.0006,  0.0092,  0.0026, -0.0080,  0.0109,\n",
       "                       0.0055, -0.0064, -0.0010, -0.0057,  0.0070,  0.0085, -0.0023, -0.0092,\n",
       "                       0.0038,  0.0098,  0.0015, -0.0062,  0.0032, -0.0029,  0.0014, -0.0069,\n",
       "                       0.0118, -0.0097,  0.0092, -0.0093, -0.0157,  0.0103, -0.0070,  0.0070,\n",
       "                       0.0085,  0.0110, -0.0085,  0.0006,  0.0075, -0.0085,  0.0102,  0.0045,\n",
       "                       0.0090,  0.0062, -0.0001, -0.0071,  0.0108, -0.0087,  0.0081,  0.0065,\n",
       "                      -0.0109,  0.0016, -0.0082,  0.0088, -0.0100,  0.0067,  0.0065,  0.0116,\n",
       "                       0.0063, -0.0071, -0.0094,  0.0094, -0.0045,  0.0038,  0.0016, -0.0075,\n",
       "                      -0.0055, -0.0074,  0.0080,  0.0098,  0.0069, -0.0078,  0.0054,  0.0097,\n",
       "                      -0.0071,  0.0076, -0.0039, -0.0060, -0.0042,  0.0120, -0.0051, -0.0082],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.0.linear_msg.weight',\n",
       "              tensor([[-0.0228, -0.0136,  0.0378,  ...,  0.0103,  0.0072,  0.0245],\n",
       "                      [ 0.0141,  0.0123,  0.0028,  ...,  0.0038, -0.0335,  0.0066],\n",
       "                      [-0.0132,  0.0015, -0.0101,  ...,  0.0129, -0.0269, -0.0066],\n",
       "                      ...,\n",
       "                      [ 0.0091, -0.0016,  0.0010,  ..., -0.0147,  0.0196, -0.0031],\n",
       "                      [-0.0192, -0.0216,  0.0086,  ..., -0.0150, -0.0088, -0.0219],\n",
       "                      [-0.0175,  0.0138,  0.0052,  ...,  0.0363,  0.0165,  0.0085]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.0.linear_msg.bias',\n",
       "              tensor([-5.3866e-03,  3.0472e-03, -1.0344e-03, -5.3162e-04,  4.4062e-03,\n",
       "                      -5.0716e-04, -1.9276e-03, -1.0177e-03,  1.3567e-04, -5.5970e-03,\n",
       "                      -2.7851e-03, -3.2132e-03, -3.1636e-03, -4.6914e-03,  4.6552e-03,\n",
       "                       3.0255e-03, -1.1477e-04,  6.7326e-03,  2.1525e-03,  2.0842e-03,\n",
       "                      -1.4159e-03, -1.8816e-03, -2.7430e-03, -2.0253e-03, -3.3133e-03,\n",
       "                       3.3950e-03, -6.2218e-03, -2.5583e-03,  2.9504e-04,  1.7181e-03,\n",
       "                       3.4868e-03,  3.0991e-03, -2.7674e-03,  2.9744e-03, -1.8529e-03,\n",
       "                      -9.6815e-04,  2.7556e-03, -2.0071e-03, -4.9960e-03,  1.4318e-03,\n",
       "                       3.5195e-03,  8.9290e-04, -9.6203e-04, -8.4096e-04,  1.8201e-03,\n",
       "                       6.7590e-04, -1.2261e-03,  4.2595e-03, -3.2022e-03, -5.6928e-03,\n",
       "                       2.2211e-03,  3.8597e-03,  4.9066e-04, -5.1769e-03, -6.4566e-03,\n",
       "                       1.7851e-04,  2.2519e-03, -1.0342e-03,  2.2334e-03, -1.1121e-03,\n",
       "                       6.2233e-03,  1.2440e-03, -6.4151e-03, -5.2799e-03, -4.2084e-03,\n",
       "                       1.6557e-03, -6.4561e-03, -3.9376e-03, -4.7575e-03, -1.3776e-03,\n",
       "                      -3.5366e-04,  3.2539e-03, -1.0009e-03,  6.7041e-03,  1.5076e-03,\n",
       "                       5.7761e-03,  3.6461e-03,  1.0494e-03,  4.5584e-03, -3.4759e-03,\n",
       "                      -1.1976e-03,  2.3873e-03,  1.8791e-03,  1.5094e-03,  1.4184e-03,\n",
       "                       2.5880e-03, -7.2604e-03, -1.0552e-03, -2.6439e-05, -4.9412e-03,\n",
       "                       8.3266e-04, -4.9513e-04, -1.0583e-03,  3.8993e-03, -1.7337e-03,\n",
       "                      -3.7942e-04,  4.3113e-03, -2.6372e-03, -1.3806e-03, -3.9547e-03,\n",
       "                       2.8319e-03, -2.2481e-03, -1.8163e-03, -1.4476e-03, -1.2262e-03,\n",
       "                      -3.8608e-03, -1.7584e-05,  1.3355e-03,  8.8289e-04,  7.9991e-03,\n",
       "                      -4.4043e-03, -5.5194e-04,  6.6556e-04, -6.3916e-03, -4.4201e-03,\n",
       "                      -1.5257e-03,  3.2736e-03,  1.9878e-03,  8.7840e-04, -4.3335e-04,\n",
       "                      -2.3059e-03, -4.2504e-03,  4.0734e-03,  2.5762e-03, -4.3900e-03,\n",
       "                      -2.6048e-03,  1.8696e-04,  4.6470e-03, -4.5471e-03, -3.7266e-03,\n",
       "                       3.9076e-03, -4.3486e-03,  4.3420e-03, -1.6889e-03,  6.5492e-04,\n",
       "                      -2.3457e-03, -2.9297e-03,  5.5363e-03, -7.1009e-03, -7.8910e-05,\n",
       "                      -4.0479e-03,  3.1595e-03, -1.1460e-03,  1.8486e-04, -1.7223e-03,\n",
       "                      -6.3869e-04, -1.6900e-05,  7.3376e-04, -3.6445e-03,  1.4384e-04,\n",
       "                       2.0924e-03, -3.5593e-03, -7.7534e-04,  2.3928e-03, -4.3426e-03,\n",
       "                       1.3877e-03, -7.9062e-03, -5.3592e-04,  4.3111e-04, -1.5242e-03,\n",
       "                      -7.4259e-04,  9.6477e-04, -4.3018e-04,  1.4458e-03,  3.8325e-03,\n",
       "                      -4.8453e-03,  4.3459e-04, -1.8165e-03, -2.8510e-03, -1.9727e-03,\n",
       "                      -4.6783e-03, -9.2575e-04,  2.4676e-03,  2.8578e-03, -1.8531e-03,\n",
       "                      -1.6163e-03,  6.8544e-03, -5.0037e-03,  9.3849e-04,  1.0190e-04,\n",
       "                      -3.6624e-03, -2.2480e-03,  7.4023e-03,  3.3938e-03, -4.4973e-03,\n",
       "                      -3.8005e-03,  3.5912e-04,  1.0327e-03, -5.3150e-05,  2.3432e-04,\n",
       "                      -6.6851e-04, -4.5942e-05, -5.3540e-03,  9.8767e-04,  3.0459e-03,\n",
       "                      -2.0120e-03,  3.3563e-04, -7.3079e-03, -2.6687e-04, -2.6506e-03],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.0.linear_query.weight',\n",
       "              tensor([[-0.0516,  0.0422, -0.0176,  ...,  0.0181, -0.0072, -0.0207],\n",
       "                      [ 0.0044,  0.0371, -0.0092,  ..., -0.0263, -0.0037, -0.0234],\n",
       "                      [ 0.0194, -0.0003, -0.0198,  ..., -0.0082, -0.0765, -0.0691],\n",
       "                      ...,\n",
       "                      [-0.0085,  0.0230, -0.0192,  ...,  0.0032,  0.0584,  0.0417],\n",
       "                      [-0.0150,  0.0114, -0.0310,  ..., -0.0136, -0.0547,  0.0063],\n",
       "                      [-0.0165, -0.0309,  0.0039,  ..., -0.0168, -0.0604,  0.0306]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.0.linear_query.bias',\n",
       "              tensor([-1.3048e-03,  1.3143e-02, -3.3463e-02, -7.2562e-04,  1.5190e-02,\n",
       "                      -1.3565e-02,  1.5085e-02,  3.4892e-02,  6.7004e-03, -1.6388e-03,\n",
       "                       2.3456e-02, -1.0326e-02,  1.5233e-02,  1.3043e-02, -3.1203e-03,\n",
       "                       9.0739e-03, -1.0168e-02,  1.4681e-02,  1.0482e-02,  2.6054e-02,\n",
       "                      -1.1218e-02,  2.6627e-03,  1.2981e-02, -2.8519e-02,  2.7826e-02,\n",
       "                      -8.0169e-03,  1.3386e-02,  2.3689e-02, -2.4517e-02, -3.0640e-02,\n",
       "                       4.4019e-03, -3.3055e-02,  1.7341e-02,  1.0518e-02,  4.5549e-03,\n",
       "                      -1.4672e-02, -1.8012e-02,  4.2676e-03, -1.6038e-03, -4.9228e-04,\n",
       "                       2.6198e-02, -1.2262e-02, -1.5125e-02, -2.7033e-02, -1.2969e-02,\n",
       "                      -1.4183e-02, -2.8728e-02,  1.3277e-02, -2.9277e-02, -8.1257e-03,\n",
       "                      -1.2792e-02,  1.6587e-02, -1.3765e-02,  4.1715e-04,  5.5216e-03,\n",
       "                      -5.8891e-04,  1.5046e-02, -1.4608e-03, -3.2937e-03,  5.9999e-03,\n",
       "                       1.3464e-02, -1.7645e-02, -1.2387e-02, -1.1575e-02, -1.0044e-02,\n",
       "                       1.4430e-02, -1.1802e-03,  9.8546e-03,  6.4404e-04, -1.4425e-02,\n",
       "                      -1.0247e-02, -9.0136e-03, -4.0311e-03, -2.8320e-03,  2.1966e-03,\n",
       "                      -1.3616e-02, -3.0786e-02,  1.1851e-02,  1.5997e-02,  2.3208e-03,\n",
       "                      -1.3942e-02, -5.7350e-04,  6.6263e-03, -1.5375e-02, -3.2511e-03,\n",
       "                      -1.7610e-02, -1.6912e-02,  2.9337e-02,  4.9077e-03, -8.7931e-03,\n",
       "                      -4.5261e-03,  1.6456e-02, -1.4535e-02,  8.8477e-03,  8.9052e-03,\n",
       "                       1.5605e-02, -1.3958e-03,  2.2376e-02,  1.9827e-04, -1.0853e-02,\n",
       "                      -5.3569e-03, -1.1689e-02, -1.7394e-03,  5.2226e-03,  1.7148e-02,\n",
       "                      -1.2738e-03, -4.0904e-03,  1.5384e-02, -9.2010e-04,  5.0495e-03,\n",
       "                       2.5212e-03,  6.8434e-03, -1.5197e-02,  7.1419e-03, -3.6426e-03,\n",
       "                      -1.9545e-02, -9.2928e-03,  1.1005e-02,  2.5226e-03,  2.0247e-03,\n",
       "                      -9.7193e-04,  7.3842e-04,  2.6807e-03, -9.0500e-03,  1.1912e-02,\n",
       "                       1.7487e-02,  7.4282e-03, -8.9033e-03,  1.1504e-02,  1.6194e-02,\n",
       "                      -8.8229e-03,  1.4104e-02,  8.6888e-03, -1.8632e-02, -2.3129e-02,\n",
       "                      -1.6390e-02, -5.4067e-03,  1.2599e-03,  2.6884e-02,  3.1190e-02,\n",
       "                       2.4626e-02,  1.1444e-02, -1.3179e-02, -2.0083e-02,  1.7062e-02,\n",
       "                      -1.1387e-02, -8.1498e-03,  1.0283e-02, -1.4465e-04,  1.0825e-02,\n",
       "                       4.5048e-03,  2.0595e-02, -7.7697e-03,  2.1224e-02, -2.4167e-02,\n",
       "                      -5.4129e-02, -1.9526e-02, -4.0584e-03,  1.3167e-02,  3.4534e-02,\n",
       "                       1.6628e-02,  1.7803e-02, -1.4351e-02, -2.3478e-02,  1.9458e-02,\n",
       "                      -1.2051e-02, -1.0052e-02,  7.2822e-03, -1.8264e-02,  3.2259e-03,\n",
       "                       6.7427e-03,  2.7694e-02, -8.3914e-03,  2.3780e-02, -3.3070e-03,\n",
       "                       2.4565e-02, -2.0493e-03, -9.4827e-03, -6.1265e-03,  6.8538e-03,\n",
       "                       1.9393e-02, -1.2401e-02, -4.5486e-03,  2.6165e-03, -1.7986e-02,\n",
       "                      -1.7136e-02,  1.6973e-02,  2.3761e-02,  9.4050e-05, -2.0901e-03,\n",
       "                       2.1286e-03,  6.5724e-03,  8.2721e-03,  1.8670e-02, -1.2718e-02,\n",
       "                      -3.1985e-02,  6.5126e-03,  9.9794e-03, -1.4638e-02,  1.3826e-03],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.0.mlp.0.weight',\n",
       "              tensor([[ 1.6657e-02,  1.5687e-02,  1.8132e-02,  ..., -1.4661e-02,\n",
       "                       -3.3071e-02, -1.7409e-02],\n",
       "                      [-1.3960e-02, -9.6247e-03,  6.7486e-03,  ..., -1.2627e-02,\n",
       "                        2.5252e-02, -3.9537e-02],\n",
       "                      [ 2.7990e-02, -1.4181e-02,  9.4380e-03,  ..., -9.8569e-03,\n",
       "                        1.8601e-02, -2.6674e-03],\n",
       "                      ...,\n",
       "                      [-9.2366e-03, -7.1377e-03, -2.0369e-02,  ...,  3.4515e-02,\n",
       "                        2.8048e-02, -1.0333e-02],\n",
       "                      [ 1.6878e-02, -2.0961e-02, -2.0579e-02,  ...,  1.6305e-02,\n",
       "                        2.0228e-02,  3.1984e-02],\n",
       "                      [ 4.3229e-05, -2.1610e-03, -8.0335e-03,  ..., -6.2529e-03,\n",
       "                       -1.1305e-02, -3.6424e-03]], device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.0.mlp.0.bias',\n",
       "              tensor([ 4.3577e-04,  4.5820e-03,  2.0473e-04, -9.9302e-04, -4.1997e-04,\n",
       "                      -4.1784e-03,  1.3987e-04, -1.3511e-03,  3.9601e-03, -1.9253e-03,\n",
       "                       2.2642e-03, -2.8373e-03,  2.6042e-03, -2.2477e-03, -8.4316e-03,\n",
       "                      -9.6520e-04,  6.0221e-03,  2.0839e-03, -3.1792e-03, -4.2746e-04,\n",
       "                       8.0884e-03,  8.4101e-04, -1.0612e-02,  3.7318e-03,  3.6280e-03,\n",
       "                      -3.8061e-03, -1.3495e-03,  1.4304e-03,  1.2664e-03, -1.1938e-04,\n",
       "                      -1.8676e-03,  3.6770e-03,  2.1746e-03, -4.5699e-04,  6.9460e-04,\n",
       "                       1.5253e-03, -5.8806e-03,  8.1981e-04,  2.1371e-03,  8.2786e-04,\n",
       "                       2.2283e-03, -5.6783e-03,  9.6302e-03,  4.4967e-04, -6.1133e-03,\n",
       "                      -7.9009e-03, -4.3020e-03, -2.4285e-03,  1.7245e-03,  3.9040e-03,\n",
       "                      -1.6543e-03, -9.5191e-04, -1.6804e-03,  5.3263e-04,  2.1484e-04,\n",
       "                      -5.6396e-03, -1.2658e-03, -1.3699e-03,  3.0223e-03, -1.1091e-03,\n",
       "                      -4.9535e-03,  1.3860e-03,  7.8258e-04, -4.9289e-03,  2.3428e-03,\n",
       "                       5.1881e-03, -9.4750e-03, -1.2560e-03, -9.5026e-04, -1.2661e-03,\n",
       "                       4.1446e-04,  3.5657e-03, -5.5326e-03, -1.0391e-02, -1.1088e-03,\n",
       "                      -3.8792e-04,  1.6971e-03, -1.2756e-03, -2.1508e-03,  9.6928e-03,\n",
       "                      -2.2760e-03, -2.4665e-03, -3.1939e-03, -3.0002e-03, -8.3616e-03,\n",
       "                       3.9118e-03, -4.2371e-03, -9.5879e-04, -4.0399e-03,  8.7206e-03,\n",
       "                       6.9614e-04,  3.0378e-03, -5.9039e-03,  3.2617e-03, -4.2223e-03,\n",
       "                       4.9237e-03, -1.4390e-03,  4.9815e-03, -6.6383e-04, -4.2856e-03,\n",
       "                       3.5415e-04, -2.3182e-03, -3.1924e-03, -2.2508e-03,  6.1779e-03,\n",
       "                       3.5841e-03, -1.4417e-03,  1.3432e-03, -1.0841e-03, -8.5003e-03,\n",
       "                      -5.1482e-03, -4.3417e-04,  1.3911e-03, -3.6372e-03,  5.6898e-03,\n",
       "                       1.9619e-04, -5.6147e-03, -5.4285e-03, -3.3266e-03,  9.0165e-03,\n",
       "                       4.9857e-04, -2.1467e-03,  4.2012e-04, -8.8901e-03, -1.3858e-03,\n",
       "                      -2.6379e-03,  2.0068e-03, -1.5239e-03, -2.4281e-03, -2.4368e-03,\n",
       "                      -2.5441e-03,  2.5771e-03,  7.5714e-03, -1.0776e-03, -8.3730e-04,\n",
       "                       1.8768e-03, -7.5132e-04, -5.3999e-03, -4.3701e-03,  3.6481e-04,\n",
       "                      -1.1754e-03, -1.6872e-03, -9.9957e-03,  5.9752e-03, -5.4038e-03,\n",
       "                      -2.0414e-04, -6.7352e-03, -2.8580e-03,  1.9297e-03,  6.3862e-03,\n",
       "                      -8.0581e-03,  4.6839e-03,  9.7868e-04, -5.3781e-03, -3.7238e-03,\n",
       "                      -1.6839e-03, -3.5489e-03, -5.6342e-03, -5.2945e-03,  1.2134e-03,\n",
       "                      -3.5639e-03, -1.5847e-05,  2.3967e-04,  3.5757e-05,  1.7236e-03,\n",
       "                       1.4886e-03,  4.1967e-04, -5.6321e-03, -2.1316e-03,  5.1023e-03,\n",
       "                      -2.0554e-03,  6.4604e-04,  2.6754e-03,  6.6370e-04,  6.2641e-04,\n",
       "                       1.1659e-03,  3.3413e-03, -6.0628e-03, -1.0826e-03, -8.3559e-03,\n",
       "                      -2.1499e-03, -8.1090e-03,  5.9019e-04, -5.6903e-03,  8.2018e-06,\n",
       "                      -1.1093e-03, -1.8331e-03, -1.0566e-03,  1.0607e-03,  6.0064e-03,\n",
       "                       1.1950e-03,  1.0427e-04, -3.7364e-03, -1.0931e-03,  6.9853e-03,\n",
       "                       9.2327e-03, -2.6022e-03,  3.6978e-04, -1.3585e-04, -3.2480e-03],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.0.mlp.1.weight',\n",
       "              tensor([0.9653, 0.9636, 0.9631, 0.9629, 0.9647, 0.9761, 0.9731, 0.9756, 0.9680,\n",
       "                      0.9558, 0.9764, 0.9680, 0.9786, 0.9773, 0.9798, 0.9763, 0.9746, 0.9746,\n",
       "                      0.9734, 0.9764, 0.9814, 0.9577, 0.9787, 0.9711, 0.9804, 0.9538, 0.9744,\n",
       "                      0.9728, 0.9766, 0.9717, 0.9664, 0.9764, 0.9793, 0.9770, 0.9780, 0.9667,\n",
       "                      0.9716, 0.9560, 0.9691, 0.9780, 0.9593, 0.9639, 0.9707, 0.9735, 0.9769,\n",
       "                      0.9770, 0.9439, 0.9561, 0.9756, 0.9781, 0.9770, 0.9687, 0.9788, 0.9756,\n",
       "                      0.9609, 0.9633, 0.9733, 0.9771, 0.9699, 0.9691, 0.9779, 0.9660, 0.9545,\n",
       "                      0.9661, 0.9884, 0.9622, 0.9777, 0.9561, 0.9751, 0.9751, 0.9740, 0.9566,\n",
       "                      0.9669, 0.9516, 0.9708, 0.9735, 0.9793, 0.9624, 0.9774, 0.9798, 0.9716,\n",
       "                      0.9754, 0.9605, 0.9618, 0.9676, 0.9850, 0.9759, 0.9738, 0.9576, 0.9645,\n",
       "                      0.9793, 0.9623, 0.9603, 0.9696, 0.9749, 0.9685, 0.9762, 0.9709, 0.9704,\n",
       "                      0.9683, 0.9728, 0.9678, 0.9556, 0.9601, 0.9758, 0.9624, 0.9594, 0.9761,\n",
       "                      0.9816, 0.9754, 0.9707, 0.9735, 0.9727, 0.9709, 0.9682, 0.9775, 0.9520,\n",
       "                      0.9637, 0.9723, 0.9590, 0.9728, 0.9780, 0.9760, 0.9804, 0.9509, 0.9667,\n",
       "                      0.9747, 0.9666, 0.9786, 0.9748, 0.9688, 0.9690, 0.9713, 0.9781, 0.9821,\n",
       "                      0.9755, 0.9746, 0.9820, 0.9745, 0.9743, 0.9751, 0.9539, 0.9838, 0.9692,\n",
       "                      0.9769, 0.9662, 0.9480, 0.9574, 0.9561, 0.9437, 0.9549, 0.9658, 0.9747,\n",
       "                      0.9765, 0.9786, 0.9724, 0.9416, 0.9754, 0.9708, 0.9834, 0.9747, 0.9758,\n",
       "                      0.9730, 0.9586, 0.9730, 0.9727, 0.9777, 0.9644, 0.9663, 0.9750, 0.9716,\n",
       "                      0.9679, 0.9814, 0.9718, 0.9597, 0.9477, 0.9707, 0.9680, 0.9679, 0.9678,\n",
       "                      0.9598, 0.9481, 0.9717, 0.9719, 0.9556, 0.9656, 0.9721, 0.9563, 0.9765,\n",
       "                      0.9759, 0.9809, 0.9448, 0.9674, 0.9758, 0.9681, 0.9673, 0.9708, 0.9795,\n",
       "                      0.9696, 0.9712], device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.0.mlp.1.bias',\n",
       "              tensor([-0.0108, -0.0142, -0.0075, -0.0093, -0.0079, -0.0088,  0.0046, -0.0091,\n",
       "                      -0.0015, -0.0090, -0.0092, -0.0093, -0.0020, -0.0052, -0.0091, -0.0079,\n",
       "                      -0.0074, -0.0056, -0.0060,  0.0068, -0.0117, -0.0177, -0.0035, -0.0086,\n",
       "                      -0.0073, -0.0080, -0.0079, -0.0190, -0.0020, -0.0114,  0.0061, -0.0016,\n",
       "                      -0.0090,  0.0080, -0.0087, -0.0072, -0.0071, -0.0150, -0.0039, -0.0022,\n",
       "                      -0.0189, -0.0084, -0.0051, -0.0060, -0.0052, -0.0100, -0.0161, -0.0146,\n",
       "                       0.0008, -0.0077, -0.0075, -0.0079,  0.0055, -0.0046, -0.0147, -0.0091,\n",
       "                      -0.0070, -0.0065, -0.0104, -0.0070, -0.0030, -0.0124, -0.0098, -0.0012,\n",
       "                      -0.0222, -0.0101, -0.0105, -0.0171, -0.0013, -0.0019, -0.0015, -0.0129,\n",
       "                      -0.0064, -0.0232, -0.0029,  0.0017,  0.0014, -0.0163, -0.0148, -0.0015,\n",
       "                      -0.0006, -0.0060, -0.0103, -0.0062, -0.0076, -0.0040, -0.0058, -0.0018,\n",
       "                      -0.0152, -0.0078, -0.0004, -0.0118, -0.0068, -0.0212, -0.0063, -0.0066,\n",
       "                      -0.0117, -0.0209, -0.0001, -0.0079, -0.0082, -0.0123, -0.0021, -0.0069,\n",
       "                      -0.0081, -0.0159, -0.0077, -0.0049,  0.0011, -0.0037, -0.0078, -0.0078,\n",
       "                      -0.0061, -0.0060, -0.0110, -0.0069,  0.0013, -0.0242, -0.0067, -0.0196,\n",
       "                      -0.0067, -0.0045, -0.0053,  0.0083, -0.0037, -0.0144, -0.0039, -0.0012,\n",
       "                      -0.0030, -0.0023, -0.0086, -0.0106, -0.0029, -0.0080,  0.0041, -0.0049,\n",
       "                      -0.0013,  0.0034, -0.0041, -0.0114, -0.0026, -0.0113,  0.0101, -0.0052,\n",
       "                      -0.0014, -0.0020, -0.0224, -0.0005, -0.0106, -0.0045, -0.0310, -0.0026,\n",
       "                      -0.0049,  0.0023,  0.0017, -0.0076, -0.0264, -0.0108, -0.0033, -0.0010,\n",
       "                      -0.0033, -0.0081, -0.0064, -0.0147,  0.0080, -0.0106, -0.0030, -0.0130,\n",
       "                      -0.0171,  0.0060, -0.0079, -0.0098, -0.0074, -0.0027, -0.0021, -0.0119,\n",
       "                      -0.0063, -0.0159, -0.0008,  0.0036, -0.0126, -0.0245,  0.0001, -0.0244,\n",
       "                      -0.0291, -0.0142, -0.0039, -0.0146, -0.0011, -0.0099,  0.0081, -0.0181,\n",
       "                      -0.0038, -0.0040, -0.0022, -0.0184, -0.0072,  0.0006, -0.0068, -0.0065],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.0.mlp.1.running_mean',\n",
       "              tensor([ 0.0348, -0.6955, -0.3395, -0.5132, -0.5143, -0.7179, -0.1752, -0.0833,\n",
       "                      -0.3422, -0.2998, -0.4089, -0.5220, -0.3514, -0.2437, -0.5897,  0.1467,\n",
       "                      -0.4386, -0.7936, -0.1423,  0.2878, -0.3872, -0.4091, -0.3015, -0.4604,\n",
       "                      -0.9507, -1.0802, -0.1988, -0.0728, -0.0120, -0.6125, -0.2735, -0.4206,\n",
       "                      -0.1806,  0.2414, -0.2712, -0.3150, -0.5112, -0.2677, -0.4636, -0.1690,\n",
       "                      -0.5382, -0.5978, -0.7204, -0.4606, -0.2252, -0.3948, -1.0849, -0.0471,\n",
       "                       0.9185, -0.1615, -0.1606, -0.1482, -0.1835, -0.3528, -1.0209, -0.5745,\n",
       "                      -0.5423, -0.2527, -0.7287,  0.4678,  0.0145, -0.7268,  0.6900,  0.4437,\n",
       "                       0.5461, -0.5311, -0.2255, -0.2552, -0.4489, -0.9165, -0.0913, -1.5561,\n",
       "                      -0.3915, -0.7370, -0.4230, -0.2617, -0.3447, -1.1374,  0.5902, -0.2980,\n",
       "                      -0.1094, -0.2633, -0.3273, -0.1937, -0.9232,  0.2420, -1.1982, -0.5430,\n",
       "                      -0.4611,  0.9024, -0.2988, -0.5611,  0.4811,  0.0492, -0.3505, -0.2595,\n",
       "                       0.0934,  0.0210,  0.7994, -0.6407, -0.4306,  0.5143, -0.2517,  0.8409,\n",
       "                      -0.5028,  0.8681, -0.0858,  0.1676, -0.2850, -0.5700, -0.2303, -0.3858,\n",
       "                      -0.5609, -0.5199, -0.4063, -0.2851, -0.4905, -0.6951, -0.9471,  0.4505,\n",
       "                      -0.4306, -0.3361, -0.2676, -0.2408, -0.7015, -0.6924, -0.6157, -1.0778,\n",
       "                      -0.3185, -0.3188, -0.3528, -0.5589,  0.2995, -0.4023, -0.1794, -0.3215,\n",
       "                      -0.1907, -0.3551, -0.4454, -0.3965, -0.2717, -0.4375, -0.7220,  0.0942,\n",
       "                      -0.3252,  0.3781, -1.4723,  0.1406, -1.1783,  0.2805, -0.9298,  0.0358,\n",
       "                      -0.0859, -0.4537, -0.1489, -0.3840, -0.8591, -0.5688,  0.2447, -0.3901,\n",
       "                      -1.0170,  0.0920, -0.2206, -0.4733,  0.5490,  0.2556, -0.3856, -0.8238,\n",
       "                      -0.8762, -0.3987, -0.2345, -0.8856, -0.4896, -0.2385, -0.0337, -0.4796,\n",
       "                      -0.3059, -0.4071, -0.3385,  0.1694, -0.6041, -0.9376, -0.6252, -0.4438,\n",
       "                      -0.9682, -0.7494, -0.0032, -0.6176, -0.0322,  0.0788,  0.2693, -1.0284,\n",
       "                      -0.3599, -0.3963,  0.7580, -0.7469, -0.0778, -0.0576, -0.2885, -0.3659],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.0.mlp.1.running_var',\n",
       "              tensor([1.0103, 1.4869, 1.4460, 1.7346, 1.4003, 0.8513, 1.4452, 0.6558, 0.3095,\n",
       "                      1.5030, 0.8842, 0.7946, 1.2833, 0.4149, 1.0727, 0.8240, 1.1954, 4.0139,\n",
       "                      0.7707, 2.4695, 1.0372, 0.8378, 0.4328, 2.2226, 4.8616, 5.8752, 0.9008,\n",
       "                      1.3284, 0.7847, 2.3498, 0.3212, 1.2535, 0.7711, 1.4526, 0.4220, 1.1635,\n",
       "                      0.4478, 2.6286, 1.2753, 0.8678, 3.8110, 1.5364, 2.9672, 1.5432, 0.1338,\n",
       "                      0.2549, 6.4604, 0.8513, 2.4544, 0.6110, 1.1899, 0.9674, 0.6564, 1.3006,\n",
       "                      8.2557, 0.9007, 1.4249, 0.7896, 3.0376, 3.6930, 1.2403, 2.4150, 2.7255,\n",
       "                      1.7195, 1.7672, 0.6528, 1.1370, 1.2011, 0.7155, 5.5027, 0.3534, 4.5980,\n",
       "                      0.6212, 3.1651, 0.6381, 0.2882, 0.4119, 6.5914, 1.3127, 1.3248, 0.6145,\n",
       "                      0.8489, 0.7112, 1.5397, 1.3213, 1.1442, 4.1378, 0.6150, 3.2615, 2.4661,\n",
       "                      1.2671, 3.9459, 2.4295, 0.8892, 1.2828, 0.2970, 0.6433, 2.6541, 1.7471,\n",
       "                      1.4250, 0.7834, 2.0207, 1.2955, 4.0219, 0.7452, 1.7421, 1.2558, 1.3682,\n",
       "                      0.2239, 0.6189, 1.5492, 0.6292, 2.6898, 1.6456, 2.2928, 0.5985, 1.6883,\n",
       "                      3.9309, 2.1393, 2.4118, 0.7536, 0.8163, 0.5976, 0.9352, 1.5058, 0.7570,\n",
       "                      1.7556, 2.0584, 0.8493, 0.4096, 0.6225, 1.8344, 1.0065, 0.7136, 0.6286,\n",
       "                      0.4602, 0.3381, 0.7996, 1.5961, 1.1262, 1.0812, 1.4527, 5.1622, 1.8803,\n",
       "                      1.1718, 0.8973, 5.3842, 0.7455, 4.7927, 3.3100, 5.6743, 1.5364, 0.4176,\n",
       "                      0.7806, 0.8981, 1.1734, 5.5778, 0.5229, 2.5432, 0.8874, 1.7319, 1.3768,\n",
       "                      0.9950, 2.5425, 2.2424, 2.4355, 0.4406, 0.9015, 4.7255, 0.5865, 0.7082,\n",
       "                      1.9491, 2.1298, 1.6515, 2.9478, 2.5302, 0.7548, 1.9166, 0.9407, 2.7675,\n",
       "                      2.2128, 4.4531, 1.7177, 0.8124, 6.5790, 1.9141, 0.9096, 2.8123, 0.4780,\n",
       "                      1.6383, 0.4880, 6.2568, 0.5417, 1.6303, 1.1658, 5.8302, 0.5142, 0.6458,\n",
       "                      0.2000, 1.0181], device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.0.mlp.1.num_batches_tracked',\n",
       "              tensor(63750, device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.0.mlp.3.weight',\n",
       "              tensor([[ 0.0391, -0.0233, -0.0011,  ..., -0.0115, -0.0527, -0.0179],\n",
       "                      [ 0.0213, -0.0177,  0.0146,  ...,  0.0187, -0.0158, -0.0398],\n",
       "                      [-0.0148, -0.0247,  0.0110,  ...,  0.0077, -0.0040,  0.0171],\n",
       "                      ...,\n",
       "                      [ 0.0134, -0.0173,  0.0004,  ..., -0.0150,  0.0197, -0.0217],\n",
       "                      [ 0.0160, -0.0105,  0.0368,  ..., -0.0177, -0.0026, -0.0115],\n",
       "                      [-0.0053, -0.0051, -0.0071,  ...,  0.0119,  0.0161, -0.0116]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.0.mlp.3.bias',\n",
       "              tensor([ 6.1656e-03, -1.6013e-03, -1.2074e-02,  2.4041e-03,  1.1872e-03,\n",
       "                       3.6780e-03, -5.4945e-03, -4.7247e-03, -9.2426e-03,  8.8125e-03,\n",
       "                       5.5197e-03,  2.3557e-03, -4.9113e-03, -4.7857e-03, -2.7365e-03,\n",
       "                      -4.7056e-03, -4.9088e-03,  2.4217e-04, -7.6868e-03, -3.4240e-03,\n",
       "                      -5.6801e-03,  2.2867e-03,  1.8062e-04, -4.7625e-03, -6.8584e-04,\n",
       "                      -1.1274e-04, -4.9655e-03, -5.6618e-03, -4.8039e-03,  6.0584e-04,\n",
       "                      -1.0462e-02,  4.7391e-03, -4.0945e-04,  9.6821e-03,  5.7003e-03,\n",
       "                      -1.5687e-03,  2.4432e-03, -5.5219e-03,  5.6147e-03, -2.7387e-04,\n",
       "                       1.0691e-03, -3.3603e-03, -1.0725e-03, -8.7726e-04, -1.7824e-02,\n",
       "                      -1.5356e-03, -9.7902e-03, -3.4480e-03,  5.8102e-03, -2.8719e-03,\n",
       "                      -3.5965e-03,  2.7789e-03, -2.8272e-03, -2.6312e-03,  6.4739e-04,\n",
       "                      -5.6602e-04,  1.4045e-03,  7.2688e-04, -1.0636e-02,  2.1185e-03,\n",
       "                       6.1663e-03, -2.2531e-03, -3.5379e-03,  5.4876e-03,  6.9310e-04,\n",
       "                      -1.6002e-02, -1.4426e-03, -3.5430e-03, -2.2429e-03,  1.7953e-03,\n",
       "                      -2.0058e-03, -6.5645e-03, -3.4517e-03, -5.6321e-04,  6.6759e-03,\n",
       "                      -6.2497e-03,  2.8620e-03,  3.9470e-05, -5.9009e-03, -6.7758e-03,\n",
       "                       5.6686e-03, -2.0457e-02,  4.5145e-03,  6.7969e-04, -9.5544e-03,\n",
       "                       2.3405e-03,  1.4647e-03, -1.4021e-02,  2.2342e-03, -1.6473e-03,\n",
       "                       2.7336e-03,  1.8282e-03, -9.8884e-03, -6.9640e-03,  1.3750e-03,\n",
       "                       8.1067e-04, -4.7351e-03,  8.9939e-04, -2.4000e-03, -1.0163e-02,\n",
       "                      -2.4920e-03, -1.0303e-02, -2.0414e-03, -2.9255e-03, -1.4921e-03,\n",
       "                       5.9379e-03, -2.2645e-03, -3.5402e-03,  1.8713e-03,  1.1765e-02,\n",
       "                      -6.4096e-03, -6.5818e-03, -2.9672e-03,  5.8839e-03, -4.1309e-03,\n",
       "                       2.1946e-03, -2.8485e-03,  8.3156e-03,  1.7059e-03,  1.5674e-03,\n",
       "                      -1.1214e-03, -6.8867e-03, -5.5665e-03, -6.3646e-03,  1.2962e-02,\n",
       "                      -4.0549e-03,  2.2176e-03,  6.3715e-03, -7.6524e-03, -6.1581e-03,\n",
       "                      -9.7678e-03,  8.7629e-05, -4.4168e-03,  2.2758e-03,  7.4711e-03,\n",
       "                       1.9315e-03,  1.8770e-03, -7.7843e-04, -4.2743e-03,  4.2402e-03,\n",
       "                       1.2969e-03,  4.4979e-03,  4.6213e-03,  1.9717e-03, -6.0349e-03,\n",
       "                      -1.3733e-03,  4.4808e-03, -6.1763e-03,  1.3049e-02,  7.0629e-03,\n",
       "                      -8.0208e-03,  4.9048e-04,  4.1246e-03,  7.6936e-04, -8.3762e-04,\n",
       "                       4.7761e-04, -7.1701e-03, -7.8831e-03, -5.4977e-03,  3.2217e-03,\n",
       "                      -3.1478e-03, -3.6775e-03, -1.1571e-04, -2.7461e-03,  3.7741e-03,\n",
       "                      -2.3699e-03, -2.6787e-03,  5.1696e-05, -2.9382e-03, -6.4471e-03,\n",
       "                      -2.9009e-03,  2.8574e-04, -6.5929e-03,  3.2578e-03,  1.6331e-03,\n",
       "                      -5.8458e-03,  5.9876e-04,  1.4955e-03, -3.2912e-03, -7.8528e-03,\n",
       "                       2.3808e-03, -1.2136e-03,  6.1272e-03, -7.3510e-03, -3.4051e-03,\n",
       "                      -4.8326e-03,  2.1165e-03, -9.5132e-03,  1.1284e-03, -6.8466e-03,\n",
       "                      -3.8380e-03, -7.0101e-03, -9.1203e-03,  3.7419e-03, -1.1808e-02,\n",
       "                      -2.8290e-03, -4.4440e-03, -1.9403e-03,  2.0661e-03, -5.5640e-06],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.1.edge_encoder.0.weight',\n",
       "              tensor([[ 0.0306, -0.0353,  0.0325,  ..., -0.0054, -0.0064, -0.0239],\n",
       "                      [ 0.0247,  0.0387,  0.0236,  ...,  0.0328,  0.0120, -0.0459],\n",
       "                      [ 0.0180, -0.0081, -0.0130,  ..., -0.0158,  0.0251,  0.0164],\n",
       "                      ...,\n",
       "                      [ 0.0070,  0.0437, -0.0125,  ..., -0.0002, -0.0051, -0.0569],\n",
       "                      [ 0.0213,  0.0714,  0.0441,  ..., -0.0479,  0.0109, -0.0085],\n",
       "                      [ 0.0176, -0.0074, -0.0351,  ..., -0.0420,  0.0276, -0.0018]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.1.edge_encoder.0.bias',\n",
       "              tensor([ 0.0077,  0.0119,  0.0017, -0.0190, -0.0046,  0.0056,  0.0168,  0.0094,\n",
       "                      -0.0051,  0.0039, -0.0029,  0.0186, -0.0180,  0.0189,  0.0191, -0.0094,\n",
       "                       0.0084,  0.0184, -0.0068, -0.0066, -0.0126, -0.0144,  0.0322,  0.0054,\n",
       "                       0.0056, -0.0084,  0.0076,  0.0117, -0.0092, -0.0210,  0.0302,  0.0111,\n",
       "                       0.0049,  0.0133,  0.0009,  0.0033,  0.0078, -0.0005,  0.0011,  0.0380,\n",
       "                       0.0042, -0.0085, -0.0131, -0.0191, -0.0132, -0.0132,  0.0060,  0.0126,\n",
       "                       0.0204, -0.0218, -0.0039,  0.0289,  0.0030,  0.0034,  0.0042,  0.0069,\n",
       "                       0.0276,  0.0014,  0.0052, -0.0010,  0.0165, -0.0045, -0.0037,  0.0045,\n",
       "                       0.0175, -0.0177, -0.0008,  0.0173, -0.0091,  0.0122, -0.0022, -0.0185,\n",
       "                      -0.0071, -0.0143,  0.0194,  0.0052,  0.0028,  0.0003, -0.0044,  0.0021,\n",
       "                      -0.0239, -0.0257,  0.0002,  0.0104,  0.0085,  0.0029,  0.0085,  0.0186,\n",
       "                       0.0136, -0.0184,  0.0170,  0.0219,  0.0114,  0.0373, -0.0013, -0.0081,\n",
       "                       0.0079,  0.0001,  0.0129, -0.0018,  0.0132,  0.0188,  0.0141, -0.0070,\n",
       "                       0.0138,  0.0063, -0.0268, -0.0065,  0.0113,  0.0060,  0.0369,  0.0077,\n",
       "                       0.0054, -0.0095, -0.0127, -0.0155, -0.0099, -0.0243, -0.0093,  0.0114,\n",
       "                      -0.0292, -0.0092, -0.0165,  0.0360, -0.0180,  0.0009, -0.0012, -0.0136,\n",
       "                      -0.0028, -0.0299, -0.0139,  0.0060, -0.0042,  0.0075, -0.0028,  0.0032,\n",
       "                       0.0168, -0.0089,  0.0203,  0.0222,  0.0033, -0.0214,  0.0055, -0.0004,\n",
       "                      -0.0070, -0.0103,  0.0122,  0.0016,  0.0049,  0.0059,  0.0101, -0.0175,\n",
       "                      -0.0075,  0.0347, -0.0166,  0.0217,  0.0009, -0.0263,  0.0026,  0.0296,\n",
       "                       0.0109,  0.0100, -0.0139, -0.0151,  0.0139,  0.0117,  0.0224,  0.0200,\n",
       "                       0.0159,  0.0146, -0.0090,  0.0056,  0.0198, -0.0114,  0.0122, -0.0099,\n",
       "                      -0.0116,  0.0004, -0.0143, -0.0011,  0.0056,  0.0021,  0.0154, -0.0226,\n",
       "                      -0.0033, -0.0069, -0.0072, -0.0033, -0.0062, -0.0068, -0.0164,  0.0153,\n",
       "                      -0.0333,  0.0075, -0.0050, -0.0042, -0.0204,  0.0111, -0.0367,  0.0139],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.1.edge_encoder.1.weight',\n",
       "              tensor([0.9628, 0.9829, 0.9672, 0.9673, 0.9706, 0.9835, 0.9779, 0.9585, 0.9801,\n",
       "                      1.0104, 0.9749, 0.9749, 0.9704, 0.9653, 0.9617, 0.9588, 0.9810, 0.9747,\n",
       "                      0.9706, 0.9653, 0.9548, 0.9736, 0.9918, 0.9715, 0.9768, 0.9686, 0.9768,\n",
       "                      0.9644, 0.9705, 0.9647, 0.9775, 0.9654, 0.9791, 0.9719, 0.9689, 1.0024,\n",
       "                      0.9714, 0.9612, 0.9602, 0.9835, 0.9716, 0.9771, 0.9913, 0.9704, 0.9972,\n",
       "                      0.9774, 0.9673, 0.9556, 0.9649, 0.9712, 0.9714, 0.9532, 0.9586, 0.9630,\n",
       "                      0.9654, 0.9569, 0.9866, 0.9909, 0.9710, 0.9789, 0.9821, 0.9766, 0.9629,\n",
       "                      1.0112, 0.9736, 1.0307, 0.9648, 0.9848, 0.9644, 0.9779, 0.9688, 0.9556,\n",
       "                      0.9911, 0.9716, 0.9692, 0.9976, 0.9801, 0.9737, 0.9750, 1.0032, 0.9712,\n",
       "                      0.9831, 0.9793, 1.0119, 0.9947, 0.9525, 0.9689, 1.0086, 0.9671, 0.9862,\n",
       "                      0.9723, 0.9898, 0.9515, 0.9780, 0.9625, 0.9707, 0.9851, 0.9711, 0.9946,\n",
       "                      0.9929, 1.0127, 0.9705, 0.9535, 0.9593, 0.9769, 0.9911, 0.9627, 0.9748,\n",
       "                      0.9724, 0.9391, 0.9803, 0.9876, 0.9843, 0.9748, 0.9582, 0.9636, 0.9737,\n",
       "                      0.9705, 0.9908, 0.9860, 0.9873, 0.9901, 0.9624, 0.9739, 0.9752, 0.9613,\n",
       "                      0.9775, 0.9644, 0.9877, 0.9880, 0.9751, 0.9752, 0.9599, 0.9629, 0.9751,\n",
       "                      0.9859, 0.9705, 0.9769, 0.9848, 0.9831, 0.9677, 1.0146, 0.9704, 0.9786,\n",
       "                      0.9771, 0.9810, 0.9668, 0.9568, 0.9419, 0.9776, 0.9674, 0.9866, 0.9767,\n",
       "                      0.9543, 0.9812, 1.0107, 0.9792, 0.9727, 0.9707, 0.9655, 0.9763, 0.9820,\n",
       "                      0.9982, 0.9833, 0.9660, 1.0028, 0.9630, 0.9713, 1.0131, 0.9784, 0.9664,\n",
       "                      0.9688, 0.9602, 0.9605, 0.9668, 0.9759, 0.9633, 0.9736, 0.9751, 0.9571,\n",
       "                      0.9551, 0.9673, 0.9850, 0.9753, 0.9827, 0.9796, 0.9681, 0.9709, 0.9784,\n",
       "                      0.9611, 0.9603, 0.9895, 0.9809, 0.9890, 0.9777, 0.9484, 0.9913, 0.9686,\n",
       "                      1.0060, 0.9723], device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.1.edge_encoder.1.bias',\n",
       "              tensor([-2.5693e-02, -9.7445e-03, -1.3280e-02, -1.4876e-02, -1.3010e-02,\n",
       "                      -2.8902e-02, -1.5408e-02, -1.3348e-02, -7.5672e-03,  1.6497e-03,\n",
       "                      -7.8495e-03, -9.1716e-03, -2.0961e-02, -2.2757e-02, -2.0028e-02,\n",
       "                      -1.7987e-02, -7.9770e-03, -1.8736e-03, -5.3145e-03, -3.8504e-03,\n",
       "                      -1.5113e-02, -2.7974e-02,  2.6333e-03, -8.1461e-03, -1.9291e-02,\n",
       "                      -1.5892e-03,  1.6622e-04, -1.8932e-02, -1.3259e-02, -2.7374e-02,\n",
       "                      -1.4522e-02, -1.6898e-02, -8.0646e-03, -1.0664e-02, -1.0739e-02,\n",
       "                      -1.7976e-03, -1.9121e-02, -1.7618e-02, -1.1595e-02, -8.5707e-03,\n",
       "                      -1.0648e-02, -1.1552e-02, -1.4868e-02, -9.6961e-03, -2.4517e-02,\n",
       "                      -7.4088e-03,  7.0666e-03, -1.7505e-02, -1.4665e-02, -2.4669e-02,\n",
       "                      -2.5899e-02, -3.7980e-02, -2.2516e-02, -3.0423e-03, -9.7302e-03,\n",
       "                      -2.5835e-02, -2.2611e-03, -4.0520e-03, -6.8373e-03, -1.9277e-02,\n",
       "                      -8.0628e-03, -1.8217e-02, -1.6750e-02, -1.5095e-02, -1.4788e-03,\n",
       "                      -3.7971e-02, -1.9556e-02,  1.5557e-04, -7.2736e-03, -3.9847e-03,\n",
       "                      -1.2300e-02, -1.9903e-02, -1.9171e-02, -9.9416e-03, -5.3805e-03,\n",
       "                       1.5913e-03, -7.6342e-03, -3.3007e-03, -6.2690e-03, -1.4096e-05,\n",
       "                      -1.5686e-02, -6.8913e-03, -1.7321e-02, -2.5634e-02, -1.4783e-02,\n",
       "                      -2.4108e-02, -1.3706e-02, -2.0894e-02, -2.0094e-02, -6.5898e-03,\n",
       "                      -1.2185e-02, -6.1023e-03, -2.7504e-02, -2.4717e-02, -2.5939e-02,\n",
       "                      -1.5674e-02, -5.1389e-03, -7.2659e-03,  4.9414e-03, -1.5022e-03,\n",
       "                      -1.3755e-02, -2.0142e-02, -2.5539e-02, -3.3021e-02, -1.7456e-02,\n",
       "                      -7.0987e-03, -1.8066e-02, -7.1374e-03, -9.0562e-03, -4.0189e-02,\n",
       "                      -4.1441e-03, -9.2944e-03, -8.8290e-03, -1.3431e-02, -1.1504e-02,\n",
       "                      -2.5691e-02, -1.5559e-02, -2.4027e-02, -1.8737e-02, -6.9398e-03,\n",
       "                      -1.3982e-02, -9.3979e-03, -2.2429e-02, -1.6925e-02, -1.1936e-02,\n",
       "                      -2.2714e-02, -8.0626e-03, -2.0102e-02, -1.1027e-02, -1.1894e-02,\n",
       "                      -2.9027e-02, -1.0246e-02, -2.0020e-02, -2.4571e-02,  1.9411e-03,\n",
       "                      -2.1970e-02, -1.8667e-02, -1.4658e-02, -3.9352e-03, -1.8957e-02,\n",
       "                      -9.4686e-03, -2.8255e-02,  5.2848e-04,  7.7191e-03, -1.7395e-02,\n",
       "                      -1.0582e-02, -1.7854e-02, -2.6494e-02, -3.3694e-02, -2.2807e-02,\n",
       "                      -2.3661e-02, -5.3341e-03, -7.3770e-03, -3.4522e-02, -2.7705e-02,\n",
       "                      -7.6568e-03, -5.1986e-03,  6.7720e-03, -2.3240e-02, -3.5141e-02,\n",
       "                      -1.3055e-02, -8.6289e-03, -2.5888e-02, -1.1771e-02, -1.2512e-02,\n",
       "                      -1.8411e-02, -3.3645e-02, -7.4316e-03, -1.2644e-02, -7.5547e-03,\n",
       "                      -1.6641e-02, -1.9724e-02, -2.6223e-02, -1.5339e-02, -6.3751e-03,\n",
       "                      -5.5682e-03, -2.3769e-02, -8.3162e-03, -7.2813e-03, -3.8014e-02,\n",
       "                      -2.6523e-02, -2.3696e-02, -9.4407e-03, -1.6965e-02, -1.8803e-02,\n",
       "                       4.4039e-03, -1.6914e-02, -1.6613e-02,  7.9222e-03, -2.1573e-02,\n",
       "                      -5.3399e-03, -1.7694e-02, -4.4106e-03, -3.1973e-03, -3.3638e-03,\n",
       "                      -3.0254e-02,  3.6135e-03, -1.7349e-02,  2.9815e-03, -8.8753e-03],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.1.edge_encoder.1.running_mean',\n",
       "              tensor([ 2.7008e-02,  1.6912e-03,  1.5797e-02, -6.7778e-02,  2.0418e-02,\n",
       "                      -1.1173e-02,  1.5179e-02,  2.4307e-02,  1.2653e-02,  4.6869e-03,\n",
       "                      -1.0762e-02, -1.9674e-03, -1.3291e-02,  3.0813e-02, -1.3610e-03,\n",
       "                       4.5526e-03,  2.5402e-02,  2.0468e-02,  1.6868e-02,  1.5769e-02,\n",
       "                      -3.7985e-03, -2.9739e-02,  3.6873e-02, -1.5693e-03, -2.0923e-02,\n",
       "                       4.5054e-02,  3.2104e-02, -3.1810e-03,  5.9307e-03, -2.4748e-03,\n",
       "                       2.8697e-02,  2.8321e-03,  4.0958e-02,  2.8253e-02,  3.6128e-02,\n",
       "                      -1.6234e-02,  1.5718e-02,  2.1499e-02,  3.2818e-02,  4.5780e-02,\n",
       "                       1.8265e-02, -2.2358e-02,  1.0330e-02, -8.1752e-03, -7.3849e-02,\n",
       "                      -7.7433e-02, -9.5062e-03,  5.6934e-02,  2.9798e-02, -5.6704e-02,\n",
       "                      -2.8998e-04,  3.8911e-02,  7.1862e-02,  2.8319e-02, -1.3835e-03,\n",
       "                       2.4380e-02,  4.7917e-02, -7.5812e-03,  4.3195e-02, -8.7772e-03,\n",
       "                       3.0336e-02, -2.1767e-02, -2.0313e-02, -5.7155e-02,  2.2238e-02,\n",
       "                      -1.7876e-02,  7.2475e-03,  5.9072e-02,  1.7254e-02,  3.5640e-02,\n",
       "                      -5.3690e-02,  3.1887e-02, -6.1408e-02,  1.1748e-02, -2.8399e-02,\n",
       "                       3.6311e-02,  3.8973e-02,  6.4906e-02,  7.8385e-03, -2.0935e-02,\n",
       "                      -5.8416e-02, -2.0047e-02, -3.1496e-02,  2.9189e-02, -3.4504e-02,\n",
       "                      -2.7514e-02,  6.8505e-02,  2.8062e-03,  1.8849e-05, -1.3774e-02,\n",
       "                       9.2343e-03,  3.7521e-02,  4.5121e-02,  1.4074e-02, -1.8121e-04,\n",
       "                      -4.0558e-02, -3.7644e-03,  1.6923e-02,  2.7104e-02, -1.5634e-02,\n",
       "                      -4.1377e-03,  9.3574e-03,  1.9628e-02,  5.6155e-02,  5.2343e-02,\n",
       "                       8.2967e-03, -3.7830e-03, -4.8709e-03, -8.8138e-03,  5.4959e-02,\n",
       "                       9.5033e-02, -8.7470e-03, -2.1711e-03, -2.7213e-02,  2.7870e-02,\n",
       "                      -6.4279e-02, -1.5909e-02, -4.3667e-02, -1.5132e-02, -9.5939e-03,\n",
       "                      -1.8963e-02, -6.7713e-03, -5.5545e-02, -1.0497e-02, -3.9040e-02,\n",
       "                      -4.8672e-03,  1.1762e-02, -1.5282e-02, -4.3349e-02, -5.3518e-02,\n",
       "                       4.6776e-03, -4.4651e-02, -4.5448e-02, -1.2307e-02,  1.7775e-02,\n",
       "                      -4.1911e-03,  2.1014e-02, -4.3004e-03,  2.7901e-02,  1.0977e-02,\n",
       "                      -7.3112e-03, -3.7840e-02, -1.7166e-03,  1.3762e-02, -2.5244e-02,\n",
       "                       1.1566e-02,  7.3994e-02, -4.3874e-03,  4.3512e-02, -4.0878e-02,\n",
       "                       1.8922e-03, -1.0121e-02, -2.9110e-02,  2.4583e-02, -4.8153e-02,\n",
       "                       2.5973e-02, -2.9922e-03, -2.0870e-02, -2.2877e-02, -1.4993e-03,\n",
       "                      -5.9943e-03, -7.2241e-03, -2.0146e-02,  1.2459e-02, -3.8290e-03,\n",
       "                      -2.0011e-02,  3.9809e-02,  1.3255e-02, -4.2352e-04,  1.7046e-02,\n",
       "                      -6.5159e-03,  1.2209e-02,  6.6373e-02, -1.1389e-02,  5.5789e-02,\n",
       "                       1.8531e-02, -1.1453e-02,  2.1218e-02,  1.8626e-02,  1.3585e-02,\n",
       "                      -3.0026e-02,  1.2386e-02, -9.9208e-03, -2.6795e-04, -8.1980e-03,\n",
       "                      -1.3025e-02, -1.7465e-02,  3.8352e-04, -2.6250e-02, -3.8193e-02,\n",
       "                       1.8636e-02, -7.6045e-03, -3.9300e-02,  1.3399e-03,  1.3233e-02,\n",
       "                       1.9639e-02, -1.1317e-02, -1.9422e-02, -3.2577e-02,  5.8234e-02],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.1.edge_encoder.1.running_var',\n",
       "              tensor([0.0007, 0.0011, 0.0017, 0.0010, 0.0004, 0.0005, 0.0011, 0.0008, 0.0008,\n",
       "                      0.0006, 0.0011, 0.0012, 0.0004, 0.0011, 0.0017, 0.0008, 0.0009, 0.0008,\n",
       "                      0.0008, 0.0017, 0.0010, 0.0005, 0.0005, 0.0005, 0.0007, 0.0009, 0.0004,\n",
       "                      0.0016, 0.0005, 0.0014, 0.0013, 0.0005, 0.0005, 0.0010, 0.0009, 0.0005,\n",
       "                      0.0009, 0.0014, 0.0012, 0.0007, 0.0004, 0.0008, 0.0005, 0.0008, 0.0010,\n",
       "                      0.0010, 0.0010, 0.0012, 0.0016, 0.0011, 0.0004, 0.0004, 0.0009, 0.0014,\n",
       "                      0.0009, 0.0013, 0.0004, 0.0005, 0.0009, 0.0005, 0.0003, 0.0009, 0.0005,\n",
       "                      0.0007, 0.0009, 0.0004, 0.0008, 0.0009, 0.0006, 0.0004, 0.0013, 0.0007,\n",
       "                      0.0007, 0.0006, 0.0007, 0.0004, 0.0007, 0.0007, 0.0007, 0.0003, 0.0020,\n",
       "                      0.0011, 0.0006, 0.0004, 0.0010, 0.0019, 0.0012, 0.0007, 0.0005, 0.0004,\n",
       "                      0.0005, 0.0009, 0.0012, 0.0007, 0.0007, 0.0014, 0.0015, 0.0009, 0.0009,\n",
       "                      0.0006, 0.0004, 0.0006, 0.0008, 0.0008, 0.0012, 0.0005, 0.0013, 0.0009,\n",
       "                      0.0006, 0.0015, 0.0007, 0.0006, 0.0007, 0.0010, 0.0010, 0.0010, 0.0005,\n",
       "                      0.0006, 0.0006, 0.0005, 0.0003, 0.0008, 0.0007, 0.0010, 0.0008, 0.0009,\n",
       "                      0.0008, 0.0012, 0.0011, 0.0014, 0.0014, 0.0012, 0.0019, 0.0012, 0.0016,\n",
       "                      0.0008, 0.0008, 0.0006, 0.0006, 0.0012, 0.0004, 0.0006, 0.0020, 0.0009,\n",
       "                      0.0004, 0.0004, 0.0010, 0.0010, 0.0006, 0.0004, 0.0008, 0.0006, 0.0010,\n",
       "                      0.0016, 0.0006, 0.0004, 0.0010, 0.0015, 0.0007, 0.0009, 0.0008, 0.0008,\n",
       "                      0.0005, 0.0006, 0.0010, 0.0003, 0.0010, 0.0007, 0.0005, 0.0007, 0.0007,\n",
       "                      0.0008, 0.0009, 0.0022, 0.0009, 0.0007, 0.0006, 0.0006, 0.0006, 0.0014,\n",
       "                      0.0004, 0.0004, 0.0003, 0.0004, 0.0008, 0.0010, 0.0010, 0.0010, 0.0016,\n",
       "                      0.0016, 0.0008, 0.0008, 0.0017, 0.0004, 0.0013, 0.0004, 0.0015, 0.0007,\n",
       "                      0.0011, 0.0009], device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.1.edge_encoder.1.num_batches_tracked',\n",
       "              tensor(318750, device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.1.edge_encoder.3.weight',\n",
       "              tensor([[-0.0193, -0.0094, -0.0241,  ...,  0.0122, -0.0301, -0.0028],\n",
       "                      [ 0.0069,  0.0188,  0.0111,  ..., -0.0008, -0.0141,  0.0301],\n",
       "                      [ 0.0371, -0.0236, -0.0005,  ..., -0.0178,  0.0145,  0.0044],\n",
       "                      ...,\n",
       "                      [ 0.0266,  0.0113,  0.0204,  ..., -0.0058,  0.0168, -0.0279],\n",
       "                      [ 0.0263, -0.0120,  0.0145,  ..., -0.0088,  0.0285, -0.0355],\n",
       "                      [ 0.0217,  0.0041,  0.0519,  ...,  0.0308, -0.0709, -0.0156]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.1.edge_encoder.3.bias',\n",
       "              tensor([-2.3653e-03, -5.7033e-03,  2.7150e-03,  1.7915e-03, -1.3082e-03,\n",
       "                      -3.1844e-04,  8.8534e-04, -5.2766e-03,  1.3499e-03,  4.7690e-03,\n",
       "                      -4.6336e-03,  1.4850e-03, -3.2236e-03,  3.7453e-03, -8.5289e-03,\n",
       "                       7.5043e-03,  5.8532e-03,  2.3962e-04, -5.7625e-04,  5.2903e-04,\n",
       "                      -1.7449e-03,  5.2435e-03,  2.9055e-03, -4.1971e-03, -5.6767e-03,\n",
       "                      -4.0691e-03, -1.4285e-03,  5.0252e-03, -1.9099e-03,  1.1951e-03,\n",
       "                       2.1446e-03, -2.3171e-03,  5.1971e-03,  1.3342e-03, -6.3974e-03,\n",
       "                       7.7394e-04, -5.0417e-03, -4.6538e-04,  8.4626e-03, -4.4000e-04,\n",
       "                      -7.0619e-04,  4.7418e-03, -5.4846e-03, -5.1588e-03, -7.3695e-03,\n",
       "                      -9.4579e-03,  4.9077e-03, -5.9823e-03,  1.0702e-03, -2.1661e-03,\n",
       "                       1.0390e-03,  1.1983e-03, -4.2399e-03, -1.2942e-03, -7.8520e-03,\n",
       "                      -3.5293e-03, -1.0280e-02,  3.5102e-04,  3.8343e-03, -1.2780e-03,\n",
       "                       4.5618e-04,  3.8666e-03,  1.8226e-03,  4.2149e-03, -7.9116e-03,\n",
       "                      -6.3569e-03,  7.4834e-04,  4.8660e-04, -3.4787e-03, -3.4874e-03,\n",
       "                      -2.9350e-03,  6.0196e-03,  2.0707e-03,  6.1710e-03, -2.5195e-04,\n",
       "                       2.7551e-03, -3.0170e-03, -3.2106e-03, -5.5723e-05,  5.0233e-03,\n",
       "                      -5.5378e-03, -8.5195e-03,  2.5666e-03, -1.8356e-03,  1.2716e-03,\n",
       "                      -1.2945e-03,  1.9425e-03,  8.8292e-04,  2.0636e-03,  1.4934e-03,\n",
       "                      -1.9848e-03,  9.8496e-03, -2.1664e-03,  1.9293e-03, -3.8735e-03,\n",
       "                      -5.7664e-03,  3.7731e-03, -2.0194e-03,  5.2783e-03,  3.5625e-03,\n",
       "                      -4.3390e-03, -4.5637e-03,  6.6010e-03,  3.1173e-03,  4.0452e-03,\n",
       "                      -2.6583e-03,  4.5262e-03, -1.5825e-03, -4.2482e-03, -3.4520e-03,\n",
       "                       2.3763e-03,  3.6228e-03,  1.7307e-03,  1.0506e-03,  4.2683e-03,\n",
       "                      -3.5708e-04, -2.0222e-03, -1.5319e-03,  4.2033e-03, -6.7279e-03,\n",
       "                       1.4046e-03,  2.9070e-03,  3.6665e-03,  1.5358e-03,  2.2912e-03,\n",
       "                       1.5417e-03, -5.5028e-03,  1.9160e-03, -3.6478e-03, -3.0722e-03,\n",
       "                      -6.0849e-04,  4.6370e-03,  1.5033e-03,  7.6505e-03,  1.1843e-03,\n",
       "                      -2.6880e-03, -7.3885e-04, -1.9909e-03, -4.8474e-03,  7.0672e-03,\n",
       "                       7.6360e-03, -5.4759e-03, -6.0674e-03, -1.4287e-03,  1.6351e-03,\n",
       "                       4.7338e-03, -4.7588e-03, -5.5839e-03,  1.8682e-03, -1.0032e-03,\n",
       "                      -1.1349e-04,  6.5163e-03,  7.6160e-04,  6.0492e-03,  2.1817e-03,\n",
       "                       5.5140e-04, -5.6854e-03,  2.1677e-04,  1.8623e-03,  1.7347e-03,\n",
       "                      -3.2468e-03,  2.5972e-03, -1.4406e-03, -4.4453e-03, -6.4311e-03,\n",
       "                      -3.7272e-03,  2.8988e-03, -3.4194e-03,  8.8222e-04,  3.5037e-03,\n",
       "                       4.3227e-04, -1.8212e-03,  1.9136e-03, -3.1052e-03, -5.8780e-03,\n",
       "                      -9.3809e-04,  2.1546e-03, -5.0847e-03, -5.3777e-03, -3.2735e-03,\n",
       "                       1.7199e-04, -1.1658e-03,  3.6198e-03,  4.1820e-03,  1.1943e-04,\n",
       "                      -1.7642e-03,  4.1916e-03,  8.8105e-04, -6.2575e-03,  6.1010e-03,\n",
       "                      -4.3334e-04,  1.6691e-03,  8.9472e-06,  5.3347e-03,  4.1516e-03,\n",
       "                       4.4639e-03,  4.7324e-03, -6.6560e-04, -5.5783e-03,  1.1676e-03],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.1.linear_key.weight',\n",
       "              tensor([[-0.0365,  0.0160,  0.0304,  ...,  0.0168, -0.0122, -0.0278],\n",
       "                      [ 0.0204, -0.0332, -0.0083,  ..., -0.0690,  0.0074,  0.0165],\n",
       "                      [ 0.0280, -0.0092,  0.0230,  ...,  0.0235,  0.0262, -0.0548],\n",
       "                      ...,\n",
       "                      [ 0.0034,  0.0052,  0.0069,  ...,  0.0079,  0.0351, -0.0030],\n",
       "                      [ 0.0025, -0.0380,  0.0424,  ...,  0.0275, -0.0281, -0.0058],\n",
       "                      [-0.0342, -0.0028,  0.0235,  ...,  0.0141,  0.0125,  0.0179]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.1.linear_key.bias',\n",
       "              tensor([ 0.0029, -0.0148,  0.0115,  0.0008, -0.0118, -0.0270,  0.0087, -0.0022,\n",
       "                       0.0169, -0.0030, -0.0077,  0.0154,  0.0082, -0.0040,  0.0022, -0.0124,\n",
       "                      -0.0116,  0.0139,  0.0038,  0.0131,  0.0131, -0.0135,  0.0080,  0.0070,\n",
       "                      -0.0167, -0.0149, -0.0040, -0.0061,  0.0209,  0.0143,  0.0111, -0.0138,\n",
       "                       0.0189, -0.0118, -0.0031,  0.0156,  0.0010, -0.0159, -0.0016,  0.0104,\n",
       "                       0.0187,  0.0154,  0.0144,  0.0141,  0.0071, -0.0189,  0.0039,  0.0008,\n",
       "                      -0.0165, -0.0109, -0.0067, -0.0099, -0.0076,  0.0049, -0.0045, -0.0040,\n",
       "                      -0.0004, -0.0018,  0.0065, -0.0023, -0.0032, -0.0031,  0.0040, -0.0037,\n",
       "                       0.0046, -0.0022, -0.0024,  0.0041,  0.0017,  0.0124, -0.0087, -0.0007,\n",
       "                       0.0086, -0.0008, -0.0021,  0.0026,  0.0021, -0.0015, -0.0025,  0.0049,\n",
       "                       0.0100, -0.0031, -0.0073,  0.0032,  0.0129,  0.0051,  0.0189,  0.0025,\n",
       "                      -0.0061,  0.0060, -0.0010,  0.0055,  0.0014, -0.0110, -0.0020, -0.0017,\n",
       "                      -0.0059,  0.0019,  0.0007,  0.0039,  0.0091,  0.0012,  0.0183,  0.0092,\n",
       "                       0.0100, -0.0046, -0.0043, -0.0072,  0.0064,  0.0145, -0.0092,  0.0140,\n",
       "                      -0.0006, -0.0023,  0.0065,  0.0037,  0.0068,  0.0032,  0.0075,  0.0079,\n",
       "                      -0.0029,  0.0100,  0.0033, -0.0010,  0.0044, -0.0071, -0.0013,  0.0077,\n",
       "                      -0.0053, -0.0024, -0.0012,  0.0081,  0.0026, -0.0050, -0.0080,  0.0052,\n",
       "                       0.0092,  0.0128,  0.0005,  0.0098,  0.0086, -0.0010,  0.0019, -0.0011,\n",
       "                       0.0053, -0.0189,  0.0061,  0.0152, -0.0046, -0.0053, -0.0022, -0.0004,\n",
       "                       0.0040, -0.0008,  0.0016, -0.0059, -0.0104, -0.0087, -0.0002, -0.0070,\n",
       "                      -0.0020, -0.0012,  0.0021, -0.0038, -0.0104, -0.0058,  0.0023, -0.0057,\n",
       "                      -0.0064,  0.0008, -0.0034,  0.0015, -0.0037,  0.0090, -0.0058, -0.0109,\n",
       "                      -0.0042, -0.0005, -0.0086,  0.0039,  0.0051, -0.0036, -0.0010, -0.0064,\n",
       "                       0.0055,  0.0012, -0.0010,  0.0001, -0.0071,  0.0065,  0.0021, -0.0108,\n",
       "                      -0.0070,  0.0045, -0.0049, -0.0012, -0.0005,  0.0119, -0.0039,  0.0031],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.1.linear_msg.weight',\n",
       "              tensor([[ 0.0048, -0.0149, -0.0018,  ...,  0.0110, -0.0394,  0.0062],\n",
       "                      [ 0.0232, -0.0325,  0.0369,  ...,  0.0131, -0.0311, -0.0155],\n",
       "                      [ 0.0492, -0.0144,  0.0010,  ...,  0.0198, -0.0007, -0.0005],\n",
       "                      ...,\n",
       "                      [ 0.0058,  0.0151,  0.0076,  ..., -0.0166,  0.0053, -0.0303],\n",
       "                      [-0.0348, -0.0194,  0.0205,  ...,  0.0008, -0.0134,  0.0208],\n",
       "                      [-0.0215, -0.0121, -0.0110,  ..., -0.0352,  0.0071,  0.0278]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.1.linear_msg.bias',\n",
       "              tensor([-9.0912e-04, -5.0648e-03,  3.7299e-03, -1.8279e-03, -2.4371e-03,\n",
       "                       1.7109e-03, -4.4889e-04, -1.1615e-02,  1.2000e-03,  1.1807e-03,\n",
       "                       8.1594e-04,  9.3078e-03,  6.9018e-04,  2.3660e-03, -6.8374e-04,\n",
       "                       7.9672e-03,  2.7059e-04, -1.9573e-03,  8.6858e-03,  1.5995e-03,\n",
       "                       8.4318e-04, -6.9388e-03, -1.3703e-03, -3.2563e-04,  6.3542e-05,\n",
       "                      -9.3438e-03,  8.8134e-03, -1.8144e-03,  1.2300e-03,  4.2298e-03,\n",
       "                       4.0938e-03,  2.0718e-03,  1.4698e-03,  5.0291e-03,  8.1200e-03,\n",
       "                       7.4951e-04, -3.5666e-03, -6.4744e-03, -8.0286e-03,  7.4153e-03,\n",
       "                       7.9158e-03, -9.8656e-04, -3.3247e-03, -2.1556e-03, -2.2723e-03,\n",
       "                       4.2422e-03,  4.8703e-04, -3.6370e-03, -4.2720e-03, -2.2175e-03,\n",
       "                       5.7013e-03, -3.7225e-03,  6.7038e-03, -6.4706e-03, -4.8568e-03,\n",
       "                      -2.3811e-03, -6.7339e-04,  6.1124e-03, -6.6132e-03, -7.6171e-04,\n",
       "                       9.2039e-03, -3.7094e-03,  2.6749e-04, -2.7393e-04,  2.6166e-03,\n",
       "                      -5.1522e-03, -1.8467e-03, -3.1470e-03, -5.9360e-03, -2.7561e-03,\n",
       "                      -8.7932e-03,  3.2445e-03,  2.9135e-03,  1.8404e-03,  2.5228e-03,\n",
       "                      -1.2404e-03,  7.7573e-03,  3.3276e-04,  1.9922e-03, -5.9718e-03,\n",
       "                       3.8326e-03,  2.1823e-03, -4.8421e-03,  4.1544e-03, -6.7257e-03,\n",
       "                       2.2073e-03,  6.7673e-03,  2.8099e-03,  5.4900e-04,  8.0328e-03,\n",
       "                       3.1768e-03, -5.5188e-03,  7.0734e-03, -1.4710e-04, -2.3696e-03,\n",
       "                       2.3423e-03, -5.7122e-03, -7.9831e-03, -9.8184e-03, -1.4914e-03,\n",
       "                       3.2584e-03,  7.3895e-04,  9.2642e-04, -7.0739e-05, -1.2003e-02,\n",
       "                      -6.1061e-03,  5.6033e-03, -5.2843e-03,  2.0007e-03,  4.6990e-03,\n",
       "                      -1.3144e-03,  9.3308e-03,  1.0047e-02, -3.1056e-03,  5.2875e-03,\n",
       "                      -2.7017e-03,  1.0980e-02,  8.3049e-04, -2.0792e-03, -4.4013e-03,\n",
       "                      -9.4917e-03, -4.1828e-04, -4.7198e-03, -6.2664e-03, -3.0700e-03,\n",
       "                       1.9418e-03,  2.2665e-03, -2.7382e-03, -3.8970e-03, -1.0421e-03,\n",
       "                      -2.8251e-03, -5.8700e-05,  3.4924e-03, -4.3947e-03, -7.5449e-03,\n",
       "                      -4.0517e-03, -4.8447e-04, -5.1811e-03,  1.1685e-02, -3.3938e-03,\n",
       "                       4.6901e-03, -2.2302e-03,  7.1039e-04, -1.4743e-03, -1.2895e-03,\n",
       "                      -1.5571e-03, -3.6816e-03,  2.0535e-03,  4.5843e-03,  5.3252e-03,\n",
       "                      -7.2482e-03,  4.0228e-04, -2.5784e-04, -3.5640e-03, -1.9747e-03,\n",
       "                      -5.3198e-03, -3.4985e-03, -3.0634e-03,  3.0743e-03,  1.4786e-03,\n",
       "                      -8.9372e-05,  9.7279e-03, -3.1692e-03, -3.0507e-03,  2.8973e-03,\n",
       "                       5.2011e-03,  1.0674e-02,  6.8154e-04, -2.9647e-03, -2.3842e-03,\n",
       "                       7.5045e-03, -3.7791e-03, -7.0873e-03, -9.4354e-04, -4.5408e-03,\n",
       "                       4.5879e-03,  8.3450e-03, -3.4509e-03, -1.5138e-03, -9.5911e-03,\n",
       "                       7.5288e-04, -1.2531e-02,  6.8431e-03,  2.6446e-04, -4.3235e-03,\n",
       "                      -9.9384e-04, -4.5522e-03, -8.5807e-04,  8.0314e-03,  2.5149e-03,\n",
       "                       1.3702e-03, -1.0342e-03, -3.1351e-03, -2.0168e-03,  4.8074e-03,\n",
       "                      -5.2633e-03, -3.1573e-03,  3.6774e-04, -2.2373e-04, -1.8178e-04],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.1.linear_query.weight',\n",
       "              tensor([[ 0.0142,  0.0101,  0.0306,  ..., -0.0505, -0.0177,  0.0002],\n",
       "                      [ 0.0120,  0.0043, -0.0289,  ...,  0.0353,  0.0547, -0.0021],\n",
       "                      [ 0.0078,  0.0222,  0.0184,  ..., -0.0820, -0.1114,  0.0175],\n",
       "                      ...,\n",
       "                      [ 0.0190,  0.0298,  0.0034,  ..., -0.0115, -0.0576, -0.0201],\n",
       "                      [-0.0254,  0.0191,  0.0003,  ..., -0.0022, -0.0099,  0.0144],\n",
       "                      [-0.0210,  0.0440,  0.0126,  ...,  0.0340,  0.0001,  0.0250]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.1.linear_query.bias',\n",
       "              tensor([-1.8319e-02,  1.2940e-02,  1.3178e-03, -9.1113e-03,  1.7112e-02,\n",
       "                       5.2464e-03, -9.0499e-03, -5.6258e-04, -1.0589e-02,  4.5054e-03,\n",
       "                      -1.1236e-04,  3.1912e-03, -2.8822e-03,  1.8783e-03, -3.2187e-03,\n",
       "                       8.6453e-03,  1.1903e-02,  1.1733e-03, -9.9742e-04, -1.5913e-02,\n",
       "                      -1.3914e-02,  1.0987e-02,  2.9328e-03, -7.0578e-03,  1.6313e-02,\n",
       "                      -2.6615e-04, -5.6232e-03, -1.5028e-03,  3.1503e-05,  1.0148e-02,\n",
       "                       4.9598e-04,  2.0538e-02, -9.1627e-03,  1.6255e-02,  1.6128e-02,\n",
       "                      -1.1973e-02, -1.2515e-03, -1.9784e-03, -1.0172e-02, -6.0695e-03,\n",
       "                       1.1685e-03, -2.7436e-03, -6.3628e-03,  6.7053e-05, -1.2686e-02,\n",
       "                       4.6722e-03,  1.4873e-02,  1.0082e-02,  5.8529e-03,  9.2943e-03,\n",
       "                       2.7004e-03,  4.4658e-03, -1.1608e-02, -4.6618e-03,  5.5633e-03,\n",
       "                       1.5851e-02, -1.1932e-02, -1.2497e-04, -5.5744e-03,  6.6877e-03,\n",
       "                      -3.5200e-04, -1.2537e-02, -6.3224e-03,  6.6995e-03, -1.3625e-02,\n",
       "                      -8.6008e-03, -1.1688e-02, -4.2383e-03, -5.9802e-03, -3.7829e-03,\n",
       "                      -8.1491e-03,  1.4848e-03, -9.7652e-03,  1.6945e-03,  8.0426e-03,\n",
       "                      -7.9757e-03, -1.0807e-03, -3.2373e-04, -5.0783e-03,  2.7555e-03,\n",
       "                       2.4809e-03,  7.9114e-04, -1.2026e-02, -2.2139e-03,  6.9465e-03,\n",
       "                      -7.2894e-03,  4.0219e-03,  8.2246e-03, -6.0593e-03, -2.3723e-03,\n",
       "                       2.8549e-03, -8.2686e-03, -4.9752e-03, -5.5246e-03, -1.0424e-03,\n",
       "                      -1.0799e-02, -1.2340e-02,  2.6179e-02,  2.9777e-04, -1.9681e-04,\n",
       "                      -1.2187e-02,  3.7354e-03, -1.4337e-03, -7.3035e-03, -2.7303e-03,\n",
       "                       6.4686e-03, -1.1146e-02,  9.8467e-03,  1.1365e-03, -2.9445e-03,\n",
       "                       8.9047e-03, -3.8334e-03,  2.6407e-03, -1.5586e-03,  1.5439e-03,\n",
       "                       4.9970e-03,  6.8578e-04, -4.6590e-03,  6.0809e-04,  1.7876e-03,\n",
       "                      -2.6516e-03, -1.4631e-02,  1.3690e-02,  4.7238e-03, -1.1895e-03,\n",
       "                       1.4812e-03,  1.7772e-03, -1.1229e-03, -2.7222e-04,  4.5907e-03,\n",
       "                       2.1765e-02, -1.4506e-02, -9.8458e-03, -6.5051e-03,  1.0383e-02,\n",
       "                       3.0645e-03,  4.8168e-03,  1.0975e-03,  1.5529e-03, -8.5267e-03,\n",
       "                      -7.3467e-03, -8.1823e-03,  6.0936e-03, -4.4456e-03, -5.7795e-05,\n",
       "                       8.1223e-04, -1.8863e-03, -9.7434e-05, -1.4370e-03, -3.3224e-03,\n",
       "                       1.8769e-03, -1.2764e-03, -3.9746e-03, -3.5161e-03, -3.9262e-03,\n",
       "                      -1.1122e-02,  2.8086e-03,  6.6216e-03,  1.1343e-03,  1.4053e-02,\n",
       "                      -2.5166e-03,  6.7284e-03, -4.9607e-04,  2.6783e-03,  1.0069e-02,\n",
       "                      -5.2321e-03,  3.8605e-03,  1.4648e-03,  1.3540e-02, -1.5866e-03,\n",
       "                      -1.9830e-04,  2.6302e-03, -1.1931e-03,  4.1689e-03,  2.0837e-03,\n",
       "                       8.2169e-03, -5.0124e-03, -1.5231e-02,  9.2464e-03,  1.7778e-03,\n",
       "                      -6.3880e-03, -3.4069e-03,  6.7030e-03, -4.7434e-03,  1.8366e-03,\n",
       "                      -1.1045e-02,  7.9979e-03, -9.1939e-03, -1.7966e-02, -4.5470e-03,\n",
       "                      -1.4129e-02, -3.0200e-03,  3.6540e-03,  2.6913e-03,  2.0685e-02,\n",
       "                       1.5365e-03, -8.1400e-03, -6.2700e-03, -2.9803e-03,  2.2370e-03],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.1.mlp.0.weight',\n",
       "              tensor([[-0.0029,  0.0143,  0.0227,  ...,  0.0141,  0.0331,  0.0199],\n",
       "                      [-0.0150,  0.0040, -0.0245,  ..., -0.0045,  0.0308,  0.0375],\n",
       "                      [-0.0321, -0.0089,  0.0132,  ..., -0.0118, -0.0059, -0.0121],\n",
       "                      ...,\n",
       "                      [-0.0336, -0.0017,  0.0203,  ...,  0.0094, -0.0109,  0.0211],\n",
       "                      [-0.0060,  0.0409,  0.0235,  ..., -0.0253,  0.0107, -0.0086],\n",
       "                      [-0.0190,  0.0116,  0.0115,  ..., -0.0263, -0.0259,  0.0011]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.1.mlp.0.bias',\n",
       "              tensor([-0.0014,  0.0009,  0.0027, -0.0008,  0.0026,  0.0017, -0.0052,  0.0048,\n",
       "                      -0.0068,  0.0064, -0.0039,  0.0008,  0.0027, -0.0044,  0.0040, -0.0010,\n",
       "                       0.0086,  0.0045,  0.0027, -0.0015,  0.0051, -0.0031,  0.0114,  0.0021,\n",
       "                      -0.0032,  0.0044,  0.0053,  0.0078, -0.0023,  0.0025,  0.0086, -0.0002,\n",
       "                      -0.0065,  0.0015, -0.0014, -0.0018,  0.0035,  0.0085,  0.0016, -0.0042,\n",
       "                       0.0007,  0.0060, -0.0036,  0.0013,  0.0024,  0.0032,  0.0002, -0.0010,\n",
       "                       0.0031,  0.0005,  0.0033, -0.0100, -0.0029, -0.0096,  0.0002,  0.0008,\n",
       "                       0.0052,  0.0020, -0.0034, -0.0022, -0.0085,  0.0019,  0.0021, -0.0013,\n",
       "                       0.0046,  0.0024, -0.0076, -0.0119, -0.0070, -0.0076, -0.0090,  0.0041,\n",
       "                       0.0077,  0.0095, -0.0041, -0.0088,  0.0031,  0.0009,  0.0005,  0.0058,\n",
       "                      -0.0042,  0.0019,  0.0031, -0.0014,  0.0018, -0.0023, -0.0026,  0.0050,\n",
       "                      -0.0076, -0.0049, -0.0016, -0.0041,  0.0084, -0.0010, -0.0025,  0.0010,\n",
       "                       0.0002, -0.0052,  0.0112,  0.0039,  0.0036,  0.0058, -0.0006, -0.0046,\n",
       "                       0.0001, -0.0085, -0.0017, -0.0184,  0.0047, -0.0030,  0.0035,  0.0028,\n",
       "                      -0.0019, -0.0011,  0.0023, -0.0029, -0.0065, -0.0028, -0.0002,  0.0016,\n",
       "                       0.0036,  0.0007, -0.0061,  0.0018,  0.0016,  0.0044, -0.0082,  0.0032,\n",
       "                       0.0066, -0.0012, -0.0023, -0.0020, -0.0026, -0.0018, -0.0041,  0.0006,\n",
       "                       0.0027, -0.0016,  0.0030,  0.0052, -0.0025, -0.0038, -0.0027, -0.0028,\n",
       "                      -0.0049, -0.0106,  0.0008, -0.0028, -0.0010, -0.0022, -0.0053,  0.0032,\n",
       "                      -0.0043, -0.0019,  0.0007, -0.0046, -0.0047,  0.0049,  0.0002, -0.0041,\n",
       "                       0.0080,  0.0108,  0.0009,  0.0036, -0.0012, -0.0111,  0.0056, -0.0030,\n",
       "                      -0.0023, -0.0056, -0.0059, -0.0008, -0.0034,  0.0018, -0.0038,  0.0042,\n",
       "                      -0.0056, -0.0042,  0.0014, -0.0020,  0.0096, -0.0049, -0.0011, -0.0039,\n",
       "                      -0.0053, -0.0072,  0.0070, -0.0033, -0.0008, -0.0072, -0.0115, -0.0011,\n",
       "                       0.0039,  0.0019, -0.0019, -0.0093,  0.0095, -0.0048, -0.0004, -0.0072],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.1.mlp.1.weight',\n",
       "              tensor([0.9730, 0.9479, 0.9560, 0.9548, 0.9768, 0.9828, 0.9751, 0.9750, 0.9873,\n",
       "                      0.9672, 0.9756, 0.9669, 0.9686, 0.9723, 0.9805, 0.9837, 0.9656, 0.9780,\n",
       "                      0.9667, 0.9769, 0.9742, 0.9678, 0.9777, 0.9583, 0.9638, 0.9679, 0.9739,\n",
       "                      0.9721, 0.9737, 0.9577, 0.9759, 0.9600, 0.9460, 0.9749, 0.9769, 0.9603,\n",
       "                      0.9727, 0.9676, 0.9691, 0.9774, 0.9824, 0.9694, 0.9802, 0.9831, 0.9514,\n",
       "                      0.9755, 0.9656, 0.9759, 0.9768, 0.9591, 0.9683, 0.9598, 0.9666, 0.9549,\n",
       "                      0.9607, 0.9601, 0.9719, 0.9573, 0.9675, 0.9671, 0.9765, 0.9776, 0.9787,\n",
       "                      0.9745, 0.9806, 0.9868, 0.9788, 0.9685, 0.9631, 0.9737, 0.9595, 0.9800,\n",
       "                      0.9677, 0.9665, 0.9689, 0.9730, 0.9658, 0.9722, 0.9744, 0.9704, 0.9721,\n",
       "                      0.9548, 0.9743, 0.9535, 0.9724, 0.9563, 0.9727, 0.9772, 0.9678, 0.9716,\n",
       "                      0.9692, 0.9699, 0.9741, 0.9844, 0.9322, 0.9726, 0.9557, 0.9669, 0.9788,\n",
       "                      0.9769, 0.9715, 0.9718, 0.9603, 0.9803, 0.9775, 0.9709, 0.9801, 0.9775,\n",
       "                      0.9534, 0.9695, 0.9735, 0.9684, 0.9606, 0.9741, 0.9593, 0.9733, 0.9789,\n",
       "                      0.9722, 0.9754, 0.9673, 0.9583, 0.9669, 0.9619, 0.9665, 0.9701, 0.9754,\n",
       "                      0.9714, 0.9751, 0.9819, 0.9727, 0.9585, 0.9811, 0.9474, 0.9647, 0.9637,\n",
       "                      0.9612, 0.9587, 0.9761, 0.9714, 0.9719, 0.9714, 0.9795, 0.9723, 0.9762,\n",
       "                      0.9710, 0.9765, 0.9656, 0.9420, 0.9748, 0.9760, 0.9737, 0.9819, 0.9654,\n",
       "                      0.9742, 0.9621, 0.9725, 0.9702, 0.9738, 0.9525, 0.9647, 0.9756, 0.9771,\n",
       "                      0.9730, 0.9755, 0.9733, 0.9665, 0.9708, 0.9645, 0.9733, 0.9757, 0.9683,\n",
       "                      0.9674, 0.9898, 0.9834, 0.9603, 0.9634, 0.9783, 0.9778, 0.9763, 0.9604,\n",
       "                      0.9786, 0.9674, 0.9642, 0.9574, 0.9509, 0.9701, 0.9740, 0.9601, 0.9561,\n",
       "                      0.9559, 0.9561, 0.9755, 0.9663, 0.9664, 0.9382, 0.9640, 0.9825, 0.9380,\n",
       "                      0.9778, 0.9701], device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.1.mlp.1.bias',\n",
       "              tensor([ 3.4657e-02, -2.5796e-02, -9.7424e-03,  2.4349e-03, -5.8099e-03,\n",
       "                       2.0100e-03,  3.1973e-02,  1.8742e-03,  1.5664e-02, -1.1924e-02,\n",
       "                       7.8245e-03, -1.7556e-03, -9.7630e-03,  3.4978e-03, -1.3139e-02,\n",
       "                      -4.4988e-03, -1.6876e-02, -1.2673e-02, -2.5421e-03,  1.0009e-02,\n",
       "                      -6.1307e-03, -2.3162e-02,  1.0852e-02, -1.8861e-02,  3.8116e-03,\n",
       "                      -3.2518e-03,  3.2115e-02,  3.4364e-03,  5.0679e-03, -7.0415e-03,\n",
       "                       1.0639e-02, -9.5283e-03, -4.3888e-03, -7.4301e-04, -5.8204e-03,\n",
       "                      -4.0872e-03, -3.5701e-03, -2.8987e-03, -1.1864e-02,  1.1958e-02,\n",
       "                       2.7957e-02, -1.8821e-02,  1.5315e-02,  1.9130e-02, -1.7457e-02,\n",
       "                       7.7958e-03, -1.8994e-02, -7.1359e-03,  6.5180e-03,  5.1095e-03,\n",
       "                      -1.8512e-02, -6.5952e-03, -1.2614e-02, -1.6167e-02, -4.2118e-03,\n",
       "                      -5.2682e-03, -6.2375e-03,  4.3906e-03,  5.2536e-04, -5.0878e-03,\n",
       "                      -1.6170e-03,  2.8812e-03,  6.7783e-03, -1.0945e-02, -5.1501e-03,\n",
       "                       1.2418e-02, -2.7596e-02, -1.5499e-02, -4.0386e-03,  7.5244e-03,\n",
       "                      -2.4812e-02,  9.6813e-03,  1.3508e-02,  5.9364e-03,  1.7945e-02,\n",
       "                      -3.0688e-03, -1.1093e-02,  1.6777e-03,  2.0968e-02, -2.0735e-04,\n",
       "                      -4.9561e-04,  1.3124e-02,  1.6657e-03, -1.1922e-02,  3.0379e-03,\n",
       "                      -7.7480e-03,  1.8005e-02,  6.1652e-03,  1.5581e-02, -1.4317e-02,\n",
       "                       1.7027e-02, -7.3958e-04, -1.0333e-02,  9.7157e-03, -2.7294e-02,\n",
       "                       7.4243e-03, -1.1505e-02,  1.5088e-03,  9.3816e-03, -4.5328e-03,\n",
       "                       8.4314e-03, -1.0564e-02,  1.1185e-02,  2.1622e-02,  1.1859e-02,\n",
       "                       4.7738e-03, -2.4279e-02, -2.4001e-03, -2.1152e-02, -4.3431e-03,\n",
       "                      -1.3474e-03, -8.4990e-03, -8.0952e-03, -5.7850e-03, -4.5457e-03,\n",
       "                      -1.4686e-02, -3.8672e-03,  1.0776e-02, -1.3250e-02, -2.8913e-03,\n",
       "                       6.7150e-03, -8.3765e-03,  8.1725e-03, -6.3875e-03, -1.6412e-03,\n",
       "                       3.1255e-03, -5.9708e-03,  5.7145e-04,  1.8550e-02,  1.5165e-02,\n",
       "                      -1.6426e-02,  2.3533e-02, -1.7556e-02, -2.2022e-02,  9.0658e-03,\n",
       "                      -1.0918e-02, -2.2209e-03, -7.1353e-03, -1.1657e-03,  2.2234e-02,\n",
       "                       2.7679e-03,  8.1843e-03, -9.1998e-03,  1.7549e-02, -7.6342e-03,\n",
       "                       3.5418e-04, -2.3575e-03, -1.5031e-02, -1.5524e-02,  8.6135e-03,\n",
       "                      -3.8239e-03,  1.7929e-02, -7.1128e-03, -1.8793e-03, -8.0501e-03,\n",
       "                       5.2614e-03, -6.5535e-05, -3.1801e-03,  4.8761e-03, -6.9472e-04,\n",
       "                       1.2125e-02,  2.3865e-02,  1.1806e-02,  4.6912e-03, -1.5766e-02,\n",
       "                      -1.9686e-02, -1.9614e-02, -1.1499e-02, -4.8891e-03, -1.3474e-02,\n",
       "                      -1.0109e-02,  8.4595e-04,  2.9266e-02, -1.1496e-03, -6.9487e-03,\n",
       "                       7.5075e-03,  2.1310e-02, -1.3316e-03, -1.9031e-03, -2.0117e-02,\n",
       "                       1.3851e-02, -7.4101e-03, -2.2746e-03, -8.6875e-03, -5.9744e-03,\n",
       "                       6.4316e-03, -8.6449e-03,  1.4165e-02, -1.7105e-02, -2.4247e-02,\n",
       "                      -1.3839e-02,  1.2793e-02,  8.6498e-03, -1.0554e-02, -2.4718e-02,\n",
       "                      -1.8369e-02,  1.6180e-02, -1.7874e-02,  4.5291e-04,  2.1423e-02],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.1.mlp.1.running_mean',\n",
       "              tensor([-1.9018,  1.2350, -1.2466, -1.0402,  1.2086,  1.2372, -0.7383, -0.1799,\n",
       "                      -1.0742,  0.9573, -0.1250, -1.0227, -0.8489, -0.9919,  1.0677, -0.6507,\n",
       "                       1.1216,  0.4074,  0.0934, -0.7853,  1.1803, -0.5442,  0.4770, -0.6731,\n",
       "                      -0.0561,  0.1988, -1.3957, -1.0296,  1.2772,  0.0537, -0.9335, -0.8596,\n",
       "                      -1.4351,  0.7346,  0.4389,  0.5683, -1.1830,  0.3470, -0.8310, -0.8439,\n",
       "                      -0.5251,  0.6873, -1.3599, -1.6161, -1.5387,  0.7854, -0.6310,  1.2680,\n",
       "                      -1.1172, -1.2258, -0.0763,  0.2617, -0.5906, -0.2155, -0.4512, -0.8484,\n",
       "                      -1.1098, -0.8112, -1.1367, -0.1164, -0.9128, -0.5586, -0.7792,  0.9794,\n",
       "                       0.0750, -0.1840, -0.5322, -1.1235, -0.8632, -0.3578, -1.0002, -0.9128,\n",
       "                       0.1307,  0.2575, -0.4078, -0.3072, -1.0140, -0.1760, -1.5258, -0.0268,\n",
       "                      -0.8399, -0.7942,  0.7773, -1.3315, -1.2336, -1.1141, -1.2229, -1.7101,\n",
       "                      -1.0473,  1.6144, -0.7178,  0.3180, -1.3159, -0.4135, -1.2074, -0.7818,\n",
       "                      -1.1531, -0.3401, -0.1141,  0.5687,  0.3275, -0.6129, -0.4887,  0.0744,\n",
       "                       0.2295, -0.2213, -1.0137,  0.7104,  0.1573, -1.1997,  0.5840, -1.2414,\n",
       "                      -0.4011, -0.6611, -0.7690, -0.5846, -1.1595, -0.9829, -0.1730, -0.7789,\n",
       "                      -1.0657, -0.7865, -0.9395, -0.9424,  0.4450, -0.0581,  0.6646, -0.8215,\n",
       "                      -1.2250,  0.0417,  1.2497, -0.9685, -0.6733,  0.9620, -0.0801,  0.7376,\n",
       "                      -0.5008, -0.4851, -0.5995, -0.8281, -0.3317, -0.2665, -0.9882, -1.1438,\n",
       "                      -0.7529,  0.3686, -0.9550, -1.1786, -0.6797, -0.5960,  0.4417, -0.8531,\n",
       "                       0.2004,  0.1227, -0.2102, -0.0819, -0.9619, -1.1526, -0.6693,  0.1620,\n",
       "                       0.1529,  0.3576, -0.1353, -0.0263, -1.2858,  1.6947,  1.5467, -0.7156,\n",
       "                      -0.7420, -0.9128, -1.0362,  0.3653, -0.7109,  0.4740, -0.3168, -0.3448,\n",
       "                      -1.2428, -0.1618, -1.0079,  0.5274, -1.1990, -0.6976,  0.8369, -0.8325,\n",
       "                      -0.9063, -1.3351, -0.3546, -1.0768,  1.3918, -1.1294, -0.1160, -0.1365,\n",
       "                      -0.9668,  1.0820, -0.0231, -0.8065, -0.0665, -0.5379, -0.8331, -1.0104],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.1.mlp.1.running_var',\n",
       "              tensor([15.6093, 11.2765, 11.1716, 13.2752, 12.4612,  4.2778,  8.2131,  3.7636,\n",
       "                       6.4345, 13.1853,  8.7392,  9.0429,  6.4402,  4.4342, 19.1769,  9.4079,\n",
       "                      40.9187, 14.6641, 10.6008,  5.2683, 13.6421,  7.7862, 13.9602,  7.2445,\n",
       "                      11.9010,  9.3483,  5.3953, 11.9577, 18.6280, 17.9788,  7.2981,  3.3670,\n",
       "                      14.1971,  3.6324, 14.9904,  3.0790, 25.4119,  8.4567,  7.6032,  3.4583,\n",
       "                       5.4076,  5.7039, 12.0072, 15.5448, 19.7328, 17.2775,  4.5219,  5.2492,\n",
       "                       5.9599, 20.9502,  3.4222,  2.5347, 17.3620,  3.2524,  5.0107,  9.1462,\n",
       "                      26.9539,  3.6165,  4.9718,  8.5166, 12.6698, 20.2489,  4.3996,  3.6789,\n",
       "                      37.0330,  3.6095, 21.3511, 27.0694, 23.7609,  3.7043, 26.7349,  8.7641,\n",
       "                      23.7088,  5.0398, 12.6161,  4.3804, 13.8621,  4.2274, 14.1595,  6.9625,\n",
       "                       4.0203, 24.1524, 16.2677, 18.2024,  4.5019,  6.6576,  3.1509, 23.6595,\n",
       "                       2.5823,  5.2438,  9.9809, 10.7942, 15.3562,  8.1515, 19.8269,  4.6662,\n",
       "                      13.5855,  3.4182, 30.9927,  3.6731, 14.5170,  7.2436,  7.0728, 17.7914,\n",
       "                       9.4680, 10.6873, 21.5791, 11.0135, 11.0704, 16.4416, 18.1173, 12.4754,\n",
       "                       5.5636,  1.6460, 29.6468,  5.1845,  7.0238,  3.1595, 16.9369,  8.0179,\n",
       "                       5.7837,  9.0538,  8.5782,  7.3702,  6.7267,  8.1097,  9.5133,  8.4042,\n",
       "                       5.3676, 14.5093,  9.3619, 11.5181, 14.8269,  6.2438,  7.2507,  7.6099,\n",
       "                      25.5636,  8.0048,  5.1511,  3.5346, 12.1030,  4.8062,  4.9382,  4.0876,\n",
       "                       3.0160,  2.4918, 31.6461, 22.9607, 14.7001,  2.4750, 11.0183,  3.9124,\n",
       "                      12.7208,  3.2622, 10.2535,  4.1041, 11.7231, 28.4507,  4.1987,  4.2268,\n",
       "                      22.1894, 32.9705,  7.9051, 26.1704,  9.6547, 10.7410, 10.0577,  4.4319,\n",
       "                       5.7534,  8.8782,  9.4884, 11.9906,  6.5902,  4.4263,  4.1643,  5.4643,\n",
       "                      13.1729,  3.2101,  8.4604, 19.4591,  5.8776, 16.0370,  6.7697, 11.2031,\n",
       "                      12.3413, 15.0882,  3.8597,  3.8518,  6.4496, 16.4621,  5.4917, 10.8493,\n",
       "                       6.3166,  8.6840,  6.4952, 10.2355,  5.3703,  8.7177, 18.6377,  6.1089],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.1.mlp.1.num_batches_tracked',\n",
       "              tensor(63750, device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.1.mlp.3.weight',\n",
       "              tensor([[-0.0102,  0.0178, -0.0374,  ...,  0.0037,  0.0166,  0.0462],\n",
       "                      [ 0.0182, -0.0114,  0.0317,  ...,  0.0001, -0.0023, -0.0040],\n",
       "                      [ 0.0119, -0.0107, -0.0037,  ..., -0.0388,  0.0281, -0.0064],\n",
       "                      ...,\n",
       "                      [-0.0193,  0.0196,  0.0064,  ..., -0.0071, -0.0018, -0.0084],\n",
       "                      [ 0.0373,  0.0055, -0.0089,  ..., -0.0323,  0.0147, -0.0027],\n",
       "                      [ 0.0376,  0.0242, -0.0084,  ...,  0.0117, -0.0067,  0.0558]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.1.mlp.3.bias',\n",
       "              tensor([ 7.9622e-03,  3.0279e-03, -1.3626e-02, -1.2081e-03,  5.4394e-04,\n",
       "                      -8.2746e-03,  1.4416e-02,  1.1352e-03, -1.2874e-02,  1.7316e-02,\n",
       "                       7.7454e-04,  7.9596e-03,  5.3997e-04, -8.2379e-03,  1.8186e-03,\n",
       "                       5.3021e-03, -5.9198e-03, -2.4327e-03, -4.5483e-03,  1.5825e-02,\n",
       "                       1.3573e-02, -4.7727e-03, -3.0281e-03, -6.9414e-03, -8.9489e-04,\n",
       "                       4.7818e-03, -2.8690e-02, -1.5221e-02, -4.7864e-03,  2.4478e-03,\n",
       "                      -1.2328e-02,  1.2404e-02, -1.3879e-03,  9.8128e-03,  1.6361e-02,\n",
       "                       4.9717e-04, -6.0779e-03, -5.2219e-03, -5.9310e-03, -1.8407e-02,\n",
       "                      -5.1901e-03, -7.7068e-03,  1.0182e-02, -9.2088e-03, -1.0210e-02,\n",
       "                      -2.7722e-03,  1.9062e-02, -2.4709e-02, -2.1461e-03,  4.8032e-03,\n",
       "                       4.8923e-03,  5.1593e-03,  9.0809e-03, -1.5027e-02, -1.2803e-02,\n",
       "                      -4.9469e-03, -1.3475e-02, -9.6674e-03, -1.6612e-03,  7.9335e-05,\n",
       "                       1.6235e-03, -1.1803e-02,  4.8681e-03, -1.3161e-02,  1.2751e-02,\n",
       "                      -9.2351e-03, -8.6782e-03,  6.9510e-03, -3.0491e-03, -9.8829e-03,\n",
       "                      -1.0581e-02, -1.1235e-02, -1.8225e-02, -3.6400e-03, -9.8334e-04,\n",
       "                       1.8641e-03, -8.8023e-03, -8.4616e-03, -3.0854e-03,  1.0353e-02,\n",
       "                      -9.3986e-03, -1.6239e-02, -2.7110e-03, -1.1658e-02, -8.7415e-03,\n",
       "                      -4.5652e-04, -1.9645e-02,  7.6536e-03, -5.5074e-03, -1.6572e-02,\n",
       "                      -7.7241e-03,  1.3777e-02,  1.1985e-02, -9.2298e-04, -2.7899e-03,\n",
       "                       3.2833e-03,  1.4790e-02, -7.9666e-03,  1.6684e-02, -5.5535e-03,\n",
       "                       9.4298e-03,  9.6350e-03,  2.2107e-02, -1.0452e-02, -3.7505e-03,\n",
       "                      -1.4268e-02, -1.2437e-02, -5.4459e-03, -1.2796e-02, -1.9765e-02,\n",
       "                      -1.2251e-02, -7.9006e-03,  3.2686e-03, -8.9631e-03,  1.6452e-02,\n",
       "                      -2.2352e-02, -1.1301e-02,  5.7909e-03, -1.5489e-02, -1.5036e-02,\n",
       "                      -1.4079e-02,  2.3820e-03,  9.0787e-03, -4.9153e-03,  2.8135e-03,\n",
       "                      -2.8659e-03, -6.7451e-03, -1.2422e-02, -1.4631e-02,  4.8998e-03,\n",
       "                      -1.4261e-02,  9.7226e-04, -1.3832e-02,  2.9070e-03, -4.1635e-03,\n",
       "                       9.6605e-03, -1.7645e-02, -1.6591e-02, -3.4265e-04,  7.3928e-03,\n",
       "                      -1.7140e-02, -1.9455e-02,  6.8476e-04,  7.1272e-03,  1.0946e-02,\n",
       "                      -3.3400e-03, -1.1697e-02, -6.0892e-03,  1.7221e-02, -2.5453e-03,\n",
       "                      -5.6772e-03,  1.6864e-02,  1.0187e-02, -2.3305e-03, -8.5733e-03,\n",
       "                       9.8183e-03, -1.0430e-02, -4.1665e-03,  1.4880e-02, -8.2354e-03,\n",
       "                      -1.6649e-03, -2.3944e-03, -1.8005e-02, -1.3927e-02, -4.0511e-03,\n",
       "                      -8.0677e-03, -8.8939e-03, -1.9296e-02,  2.1850e-02, -1.8827e-02,\n",
       "                      -1.4240e-02, -6.9041e-03, -1.4883e-02, -1.5523e-04, -1.3082e-02,\n",
       "                       1.9668e-03, -1.7202e-02, -1.4444e-02,  4.8704e-04,  4.9032e-03,\n",
       "                      -1.5775e-02,  3.5383e-03, -1.8642e-03, -5.7349e-05, -1.0353e-02,\n",
       "                       1.4028e-02,  3.1695e-03, -9.4482e-03,  1.3516e-02,  5.6247e-03,\n",
       "                      -1.4536e-02, -1.4192e-03, -1.1911e-02,  1.0714e-02,  1.3734e-02,\n",
       "                      -6.8823e-03,  6.7205e-03, -1.5873e-02,  1.4803e-02,  1.3652e-02],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.2.edge_encoder.0.weight',\n",
       "              tensor([[ 0.0306, -0.0353,  0.0325,  ..., -0.0054, -0.0064, -0.0239],\n",
       "                      [ 0.0247,  0.0387,  0.0236,  ...,  0.0328,  0.0120, -0.0459],\n",
       "                      [ 0.0180, -0.0081, -0.0130,  ..., -0.0158,  0.0251,  0.0164],\n",
       "                      ...,\n",
       "                      [ 0.0070,  0.0437, -0.0125,  ..., -0.0002, -0.0051, -0.0569],\n",
       "                      [ 0.0213,  0.0714,  0.0441,  ..., -0.0479,  0.0109, -0.0085],\n",
       "                      [ 0.0176, -0.0074, -0.0351,  ..., -0.0420,  0.0276, -0.0018]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.2.edge_encoder.0.bias',\n",
       "              tensor([ 0.0077,  0.0119,  0.0017, -0.0190, -0.0046,  0.0056,  0.0168,  0.0094,\n",
       "                      -0.0051,  0.0039, -0.0029,  0.0186, -0.0180,  0.0189,  0.0191, -0.0094,\n",
       "                       0.0084,  0.0184, -0.0068, -0.0066, -0.0126, -0.0144,  0.0322,  0.0054,\n",
       "                       0.0056, -0.0084,  0.0076,  0.0117, -0.0092, -0.0210,  0.0302,  0.0111,\n",
       "                       0.0049,  0.0133,  0.0009,  0.0033,  0.0078, -0.0005,  0.0011,  0.0380,\n",
       "                       0.0042, -0.0085, -0.0131, -0.0191, -0.0132, -0.0132,  0.0060,  0.0126,\n",
       "                       0.0204, -0.0218, -0.0039,  0.0289,  0.0030,  0.0034,  0.0042,  0.0069,\n",
       "                       0.0276,  0.0014,  0.0052, -0.0010,  0.0165, -0.0045, -0.0037,  0.0045,\n",
       "                       0.0175, -0.0177, -0.0008,  0.0173, -0.0091,  0.0122, -0.0022, -0.0185,\n",
       "                      -0.0071, -0.0143,  0.0194,  0.0052,  0.0028,  0.0003, -0.0044,  0.0021,\n",
       "                      -0.0239, -0.0257,  0.0002,  0.0104,  0.0085,  0.0029,  0.0085,  0.0186,\n",
       "                       0.0136, -0.0184,  0.0170,  0.0219,  0.0114,  0.0373, -0.0013, -0.0081,\n",
       "                       0.0079,  0.0001,  0.0129, -0.0018,  0.0132,  0.0188,  0.0141, -0.0070,\n",
       "                       0.0138,  0.0063, -0.0268, -0.0065,  0.0113,  0.0060,  0.0369,  0.0077,\n",
       "                       0.0054, -0.0095, -0.0127, -0.0155, -0.0099, -0.0243, -0.0093,  0.0114,\n",
       "                      -0.0292, -0.0092, -0.0165,  0.0360, -0.0180,  0.0009, -0.0012, -0.0136,\n",
       "                      -0.0028, -0.0299, -0.0139,  0.0060, -0.0042,  0.0075, -0.0028,  0.0032,\n",
       "                       0.0168, -0.0089,  0.0203,  0.0222,  0.0033, -0.0214,  0.0055, -0.0004,\n",
       "                      -0.0070, -0.0103,  0.0122,  0.0016,  0.0049,  0.0059,  0.0101, -0.0175,\n",
       "                      -0.0075,  0.0347, -0.0166,  0.0217,  0.0009, -0.0263,  0.0026,  0.0296,\n",
       "                       0.0109,  0.0100, -0.0139, -0.0151,  0.0139,  0.0117,  0.0224,  0.0200,\n",
       "                       0.0159,  0.0146, -0.0090,  0.0056,  0.0198, -0.0114,  0.0122, -0.0099,\n",
       "                      -0.0116,  0.0004, -0.0143, -0.0011,  0.0056,  0.0021,  0.0154, -0.0226,\n",
       "                      -0.0033, -0.0069, -0.0072, -0.0033, -0.0062, -0.0068, -0.0164,  0.0153,\n",
       "                      -0.0333,  0.0075, -0.0050, -0.0042, -0.0204,  0.0111, -0.0367,  0.0139],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.2.edge_encoder.1.weight',\n",
       "              tensor([0.9628, 0.9829, 0.9672, 0.9673, 0.9706, 0.9835, 0.9779, 0.9585, 0.9801,\n",
       "                      1.0104, 0.9749, 0.9749, 0.9704, 0.9653, 0.9617, 0.9588, 0.9810, 0.9747,\n",
       "                      0.9706, 0.9653, 0.9548, 0.9736, 0.9918, 0.9715, 0.9768, 0.9686, 0.9768,\n",
       "                      0.9644, 0.9705, 0.9647, 0.9775, 0.9654, 0.9791, 0.9719, 0.9689, 1.0024,\n",
       "                      0.9714, 0.9612, 0.9602, 0.9835, 0.9716, 0.9771, 0.9913, 0.9704, 0.9972,\n",
       "                      0.9774, 0.9673, 0.9556, 0.9649, 0.9712, 0.9714, 0.9532, 0.9586, 0.9630,\n",
       "                      0.9654, 0.9569, 0.9866, 0.9909, 0.9710, 0.9789, 0.9821, 0.9766, 0.9629,\n",
       "                      1.0112, 0.9736, 1.0307, 0.9648, 0.9848, 0.9644, 0.9779, 0.9688, 0.9556,\n",
       "                      0.9911, 0.9716, 0.9692, 0.9976, 0.9801, 0.9737, 0.9750, 1.0032, 0.9712,\n",
       "                      0.9831, 0.9793, 1.0119, 0.9947, 0.9525, 0.9689, 1.0086, 0.9671, 0.9862,\n",
       "                      0.9723, 0.9898, 0.9515, 0.9780, 0.9625, 0.9707, 0.9851, 0.9711, 0.9946,\n",
       "                      0.9929, 1.0127, 0.9705, 0.9535, 0.9593, 0.9769, 0.9911, 0.9627, 0.9748,\n",
       "                      0.9724, 0.9391, 0.9803, 0.9876, 0.9843, 0.9748, 0.9582, 0.9636, 0.9737,\n",
       "                      0.9705, 0.9908, 0.9860, 0.9873, 0.9901, 0.9624, 0.9739, 0.9752, 0.9613,\n",
       "                      0.9775, 0.9644, 0.9877, 0.9880, 0.9751, 0.9752, 0.9599, 0.9629, 0.9751,\n",
       "                      0.9859, 0.9705, 0.9769, 0.9848, 0.9831, 0.9677, 1.0146, 0.9704, 0.9786,\n",
       "                      0.9771, 0.9810, 0.9668, 0.9568, 0.9419, 0.9776, 0.9674, 0.9866, 0.9767,\n",
       "                      0.9543, 0.9812, 1.0107, 0.9792, 0.9727, 0.9707, 0.9655, 0.9763, 0.9820,\n",
       "                      0.9982, 0.9833, 0.9660, 1.0028, 0.9630, 0.9713, 1.0131, 0.9784, 0.9664,\n",
       "                      0.9688, 0.9602, 0.9605, 0.9668, 0.9759, 0.9633, 0.9736, 0.9751, 0.9571,\n",
       "                      0.9551, 0.9673, 0.9850, 0.9753, 0.9827, 0.9796, 0.9681, 0.9709, 0.9784,\n",
       "                      0.9611, 0.9603, 0.9895, 0.9809, 0.9890, 0.9777, 0.9484, 0.9913, 0.9686,\n",
       "                      1.0060, 0.9723], device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.2.edge_encoder.1.bias',\n",
       "              tensor([-2.5693e-02, -9.7445e-03, -1.3280e-02, -1.4876e-02, -1.3010e-02,\n",
       "                      -2.8902e-02, -1.5408e-02, -1.3348e-02, -7.5672e-03,  1.6497e-03,\n",
       "                      -7.8495e-03, -9.1716e-03, -2.0961e-02, -2.2757e-02, -2.0028e-02,\n",
       "                      -1.7987e-02, -7.9770e-03, -1.8736e-03, -5.3145e-03, -3.8504e-03,\n",
       "                      -1.5113e-02, -2.7974e-02,  2.6333e-03, -8.1461e-03, -1.9291e-02,\n",
       "                      -1.5892e-03,  1.6622e-04, -1.8932e-02, -1.3259e-02, -2.7374e-02,\n",
       "                      -1.4522e-02, -1.6898e-02, -8.0646e-03, -1.0664e-02, -1.0739e-02,\n",
       "                      -1.7976e-03, -1.9121e-02, -1.7618e-02, -1.1595e-02, -8.5707e-03,\n",
       "                      -1.0648e-02, -1.1552e-02, -1.4868e-02, -9.6961e-03, -2.4517e-02,\n",
       "                      -7.4088e-03,  7.0666e-03, -1.7505e-02, -1.4665e-02, -2.4669e-02,\n",
       "                      -2.5899e-02, -3.7980e-02, -2.2516e-02, -3.0423e-03, -9.7302e-03,\n",
       "                      -2.5835e-02, -2.2611e-03, -4.0520e-03, -6.8373e-03, -1.9277e-02,\n",
       "                      -8.0628e-03, -1.8217e-02, -1.6750e-02, -1.5095e-02, -1.4788e-03,\n",
       "                      -3.7971e-02, -1.9556e-02,  1.5557e-04, -7.2736e-03, -3.9847e-03,\n",
       "                      -1.2300e-02, -1.9903e-02, -1.9171e-02, -9.9416e-03, -5.3805e-03,\n",
       "                       1.5913e-03, -7.6342e-03, -3.3007e-03, -6.2690e-03, -1.4096e-05,\n",
       "                      -1.5686e-02, -6.8913e-03, -1.7321e-02, -2.5634e-02, -1.4783e-02,\n",
       "                      -2.4108e-02, -1.3706e-02, -2.0894e-02, -2.0094e-02, -6.5898e-03,\n",
       "                      -1.2185e-02, -6.1023e-03, -2.7504e-02, -2.4717e-02, -2.5939e-02,\n",
       "                      -1.5674e-02, -5.1389e-03, -7.2659e-03,  4.9414e-03, -1.5022e-03,\n",
       "                      -1.3755e-02, -2.0142e-02, -2.5539e-02, -3.3021e-02, -1.7456e-02,\n",
       "                      -7.0987e-03, -1.8066e-02, -7.1374e-03, -9.0562e-03, -4.0189e-02,\n",
       "                      -4.1441e-03, -9.2944e-03, -8.8290e-03, -1.3431e-02, -1.1504e-02,\n",
       "                      -2.5691e-02, -1.5559e-02, -2.4027e-02, -1.8737e-02, -6.9398e-03,\n",
       "                      -1.3982e-02, -9.3979e-03, -2.2429e-02, -1.6925e-02, -1.1936e-02,\n",
       "                      -2.2714e-02, -8.0626e-03, -2.0102e-02, -1.1027e-02, -1.1894e-02,\n",
       "                      -2.9027e-02, -1.0246e-02, -2.0020e-02, -2.4571e-02,  1.9411e-03,\n",
       "                      -2.1970e-02, -1.8667e-02, -1.4658e-02, -3.9352e-03, -1.8957e-02,\n",
       "                      -9.4686e-03, -2.8255e-02,  5.2848e-04,  7.7191e-03, -1.7395e-02,\n",
       "                      -1.0582e-02, -1.7854e-02, -2.6494e-02, -3.3694e-02, -2.2807e-02,\n",
       "                      -2.3661e-02, -5.3341e-03, -7.3770e-03, -3.4522e-02, -2.7705e-02,\n",
       "                      -7.6568e-03, -5.1986e-03,  6.7720e-03, -2.3240e-02, -3.5141e-02,\n",
       "                      -1.3055e-02, -8.6289e-03, -2.5888e-02, -1.1771e-02, -1.2512e-02,\n",
       "                      -1.8411e-02, -3.3645e-02, -7.4316e-03, -1.2644e-02, -7.5547e-03,\n",
       "                      -1.6641e-02, -1.9724e-02, -2.6223e-02, -1.5339e-02, -6.3751e-03,\n",
       "                      -5.5682e-03, -2.3769e-02, -8.3162e-03, -7.2813e-03, -3.8014e-02,\n",
       "                      -2.6523e-02, -2.3696e-02, -9.4407e-03, -1.6965e-02, -1.8803e-02,\n",
       "                       4.4039e-03, -1.6914e-02, -1.6613e-02,  7.9222e-03, -2.1573e-02,\n",
       "                      -5.3399e-03, -1.7694e-02, -4.4106e-03, -3.1973e-03, -3.3638e-03,\n",
       "                      -3.0254e-02,  3.6135e-03, -1.7349e-02,  2.9815e-03, -8.8753e-03],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.2.edge_encoder.1.running_mean',\n",
       "              tensor([ 2.7008e-02,  1.6912e-03,  1.5797e-02, -6.7778e-02,  2.0418e-02,\n",
       "                      -1.1173e-02,  1.5179e-02,  2.4307e-02,  1.2653e-02,  4.6869e-03,\n",
       "                      -1.0762e-02, -1.9674e-03, -1.3291e-02,  3.0813e-02, -1.3610e-03,\n",
       "                       4.5526e-03,  2.5402e-02,  2.0468e-02,  1.6868e-02,  1.5769e-02,\n",
       "                      -3.7985e-03, -2.9739e-02,  3.6873e-02, -1.5693e-03, -2.0923e-02,\n",
       "                       4.5054e-02,  3.2104e-02, -3.1810e-03,  5.9307e-03, -2.4748e-03,\n",
       "                       2.8697e-02,  2.8321e-03,  4.0958e-02,  2.8253e-02,  3.6128e-02,\n",
       "                      -1.6234e-02,  1.5718e-02,  2.1499e-02,  3.2818e-02,  4.5780e-02,\n",
       "                       1.8265e-02, -2.2358e-02,  1.0330e-02, -8.1752e-03, -7.3849e-02,\n",
       "                      -7.7433e-02, -9.5062e-03,  5.6934e-02,  2.9798e-02, -5.6704e-02,\n",
       "                      -2.8998e-04,  3.8911e-02,  7.1862e-02,  2.8319e-02, -1.3835e-03,\n",
       "                       2.4380e-02,  4.7917e-02, -7.5812e-03,  4.3195e-02, -8.7772e-03,\n",
       "                       3.0336e-02, -2.1767e-02, -2.0313e-02, -5.7155e-02,  2.2238e-02,\n",
       "                      -1.7876e-02,  7.2475e-03,  5.9072e-02,  1.7254e-02,  3.5640e-02,\n",
       "                      -5.3690e-02,  3.1887e-02, -6.1408e-02,  1.1748e-02, -2.8399e-02,\n",
       "                       3.6311e-02,  3.8973e-02,  6.4906e-02,  7.8385e-03, -2.0935e-02,\n",
       "                      -5.8416e-02, -2.0047e-02, -3.1496e-02,  2.9189e-02, -3.4504e-02,\n",
       "                      -2.7514e-02,  6.8505e-02,  2.8062e-03,  1.8849e-05, -1.3774e-02,\n",
       "                       9.2343e-03,  3.7521e-02,  4.5121e-02,  1.4074e-02, -1.8121e-04,\n",
       "                      -4.0558e-02, -3.7644e-03,  1.6923e-02,  2.7104e-02, -1.5634e-02,\n",
       "                      -4.1377e-03,  9.3574e-03,  1.9628e-02,  5.6155e-02,  5.2343e-02,\n",
       "                       8.2967e-03, -3.7830e-03, -4.8709e-03, -8.8138e-03,  5.4959e-02,\n",
       "                       9.5033e-02, -8.7470e-03, -2.1711e-03, -2.7213e-02,  2.7870e-02,\n",
       "                      -6.4279e-02, -1.5909e-02, -4.3667e-02, -1.5132e-02, -9.5939e-03,\n",
       "                      -1.8963e-02, -6.7713e-03, -5.5545e-02, -1.0497e-02, -3.9040e-02,\n",
       "                      -4.8672e-03,  1.1762e-02, -1.5282e-02, -4.3349e-02, -5.3518e-02,\n",
       "                       4.6776e-03, -4.4651e-02, -4.5448e-02, -1.2307e-02,  1.7775e-02,\n",
       "                      -4.1911e-03,  2.1014e-02, -4.3004e-03,  2.7901e-02,  1.0977e-02,\n",
       "                      -7.3112e-03, -3.7840e-02, -1.7166e-03,  1.3762e-02, -2.5244e-02,\n",
       "                       1.1566e-02,  7.3994e-02, -4.3874e-03,  4.3512e-02, -4.0878e-02,\n",
       "                       1.8922e-03, -1.0121e-02, -2.9110e-02,  2.4583e-02, -4.8153e-02,\n",
       "                       2.5973e-02, -2.9922e-03, -2.0870e-02, -2.2877e-02, -1.4993e-03,\n",
       "                      -5.9943e-03, -7.2241e-03, -2.0146e-02,  1.2459e-02, -3.8290e-03,\n",
       "                      -2.0011e-02,  3.9809e-02,  1.3255e-02, -4.2352e-04,  1.7046e-02,\n",
       "                      -6.5159e-03,  1.2209e-02,  6.6373e-02, -1.1389e-02,  5.5789e-02,\n",
       "                       1.8531e-02, -1.1453e-02,  2.1218e-02,  1.8626e-02,  1.3585e-02,\n",
       "                      -3.0026e-02,  1.2386e-02, -9.9208e-03, -2.6795e-04, -8.1980e-03,\n",
       "                      -1.3025e-02, -1.7465e-02,  3.8352e-04, -2.6250e-02, -3.8193e-02,\n",
       "                       1.8636e-02, -7.6045e-03, -3.9300e-02,  1.3399e-03,  1.3233e-02,\n",
       "                       1.9639e-02, -1.1317e-02, -1.9422e-02, -3.2577e-02,  5.8234e-02],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.2.edge_encoder.1.running_var',\n",
       "              tensor([0.0007, 0.0011, 0.0017, 0.0010, 0.0004, 0.0005, 0.0011, 0.0008, 0.0008,\n",
       "                      0.0006, 0.0011, 0.0012, 0.0004, 0.0011, 0.0017, 0.0008, 0.0009, 0.0008,\n",
       "                      0.0008, 0.0017, 0.0010, 0.0005, 0.0005, 0.0005, 0.0007, 0.0009, 0.0004,\n",
       "                      0.0016, 0.0005, 0.0014, 0.0013, 0.0005, 0.0005, 0.0010, 0.0009, 0.0005,\n",
       "                      0.0009, 0.0014, 0.0012, 0.0007, 0.0004, 0.0008, 0.0005, 0.0008, 0.0010,\n",
       "                      0.0010, 0.0010, 0.0012, 0.0016, 0.0011, 0.0004, 0.0004, 0.0009, 0.0014,\n",
       "                      0.0009, 0.0013, 0.0004, 0.0005, 0.0009, 0.0005, 0.0003, 0.0009, 0.0005,\n",
       "                      0.0007, 0.0009, 0.0004, 0.0008, 0.0009, 0.0006, 0.0004, 0.0013, 0.0007,\n",
       "                      0.0007, 0.0006, 0.0007, 0.0004, 0.0007, 0.0007, 0.0007, 0.0003, 0.0020,\n",
       "                      0.0011, 0.0006, 0.0004, 0.0010, 0.0019, 0.0012, 0.0007, 0.0005, 0.0004,\n",
       "                      0.0005, 0.0009, 0.0012, 0.0007, 0.0007, 0.0014, 0.0015, 0.0009, 0.0009,\n",
       "                      0.0006, 0.0004, 0.0006, 0.0008, 0.0008, 0.0012, 0.0005, 0.0013, 0.0009,\n",
       "                      0.0006, 0.0015, 0.0007, 0.0006, 0.0007, 0.0010, 0.0010, 0.0010, 0.0005,\n",
       "                      0.0006, 0.0006, 0.0005, 0.0003, 0.0008, 0.0007, 0.0010, 0.0008, 0.0009,\n",
       "                      0.0008, 0.0012, 0.0011, 0.0014, 0.0014, 0.0012, 0.0019, 0.0012, 0.0016,\n",
       "                      0.0008, 0.0008, 0.0006, 0.0006, 0.0012, 0.0004, 0.0006, 0.0020, 0.0009,\n",
       "                      0.0004, 0.0004, 0.0010, 0.0010, 0.0006, 0.0004, 0.0008, 0.0006, 0.0010,\n",
       "                      0.0016, 0.0006, 0.0004, 0.0010, 0.0015, 0.0007, 0.0009, 0.0008, 0.0008,\n",
       "                      0.0005, 0.0006, 0.0010, 0.0003, 0.0010, 0.0007, 0.0005, 0.0007, 0.0007,\n",
       "                      0.0008, 0.0009, 0.0022, 0.0009, 0.0007, 0.0006, 0.0006, 0.0006, 0.0014,\n",
       "                      0.0004, 0.0004, 0.0003, 0.0004, 0.0008, 0.0010, 0.0010, 0.0010, 0.0016,\n",
       "                      0.0016, 0.0008, 0.0008, 0.0017, 0.0004, 0.0013, 0.0004, 0.0015, 0.0007,\n",
       "                      0.0011, 0.0009], device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.2.edge_encoder.1.num_batches_tracked',\n",
       "              tensor(318750, device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.2.edge_encoder.3.weight',\n",
       "              tensor([[-0.0193, -0.0094, -0.0241,  ...,  0.0122, -0.0301, -0.0028],\n",
       "                      [ 0.0069,  0.0188,  0.0111,  ..., -0.0008, -0.0141,  0.0301],\n",
       "                      [ 0.0371, -0.0236, -0.0005,  ..., -0.0178,  0.0145,  0.0044],\n",
       "                      ...,\n",
       "                      [ 0.0266,  0.0113,  0.0204,  ..., -0.0058,  0.0168, -0.0279],\n",
       "                      [ 0.0263, -0.0120,  0.0145,  ..., -0.0088,  0.0285, -0.0355],\n",
       "                      [ 0.0217,  0.0041,  0.0519,  ...,  0.0308, -0.0709, -0.0156]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.2.edge_encoder.3.bias',\n",
       "              tensor([-2.3653e-03, -5.7033e-03,  2.7150e-03,  1.7915e-03, -1.3082e-03,\n",
       "                      -3.1844e-04,  8.8534e-04, -5.2766e-03,  1.3499e-03,  4.7690e-03,\n",
       "                      -4.6336e-03,  1.4850e-03, -3.2236e-03,  3.7453e-03, -8.5289e-03,\n",
       "                       7.5043e-03,  5.8532e-03,  2.3962e-04, -5.7625e-04,  5.2903e-04,\n",
       "                      -1.7449e-03,  5.2435e-03,  2.9055e-03, -4.1971e-03, -5.6767e-03,\n",
       "                      -4.0691e-03, -1.4285e-03,  5.0252e-03, -1.9099e-03,  1.1951e-03,\n",
       "                       2.1446e-03, -2.3171e-03,  5.1971e-03,  1.3342e-03, -6.3974e-03,\n",
       "                       7.7394e-04, -5.0417e-03, -4.6538e-04,  8.4626e-03, -4.4000e-04,\n",
       "                      -7.0619e-04,  4.7418e-03, -5.4846e-03, -5.1588e-03, -7.3695e-03,\n",
       "                      -9.4579e-03,  4.9077e-03, -5.9823e-03,  1.0702e-03, -2.1661e-03,\n",
       "                       1.0390e-03,  1.1983e-03, -4.2399e-03, -1.2942e-03, -7.8520e-03,\n",
       "                      -3.5293e-03, -1.0280e-02,  3.5102e-04,  3.8343e-03, -1.2780e-03,\n",
       "                       4.5618e-04,  3.8666e-03,  1.8226e-03,  4.2149e-03, -7.9116e-03,\n",
       "                      -6.3569e-03,  7.4834e-04,  4.8660e-04, -3.4787e-03, -3.4874e-03,\n",
       "                      -2.9350e-03,  6.0196e-03,  2.0707e-03,  6.1710e-03, -2.5195e-04,\n",
       "                       2.7551e-03, -3.0170e-03, -3.2106e-03, -5.5723e-05,  5.0233e-03,\n",
       "                      -5.5378e-03, -8.5195e-03,  2.5666e-03, -1.8356e-03,  1.2716e-03,\n",
       "                      -1.2945e-03,  1.9425e-03,  8.8292e-04,  2.0636e-03,  1.4934e-03,\n",
       "                      -1.9848e-03,  9.8496e-03, -2.1664e-03,  1.9293e-03, -3.8735e-03,\n",
       "                      -5.7664e-03,  3.7731e-03, -2.0194e-03,  5.2783e-03,  3.5625e-03,\n",
       "                      -4.3390e-03, -4.5637e-03,  6.6010e-03,  3.1173e-03,  4.0452e-03,\n",
       "                      -2.6583e-03,  4.5262e-03, -1.5825e-03, -4.2482e-03, -3.4520e-03,\n",
       "                       2.3763e-03,  3.6228e-03,  1.7307e-03,  1.0506e-03,  4.2683e-03,\n",
       "                      -3.5708e-04, -2.0222e-03, -1.5319e-03,  4.2033e-03, -6.7279e-03,\n",
       "                       1.4046e-03,  2.9070e-03,  3.6665e-03,  1.5358e-03,  2.2912e-03,\n",
       "                       1.5417e-03, -5.5028e-03,  1.9160e-03, -3.6478e-03, -3.0722e-03,\n",
       "                      -6.0849e-04,  4.6370e-03,  1.5033e-03,  7.6505e-03,  1.1843e-03,\n",
       "                      -2.6880e-03, -7.3885e-04, -1.9909e-03, -4.8474e-03,  7.0672e-03,\n",
       "                       7.6360e-03, -5.4759e-03, -6.0674e-03, -1.4287e-03,  1.6351e-03,\n",
       "                       4.7338e-03, -4.7588e-03, -5.5839e-03,  1.8682e-03, -1.0032e-03,\n",
       "                      -1.1349e-04,  6.5163e-03,  7.6160e-04,  6.0492e-03,  2.1817e-03,\n",
       "                       5.5140e-04, -5.6854e-03,  2.1677e-04,  1.8623e-03,  1.7347e-03,\n",
       "                      -3.2468e-03,  2.5972e-03, -1.4406e-03, -4.4453e-03, -6.4311e-03,\n",
       "                      -3.7272e-03,  2.8988e-03, -3.4194e-03,  8.8222e-04,  3.5037e-03,\n",
       "                       4.3227e-04, -1.8212e-03,  1.9136e-03, -3.1052e-03, -5.8780e-03,\n",
       "                      -9.3809e-04,  2.1546e-03, -5.0847e-03, -5.3777e-03, -3.2735e-03,\n",
       "                       1.7199e-04, -1.1658e-03,  3.6198e-03,  4.1820e-03,  1.1943e-04,\n",
       "                      -1.7642e-03,  4.1916e-03,  8.8105e-04, -6.2575e-03,  6.1010e-03,\n",
       "                      -4.3334e-04,  1.6691e-03,  8.9472e-06,  5.3347e-03,  4.1516e-03,\n",
       "                       4.4639e-03,  4.7324e-03, -6.6560e-04, -5.5783e-03,  1.1676e-03],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.2.linear_key.weight',\n",
       "              tensor([[-0.0050,  0.0286, -0.0298,  ...,  0.0195,  0.0095,  0.0048],\n",
       "                      [-0.0067, -0.0032,  0.0213,  ...,  0.0169, -0.0141,  0.0331],\n",
       "                      [-0.0307, -0.0036, -0.0123,  ..., -0.0191, -0.0231,  0.0377],\n",
       "                      ...,\n",
       "                      [-0.0191, -0.0043, -0.0128,  ..., -0.0029,  0.0061, -0.0056],\n",
       "                      [-0.0050, -0.0293, -0.0038,  ..., -0.0536,  0.0291,  0.0308],\n",
       "                      [ 0.0055, -0.0071,  0.0039,  ..., -0.0004, -0.0236, -0.0107]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.2.linear_key.bias',\n",
       "              tensor([ 0.0031,  0.0115,  0.0075,  0.0047, -0.0123, -0.0102,  0.0011, -0.0035,\n",
       "                       0.0029, -0.0103,  0.0116, -0.0100, -0.0151,  0.0058,  0.0023, -0.0030,\n",
       "                      -0.0099,  0.0140, -0.0279, -0.0145, -0.0154, -0.0037, -0.0073, -0.0116,\n",
       "                       0.0035,  0.0055, -0.0106,  0.0162, -0.0039,  0.0056,  0.0088, -0.0053,\n",
       "                       0.0087,  0.0002,  0.0119,  0.0153,  0.0012, -0.0048, -0.0126, -0.0043,\n",
       "                       0.0077,  0.0078, -0.0044, -0.0038,  0.0038, -0.0140, -0.0092, -0.0075,\n",
       "                      -0.0027, -0.0022,  0.0048, -0.0042, -0.0034, -0.0051,  0.0084, -0.0106,\n",
       "                       0.0034, -0.0025, -0.0120,  0.0067,  0.0013,  0.0271, -0.0268, -0.0256,\n",
       "                       0.0021,  0.0023,  0.0018,  0.0145,  0.0183, -0.0120, -0.0223, -0.0051,\n",
       "                      -0.0124, -0.0263,  0.0059,  0.0081, -0.0039, -0.0102, -0.0187,  0.0215,\n",
       "                       0.0310,  0.0283, -0.0033,  0.0053,  0.0123,  0.0291,  0.0010, -0.0197,\n",
       "                      -0.0110, -0.0105, -0.0156, -0.0107,  0.0133,  0.0156,  0.0083,  0.0119,\n",
       "                      -0.0038, -0.0128, -0.0107,  0.0189, -0.0177, -0.0071,  0.0112,  0.0092,\n",
       "                      -0.0139, -0.0008,  0.0108,  0.0039, -0.0166, -0.0262, -0.0043,  0.0034,\n",
       "                       0.0132,  0.0079, -0.0082, -0.0199, -0.0052,  0.0032,  0.0045, -0.0045,\n",
       "                      -0.0052,  0.0026,  0.0061,  0.0113, -0.0002, -0.0280,  0.0036,  0.0107,\n",
       "                      -0.0053, -0.0104,  0.0116, -0.0212, -0.0079,  0.0055, -0.0132,  0.0025,\n",
       "                      -0.0148, -0.0249, -0.0187,  0.0306,  0.0206, -0.0100,  0.0282,  0.0104,\n",
       "                      -0.0083,  0.0274, -0.0031, -0.0042,  0.0108, -0.0194, -0.0102, -0.0107,\n",
       "                       0.0027, -0.0333, -0.0202,  0.0077,  0.0174, -0.0057,  0.0097,  0.0137,\n",
       "                      -0.0057, -0.0141,  0.0022,  0.0055, -0.0076, -0.0112,  0.0037,  0.0040,\n",
       "                       0.0230, -0.0255,  0.0031, -0.0287, -0.0073, -0.0044, -0.0057,  0.0140,\n",
       "                       0.0121, -0.0055,  0.0044,  0.0260,  0.0103, -0.0086, -0.0082,  0.0011,\n",
       "                      -0.0143, -0.0008,  0.0168, -0.0138,  0.0104,  0.0175, -0.0011, -0.0126,\n",
       "                      -0.0118,  0.0039,  0.0094,  0.0058,  0.0031, -0.0157,  0.0182,  0.0174],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.2.linear_msg.weight',\n",
       "              tensor([[ 0.0234, -0.0279,  0.0103,  ..., -0.0244,  0.0069, -0.0083],\n",
       "                      [ 0.0144,  0.0296,  0.0031,  ...,  0.0054,  0.0159, -0.0063],\n",
       "                      [ 0.0312,  0.0186,  0.0028,  ..., -0.0151, -0.0157,  0.0044],\n",
       "                      ...,\n",
       "                      [ 0.0299, -0.0076,  0.0167,  ..., -0.0208, -0.0082, -0.0151],\n",
       "                      [-0.0178,  0.0180,  0.0519,  ...,  0.0306, -0.0058,  0.0247],\n",
       "                      [-0.0082,  0.0046,  0.0048,  ...,  0.0122, -0.0337, -0.0204]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.2.linear_msg.bias',\n",
       "              tensor([ 3.5557e-03, -3.3683e-03,  7.3093e-03,  3.1990e-03,  5.7287e-04,\n",
       "                      -3.5040e-03, -2.4501e-03,  4.3191e-03,  4.5917e-03,  1.8703e-03,\n",
       "                      -2.9002e-03,  1.5357e-02,  1.4043e-03,  4.7136e-03,  3.7502e-04,\n",
       "                       7.5452e-03,  1.3831e-04,  1.4531e-03,  1.1832e-02, -3.2456e-03,\n",
       "                      -8.0041e-03, -5.3356e-03,  1.3095e-02, -2.2812e-03, -2.0043e-03,\n",
       "                      -2.0252e-04,  2.5035e-03, -1.2835e-03,  1.6587e-03, -3.9106e-03,\n",
       "                       3.8810e-03, -3.3573e-03,  6.2365e-04,  1.5213e-03, -8.0388e-03,\n",
       "                      -1.2511e-04, -9.7592e-04, -6.2524e-04, -1.1221e-03, -7.2151e-03,\n",
       "                      -1.8895e-03,  3.2902e-03, -6.8993e-03, -2.2584e-03, -3.1210e-03,\n",
       "                      -2.2678e-03,  5.2657e-03, -2.8013e-03, -7.7860e-04,  6.1690e-03,\n",
       "                       1.8209e-03,  8.3377e-03, -4.3679e-03, -2.2022e-03,  3.4671e-03,\n",
       "                      -3.3009e-03, -4.1262e-03, -9.9036e-04, -6.7728e-03,  9.7956e-03,\n",
       "                       1.1102e-02,  6.0470e-03, -8.3191e-03,  4.6018e-03, -8.0117e-04,\n",
       "                       6.1408e-03,  1.0074e-02, -1.3606e-02,  7.1714e-04, -6.9246e-03,\n",
       "                       1.5943e-02,  1.5409e-02,  7.2093e-03, -6.2534e-03,  2.9874e-03,\n",
       "                       9.4798e-03,  8.9367e-03, -4.7450e-03, -3.5330e-03,  5.4665e-03,\n",
       "                      -7.4053e-03, -3.5909e-03, -3.4037e-03, -9.6878e-03, -6.3166e-03,\n",
       "                      -6.9543e-03, -4.8313e-03, -4.6280e-03,  1.4641e-02, -1.0825e-02,\n",
       "                       4.8183e-03,  1.1814e-02, -7.2031e-03, -3.7738e-05, -1.2903e-02,\n",
       "                      -7.9356e-03,  6.0336e-03, -9.2157e-03, -1.0405e-02,  1.5260e-03,\n",
       "                      -1.2206e-03,  2.8135e-03, -6.4011e-03,  1.9506e-04,  1.3696e-03,\n",
       "                       1.8914e-03, -4.6111e-03,  4.1951e-03,  8.4058e-03, -3.4946e-05,\n",
       "                       2.5874e-03,  5.9644e-03, -1.5645e-03, -3.7658e-03, -7.1780e-03,\n",
       "                       8.0830e-04, -6.4758e-04,  1.2526e-02, -1.4460e-02,  5.7091e-04,\n",
       "                       2.1390e-03, -3.7827e-03,  3.8974e-03, -1.2054e-03, -6.0569e-03,\n",
       "                       4.8305e-04,  3.4000e-03,  1.2341e-03, -4.7774e-04, -6.2685e-03,\n",
       "                      -5.5003e-03,  7.3050e-03, -3.6272e-03,  3.8701e-03, -5.0708e-04,\n",
       "                       1.3514e-03,  1.2959e-03,  5.2070e-03,  9.6303e-03,  6.0838e-03,\n",
       "                       6.3478e-03,  5.6866e-03,  1.1448e-03, -1.4471e-02, -7.2873e-04,\n",
       "                      -2.0081e-03, -5.6453e-03,  6.2539e-03,  7.0338e-03,  2.8993e-03,\n",
       "                      -9.8970e-03, -6.2293e-03, -4.4407e-03,  7.0187e-05,  1.0056e-03,\n",
       "                      -2.6419e-03,  4.6824e-03,  6.8164e-03,  3.5277e-03, -9.8037e-03,\n",
       "                      -1.0242e-02,  5.1112e-03, -3.3304e-03,  3.6380e-03, -1.7803e-03,\n",
       "                      -6.4673e-03, -1.0467e-02,  2.3282e-03,  6.8396e-03,  1.1173e-02,\n",
       "                       7.0380e-03, -9.3256e-03,  6.7246e-03,  6.6077e-03,  1.5466e-02,\n",
       "                      -1.0292e-03, -1.4538e-02, -8.6535e-03, -3.6473e-03,  6.1595e-03,\n",
       "                       3.5209e-03,  1.6608e-02,  8.0942e-03, -8.1379e-03, -8.0691e-04,\n",
       "                       1.7681e-02,  1.0757e-02, -9.3825e-04, -1.9188e-03, -4.1992e-03,\n",
       "                       1.1618e-02, -2.8175e-03,  3.4841e-03,  3.1969e-03, -3.2854e-03,\n",
       "                      -1.0237e-02,  5.2765e-03,  1.4662e-02, -1.6197e-02, -4.6431e-03],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.2.linear_query.weight',\n",
       "              tensor([[-0.0102,  0.0240,  0.0161,  ...,  0.0230, -0.0343,  0.0014],\n",
       "                      [-0.0187,  0.0017,  0.0214,  ..., -0.0012,  0.0257, -0.0325],\n",
       "                      [ 0.0013,  0.0147, -0.0097,  ..., -0.0008, -0.0222,  0.0151],\n",
       "                      ...,\n",
       "                      [ 0.0151,  0.0154,  0.0266,  ...,  0.0318,  0.0185,  0.0108],\n",
       "                      [ 0.0094,  0.0029,  0.0079,  ..., -0.0141, -0.0363, -0.0174],\n",
       "                      [-0.0522,  0.0188,  0.0139,  ...,  0.0138, -0.0021,  0.0313]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.2.linear_query.bias',\n",
       "              tensor([ 0.0229, -0.0248, -0.0207, -0.0280, -0.0243,  0.0315, -0.0306,  0.0003,\n",
       "                       0.0065,  0.0192, -0.0325,  0.0232, -0.0035, -0.0195,  0.0279,  0.0327,\n",
       "                       0.0314, -0.0299,  0.0220, -0.0105,  0.0195,  0.0008,  0.0225,  0.0285,\n",
       "                      -0.0259, -0.0243,  0.0331, -0.0255,  0.0339,  0.0066,  0.0234, -0.0201,\n",
       "                       0.0344,  0.0156, -0.0338, -0.0284,  0.0240,  0.0259,  0.0268, -0.0249,\n",
       "                      -0.0184,  0.0329,  0.0247,  0.0184,  0.0244,  0.0227,  0.0347,  0.0176,\n",
       "                      -0.0339, -0.0110,  0.0053, -0.0154, -0.0314,  0.0063,  0.0151, -0.0204,\n",
       "                      -0.0055,  0.0050, -0.0043,  0.0043,  0.0169,  0.0198, -0.0026, -0.0255,\n",
       "                       0.0006, -0.0088, -0.0110,  0.0331,  0.0203, -0.0274, -0.0205, -0.0176,\n",
       "                      -0.0117, -0.0116,  0.0156, -0.0186, -0.0148, -0.0154, -0.0262,  0.0164,\n",
       "                       0.0032,  0.0218,  0.0129,  0.0008,  0.0053,  0.0088,  0.0003, -0.0076,\n",
       "                       0.0015, -0.0261, -0.0265, -0.0157,  0.0206,  0.0236,  0.0178,  0.0197,\n",
       "                      -0.0176, -0.0021,  0.0021, -0.0027, -0.0453, -0.0247,  0.0139,  0.0381,\n",
       "                      -0.0200,  0.0367,  0.0530, -0.0068, -0.0220, -0.0414, -0.0190, -0.0051,\n",
       "                       0.0466,  0.0493, -0.0255, -0.0221,  0.0156, -0.0458, -0.0094, -0.0342,\n",
       "                      -0.0269,  0.0326,  0.0547,  0.0229,  0.0649, -0.0338,  0.0370,  0.0173,\n",
       "                       0.0033,  0.0497,  0.0175, -0.0061, -0.0181,  0.0510, -0.0160, -0.0562,\n",
       "                      -0.0102, -0.0486, -0.0234,  0.0352,  0.0211, -0.0319,  0.0611,  0.0490,\n",
       "                      -0.0299,  0.0120, -0.0462, -0.0527,  0.0280, -0.0265, -0.0042,  0.0070,\n",
       "                       0.0154,  0.0024,  0.0049,  0.0118, -0.0049, -0.0098, -0.0037, -0.0180,\n",
       "                       0.0002,  0.0186, -0.0052,  0.0100,  0.0054,  0.0065, -0.0124,  0.0141,\n",
       "                       0.0032, -0.0030, -0.0076,  0.0158,  0.0230,  0.0131,  0.0014, -0.0120,\n",
       "                      -0.0033, -0.0063,  0.0116, -0.0042, -0.0008,  0.0055, -0.0080, -0.0083,\n",
       "                       0.0015,  0.0017, -0.0191,  0.0032, -0.0065, -0.0045, -0.0126,  0.0038,\n",
       "                      -0.0089, -0.0045, -0.0056,  0.0198, -0.0151,  0.0167,  0.0097, -0.0052],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.2.mlp.0.weight',\n",
       "              tensor([[ 0.0033, -0.0183,  0.0277,  ..., -0.0124, -0.0121, -0.0183],\n",
       "                      [-0.0050,  0.0179, -0.0056,  ..., -0.0369,  0.0033,  0.0003],\n",
       "                      [-0.0173,  0.0022, -0.0198,  ...,  0.0007,  0.0325, -0.0164],\n",
       "                      ...,\n",
       "                      [ 0.0126,  0.0157, -0.0235,  ..., -0.0402,  0.0127, -0.0104],\n",
       "                      [ 0.0044, -0.0070,  0.0353,  ...,  0.0231,  0.0206,  0.0227],\n",
       "                      [-0.0301,  0.0023, -0.0192,  ...,  0.0183, -0.0231,  0.0131]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.2.mlp.0.bias',\n",
       "              tensor([-1.1284e-02, -4.8851e-03,  1.2102e-03, -2.3576e-03, -1.6810e-02,\n",
       "                      -5.9505e-03, -1.4583e-02, -1.3196e-02, -7.6875e-03,  2.8414e-03,\n",
       "                       6.1533e-04,  7.4024e-03,  1.4893e-03, -3.6733e-03,  3.1031e-03,\n",
       "                      -1.9047e-02,  7.0520e-03,  9.8696e-03, -8.8089e-03, -3.0547e-03,\n",
       "                       9.5064e-04, -6.3215e-03, -4.1793e-04, -5.3268e-03, -1.1905e-03,\n",
       "                      -1.3343e-02,  1.8871e-02, -2.4816e-03,  8.1144e-04, -2.1901e-03,\n",
       "                      -1.8551e-03,  1.3221e-03,  1.9266e-03, -4.4540e-03,  5.6795e-03,\n",
       "                      -1.8956e-03,  3.2184e-03, -7.4837e-05, -2.2051e-03, -2.9701e-04,\n",
       "                      -9.4856e-03, -7.7798e-03, -6.9508e-03, -8.5345e-04,  1.2676e-02,\n",
       "                       2.3962e-04,  2.6541e-03, -5.8712e-03,  1.4660e-03, -1.0572e-02,\n",
       "                       2.3240e-03, -2.3950e-03,  3.7385e-03, -1.0757e-03, -5.3231e-03,\n",
       "                       3.8618e-06,  9.1415e-03, -2.3264e-03, -5.5155e-03, -4.1281e-04,\n",
       "                      -1.9577e-03, -5.4460e-03,  1.0557e-02, -5.4249e-03,  8.1611e-03,\n",
       "                       3.0906e-03,  1.1314e-04,  7.5793e-04, -2.6828e-03,  2.3193e-03,\n",
       "                       7.7505e-03, -2.6651e-04, -7.5420e-03, -1.2085e-02,  1.1013e-03,\n",
       "                      -7.8453e-03,  9.0256e-04, -4.8060e-03,  1.7421e-03,  2.1741e-03,\n",
       "                       1.0683e-02, -1.3267e-02, -6.5426e-03,  4.2389e-03, -1.1185e-02,\n",
       "                       1.8687e-03, -1.8414e-02, -2.8016e-03, -2.6849e-04,  3.5103e-03,\n",
       "                       3.3442e-03, -1.2484e-03,  8.0259e-04, -2.2083e-02, -1.9019e-02,\n",
       "                       2.9514e-03, -1.5928e-03, -7.5794e-04, -8.2260e-04,  7.9840e-04,\n",
       "                      -6.9188e-03, -3.0512e-03,  6.7043e-04, -4.6597e-03,  1.9815e-03,\n",
       "                      -1.8107e-03, -2.4113e-03, -5.5248e-04, -9.4259e-04, -2.3180e-03,\n",
       "                       4.3322e-04,  4.6038e-03, -1.0409e-02, -4.6087e-03, -4.2075e-03,\n",
       "                      -1.5905e-02, -1.2865e-02, -5.5172e-03,  1.1443e-03, -8.1086e-03,\n",
       "                      -9.7415e-03, -6.6315e-03, -8.5304e-03,  4.2073e-03,  1.6807e-03,\n",
       "                       8.2835e-04,  9.0408e-03, -3.4338e-03, -2.2048e-03, -4.4344e-03,\n",
       "                       6.2737e-03,  2.1362e-04,  1.6117e-02, -1.1636e-02,  3.6640e-04,\n",
       "                      -1.1576e-03, -3.3897e-03,  1.4295e-03, -2.4082e-03,  4.9522e-03,\n",
       "                      -8.7211e-04, -5.6396e-03, -6.8201e-04, -1.8719e-03,  5.5256e-03,\n",
       "                      -1.0254e-03, -8.0866e-03,  1.7012e-03,  5.5509e-03,  7.2070e-03,\n",
       "                       4.5989e-03,  2.0866e-03, -4.7362e-03,  6.8217e-03, -7.2540e-03,\n",
       "                      -6.2590e-03,  1.2591e-02,  2.2083e-03,  7.2825e-03, -5.1907e-03,\n",
       "                       5.8627e-03,  4.7043e-03, -1.2656e-03, -9.3565e-04,  1.9048e-03,\n",
       "                       3.0422e-03,  4.1128e-03, -8.2928e-03,  1.1911e-03, -7.4020e-03,\n",
       "                       7.3585e-03, -5.5995e-04, -2.6928e-03,  1.0748e-02, -9.2013e-03,\n",
       "                       2.9504e-03,  5.4912e-03, -5.4928e-03, -3.5354e-03, -4.0140e-05,\n",
       "                       4.2302e-03, -1.2092e-03, -7.3597e-03,  1.1647e-02,  7.2732e-03,\n",
       "                      -2.5340e-03,  2.4824e-03, -1.4984e-03, -9.9228e-03, -6.7766e-03,\n",
       "                      -2.1154e-03, -3.0980e-03, -5.0699e-03, -9.5963e-03, -1.7905e-02,\n",
       "                       7.6631e-03, -1.2705e-02, -9.4830e-03, -6.9931e-03, -3.4110e-03],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.2.mlp.1.weight',\n",
       "              tensor([0.9610, 0.9648, 0.9724, 0.9757, 0.9614, 0.9729, 0.9762, 0.9721, 0.9702,\n",
       "                      0.9727, 0.9750, 0.9701, 0.9707, 0.9579, 0.9748, 0.9718, 0.9573, 0.9653,\n",
       "                      0.9770, 0.9723, 0.9679, 0.9694, 0.9727, 0.9736, 0.9583, 0.9597, 0.9709,\n",
       "                      0.9646, 0.9643, 0.9665, 0.9508, 0.9757, 0.9745, 0.9819, 0.9653, 0.9604,\n",
       "                      0.9683, 0.9676, 0.9750, 0.9710, 0.9641, 0.9617, 0.9800, 0.9625, 0.9657,\n",
       "                      0.9507, 0.9737, 0.9517, 0.9562, 0.9606, 0.9721, 0.9744, 0.9799, 0.9642,\n",
       "                      0.9532, 0.9686, 0.9727, 0.9632, 0.9753, 0.9735, 0.9630, 0.9697, 0.9621,\n",
       "                      0.9689, 0.9825, 0.9758, 0.9779, 0.9625, 0.9826, 0.9719, 0.9813, 0.9690,\n",
       "                      0.9709, 0.9582, 0.9580, 0.9510, 0.9369, 0.9720, 0.9568, 0.9710, 0.9620,\n",
       "                      0.9685, 0.9726, 0.9797, 0.9671, 0.9669, 0.9672, 0.9791, 0.9718, 0.9476,\n",
       "                      0.9910, 0.9681, 0.9638, 0.9760, 0.9702, 0.9743, 0.9655, 0.9630, 0.9780,\n",
       "                      0.9579, 0.9679, 0.9842, 0.9779, 0.9548, 0.9670, 0.9711, 0.9793, 0.9774,\n",
       "                      0.9896, 0.9695, 0.9715, 0.9633, 0.9764, 0.9851, 0.9611, 0.9688, 0.9702,\n",
       "                      0.9487, 0.9666, 0.9645, 0.9694, 0.9632, 0.9463, 0.9770, 0.9750, 0.9743,\n",
       "                      0.9543, 0.9707, 0.9649, 0.9699, 0.9747, 0.9752, 0.9799, 0.9701, 0.9719,\n",
       "                      0.9714, 0.9809, 0.9694, 0.9592, 0.9837, 0.9616, 0.9663, 0.9695, 0.9532,\n",
       "                      0.9683, 0.9546, 0.9545, 0.9697, 0.9703, 0.9693, 0.9777, 0.9657, 0.9789,\n",
       "                      0.9611, 0.9704, 0.9732, 0.9751, 0.9617, 0.9790, 0.9661, 0.9586, 0.9583,\n",
       "                      0.9759, 0.9698, 0.9709, 0.9741, 0.9779, 0.9700, 0.9660, 0.9677, 0.9713,\n",
       "                      0.9653, 0.9618, 0.9527, 0.9659, 0.9837, 0.9737, 0.9561, 0.9528, 0.9706,\n",
       "                      0.9729, 0.9833, 0.9710, 0.9649, 0.9729, 0.9671, 0.9615, 0.9650, 0.9834,\n",
       "                      0.9649, 0.9652, 0.9650, 0.9741, 0.9673, 0.9617, 0.9641, 0.9888, 0.9596,\n",
       "                      0.9634, 0.9690], device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.2.mlp.1.bias',\n",
       "              tensor([-6.1240e-03, -2.0490e-02, -6.1568e-03, -1.5790e-02,  1.9195e-02,\n",
       "                      -1.0463e-02, -4.8692e-02, -2.7613e-02, -7.5193e-03, -3.5507e-03,\n",
       "                       1.6371e-02, -2.1050e-02,  2.3939e-02, -2.2751e-02,  1.7430e-02,\n",
       "                      -7.3674e-03, -2.4411e-02, -1.4509e-02, -2.5964e-02, -1.8335e-02,\n",
       "                      -1.1912e-02, -6.5637e-03, -2.3153e-02, -2.0549e-02,  1.7197e-03,\n",
       "                      -1.6210e-02, -1.0512e-02, -2.3755e-02, -1.9268e-02, -1.7810e-02,\n",
       "                      -6.4909e-03,  7.8663e-03, -1.2652e-02,  1.9175e-02, -1.4401e-02,\n",
       "                      -8.5590e-03, -2.4286e-03, -1.2499e-02, -9.8570e-03, -1.8805e-02,\n",
       "                      -2.0775e-02, -2.5532e-02, -3.3604e-03, -2.5661e-02,  1.5783e-02,\n",
       "                      -2.8856e-02, -9.4566e-03, -2.5915e-02, -4.0702e-03,  1.6345e-04,\n",
       "                       1.2483e-02, -1.1715e-02, -2.1569e-04, -9.6732e-03, -2.6981e-02,\n",
       "                      -8.4525e-03, -5.4613e-03, -3.9169e-03,  1.5303e-02, -2.9718e-02,\n",
       "                      -2.5357e-02, -7.8436e-03,  1.0006e-02, -1.3445e-02,  1.2611e-02,\n",
       "                       3.6377e-03,  3.4957e-03, -2.2243e-02, -7.9200e-03,  6.1218e-03,\n",
       "                       2.5842e-02, -2.5371e-02, -4.5990e-03, -1.7996e-02, -6.1422e-03,\n",
       "                      -1.9938e-02, -2.8308e-02, -8.2369e-03, -4.8432e-02, -2.1160e-03,\n",
       "                      -1.7766e-02, -1.1169e-02, -1.7043e-02,  9.5663e-03, -2.8479e-02,\n",
       "                      -2.7480e-03, -5.0248e-02, -4.9671e-03, -1.2542e-02, -9.2796e-04,\n",
       "                      -1.1169e-02,  9.3178e-03, -1.3993e-02, -1.4114e-02,  2.3288e-03,\n",
       "                      -9.0428e-03, -7.2124e-03, -2.2107e-02, -4.6714e-03, -2.3701e-02,\n",
       "                      -1.8159e-02, -1.2182e-02,  2.5050e-02, -3.3950e-02,  7.4664e-03,\n",
       "                       1.0891e-03, -3.6911e-03, -3.6664e-03, -2.6299e-03, -1.9009e-02,\n",
       "                      -3.2103e-03, -1.1103e-02, -2.1934e-02,  6.2887e-05, -5.1002e-03,\n",
       "                      -1.0132e-02, -2.1678e-02, -1.4331e-02,  1.1011e-02, -5.1645e-03,\n",
       "                      -2.4202e-02,  1.0215e-02, -2.8818e-02,  4.6237e-03, -4.5970e-03,\n",
       "                      -9.5626e-03, -4.9581e-02, -1.3041e-02,  1.2372e-03, -1.2646e-02,\n",
       "                      -5.3054e-03, -1.7655e-02,  4.7960e-03, -1.1725e-02, -9.5259e-03,\n",
       "                      -2.4150e-03, -2.4690e-02, -9.0231e-03,  1.2652e-02,  1.0612e-02,\n",
       "                      -3.3709e-02,  6.7261e-03, -1.1275e-02, -9.8663e-03, -8.9868e-03,\n",
       "                      -3.5603e-02, -2.9399e-02, -1.4285e-02, -4.7240e-03,  9.7647e-03,\n",
       "                      -1.1051e-02,  5.3087e-03, -8.2503e-04, -3.7878e-03, -1.0934e-02,\n",
       "                      -6.3278e-03, -1.8109e-02, -2.2617e-02, -1.2299e-02, -2.3731e-02,\n",
       "                      -1.9370e-02, -2.4127e-02, -1.0356e-02, -4.7337e-03,  1.2092e-02,\n",
       "                      -2.0064e-02, -1.3533e-02, -3.3310e-04, -1.7387e-02,  4.3918e-03,\n",
       "                      -2.6446e-02, -6.2157e-03,  1.2004e-02, -1.6786e-02, -1.5954e-02,\n",
       "                      -1.3820e-02, -6.2756e-03, -3.9450e-06, -2.8511e-02, -1.9857e-02,\n",
       "                      -1.6897e-02,  8.6487e-03, -8.6894e-03, -2.4654e-02, -1.6069e-03,\n",
       "                      -2.2587e-02, -3.6015e-03, -7.0541e-03, -1.8340e-02, -9.4616e-03,\n",
       "                      -1.4547e-02, -2.5621e-02, -1.3895e-02,  1.3580e-02, -3.1093e-03,\n",
       "                      -2.3308e-02, -9.9155e-05, -6.3593e-03, -4.5416e-03, -3.7272e-02],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.2.mlp.1.running_mean',\n",
       "              tensor([ 0.8303, -1.2419, -2.3097, -2.1199,  0.5161, -2.2670,  3.0922,  2.8198,\n",
       "                      -2.2673, -2.8437,  0.3924, -1.2908,  0.6406, -1.6918, -0.6915, -1.2085,\n",
       "                      -2.7616, -1.2017,  0.9373,  1.8842, -2.6021, -2.6005,  2.3392,  0.9395,\n",
       "                      -2.2562, -2.9473, -0.8573,  1.8757,  1.2875,  1.7642,  1.1980, -0.0455,\n",
       "                      -1.5185,  1.1558, -1.3143, -2.4603, -2.3840, -1.5825, -0.8291,  1.5794,\n",
       "                       1.3578, -1.1185, -1.1044, -0.4371,  0.5396, -0.5274, -1.9624,  0.6189,\n",
       "                      -1.5335,  0.7308,  1.4529,  1.0757, -1.4838,  2.4813, -2.1580, -1.8025,\n",
       "                       1.2179, -2.6690, -2.1558, -0.3065,  1.8744, -1.8761,  1.6500, -1.6641,\n",
       "                       0.8238, -1.9283,  0.6327, -1.7768, -1.6295,  0.9277,  1.3210,  1.3412,\n",
       "                      -1.2068, -2.3078,  0.7101, -1.9040, -2.9574, -1.1712,  2.5767, -2.0881,\n",
       "                      -0.9942, -1.7785, -2.4412, -2.2668, -2.8842, -2.7666,  2.0469, -1.0843,\n",
       "                      -1.6182,  2.1738, -2.3407, -0.7975,  0.2278, -0.3530,  0.4510, -2.3321,\n",
       "                      -1.5503,  3.0402, -1.7864,  1.6915, -1.7080, -2.6557,  1.0694, -0.7554,\n",
       "                      -0.5404, -2.4736, -2.3028, -0.9026, -1.6640, -1.4528, -1.5015, -1.5256,\n",
       "                      -0.6599, -2.3125,  1.6171, -0.7385, -1.7463,  1.0296, -0.8421, -0.8802,\n",
       "                       1.2803, -1.3485,  1.2996, -1.3131, -0.7808,  2.7407,  0.2878, -2.4964,\n",
       "                       2.2600, -2.1481, -2.0986, -1.9132, -1.3086, -2.3831, -2.0768, -3.0500,\n",
       "                       1.6640,  1.9357,  1.3011,  1.4731,  1.4788, -2.1873, -1.6396, -1.9729,\n",
       "                      -1.8171,  1.6395, -2.1725, -1.6482, -2.4356,  1.1730, -1.4637, -0.8881,\n",
       "                      -1.0549,  0.1815, -1.4692, -2.1475,  2.2731, -1.8244, -2.2140, -0.3678,\n",
       "                       1.6423,  3.0464, -1.0822, -2.3926,  1.4768, -2.7179, -2.1886, -1.4338,\n",
       "                      -1.7099, -1.8036,  2.5709, -0.8153,  0.7717, -1.3210,  1.2779, -2.4352,\n",
       "                      -2.2131,  1.9006,  2.0553, -1.6676, -0.8575, -0.3557,  1.8543,  0.8823,\n",
       "                      -1.4259, -1.9966, -1.0239, -2.3717, -2.2979,  0.8525, -2.2021,  0.6779,\n",
       "                      -0.5575,  2.4761,  1.7045, -1.0937, -2.1765, -2.3550,  1.3965,  2.7160],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.2.mlp.1.running_var',\n",
       "              tensor([ 7.6567,  7.2152,  9.8320, 13.2183, 10.5945, 18.7285, 31.9680, 39.6737,\n",
       "                      13.9750, 19.2513, 13.2395,  4.2182, 10.5255,  7.7199,  3.7701,  3.5169,\n",
       "                      20.9712,  7.1871, 14.0668, 20.4405, 14.7967, 24.1368, 27.6561, 14.3395,\n",
       "                      13.7610, 25.5228,  8.1007, 15.4653, 11.9040, 16.6213,  7.9934,  8.4686,\n",
       "                       7.7961, 13.1679,  3.9822, 26.3894, 16.4438,  6.8913,  6.8951, 17.5795,\n",
       "                      11.6276, 25.7982,  6.1216,  9.2506,  8.7946, 11.0476,  7.1647, 15.2910,\n",
       "                      11.4329, 10.2268, 13.7344, 10.8192,  4.9873, 26.9188, 11.5801, 11.6176,\n",
       "                      22.3323, 24.4622, 13.2052, 17.2312, 19.6947, 15.4660,  7.8659,  8.8992,\n",
       "                       8.1239, 18.3633,  7.3603, 14.7590, 10.3308,  5.2066, 14.4574,  6.8883,\n",
       "                       3.5958, 17.8272,  3.6519,  8.6386, 29.8705,  3.1111, 14.7723, 16.3070,\n",
       "                      10.2895,  6.7574, 14.7771, 15.6120, 21.2806, 18.8022, 20.4276,  6.6382,\n",
       "                       7.4209, 34.1657, 11.6490,  5.7186, 16.1182,  4.6426,  8.1763, 12.4206,\n",
       "                       6.9840, 35.9138, 25.2906, 15.8380,  9.1822, 17.6924,  7.4420,  4.1050,\n",
       "                      12.1490, 14.2341, 17.6356,  5.1978,  8.3083, 46.5002,  8.6265,  6.1155,\n",
       "                      16.6870, 13.6883, 14.3624,  3.9465,  9.4192,  6.8826,  7.4241,  2.8831,\n",
       "                      17.2076, 22.5885,  8.7049, 12.0305,  6.3687, 25.0743,  7.2606, 11.9280,\n",
       "                      18.3186,  8.8320, 19.1884, 12.4294,  5.9244, 10.8255, 26.6246, 37.5289,\n",
       "                      16.9815, 23.9416, 13.2272,  8.7240, 14.2074,  9.4403,  5.1428, 12.4803,\n",
       "                      10.3023, 11.6293, 12.4158, 18.1196, 12.5469, 14.4127,  6.5081, 14.2641,\n",
       "                       4.3938,  7.2922,  5.3457, 16.1331, 15.8369, 10.8660, 15.8458, 12.3500,\n",
       "                      26.5500, 28.3429,  6.2145, 24.9494, 18.1027, 15.9282, 10.3887,  5.2352,\n",
       "                      12.9217, 18.4363, 28.9517,  4.2616,  4.1475,  9.8633,  7.4873, 14.8568,\n",
       "                      21.6818,  9.4750, 17.2413, 30.6068,  5.7274,  8.6642,  8.0790,  6.7514,\n",
       "                      17.8713,  9.9266,  8.2369, 28.6040, 13.9913, 11.4074, 18.8710,  6.9688,\n",
       "                       5.1993, 14.8264,  9.7983, 15.8449,  9.8004, 14.8109, 25.7226, 24.7865],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.2.mlp.1.num_batches_tracked',\n",
       "              tensor(63750, device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.2.mlp.3.weight',\n",
       "              tensor([[ 0.0303, -0.0169,  0.0019,  ..., -0.0222,  0.0024, -0.0116],\n",
       "                      [-0.0239,  0.0583,  0.0070,  ..., -0.0148,  0.0087, -0.0138],\n",
       "                      [ 0.0094,  0.0290, -0.0138,  ..., -0.0024, -0.0099, -0.0095],\n",
       "                      ...,\n",
       "                      [-0.0041, -0.0024,  0.0061,  ..., -0.0036,  0.0164, -0.0283],\n",
       "                      [-0.0439, -0.0012,  0.0165,  ...,  0.0297,  0.0260, -0.0252],\n",
       "                      [ 0.0267,  0.0031,  0.0097,  ...,  0.0170,  0.0090,  0.0128]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.2.mlp.3.bias',\n",
       "              tensor([ 8.7054e-04, -6.6267e-03,  1.9747e-02,  1.3476e-02,  1.1565e-02,\n",
       "                      -4.9119e-03, -1.4323e-02,  2.9737e-02, -3.0976e-03,  6.5166e-03,\n",
       "                       1.0614e-02,  2.8126e-04, -1.7283e-03, -1.1591e-03,  5.9588e-03,\n",
       "                       1.3323e-02, -3.2746e-03,  8.8303e-03,  1.3161e-03,  3.0525e-03,\n",
       "                      -2.0261e-02,  1.6040e-02, -6.8260e-03, -3.8821e-03, -4.2605e-03,\n",
       "                       1.4317e-02, -1.4690e-02, -2.2616e-02, -6.1217e-03, -3.1910e-03,\n",
       "                       2.7103e-03,  1.8549e-02,  1.8048e-02,  1.8562e-02,  2.5272e-03,\n",
       "                       9.8293e-03, -1.1869e-02,  1.7767e-02,  2.4271e-03,  5.9234e-03,\n",
       "                       7.5009e-03, -2.8277e-03,  1.9857e-02,  4.0175e-03,  1.4523e-02,\n",
       "                      -2.7165e-03, -6.9286e-03,  2.1091e-02,  2.0177e-02, -8.6327e-04,\n",
       "                       2.7595e-02, -6.7668e-04, -1.0050e-02, -4.5129e-03, -1.6938e-03,\n",
       "                      -3.2883e-03, -1.1644e-02,  3.8751e-02, -1.1636e-02, -3.1741e-03,\n",
       "                       2.2423e-02,  4.2888e-03,  2.8705e-03, -2.5553e-03,  1.3982e-02,\n",
       "                      -2.1512e-02,  1.0843e-02,  1.1842e-02, -2.3143e-03,  1.3468e-03,\n",
       "                      -1.7977e-02, -1.2390e-03,  4.3621e-02,  1.2525e-03,  1.5094e-02,\n",
       "                       3.0714e-02, -5.0541e-03,  2.7482e-02,  4.8315e-03,  1.5723e-03,\n",
       "                      -4.2895e-03, -1.0948e-03,  1.7236e-02,  7.1153e-05,  2.0038e-02,\n",
       "                      -2.9459e-03, -7.8115e-04,  2.0600e-02,  2.4917e-02,  3.8050e-03,\n",
       "                      -6.0510e-04,  1.3227e-02, -1.1102e-02, -6.9384e-03,  1.9340e-02,\n",
       "                       3.6418e-02,  7.8827e-04, -5.0456e-03,  3.4268e-03,  5.6099e-03,\n",
       "                       1.4852e-03,  2.7232e-02, -1.0136e-02,  3.2878e-03,  9.9975e-03,\n",
       "                      -8.9942e-03,  2.4030e-02,  2.8560e-03, -1.0682e-02,  1.4672e-02,\n",
       "                      -3.4824e-04, -1.5826e-02, -1.2925e-03, -1.4908e-02,  5.6205e-03,\n",
       "                       2.5162e-03,  7.4495e-03, -4.8404e-03, -1.4742e-02,  7.0922e-03,\n",
       "                       2.5375e-03, -1.2990e-03, -7.4052e-03,  3.1700e-03, -1.4648e-02,\n",
       "                       2.2179e-02,  1.2813e-02, -1.0732e-02, -2.7754e-02,  3.2636e-02,\n",
       "                      -2.0182e-02,  1.0199e-02, -3.3452e-03,  1.3525e-02, -1.5891e-02,\n",
       "                      -1.5970e-02,  4.4147e-03, -5.7740e-03, -7.4802e-04, -8.0601e-04,\n",
       "                       2.0029e-02,  1.6532e-02, -3.0088e-03, -1.0124e-02,  2.1734e-04,\n",
       "                      -5.5306e-03, -1.1395e-03, -9.0653e-03, -1.7462e-02,  2.8172e-03,\n",
       "                      -9.0531e-03,  6.7841e-04, -7.1417e-03,  3.4618e-02,  1.7215e-02,\n",
       "                      -5.1776e-03,  8.2269e-03, -7.0922e-03, -4.5566e-03,  2.4787e-03,\n",
       "                      -8.2692e-04,  1.3688e-02,  9.5636e-03, -9.3728e-03,  2.2388e-02,\n",
       "                       2.0814e-02,  2.9135e-02, -7.9737e-03,  1.4104e-03, -1.9412e-02,\n",
       "                      -1.3269e-02, -3.7005e-03, -1.0934e-02, -8.0501e-03, -1.2621e-02,\n",
       "                       2.9776e-03,  2.1363e-02, -8.3281e-03,  5.5439e-03, -1.8556e-02,\n",
       "                      -2.9854e-03,  1.4664e-02,  2.8348e-03,  2.7314e-03, -7.4287e-03,\n",
       "                       4.4195e-04,  3.6514e-03, -4.2109e-03, -8.3028e-03,  1.5438e-03,\n",
       "                      -6.5564e-03,  1.8654e-02,  1.2327e-02,  5.9583e-03,  1.7673e-02,\n",
       "                       1.6283e-02,  1.5410e-02,  5.8159e-03,  1.9708e-02,  1.5401e-02],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.3.edge_encoder.0.weight',\n",
       "              tensor([[ 0.0306, -0.0353,  0.0325,  ..., -0.0054, -0.0064, -0.0239],\n",
       "                      [ 0.0247,  0.0387,  0.0236,  ...,  0.0328,  0.0120, -0.0459],\n",
       "                      [ 0.0180, -0.0081, -0.0130,  ..., -0.0158,  0.0251,  0.0164],\n",
       "                      ...,\n",
       "                      [ 0.0070,  0.0437, -0.0125,  ..., -0.0002, -0.0051, -0.0569],\n",
       "                      [ 0.0213,  0.0714,  0.0441,  ..., -0.0479,  0.0109, -0.0085],\n",
       "                      [ 0.0176, -0.0074, -0.0351,  ..., -0.0420,  0.0276, -0.0018]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.3.edge_encoder.0.bias',\n",
       "              tensor([ 0.0077,  0.0119,  0.0017, -0.0190, -0.0046,  0.0056,  0.0168,  0.0094,\n",
       "                      -0.0051,  0.0039, -0.0029,  0.0186, -0.0180,  0.0189,  0.0191, -0.0094,\n",
       "                       0.0084,  0.0184, -0.0068, -0.0066, -0.0126, -0.0144,  0.0322,  0.0054,\n",
       "                       0.0056, -0.0084,  0.0076,  0.0117, -0.0092, -0.0210,  0.0302,  0.0111,\n",
       "                       0.0049,  0.0133,  0.0009,  0.0033,  0.0078, -0.0005,  0.0011,  0.0380,\n",
       "                       0.0042, -0.0085, -0.0131, -0.0191, -0.0132, -0.0132,  0.0060,  0.0126,\n",
       "                       0.0204, -0.0218, -0.0039,  0.0289,  0.0030,  0.0034,  0.0042,  0.0069,\n",
       "                       0.0276,  0.0014,  0.0052, -0.0010,  0.0165, -0.0045, -0.0037,  0.0045,\n",
       "                       0.0175, -0.0177, -0.0008,  0.0173, -0.0091,  0.0122, -0.0022, -0.0185,\n",
       "                      -0.0071, -0.0143,  0.0194,  0.0052,  0.0028,  0.0003, -0.0044,  0.0021,\n",
       "                      -0.0239, -0.0257,  0.0002,  0.0104,  0.0085,  0.0029,  0.0085,  0.0186,\n",
       "                       0.0136, -0.0184,  0.0170,  0.0219,  0.0114,  0.0373, -0.0013, -0.0081,\n",
       "                       0.0079,  0.0001,  0.0129, -0.0018,  0.0132,  0.0188,  0.0141, -0.0070,\n",
       "                       0.0138,  0.0063, -0.0268, -0.0065,  0.0113,  0.0060,  0.0369,  0.0077,\n",
       "                       0.0054, -0.0095, -0.0127, -0.0155, -0.0099, -0.0243, -0.0093,  0.0114,\n",
       "                      -0.0292, -0.0092, -0.0165,  0.0360, -0.0180,  0.0009, -0.0012, -0.0136,\n",
       "                      -0.0028, -0.0299, -0.0139,  0.0060, -0.0042,  0.0075, -0.0028,  0.0032,\n",
       "                       0.0168, -0.0089,  0.0203,  0.0222,  0.0033, -0.0214,  0.0055, -0.0004,\n",
       "                      -0.0070, -0.0103,  0.0122,  0.0016,  0.0049,  0.0059,  0.0101, -0.0175,\n",
       "                      -0.0075,  0.0347, -0.0166,  0.0217,  0.0009, -0.0263,  0.0026,  0.0296,\n",
       "                       0.0109,  0.0100, -0.0139, -0.0151,  0.0139,  0.0117,  0.0224,  0.0200,\n",
       "                       0.0159,  0.0146, -0.0090,  0.0056,  0.0198, -0.0114,  0.0122, -0.0099,\n",
       "                      -0.0116,  0.0004, -0.0143, -0.0011,  0.0056,  0.0021,  0.0154, -0.0226,\n",
       "                      -0.0033, -0.0069, -0.0072, -0.0033, -0.0062, -0.0068, -0.0164,  0.0153,\n",
       "                      -0.0333,  0.0075, -0.0050, -0.0042, -0.0204,  0.0111, -0.0367,  0.0139],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.3.edge_encoder.1.weight',\n",
       "              tensor([0.9628, 0.9829, 0.9672, 0.9673, 0.9706, 0.9835, 0.9779, 0.9585, 0.9801,\n",
       "                      1.0104, 0.9749, 0.9749, 0.9704, 0.9653, 0.9617, 0.9588, 0.9810, 0.9747,\n",
       "                      0.9706, 0.9653, 0.9548, 0.9736, 0.9918, 0.9715, 0.9768, 0.9686, 0.9768,\n",
       "                      0.9644, 0.9705, 0.9647, 0.9775, 0.9654, 0.9791, 0.9719, 0.9689, 1.0024,\n",
       "                      0.9714, 0.9612, 0.9602, 0.9835, 0.9716, 0.9771, 0.9913, 0.9704, 0.9972,\n",
       "                      0.9774, 0.9673, 0.9556, 0.9649, 0.9712, 0.9714, 0.9532, 0.9586, 0.9630,\n",
       "                      0.9654, 0.9569, 0.9866, 0.9909, 0.9710, 0.9789, 0.9821, 0.9766, 0.9629,\n",
       "                      1.0112, 0.9736, 1.0307, 0.9648, 0.9848, 0.9644, 0.9779, 0.9688, 0.9556,\n",
       "                      0.9911, 0.9716, 0.9692, 0.9976, 0.9801, 0.9737, 0.9750, 1.0032, 0.9712,\n",
       "                      0.9831, 0.9793, 1.0119, 0.9947, 0.9525, 0.9689, 1.0086, 0.9671, 0.9862,\n",
       "                      0.9723, 0.9898, 0.9515, 0.9780, 0.9625, 0.9707, 0.9851, 0.9711, 0.9946,\n",
       "                      0.9929, 1.0127, 0.9705, 0.9535, 0.9593, 0.9769, 0.9911, 0.9627, 0.9748,\n",
       "                      0.9724, 0.9391, 0.9803, 0.9876, 0.9843, 0.9748, 0.9582, 0.9636, 0.9737,\n",
       "                      0.9705, 0.9908, 0.9860, 0.9873, 0.9901, 0.9624, 0.9739, 0.9752, 0.9613,\n",
       "                      0.9775, 0.9644, 0.9877, 0.9880, 0.9751, 0.9752, 0.9599, 0.9629, 0.9751,\n",
       "                      0.9859, 0.9705, 0.9769, 0.9848, 0.9831, 0.9677, 1.0146, 0.9704, 0.9786,\n",
       "                      0.9771, 0.9810, 0.9668, 0.9568, 0.9419, 0.9776, 0.9674, 0.9866, 0.9767,\n",
       "                      0.9543, 0.9812, 1.0107, 0.9792, 0.9727, 0.9707, 0.9655, 0.9763, 0.9820,\n",
       "                      0.9982, 0.9833, 0.9660, 1.0028, 0.9630, 0.9713, 1.0131, 0.9784, 0.9664,\n",
       "                      0.9688, 0.9602, 0.9605, 0.9668, 0.9759, 0.9633, 0.9736, 0.9751, 0.9571,\n",
       "                      0.9551, 0.9673, 0.9850, 0.9753, 0.9827, 0.9796, 0.9681, 0.9709, 0.9784,\n",
       "                      0.9611, 0.9603, 0.9895, 0.9809, 0.9890, 0.9777, 0.9484, 0.9913, 0.9686,\n",
       "                      1.0060, 0.9723], device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.3.edge_encoder.1.bias',\n",
       "              tensor([-2.5693e-02, -9.7445e-03, -1.3280e-02, -1.4876e-02, -1.3010e-02,\n",
       "                      -2.8902e-02, -1.5408e-02, -1.3348e-02, -7.5672e-03,  1.6497e-03,\n",
       "                      -7.8495e-03, -9.1716e-03, -2.0961e-02, -2.2757e-02, -2.0028e-02,\n",
       "                      -1.7987e-02, -7.9770e-03, -1.8736e-03, -5.3145e-03, -3.8504e-03,\n",
       "                      -1.5113e-02, -2.7974e-02,  2.6333e-03, -8.1461e-03, -1.9291e-02,\n",
       "                      -1.5892e-03,  1.6622e-04, -1.8932e-02, -1.3259e-02, -2.7374e-02,\n",
       "                      -1.4522e-02, -1.6898e-02, -8.0646e-03, -1.0664e-02, -1.0739e-02,\n",
       "                      -1.7976e-03, -1.9121e-02, -1.7618e-02, -1.1595e-02, -8.5707e-03,\n",
       "                      -1.0648e-02, -1.1552e-02, -1.4868e-02, -9.6961e-03, -2.4517e-02,\n",
       "                      -7.4088e-03,  7.0666e-03, -1.7505e-02, -1.4665e-02, -2.4669e-02,\n",
       "                      -2.5899e-02, -3.7980e-02, -2.2516e-02, -3.0423e-03, -9.7302e-03,\n",
       "                      -2.5835e-02, -2.2611e-03, -4.0520e-03, -6.8373e-03, -1.9277e-02,\n",
       "                      -8.0628e-03, -1.8217e-02, -1.6750e-02, -1.5095e-02, -1.4788e-03,\n",
       "                      -3.7971e-02, -1.9556e-02,  1.5557e-04, -7.2736e-03, -3.9847e-03,\n",
       "                      -1.2300e-02, -1.9903e-02, -1.9171e-02, -9.9416e-03, -5.3805e-03,\n",
       "                       1.5913e-03, -7.6342e-03, -3.3007e-03, -6.2690e-03, -1.4096e-05,\n",
       "                      -1.5686e-02, -6.8913e-03, -1.7321e-02, -2.5634e-02, -1.4783e-02,\n",
       "                      -2.4108e-02, -1.3706e-02, -2.0894e-02, -2.0094e-02, -6.5898e-03,\n",
       "                      -1.2185e-02, -6.1023e-03, -2.7504e-02, -2.4717e-02, -2.5939e-02,\n",
       "                      -1.5674e-02, -5.1389e-03, -7.2659e-03,  4.9414e-03, -1.5022e-03,\n",
       "                      -1.3755e-02, -2.0142e-02, -2.5539e-02, -3.3021e-02, -1.7456e-02,\n",
       "                      -7.0987e-03, -1.8066e-02, -7.1374e-03, -9.0562e-03, -4.0189e-02,\n",
       "                      -4.1441e-03, -9.2944e-03, -8.8290e-03, -1.3431e-02, -1.1504e-02,\n",
       "                      -2.5691e-02, -1.5559e-02, -2.4027e-02, -1.8737e-02, -6.9398e-03,\n",
       "                      -1.3982e-02, -9.3979e-03, -2.2429e-02, -1.6925e-02, -1.1936e-02,\n",
       "                      -2.2714e-02, -8.0626e-03, -2.0102e-02, -1.1027e-02, -1.1894e-02,\n",
       "                      -2.9027e-02, -1.0246e-02, -2.0020e-02, -2.4571e-02,  1.9411e-03,\n",
       "                      -2.1970e-02, -1.8667e-02, -1.4658e-02, -3.9352e-03, -1.8957e-02,\n",
       "                      -9.4686e-03, -2.8255e-02,  5.2848e-04,  7.7191e-03, -1.7395e-02,\n",
       "                      -1.0582e-02, -1.7854e-02, -2.6494e-02, -3.3694e-02, -2.2807e-02,\n",
       "                      -2.3661e-02, -5.3341e-03, -7.3770e-03, -3.4522e-02, -2.7705e-02,\n",
       "                      -7.6568e-03, -5.1986e-03,  6.7720e-03, -2.3240e-02, -3.5141e-02,\n",
       "                      -1.3055e-02, -8.6289e-03, -2.5888e-02, -1.1771e-02, -1.2512e-02,\n",
       "                      -1.8411e-02, -3.3645e-02, -7.4316e-03, -1.2644e-02, -7.5547e-03,\n",
       "                      -1.6641e-02, -1.9724e-02, -2.6223e-02, -1.5339e-02, -6.3751e-03,\n",
       "                      -5.5682e-03, -2.3769e-02, -8.3162e-03, -7.2813e-03, -3.8014e-02,\n",
       "                      -2.6523e-02, -2.3696e-02, -9.4407e-03, -1.6965e-02, -1.8803e-02,\n",
       "                       4.4039e-03, -1.6914e-02, -1.6613e-02,  7.9222e-03, -2.1573e-02,\n",
       "                      -5.3399e-03, -1.7694e-02, -4.4106e-03, -3.1973e-03, -3.3638e-03,\n",
       "                      -3.0254e-02,  3.6135e-03, -1.7349e-02,  2.9815e-03, -8.8753e-03],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.3.edge_encoder.1.running_mean',\n",
       "              tensor([ 2.7008e-02,  1.6912e-03,  1.5797e-02, -6.7778e-02,  2.0418e-02,\n",
       "                      -1.1173e-02,  1.5179e-02,  2.4307e-02,  1.2653e-02,  4.6869e-03,\n",
       "                      -1.0762e-02, -1.9674e-03, -1.3291e-02,  3.0813e-02, -1.3610e-03,\n",
       "                       4.5526e-03,  2.5402e-02,  2.0468e-02,  1.6868e-02,  1.5769e-02,\n",
       "                      -3.7985e-03, -2.9739e-02,  3.6873e-02, -1.5693e-03, -2.0923e-02,\n",
       "                       4.5054e-02,  3.2104e-02, -3.1810e-03,  5.9307e-03, -2.4748e-03,\n",
       "                       2.8697e-02,  2.8321e-03,  4.0958e-02,  2.8253e-02,  3.6128e-02,\n",
       "                      -1.6234e-02,  1.5718e-02,  2.1499e-02,  3.2818e-02,  4.5780e-02,\n",
       "                       1.8265e-02, -2.2358e-02,  1.0330e-02, -8.1752e-03, -7.3849e-02,\n",
       "                      -7.7433e-02, -9.5062e-03,  5.6934e-02,  2.9798e-02, -5.6704e-02,\n",
       "                      -2.8998e-04,  3.8911e-02,  7.1862e-02,  2.8319e-02, -1.3835e-03,\n",
       "                       2.4380e-02,  4.7917e-02, -7.5812e-03,  4.3195e-02, -8.7772e-03,\n",
       "                       3.0336e-02, -2.1767e-02, -2.0313e-02, -5.7155e-02,  2.2238e-02,\n",
       "                      -1.7876e-02,  7.2475e-03,  5.9072e-02,  1.7254e-02,  3.5640e-02,\n",
       "                      -5.3690e-02,  3.1887e-02, -6.1408e-02,  1.1748e-02, -2.8399e-02,\n",
       "                       3.6311e-02,  3.8973e-02,  6.4906e-02,  7.8385e-03, -2.0935e-02,\n",
       "                      -5.8416e-02, -2.0047e-02, -3.1496e-02,  2.9189e-02, -3.4504e-02,\n",
       "                      -2.7514e-02,  6.8505e-02,  2.8062e-03,  1.8849e-05, -1.3774e-02,\n",
       "                       9.2343e-03,  3.7521e-02,  4.5121e-02,  1.4074e-02, -1.8121e-04,\n",
       "                      -4.0558e-02, -3.7644e-03,  1.6923e-02,  2.7104e-02, -1.5634e-02,\n",
       "                      -4.1377e-03,  9.3574e-03,  1.9628e-02,  5.6155e-02,  5.2343e-02,\n",
       "                       8.2967e-03, -3.7830e-03, -4.8709e-03, -8.8138e-03,  5.4959e-02,\n",
       "                       9.5033e-02, -8.7470e-03, -2.1711e-03, -2.7213e-02,  2.7870e-02,\n",
       "                      -6.4279e-02, -1.5909e-02, -4.3667e-02, -1.5132e-02, -9.5939e-03,\n",
       "                      -1.8963e-02, -6.7713e-03, -5.5545e-02, -1.0497e-02, -3.9040e-02,\n",
       "                      -4.8672e-03,  1.1762e-02, -1.5282e-02, -4.3349e-02, -5.3518e-02,\n",
       "                       4.6776e-03, -4.4651e-02, -4.5448e-02, -1.2307e-02,  1.7775e-02,\n",
       "                      -4.1911e-03,  2.1014e-02, -4.3004e-03,  2.7901e-02,  1.0977e-02,\n",
       "                      -7.3112e-03, -3.7840e-02, -1.7166e-03,  1.3762e-02, -2.5244e-02,\n",
       "                       1.1566e-02,  7.3994e-02, -4.3874e-03,  4.3512e-02, -4.0878e-02,\n",
       "                       1.8922e-03, -1.0121e-02, -2.9110e-02,  2.4583e-02, -4.8153e-02,\n",
       "                       2.5973e-02, -2.9922e-03, -2.0870e-02, -2.2877e-02, -1.4993e-03,\n",
       "                      -5.9943e-03, -7.2241e-03, -2.0146e-02,  1.2459e-02, -3.8290e-03,\n",
       "                      -2.0011e-02,  3.9809e-02,  1.3255e-02, -4.2352e-04,  1.7046e-02,\n",
       "                      -6.5159e-03,  1.2209e-02,  6.6373e-02, -1.1389e-02,  5.5789e-02,\n",
       "                       1.8531e-02, -1.1453e-02,  2.1218e-02,  1.8626e-02,  1.3585e-02,\n",
       "                      -3.0026e-02,  1.2386e-02, -9.9208e-03, -2.6795e-04, -8.1980e-03,\n",
       "                      -1.3025e-02, -1.7465e-02,  3.8352e-04, -2.6250e-02, -3.8193e-02,\n",
       "                       1.8636e-02, -7.6045e-03, -3.9300e-02,  1.3399e-03,  1.3233e-02,\n",
       "                       1.9639e-02, -1.1317e-02, -1.9422e-02, -3.2577e-02,  5.8234e-02],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.3.edge_encoder.1.running_var',\n",
       "              tensor([0.0007, 0.0011, 0.0017, 0.0010, 0.0004, 0.0005, 0.0011, 0.0008, 0.0008,\n",
       "                      0.0006, 0.0011, 0.0012, 0.0004, 0.0011, 0.0017, 0.0008, 0.0009, 0.0008,\n",
       "                      0.0008, 0.0017, 0.0010, 0.0005, 0.0005, 0.0005, 0.0007, 0.0009, 0.0004,\n",
       "                      0.0016, 0.0005, 0.0014, 0.0013, 0.0005, 0.0005, 0.0010, 0.0009, 0.0005,\n",
       "                      0.0009, 0.0014, 0.0012, 0.0007, 0.0004, 0.0008, 0.0005, 0.0008, 0.0010,\n",
       "                      0.0010, 0.0010, 0.0012, 0.0016, 0.0011, 0.0004, 0.0004, 0.0009, 0.0014,\n",
       "                      0.0009, 0.0013, 0.0004, 0.0005, 0.0009, 0.0005, 0.0003, 0.0009, 0.0005,\n",
       "                      0.0007, 0.0009, 0.0004, 0.0008, 0.0009, 0.0006, 0.0004, 0.0013, 0.0007,\n",
       "                      0.0007, 0.0006, 0.0007, 0.0004, 0.0007, 0.0007, 0.0007, 0.0003, 0.0020,\n",
       "                      0.0011, 0.0006, 0.0004, 0.0010, 0.0019, 0.0012, 0.0007, 0.0005, 0.0004,\n",
       "                      0.0005, 0.0009, 0.0012, 0.0007, 0.0007, 0.0014, 0.0015, 0.0009, 0.0009,\n",
       "                      0.0006, 0.0004, 0.0006, 0.0008, 0.0008, 0.0012, 0.0005, 0.0013, 0.0009,\n",
       "                      0.0006, 0.0015, 0.0007, 0.0006, 0.0007, 0.0010, 0.0010, 0.0010, 0.0005,\n",
       "                      0.0006, 0.0006, 0.0005, 0.0003, 0.0008, 0.0007, 0.0010, 0.0008, 0.0009,\n",
       "                      0.0008, 0.0012, 0.0011, 0.0014, 0.0014, 0.0012, 0.0019, 0.0012, 0.0016,\n",
       "                      0.0008, 0.0008, 0.0006, 0.0006, 0.0012, 0.0004, 0.0006, 0.0020, 0.0009,\n",
       "                      0.0004, 0.0004, 0.0010, 0.0010, 0.0006, 0.0004, 0.0008, 0.0006, 0.0010,\n",
       "                      0.0016, 0.0006, 0.0004, 0.0010, 0.0015, 0.0007, 0.0009, 0.0008, 0.0008,\n",
       "                      0.0005, 0.0006, 0.0010, 0.0003, 0.0010, 0.0007, 0.0005, 0.0007, 0.0007,\n",
       "                      0.0008, 0.0009, 0.0022, 0.0009, 0.0007, 0.0006, 0.0006, 0.0006, 0.0014,\n",
       "                      0.0004, 0.0004, 0.0003, 0.0004, 0.0008, 0.0010, 0.0010, 0.0010, 0.0016,\n",
       "                      0.0016, 0.0008, 0.0008, 0.0017, 0.0004, 0.0013, 0.0004, 0.0015, 0.0007,\n",
       "                      0.0011, 0.0009], device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.3.edge_encoder.1.num_batches_tracked',\n",
       "              tensor(318750, device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.3.edge_encoder.3.weight',\n",
       "              tensor([[-0.0193, -0.0094, -0.0241,  ...,  0.0122, -0.0301, -0.0028],\n",
       "                      [ 0.0069,  0.0188,  0.0111,  ..., -0.0008, -0.0141,  0.0301],\n",
       "                      [ 0.0371, -0.0236, -0.0005,  ..., -0.0178,  0.0145,  0.0044],\n",
       "                      ...,\n",
       "                      [ 0.0266,  0.0113,  0.0204,  ..., -0.0058,  0.0168, -0.0279],\n",
       "                      [ 0.0263, -0.0120,  0.0145,  ..., -0.0088,  0.0285, -0.0355],\n",
       "                      [ 0.0217,  0.0041,  0.0519,  ...,  0.0308, -0.0709, -0.0156]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.3.edge_encoder.3.bias',\n",
       "              tensor([-2.3653e-03, -5.7033e-03,  2.7150e-03,  1.7915e-03, -1.3082e-03,\n",
       "                      -3.1844e-04,  8.8534e-04, -5.2766e-03,  1.3499e-03,  4.7690e-03,\n",
       "                      -4.6336e-03,  1.4850e-03, -3.2236e-03,  3.7453e-03, -8.5289e-03,\n",
       "                       7.5043e-03,  5.8532e-03,  2.3962e-04, -5.7625e-04,  5.2903e-04,\n",
       "                      -1.7449e-03,  5.2435e-03,  2.9055e-03, -4.1971e-03, -5.6767e-03,\n",
       "                      -4.0691e-03, -1.4285e-03,  5.0252e-03, -1.9099e-03,  1.1951e-03,\n",
       "                       2.1446e-03, -2.3171e-03,  5.1971e-03,  1.3342e-03, -6.3974e-03,\n",
       "                       7.7394e-04, -5.0417e-03, -4.6538e-04,  8.4626e-03, -4.4000e-04,\n",
       "                      -7.0619e-04,  4.7418e-03, -5.4846e-03, -5.1588e-03, -7.3695e-03,\n",
       "                      -9.4579e-03,  4.9077e-03, -5.9823e-03,  1.0702e-03, -2.1661e-03,\n",
       "                       1.0390e-03,  1.1983e-03, -4.2399e-03, -1.2942e-03, -7.8520e-03,\n",
       "                      -3.5293e-03, -1.0280e-02,  3.5102e-04,  3.8343e-03, -1.2780e-03,\n",
       "                       4.5618e-04,  3.8666e-03,  1.8226e-03,  4.2149e-03, -7.9116e-03,\n",
       "                      -6.3569e-03,  7.4834e-04,  4.8660e-04, -3.4787e-03, -3.4874e-03,\n",
       "                      -2.9350e-03,  6.0196e-03,  2.0707e-03,  6.1710e-03, -2.5195e-04,\n",
       "                       2.7551e-03, -3.0170e-03, -3.2106e-03, -5.5723e-05,  5.0233e-03,\n",
       "                      -5.5378e-03, -8.5195e-03,  2.5666e-03, -1.8356e-03,  1.2716e-03,\n",
       "                      -1.2945e-03,  1.9425e-03,  8.8292e-04,  2.0636e-03,  1.4934e-03,\n",
       "                      -1.9848e-03,  9.8496e-03, -2.1664e-03,  1.9293e-03, -3.8735e-03,\n",
       "                      -5.7664e-03,  3.7731e-03, -2.0194e-03,  5.2783e-03,  3.5625e-03,\n",
       "                      -4.3390e-03, -4.5637e-03,  6.6010e-03,  3.1173e-03,  4.0452e-03,\n",
       "                      -2.6583e-03,  4.5262e-03, -1.5825e-03, -4.2482e-03, -3.4520e-03,\n",
       "                       2.3763e-03,  3.6228e-03,  1.7307e-03,  1.0506e-03,  4.2683e-03,\n",
       "                      -3.5708e-04, -2.0222e-03, -1.5319e-03,  4.2033e-03, -6.7279e-03,\n",
       "                       1.4046e-03,  2.9070e-03,  3.6665e-03,  1.5358e-03,  2.2912e-03,\n",
       "                       1.5417e-03, -5.5028e-03,  1.9160e-03, -3.6478e-03, -3.0722e-03,\n",
       "                      -6.0849e-04,  4.6370e-03,  1.5033e-03,  7.6505e-03,  1.1843e-03,\n",
       "                      -2.6880e-03, -7.3885e-04, -1.9909e-03, -4.8474e-03,  7.0672e-03,\n",
       "                       7.6360e-03, -5.4759e-03, -6.0674e-03, -1.4287e-03,  1.6351e-03,\n",
       "                       4.7338e-03, -4.7588e-03, -5.5839e-03,  1.8682e-03, -1.0032e-03,\n",
       "                      -1.1349e-04,  6.5163e-03,  7.6160e-04,  6.0492e-03,  2.1817e-03,\n",
       "                       5.5140e-04, -5.6854e-03,  2.1677e-04,  1.8623e-03,  1.7347e-03,\n",
       "                      -3.2468e-03,  2.5972e-03, -1.4406e-03, -4.4453e-03, -6.4311e-03,\n",
       "                      -3.7272e-03,  2.8988e-03, -3.4194e-03,  8.8222e-04,  3.5037e-03,\n",
       "                       4.3227e-04, -1.8212e-03,  1.9136e-03, -3.1052e-03, -5.8780e-03,\n",
       "                      -9.3809e-04,  2.1546e-03, -5.0847e-03, -5.3777e-03, -3.2735e-03,\n",
       "                       1.7199e-04, -1.1658e-03,  3.6198e-03,  4.1820e-03,  1.1943e-04,\n",
       "                      -1.7642e-03,  4.1916e-03,  8.8105e-04, -6.2575e-03,  6.1010e-03,\n",
       "                      -4.3334e-04,  1.6691e-03,  8.9472e-06,  5.3347e-03,  4.1516e-03,\n",
       "                       4.4639e-03,  4.7324e-03, -6.6560e-04, -5.5783e-03,  1.1676e-03],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.3.linear_key.weight',\n",
       "              tensor([[-0.0250,  0.0194, -0.0263,  ...,  0.0255, -0.0209, -0.0072],\n",
       "                      [-0.0001, -0.0180,  0.0040,  ...,  0.0030, -0.0343,  0.0061],\n",
       "                      [ 0.0091, -0.0014, -0.0426,  ...,  0.0115,  0.0284, -0.0286],\n",
       "                      ...,\n",
       "                      [ 0.0223, -0.0115,  0.0229,  ...,  0.0020,  0.0218, -0.0081],\n",
       "                      [ 0.0017,  0.0456,  0.0441,  ...,  0.0109,  0.0057, -0.0134],\n",
       "                      [-0.0010, -0.0146, -0.0328,  ...,  0.0183,  0.0092, -0.0155]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.3.linear_key.bias',\n",
       "              tensor([ 4.2918e-03, -2.1370e-03, -4.8462e-03, -1.1138e-02, -1.3881e-02,\n",
       "                      -4.7030e-03, -4.1497e-03,  6.1426e-04,  7.4234e-03, -1.5045e-02,\n",
       "                       1.2601e-02,  7.0833e-03,  1.7693e-03, -8.9814e-03,  6.6946e-03,\n",
       "                       1.3289e-02,  1.8041e-03,  1.3949e-02, -5.5115e-03,  5.2350e-03,\n",
       "                      -1.6544e-02, -5.0876e-03,  1.7893e-03,  7.5309e-04,  9.9210e-03,\n",
       "                       1.7701e-03, -1.1219e-03,  1.2466e-02,  2.4871e-03,  1.2461e-02,\n",
       "                       1.5792e-02, -7.0065e-03,  1.2266e-02,  2.7592e-03, -9.6039e-03,\n",
       "                       2.4116e-02,  5.8985e-04, -6.7586e-03, -1.9251e-02, -5.1713e-03,\n",
       "                      -1.4951e-02, -1.3736e-02,  2.7197e-02,  1.9886e-02, -1.2564e-02,\n",
       "                      -2.8641e-03,  7.8703e-03, -4.4442e-03,  5.5606e-03, -1.5373e-02,\n",
       "                      -3.4273e-03,  9.3207e-03,  1.3485e-02,  5.0920e-03,  1.3996e-02,\n",
       "                       7.9046e-04,  6.8437e-03, -1.3771e-02, -6.4161e-04, -3.6874e-03,\n",
       "                       7.3724e-03,  3.4598e-03,  3.8036e-03, -5.3308e-04, -9.8291e-03,\n",
       "                      -6.5341e-03,  8.2710e-03, -1.2257e-02, -6.4948e-03, -4.5766e-03,\n",
       "                      -5.0882e-03, -1.4194e-02,  1.1845e-02, -3.8473e-03,  7.6566e-03,\n",
       "                       1.1042e-03,  6.4095e-03, -1.0619e-02,  4.9411e-03, -1.3960e-03,\n",
       "                       2.9066e-02,  6.0726e-03, -8.3111e-03, -4.4800e-03, -2.0951e-04,\n",
       "                       6.4791e-04,  7.9511e-03,  7.2908e-03, -1.5441e-02, -5.1750e-03,\n",
       "                       5.0317e-03,  7.7267e-03, -4.7041e-03,  1.5865e-02,  2.9893e-04,\n",
       "                       4.0980e-03, -2.1672e-03, -1.1285e-02, -5.1786e-03, -2.0530e-03,\n",
       "                       1.8980e-02,  9.0254e-03, -4.3006e-03,  9.4919e-03,  1.3487e-02,\n",
       "                      -2.7551e-02,  9.7387e-03,  1.3694e-02, -9.1724e-03,  6.1290e-03,\n",
       "                      -1.6390e-02,  1.2537e-02,  1.3482e-02,  7.3137e-03, -5.8259e-03,\n",
       "                      -1.4638e-02,  1.0315e-02, -1.6620e-02,  1.2407e-02, -1.5162e-02,\n",
       "                       2.0290e-02,  1.7127e-02, -1.0949e-02, -1.3520e-02, -2.6606e-04,\n",
       "                      -1.7517e-02,  4.5773e-03,  2.3657e-02,  2.1977e-02,  2.1524e-03,\n",
       "                      -1.1221e-02,  1.9298e-02, -2.0862e-02,  2.7593e-02, -2.1407e-02,\n",
       "                       8.2414e-03, -9.4683e-03, -1.0949e-02,  2.9718e-03,  2.0019e-03,\n",
       "                       2.0446e-02, -6.4929e-03,  1.7065e-02,  6.0453e-03, -1.8251e-02,\n",
       "                      -9.8865e-03,  9.6488e-03, -1.7408e-02, -1.7923e-02, -2.7038e-02,\n",
       "                       8.4755e-03,  3.8143e-03, -1.7843e-02, -1.3603e-02,  9.1592e-03,\n",
       "                      -4.3563e-03, -6.0041e-03,  1.3170e-02,  6.7848e-03, -7.0038e-03,\n",
       "                       4.5807e-03, -6.2733e-03,  3.0199e-03, -1.3571e-02,  5.7319e-04,\n",
       "                      -2.9164e-03, -1.5345e-02, -1.8740e-03, -4.8418e-03, -1.3282e-04,\n",
       "                      -1.1169e-02,  7.9211e-03,  3.5835e-03,  5.4126e-03, -1.0872e-02,\n",
       "                       1.8876e-02, -1.3481e-02, -8.8402e-03,  4.5770e-03,  1.6374e-02,\n",
       "                      -2.9096e-02, -9.6652e-03,  2.1017e-02, -5.9485e-04, -4.5055e-03,\n",
       "                       7.2849e-05, -1.9001e-02,  6.9347e-03, -1.3595e-03, -3.2466e-02,\n",
       "                      -2.3728e-02,  2.3447e-04,  2.0522e-02,  5.3600e-03,  7.8465e-03,\n",
       "                      -5.0879e-03,  1.5813e-02, -8.0621e-03,  6.0345e-03,  3.7412e-03],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.3.linear_msg.weight',\n",
       "              tensor([[-0.0115,  0.0019,  0.0335,  ...,  0.0157, -0.0035,  0.0190],\n",
       "                      [-0.0057,  0.0205, -0.0236,  ..., -0.0351, -0.0123,  0.0170],\n",
       "                      [ 0.0016,  0.0037,  0.0148,  ...,  0.0168, -0.0369,  0.0079],\n",
       "                      ...,\n",
       "                      [ 0.0025, -0.0121, -0.0053,  ..., -0.0419,  0.0004,  0.0292],\n",
       "                      [-0.0323, -0.0024,  0.0205,  ..., -0.0190,  0.0334, -0.0491],\n",
       "                      [-0.0058,  0.0114,  0.0241,  ...,  0.0077, -0.0372,  0.0010]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.3.linear_msg.bias',\n",
       "              tensor([-9.2972e-03,  3.5786e-03, -5.6857e-03,  5.1329e-03, -1.7987e-03,\n",
       "                      -1.1666e-03,  1.4705e-02,  4.0380e-03,  1.1473e-03,  7.8397e-03,\n",
       "                       4.5409e-03, -8.5567e-03,  1.2844e-02,  2.5424e-03,  8.0654e-03,\n",
       "                      -2.5875e-03, -5.4112e-03,  4.0155e-04,  7.8114e-03, -6.0530e-03,\n",
       "                       1.9665e-03, -3.1314e-03,  1.8507e-03, -1.4163e-02, -5.4234e-05,\n",
       "                       2.5361e-03,  9.1829e-03,  1.4077e-02, -5.8525e-03, -7.2719e-03,\n",
       "                      -8.1472e-03, -1.2350e-02,  1.7240e-02,  7.1031e-03,  6.2329e-04,\n",
       "                       3.8994e-03,  3.7115e-03,  5.4724e-03, -8.9645e-03, -1.4701e-02,\n",
       "                       1.2483e-02, -6.1663e-03, -3.3869e-03, -3.3437e-03,  2.7451e-03,\n",
       "                       4.8871e-03,  1.6544e-03,  4.0517e-03,  7.7833e-03,  1.4745e-02,\n",
       "                       6.0989e-03, -7.5479e-03, -5.5616e-04, -6.6934e-03,  1.2342e-02,\n",
       "                       7.6298e-03, -8.1780e-03,  9.9464e-04, -7.7021e-03, -2.7985e-03,\n",
       "                       1.6687e-03, -6.8292e-04,  9.6227e-03, -5.1502e-04,  1.2029e-02,\n",
       "                      -4.1143e-03,  8.4327e-03, -1.5278e-02,  3.4873e-03,  3.0044e-03,\n",
       "                       1.5953e-04,  8.2658e-03,  1.9794e-03,  1.0545e-02,  3.5177e-03,\n",
       "                      -1.0803e-02, -3.4489e-03, -4.9023e-03,  8.3477e-04, -1.1459e-02,\n",
       "                       5.9419e-03, -1.9817e-03,  1.8864e-03,  7.8002e-03,  8.3337e-03,\n",
       "                      -1.7443e-03, -5.2243e-03,  6.1385e-03, -1.4301e-04,  2.7341e-03,\n",
       "                      -7.4565e-03, -5.8470e-03, -2.5784e-04, -2.4033e-03, -4.7456e-03,\n",
       "                       6.9408e-03,  6.7165e-03,  3.8833e-03,  2.7049e-04, -1.2977e-02,\n",
       "                      -4.9218e-03, -4.0622e-03, -3.7776e-03,  6.4094e-03,  9.8976e-03,\n",
       "                       5.2494e-03,  5.0986e-03, -4.7096e-03, -2.3042e-03,  8.7540e-03,\n",
       "                       5.4772e-03, -4.7597e-03, -1.2582e-04,  3.5795e-03, -3.4181e-04,\n",
       "                       5.1009e-03,  7.9694e-04,  6.6775e-03, -7.6926e-03, -1.0444e-03,\n",
       "                      -3.4476e-03,  4.9805e-04,  4.7430e-03, -5.7598e-03, -5.1716e-03,\n",
       "                       5.0748e-03, -9.1366e-03,  3.6491e-03, -2.7144e-03,  2.4564e-03,\n",
       "                       6.3791e-04, -7.4813e-03, -3.2707e-04,  8.3362e-03, -1.0169e-03,\n",
       "                      -3.5500e-03,  4.0592e-03, -1.5248e-03, -2.4933e-03, -2.0193e-03,\n",
       "                       6.5204e-03, -1.7757e-03,  5.8728e-03, -3.1210e-03, -1.7500e-03,\n",
       "                      -1.7530e-03, -3.5873e-03,  1.0930e-03,  9.1384e-03, -3.3935e-03,\n",
       "                       6.4301e-04, -2.3480e-03, -2.6618e-03, -1.2921e-02, -3.2587e-03,\n",
       "                      -7.4466e-03,  1.6869e-02,  3.7200e-03,  6.3730e-03, -4.8379e-03,\n",
       "                       4.1324e-03, -6.5117e-03, -3.7427e-04,  2.8563e-03,  1.3573e-03,\n",
       "                       2.4934e-03, -2.0688e-03,  2.5430e-03, -3.8379e-03, -9.5005e-03,\n",
       "                       8.4213e-03,  8.2432e-03, -4.5166e-04, -3.1925e-03,  1.9597e-03,\n",
       "                      -8.7929e-03, -4.1794e-03,  5.8196e-03,  1.0086e-02, -1.1019e-02,\n",
       "                      -3.9371e-03,  7.5188e-03, -6.0397e-03, -9.3034e-04,  4.8756e-03,\n",
       "                       2.8522e-03, -1.4749e-02, -3.7806e-03, -5.8035e-03, -4.2733e-03,\n",
       "                       2.6382e-03, -5.2518e-04, -3.6234e-03,  3.0737e-03,  1.4377e-02,\n",
       "                      -9.5045e-03,  2.6337e-03,  1.0465e-02,  9.3199e-03,  8.5393e-03],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.3.linear_query.weight',\n",
       "              tensor([[ 0.0206,  0.0156,  0.0208,  ...,  0.0760,  0.0657, -0.0123],\n",
       "                      [-0.0661, -0.0219,  0.0144,  ...,  0.0039, -0.0157,  0.0167],\n",
       "                      [ 0.0125,  0.0406,  0.0816,  ...,  0.0686, -0.0145, -0.0564],\n",
       "                      ...,\n",
       "                      [-0.0312,  0.0196, -0.0066,  ..., -0.0409, -0.0445,  0.0542],\n",
       "                      [-0.0369, -0.0172, -0.0219,  ...,  0.0100,  0.0076,  0.0295],\n",
       "                      [ 0.0173,  0.0087,  0.0528,  ..., -0.0356, -0.0534,  0.0001]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.3.linear_query.bias',\n",
       "              tensor([-0.0080,  0.0308,  0.0005, -0.0134,  0.0286, -0.0243, -0.0166, -0.0095,\n",
       "                       0.0308,  0.0293,  0.0220,  0.0354, -0.0476,  0.0158,  0.0287, -0.0191,\n",
       "                      -0.0032, -0.0327,  0.0239,  0.0013,  0.0141, -0.0312, -0.0225,  0.0111,\n",
       "                       0.0146, -0.0046,  0.0327,  0.0248, -0.0176,  0.0155, -0.0047, -0.0193,\n",
       "                       0.0284,  0.0238, -0.0211, -0.0016,  0.0141, -0.0375,  0.0218, -0.0080,\n",
       "                       0.0061,  0.0069, -0.0126,  0.0026, -0.0053, -0.0336,  0.0270, -0.0233,\n",
       "                      -0.0402, -0.0255,  0.0017,  0.0173, -0.0218,  0.0275,  0.0038, -0.0508,\n",
       "                       0.0233, -0.0479,  0.0057,  0.0162, -0.0032,  0.0016, -0.0173,  0.0132,\n",
       "                       0.0027, -0.0612, -0.0418,  0.0118, -0.0206,  0.0017, -0.0268, -0.0300,\n",
       "                       0.0191,  0.0268,  0.0289,  0.0189,  0.0390, -0.0232, -0.0003, -0.0368,\n",
       "                       0.0480, -0.0014, -0.0119, -0.0252,  0.0114,  0.0112,  0.0004,  0.0473,\n",
       "                       0.0132, -0.0241,  0.0082, -0.0046,  0.0035, -0.0055,  0.0353, -0.0006,\n",
       "                      -0.0210,  0.0309, -0.0033, -0.0198, -0.0009,  0.0181, -0.0390,  0.0174,\n",
       "                       0.0482, -0.0051,  0.0450,  0.0041,  0.0338,  0.0536, -0.0325,  0.0248,\n",
       "                       0.0557,  0.0511, -0.0546, -0.0426, -0.0155, -0.0487,  0.0569, -0.0456,\n",
       "                       0.0312,  0.0545,  0.0236, -0.0351,  0.0236, -0.0381, -0.0036,  0.0371,\n",
       "                       0.0523,  0.0347, -0.0486, -0.0422, -0.0359,  0.0351,  0.0209,  0.0406,\n",
       "                      -0.0327, -0.0397, -0.0343,  0.0161,  0.0388, -0.0542,  0.0614,  0.0007,\n",
       "                      -0.0503,  0.0535, -0.0094, -0.0517, -0.0403, -0.0524,  0.0052, -0.0479,\n",
       "                       0.0119, -0.0469, -0.0042,  0.0114,  0.0104,  0.0127, -0.0302, -0.0592,\n",
       "                       0.0044,  0.0038,  0.0255,  0.0051, -0.0083, -0.0414,  0.0006,  0.0121,\n",
       "                       0.0221, -0.0126, -0.0158, -0.0595, -0.0149,  0.0480,  0.0006, -0.0134,\n",
       "                      -0.0388, -0.0170,  0.0739, -0.0117,  0.0057,  0.0195,  0.0028, -0.0090,\n",
       "                      -0.0169,  0.0310,  0.0141,  0.0355, -0.0260, -0.0101, -0.0127,  0.0331,\n",
       "                       0.0154,  0.0287, -0.0153,  0.0097,  0.0566, -0.0196,  0.0009, -0.0142],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.3.mlp.0.weight',\n",
       "              tensor([[ 0.0405, -0.0099,  0.0266,  ..., -0.0435,  0.0033,  0.0145],\n",
       "                      [ 0.0009, -0.0102,  0.0319,  ..., -0.0162, -0.0006, -0.0017],\n",
       "                      [ 0.0446, -0.0072, -0.0285,  ...,  0.0306,  0.0164, -0.0258],\n",
       "                      ...,\n",
       "                      [ 0.0240, -0.0178,  0.0077,  ...,  0.0041,  0.0144,  0.0173],\n",
       "                      [ 0.0042, -0.0252, -0.0041,  ...,  0.0149,  0.0110, -0.0146],\n",
       "                      [ 0.0114, -0.0207, -0.0386,  ..., -0.0385, -0.0018,  0.0160]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.3.mlp.0.bias',\n",
       "              tensor([-9.5172e-03,  1.0344e-02, -5.4007e-03,  5.8811e-03,  1.8790e-03,\n",
       "                      -2.9831e-03,  5.6831e-03,  1.2634e-04, -4.4788e-03, -3.8998e-03,\n",
       "                      -8.9841e-04, -7.7329e-03, -3.7134e-03, -3.6636e-04, -1.3866e-02,\n",
       "                      -1.9881e-02, -3.4032e-03,  1.2861e-03,  3.9377e-03, -1.0393e-02,\n",
       "                      -4.8011e-03,  8.1925e-03,  4.2041e-03,  1.3576e-02, -3.0987e-03,\n",
       "                       9.6978e-03, -1.0575e-02, -4.2787e-03,  1.1397e-02, -1.3226e-03,\n",
       "                      -7.5323e-03, -6.0839e-03,  3.0977e-03, -4.7847e-03, -6.1844e-03,\n",
       "                      -9.7687e-03, -1.0838e-02,  3.0311e-03, -5.2109e-04, -2.7714e-03,\n",
       "                       2.7970e-03,  2.2669e-02,  8.2701e-03,  7.0387e-03, -6.5292e-03,\n",
       "                       9.8267e-03,  1.8014e-03,  4.1706e-03, -3.5774e-03, -1.8798e-02,\n",
       "                      -1.2260e-02,  3.1820e-03, -6.4230e-04,  1.2814e-02, -2.3370e-03,\n",
       "                      -2.9715e-04, -5.0553e-03, -2.9553e-03, -4.3669e-03, -1.7219e-02,\n",
       "                      -1.2901e-02, -4.1505e-03,  2.0106e-02, -2.5858e-03, -1.3203e-02,\n",
       "                       5.8503e-03,  8.1463e-03,  3.7167e-03,  6.4484e-03,  1.2664e-02,\n",
       "                      -8.9502e-03, -1.2689e-02, -1.4299e-02,  2.6905e-03,  5.8261e-03,\n",
       "                       2.8315e-03,  1.0747e-02, -3.9665e-04,  1.6596e-03, -7.4204e-03,\n",
       "                       3.0230e-03, -1.0489e-02, -4.3785e-03, -1.4071e-03, -5.7662e-03,\n",
       "                      -7.9349e-03,  2.0547e-02, -2.2009e-03, -3.6311e-04, -1.2156e-02,\n",
       "                       1.6181e-02,  2.3768e-03, -1.0895e-02,  3.3452e-03, -7.7467e-03,\n",
       "                      -1.8114e-02, -6.4457e-06, -1.5249e-02, -7.8392e-03, -8.1341e-03,\n",
       "                       2.1305e-03,  1.0553e-02,  7.6435e-03,  8.1693e-03, -7.8992e-03,\n",
       "                      -1.7246e-03, -4.0591e-03, -6.8863e-03,  5.3046e-03,  1.7128e-03,\n",
       "                      -1.1216e-02,  1.2054e-02,  3.9804e-03, -5.9696e-03, -4.4909e-03,\n",
       "                      -7.3462e-03, -1.0292e-02,  6.7007e-03, -1.1432e-02,  1.3732e-03,\n",
       "                      -6.2693e-03,  1.9127e-03,  3.7474e-03,  8.1752e-04,  9.0663e-03,\n",
       "                       4.7490e-03, -1.2445e-02, -7.9311e-03, -1.9963e-02,  4.6431e-03,\n",
       "                       1.5833e-02,  1.4090e-03,  1.8193e-02,  1.2315e-02,  1.1211e-02,\n",
       "                       1.0403e-02,  1.3030e-03,  6.3211e-03, -9.1666e-03,  4.7467e-03,\n",
       "                      -1.6379e-03, -1.3570e-02,  8.7186e-03,  5.4719e-03, -3.5346e-04,\n",
       "                       6.1109e-03,  2.7035e-03, -5.2920e-03, -2.5478e-03, -8.0417e-03,\n",
       "                       4.7235e-03, -1.0432e-02,  6.1484e-03,  1.2054e-02, -1.2534e-03,\n",
       "                      -2.0699e-03,  4.0021e-03, -8.9925e-03, -6.6512e-03,  7.6096e-03,\n",
       "                       2.9166e-03,  1.3358e-04, -1.0777e-02,  1.5155e-02,  3.1260e-03,\n",
       "                       9.1313e-03, -2.3418e-03, -5.4433e-03, -5.7031e-03, -1.2949e-02,\n",
       "                      -8.9656e-03,  5.2324e-03,  4.1253e-03, -1.9001e-03,  6.3223e-03,\n",
       "                      -1.9653e-03, -7.3621e-03,  2.4113e-03,  1.9141e-03,  9.7265e-04,\n",
       "                      -1.0130e-02, -3.4096e-03, -1.0892e-02,  1.0351e-02, -5.0605e-03,\n",
       "                      -2.0626e-03, -1.2366e-02, -2.4421e-03,  9.6134e-03,  8.6219e-03,\n",
       "                      -7.2328e-03,  4.7008e-03,  5.1888e-03, -1.0114e-02, -1.2494e-02,\n",
       "                      -4.1526e-03,  8.0144e-03,  7.0517e-03, -9.4290e-03, -1.2735e-02],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.3.mlp.1.weight',\n",
       "              tensor([0.9653, 0.9688, 0.9760, 0.9662, 0.9742, 0.9741, 0.9885, 0.9743, 0.9764,\n",
       "                      0.9720, 0.9581, 0.9705, 0.9843, 0.9826, 0.9736, 0.9576, 0.9628, 0.9710,\n",
       "                      0.9640, 0.9818, 0.9735, 0.9742, 0.9923, 0.9741, 0.9662, 0.9530, 0.9696,\n",
       "                      0.9642, 0.9538, 0.9750, 0.9662, 0.9617, 0.9648, 0.9684, 0.9900, 0.9707,\n",
       "                      0.9555, 0.9846, 0.9752, 0.9663, 0.9822, 0.9602, 0.9747, 0.9758, 0.9686,\n",
       "                      0.9712, 0.9662, 0.9855, 0.9623, 0.9913, 0.9721, 0.9651, 0.9696, 0.9632,\n",
       "                      0.9713, 0.9706, 0.9815, 0.9793, 0.9753, 0.9677, 0.9829, 0.9860, 0.9534,\n",
       "                      0.9796, 0.9682, 0.9775, 0.9717, 0.9943, 0.9604, 0.9752, 0.9908, 0.9690,\n",
       "                      0.9752, 0.9754, 0.9824, 0.9836, 0.9637, 0.9846, 0.9775, 0.9592, 0.9593,\n",
       "                      0.9730, 0.9611, 0.9711, 0.9749, 0.9779, 0.9800, 0.9381, 0.9565, 0.9698,\n",
       "                      0.9811, 0.9843, 0.9843, 0.9676, 0.9724, 0.9592, 0.9784, 0.9625, 0.9800,\n",
       "                      0.9534, 0.9795, 0.9807, 0.9706, 0.9652, 0.9780, 0.9530, 0.9874, 0.9685,\n",
       "                      0.9754, 0.9582, 0.9585, 0.9658, 0.9191, 0.9593, 0.9794, 0.9706, 0.9710,\n",
       "                      0.9732, 0.9840, 0.9696, 0.9654, 0.9844, 0.9844, 0.9604, 0.9793, 0.9654,\n",
       "                      0.9643, 0.9554, 0.9884, 0.9754, 0.9706, 0.9779, 0.9634, 0.9666, 0.9674,\n",
       "                      0.9860, 0.9724, 0.9864, 0.9660, 0.9728, 0.9841, 0.9529, 0.9410, 0.9830,\n",
       "                      0.9875, 0.9751, 0.9663, 0.9621, 0.9946, 0.9535, 0.9668, 0.9877, 0.9452,\n",
       "                      0.9847, 0.9715, 0.9889, 0.9930, 0.9665, 0.9626, 0.9849, 0.9707, 0.9566,\n",
       "                      0.9585, 0.9660, 0.9881, 0.9745, 0.9687, 0.9601, 0.9637, 0.9727, 0.9762,\n",
       "                      0.9837, 0.9774, 0.9525, 0.9645, 0.9672, 0.9782, 0.9783, 0.9788, 0.9683,\n",
       "                      0.9725, 0.9553, 0.9570, 0.9674, 0.9681, 0.9718, 0.9698, 0.9639, 0.9704,\n",
       "                      0.9715, 0.9805, 0.9727, 0.9873, 0.9531, 0.9682, 0.9632, 0.9718, 0.9631,\n",
       "                      0.9664, 0.9668], device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.3.mlp.1.bias',\n",
       "              tensor([ 1.6840e-02, -6.3337e-02, -6.4440e-03,  1.7163e-05,  9.2320e-04,\n",
       "                       2.0938e-03,  8.2581e-03, -1.6156e-02, -2.0429e-03, -8.5165e-03,\n",
       "                      -1.7291e-02, -8.1102e-03,  5.3742e-03,  7.7875e-03, -3.0644e-02,\n",
       "                       1.6911e-02, -2.3957e-02, -1.5599e-02,  6.7266e-03,  1.1572e-02,\n",
       "                      -5.2639e-03,  8.8660e-05, -3.0953e-03,  6.1086e-03, -4.0255e-03,\n",
       "                      -1.4621e-02,  1.2622e-02, -1.2569e-02,  2.6965e-02, -2.0731e-03,\n",
       "                      -4.7878e-02, -1.1183e-02, -2.2440e-02, -2.8885e-03, -1.7245e-02,\n",
       "                      -1.2952e-02, -1.0746e-02,  6.3439e-03, -3.9163e-03, -1.0467e-02,\n",
       "                      -4.3194e-02, -1.5752e-02, -2.7109e-02, -2.9177e-03, -1.4840e-02,\n",
       "                      -3.5413e-03,  6.0763e-03,  5.2082e-03,  3.0434e-04,  1.2402e-03,\n",
       "                      -2.1208e-02, -4.7834e-03, -3.4132e-02, -4.9791e-03,  1.2124e-02,\n",
       "                       8.1821e-04,  6.8703e-03, -1.6366e-02, -1.1764e-02, -2.1652e-02,\n",
       "                       2.1944e-03,  1.4170e-03, -1.7480e-02,  4.7419e-03, -3.2794e-02,\n",
       "                       2.5858e-02,  1.0888e-02,  2.1641e-02, -5.7780e-02, -2.0130e-02,\n",
       "                       1.2478e-02, -3.6331e-03, -3.3799e-02, -1.1850e-02,  6.1794e-04,\n",
       "                       1.8435e-02, -7.0738e-04, -1.6283e-03, -3.0634e-03, -2.3577e-02,\n",
       "                      -3.8598e-03, -1.0925e-02, -1.5045e-02, -4.6576e-03, -2.0313e-02,\n",
       "                       7.5752e-03,  1.2248e-03,  3.2317e-03, -1.8163e-02,  6.0973e-03,\n",
       "                      -1.2712e-03,  1.2769e-02, -1.7336e-02, -5.8132e-03, -7.7253e-04,\n",
       "                      -4.7653e-03,  4.7265e-03,  7.3526e-04, -4.8856e-02, -2.7997e-02,\n",
       "                       4.9832e-03,  8.3851e-03, -2.1549e-02,  2.1592e-02, -4.1016e-02,\n",
       "                      -3.9317e-02, -6.8482e-03, -1.2110e-03, -2.5410e-04, -6.9236e-04,\n",
       "                      -3.6940e-02,  7.5501e-03, -3.3267e-02,  8.3859e-03,  1.0334e-02,\n",
       "                       6.6046e-04,  1.2591e-02, -1.6658e-02,  3.4753e-03, -1.1793e-02,\n",
       "                       7.5828e-04, -1.1683e-02,  1.1473e-02, -4.5972e-04,  6.0178e-03,\n",
       "                      -2.5325e-02, -1.3138e-02, -3.3847e-03, -9.5791e-03, -6.4085e-03,\n",
       "                      -3.5383e-02, -1.4389e-02, -9.8895e-03, -4.4122e-03, -7.2233e-03,\n",
       "                      -4.4602e-02, -8.6448e-03,  2.0048e-02, -1.2172e-03,  5.6931e-03,\n",
       "                       8.3788e-03, -5.4133e-03, -4.9282e-02,  1.5275e-02, -8.1248e-03,\n",
       "                      -7.8886e-03, -4.8608e-02, -2.3526e-02,  8.9246e-03, -4.5603e-02,\n",
       "                      -1.1186e-03,  5.9955e-03, -2.4943e-02,  9.9545e-03, -2.3680e-03,\n",
       "                      -2.6178e-03,  2.0241e-02, -7.5387e-03, -1.5385e-02, -1.2158e-02,\n",
       "                      -5.6976e-03, -1.3265e-02, -1.6485e-02,  5.8646e-03,  8.5644e-03,\n",
       "                      -1.4430e-02, -1.0980e-02, -3.0647e-02, -1.8852e-02, -1.1750e-02,\n",
       "                      -1.0838e-02, -3.0448e-03, -1.2978e-03, -2.3662e-02, -4.3978e-03,\n",
       "                      -1.2174e-02, -2.1986e-03,  3.4387e-03, -6.0934e-03,  1.1396e-03,\n",
       "                      -6.3280e-03, -1.7538e-02, -8.0300e-03,  1.9911e-02,  1.2648e-02,\n",
       "                      -1.0148e-02,  1.9507e-02,  7.4653e-03, -1.2651e-02,  1.0334e-02,\n",
       "                      -1.5045e-03, -2.7204e-03,  7.4992e-03, -5.5112e-02,  7.7407e-03,\n",
       "                      -2.2689e-02,  4.5753e-03,  4.1462e-03, -1.3165e-02,  3.2177e-02],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.3.mlp.1.running_mean',\n",
       "              tensor([-1.2450,  2.4895, -2.2073, -1.2929, -2.5708, -2.4237, -3.1747, -2.3930,\n",
       "                      -2.3399,  0.7292, -0.6992,  0.4968, -2.4778, -1.9441,  1.2376, -1.1367,\n",
       "                       0.1236,  0.3287, -1.6354, -1.4915, -1.1600, -2.3542, -2.6504, -0.7699,\n",
       "                      -0.7222, -1.2431, -0.7735, -2.2100,  0.1040,  0.9628,  3.0839, -0.4731,\n",
       "                       1.0459,  1.2963,  2.9466, -0.7133,  1.6505, -1.8822, -1.5510,  1.0318,\n",
       "                       2.4857, -0.8986,  1.6592, -2.0162, -1.5342, -2.7552, -2.1840, -1.4439,\n",
       "                      -0.8472, -0.7096,  2.3024, -2.1732, -0.7490, -1.3250, -2.3031, -1.8606,\n",
       "                      -1.4187, -2.0512, -2.0594,  0.8260, -2.0125, -1.7710,  0.8928, -2.5513,\n",
       "                       2.9254, -1.2138, -1.2634, -2.7301,  2.1970,  2.3113, -2.9060, -0.6350,\n",
       "                       2.9007, -1.4416, -2.2641, -1.5283, -1.6761, -2.1683, -2.4238,  0.4912,\n",
       "                       0.8083, -0.5764,  1.5957, -1.8313, -1.2634, -2.9375,  0.0238, -0.2926,\n",
       "                      -1.3587, -0.6733,  0.9349, -2.2249, -1.2464, -0.8170, -2.5882,  0.6710,\n",
       "                      -2.2441, -1.2091,  2.8721, -2.5231, -1.9153, -2.4854, -1.3467, -2.3717,\n",
       "                       2.9509, -1.1256, -2.2785, -2.3796, -2.7281, -3.1141,  1.7208, -1.9615,\n",
       "                       2.6274, -2.9903, -0.2946, -1.9573, -2.6350,  3.6684, -2.7380, -0.8165,\n",
       "                      -0.6821, -2.1525, -3.1276, -0.8281, -2.9783,  1.7016,  0.0284, -0.6371,\n",
       "                       3.1480, -1.3977,  2.6036, -1.7571,  0.9829, -2.7242, -2.5802,  3.9150,\n",
       "                       1.9232, -2.3813, -1.2450,  0.9753,  0.3886, -1.1718,  3.1854, -0.7562,\n",
       "                      -2.4374, -2.3473, -1.0987, -0.8658, -2.0580, -1.6984, -1.7765, -2.2179,\n",
       "                       2.7600, -1.6203, -1.4203, -1.5411, -2.8006, -0.1851, -1.1866,  0.5777,\n",
       "                      -0.3437, -2.0236,  1.1281, -1.0294, -0.8793, -0.9669, -1.9423,  0.4445,\n",
       "                      -1.8172, -1.3322, -2.0109, -1.3815, -2.2938, -0.2737,  0.0701, -2.6862,\n",
       "                      -2.2127,  1.5834, -1.0380, -1.5825, -1.2460, -0.6043, -0.6822, -0.0588,\n",
       "                      -1.0505, -0.1919, -0.9424,  1.0946, -0.9791, -1.7983, -2.3633, -1.1569,\n",
       "                      -2.7655,  2.5920, -1.1498,  2.2374, -0.3448, -0.8324, -0.3944, -1.7926],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.3.mlp.1.running_var',\n",
       "              tensor([ 5.6490, 11.6624, 13.3093,  4.7043, 11.6839, 10.2432, 18.9698, 11.4820,\n",
       "                      11.7550,  3.6701, 10.9618,  6.4676, 11.9775, 13.0490,  5.7158,  7.2491,\n",
       "                      10.0342,  9.5447,  6.3205,  8.2877,  5.2653, 11.2820, 14.1501,  9.1266,\n",
       "                       9.2626,  4.4397,  4.3615,  9.7988,  3.7878,  5.9380, 17.5665,  7.8868,\n",
       "                      10.7442,  9.6606, 15.6137,  9.0050,  6.7363,  8.5412, 15.8288,  4.7229,\n",
       "                      12.6786, 12.4208,  6.0980,  8.5737,  5.2540, 16.1205, 11.6232,  5.8876,\n",
       "                      10.8155,  9.0561, 11.3320,  8.2265,  2.2666,  3.9871, 11.2129, 13.7600,\n",
       "                       5.6460,  8.8254,  8.0989,  2.7909,  8.8297,  9.3913,  3.1882, 14.7143,\n",
       "                      15.9181,  5.9760,  5.2927, 15.2866,  9.2072, 10.7992, 19.8593,  7.8749,\n",
       "                      15.6329,  7.6049, 11.3761,  8.1692, 13.8963, 11.5948, 12.0386,  4.9904,\n",
       "                       4.4286,  2.2093,  6.4303, 18.8106,  5.3576, 16.6782,  9.5721,  4.3648,\n",
       "                       9.8454,  8.7207,  8.9657, 11.8336,  2.8695,  3.5000, 12.5256,  6.4800,\n",
       "                      10.5902, 12.3103, 15.9970, 16.6085,  7.0752, 13.8707,  5.4365, 12.3348,\n",
       "                      16.7483,  6.2262, 11.6397, 13.8623, 14.1475, 23.4764,  9.6048, 13.2442,\n",
       "                      13.0632, 22.3289,  4.0164, 12.1347, 13.1907, 24.0781, 18.3425,  2.7940,\n",
       "                       3.3855, 10.5290, 23.7585, 11.4270, 18.0355,  8.1707, 12.7381, 13.4364,\n",
       "                      17.9258,  3.6217, 13.7130, 12.2575,  5.6624, 14.2554, 18.1771, 24.9913,\n",
       "                       9.2937, 11.3632,  4.5262,  5.7525,  7.9407,  3.8771, 16.6211,  4.1931,\n",
       "                      14.4021,  9.8766,  3.3033,  4.3498,  9.0001,  8.1559,  9.1518, 11.0190,\n",
       "                      16.6558,  6.5191,  8.7372,  7.1063, 16.0966,  6.4720,  9.5512,  4.5819,\n",
       "                       3.0522, 11.6817,  7.7604,  6.3105,  3.3431,  8.4583,  8.7456,  6.1692,\n",
       "                       8.6170,  3.8394, 10.6721,  6.9196, 10.4985, 10.6592,  3.8752, 14.9068,\n",
       "                      16.6154,  6.7120,  3.8397,  9.5364,  4.4039,  8.4026,  9.7888,  3.3155,\n",
       "                       4.1881,  8.6991,  2.6188,  7.7587,  4.8517,  6.8378, 12.8157,  4.6840,\n",
       "                      19.9788, 12.3354,  3.7281, 12.3484,  5.1266,  6.5947,  9.5004,  9.6874],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.3.mlp.1.num_batches_tracked',\n",
       "              tensor(63750, device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.3.mlp.3.weight',\n",
       "              tensor([[ 0.0009, -0.0181,  0.0256,  ...,  0.0003, -0.0315, -0.0080],\n",
       "                      [-0.0056, -0.0146, -0.0240,  ...,  0.0369,  0.0108,  0.0030],\n",
       "                      [-0.0055,  0.0316,  0.0151,  ..., -0.0319, -0.0133,  0.0041],\n",
       "                      ...,\n",
       "                      [-0.0078, -0.0150,  0.0147,  ..., -0.0354,  0.0030,  0.0345],\n",
       "                      [-0.0254, -0.0065, -0.0274,  ..., -0.0124,  0.0230,  0.0432],\n",
       "                      [-0.0334, -0.0243,  0.0069,  ...,  0.0310, -0.0156, -0.0176]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.3.mlp.3.bias',\n",
       "              tensor([ 9.1001e-03,  1.2445e-02, -1.1444e-03,  5.9663e-03,  9.8035e-03,\n",
       "                       1.5954e-02, -1.5896e-02,  1.0790e-02, -8.9629e-03,  1.8887e-02,\n",
       "                       7.3561e-03,  3.8018e-03,  1.9889e-02,  1.3966e-02,  1.8728e-02,\n",
       "                       4.1894e-03,  3.7231e-03, -6.4757e-03,  9.3939e-03,  1.2204e-03,\n",
       "                       1.2392e-02, -1.8794e-02, -4.4216e-03,  2.3699e-02,  5.5036e-03,\n",
       "                      -4.6867e-03,  1.1126e-02, -7.8811e-03,  2.0774e-03,  2.2937e-02,\n",
       "                       1.1766e-02,  1.0888e-02,  1.3914e-02,  6.7895e-03,  1.5910e-02,\n",
       "                       1.6665e-02,  5.5908e-03,  3.4307e-03,  1.6741e-02,  3.5933e-02,\n",
       "                       3.6657e-03,  1.6642e-02, -2.9206e-03, -2.6560e-02,  3.4101e-04,\n",
       "                      -4.6386e-05,  8.9774e-03,  1.2080e-02,  6.0495e-03,  1.1289e-02,\n",
       "                       9.9181e-03,  2.2598e-02,  6.2083e-03, -1.2565e-02,  9.0498e-03,\n",
       "                       1.8340e-02, -8.7903e-03,  1.2204e-02,  2.2420e-02,  1.7635e-02,\n",
       "                       1.2630e-02, -6.9581e-03, -7.5538e-03, -2.8793e-03,  2.1720e-02,\n",
       "                      -6.9438e-03, -9.1123e-04, -6.7090e-03,  9.6207e-03,  7.2143e-03,\n",
       "                       1.5015e-02,  6.8548e-03,  2.4583e-02,  8.6679e-03,  1.4667e-02,\n",
       "                       9.6649e-03,  1.4485e-02, -5.8696e-03,  1.0113e-02,  1.5500e-02,\n",
       "                       3.5528e-03,  2.3111e-02,  1.2688e-02,  1.8902e-02,  1.8136e-02,\n",
       "                       2.1633e-02,  1.2754e-02,  2.6635e-02, -1.1400e-03,  6.6982e-03,\n",
       "                      -8.7034e-03,  8.0057e-03,  2.0764e-03,  2.9824e-03,  2.0906e-02,\n",
       "                       2.3959e-02, -7.0429e-03,  1.7641e-02,  7.0470e-03,  3.8810e-02,\n",
       "                       2.1880e-02,  2.0685e-02,  1.7676e-02,  1.3271e-02,  1.5489e-02,\n",
       "                       3.1439e-03,  1.4043e-02, -2.1893e-02, -3.9217e-03, -1.9317e-02,\n",
       "                      -1.1621e-02,  2.5370e-02,  1.8595e-02,  5.5369e-03,  2.8377e-02,\n",
       "                       7.0321e-04,  3.0216e-03,  1.0885e-02, -3.5471e-03, -3.4434e-03,\n",
       "                      -2.9884e-03,  2.2567e-03,  8.7348e-03,  1.8374e-02,  1.4265e-03,\n",
       "                      -1.0535e-02,  3.0123e-02,  1.3774e-02, -1.3888e-02,  1.9549e-03,\n",
       "                       2.0544e-02,  5.7959e-03,  1.5295e-02, -2.1561e-02,  1.6517e-02,\n",
       "                       1.8871e-03,  5.6566e-03, -2.1870e-02,  1.1841e-02,  1.0172e-02,\n",
       "                       1.0175e-02, -3.4700e-03,  8.9811e-03,  1.6012e-02,  2.6701e-03,\n",
       "                       6.2839e-03,  1.0099e-02,  7.9739e-03,  1.0462e-02,  6.0668e-03,\n",
       "                      -7.5618e-03,  1.5839e-02,  9.0176e-03, -5.3363e-04,  1.3397e-02,\n",
       "                       3.9545e-03, -3.9281e-04, -1.0878e-02, -8.8756e-05, -3.4557e-03,\n",
       "                       1.0853e-02,  7.4721e-03, -1.5804e-05, -2.0941e-02,  7.2353e-03,\n",
       "                      -6.1024e-03, -1.3246e-02,  1.4677e-02,  3.5522e-04,  1.6858e-02,\n",
       "                      -3.0463e-03,  1.8374e-02,  8.8343e-03, -4.0443e-03,  8.9950e-03,\n",
       "                       4.1851e-03,  1.7842e-02,  2.7115e-03,  1.2059e-02,  3.4100e-02,\n",
       "                       2.6609e-03,  2.0812e-02,  7.0620e-03,  9.0362e-03,  1.1689e-02,\n",
       "                       1.3980e-02, -2.8495e-04,  4.3204e-03,  3.6332e-03, -3.2960e-03,\n",
       "                       3.3398e-03, -3.5834e-03,  4.5469e-03,  1.9004e-02,  1.7964e-02,\n",
       "                       1.8289e-02,  2.5478e-02,  6.0373e-03,  1.6054e-02,  3.9777e-03],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.4.edge_encoder.0.weight',\n",
       "              tensor([[ 0.0306, -0.0353,  0.0325,  ..., -0.0054, -0.0064, -0.0239],\n",
       "                      [ 0.0247,  0.0387,  0.0236,  ...,  0.0328,  0.0120, -0.0459],\n",
       "                      [ 0.0180, -0.0081, -0.0130,  ..., -0.0158,  0.0251,  0.0164],\n",
       "                      ...,\n",
       "                      [ 0.0070,  0.0437, -0.0125,  ..., -0.0002, -0.0051, -0.0569],\n",
       "                      [ 0.0213,  0.0714,  0.0441,  ..., -0.0479,  0.0109, -0.0085],\n",
       "                      [ 0.0176, -0.0074, -0.0351,  ..., -0.0420,  0.0276, -0.0018]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.4.edge_encoder.0.bias',\n",
       "              tensor([ 0.0077,  0.0119,  0.0017, -0.0190, -0.0046,  0.0056,  0.0168,  0.0094,\n",
       "                      -0.0051,  0.0039, -0.0029,  0.0186, -0.0180,  0.0189,  0.0191, -0.0094,\n",
       "                       0.0084,  0.0184, -0.0068, -0.0066, -0.0126, -0.0144,  0.0322,  0.0054,\n",
       "                       0.0056, -0.0084,  0.0076,  0.0117, -0.0092, -0.0210,  0.0302,  0.0111,\n",
       "                       0.0049,  0.0133,  0.0009,  0.0033,  0.0078, -0.0005,  0.0011,  0.0380,\n",
       "                       0.0042, -0.0085, -0.0131, -0.0191, -0.0132, -0.0132,  0.0060,  0.0126,\n",
       "                       0.0204, -0.0218, -0.0039,  0.0289,  0.0030,  0.0034,  0.0042,  0.0069,\n",
       "                       0.0276,  0.0014,  0.0052, -0.0010,  0.0165, -0.0045, -0.0037,  0.0045,\n",
       "                       0.0175, -0.0177, -0.0008,  0.0173, -0.0091,  0.0122, -0.0022, -0.0185,\n",
       "                      -0.0071, -0.0143,  0.0194,  0.0052,  0.0028,  0.0003, -0.0044,  0.0021,\n",
       "                      -0.0239, -0.0257,  0.0002,  0.0104,  0.0085,  0.0029,  0.0085,  0.0186,\n",
       "                       0.0136, -0.0184,  0.0170,  0.0219,  0.0114,  0.0373, -0.0013, -0.0081,\n",
       "                       0.0079,  0.0001,  0.0129, -0.0018,  0.0132,  0.0188,  0.0141, -0.0070,\n",
       "                       0.0138,  0.0063, -0.0268, -0.0065,  0.0113,  0.0060,  0.0369,  0.0077,\n",
       "                       0.0054, -0.0095, -0.0127, -0.0155, -0.0099, -0.0243, -0.0093,  0.0114,\n",
       "                      -0.0292, -0.0092, -0.0165,  0.0360, -0.0180,  0.0009, -0.0012, -0.0136,\n",
       "                      -0.0028, -0.0299, -0.0139,  0.0060, -0.0042,  0.0075, -0.0028,  0.0032,\n",
       "                       0.0168, -0.0089,  0.0203,  0.0222,  0.0033, -0.0214,  0.0055, -0.0004,\n",
       "                      -0.0070, -0.0103,  0.0122,  0.0016,  0.0049,  0.0059,  0.0101, -0.0175,\n",
       "                      -0.0075,  0.0347, -0.0166,  0.0217,  0.0009, -0.0263,  0.0026,  0.0296,\n",
       "                       0.0109,  0.0100, -0.0139, -0.0151,  0.0139,  0.0117,  0.0224,  0.0200,\n",
       "                       0.0159,  0.0146, -0.0090,  0.0056,  0.0198, -0.0114,  0.0122, -0.0099,\n",
       "                      -0.0116,  0.0004, -0.0143, -0.0011,  0.0056,  0.0021,  0.0154, -0.0226,\n",
       "                      -0.0033, -0.0069, -0.0072, -0.0033, -0.0062, -0.0068, -0.0164,  0.0153,\n",
       "                      -0.0333,  0.0075, -0.0050, -0.0042, -0.0204,  0.0111, -0.0367,  0.0139],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.4.edge_encoder.1.weight',\n",
       "              tensor([0.9628, 0.9829, 0.9672, 0.9673, 0.9706, 0.9835, 0.9779, 0.9585, 0.9801,\n",
       "                      1.0104, 0.9749, 0.9749, 0.9704, 0.9653, 0.9617, 0.9588, 0.9810, 0.9747,\n",
       "                      0.9706, 0.9653, 0.9548, 0.9736, 0.9918, 0.9715, 0.9768, 0.9686, 0.9768,\n",
       "                      0.9644, 0.9705, 0.9647, 0.9775, 0.9654, 0.9791, 0.9719, 0.9689, 1.0024,\n",
       "                      0.9714, 0.9612, 0.9602, 0.9835, 0.9716, 0.9771, 0.9913, 0.9704, 0.9972,\n",
       "                      0.9774, 0.9673, 0.9556, 0.9649, 0.9712, 0.9714, 0.9532, 0.9586, 0.9630,\n",
       "                      0.9654, 0.9569, 0.9866, 0.9909, 0.9710, 0.9789, 0.9821, 0.9766, 0.9629,\n",
       "                      1.0112, 0.9736, 1.0307, 0.9648, 0.9848, 0.9644, 0.9779, 0.9688, 0.9556,\n",
       "                      0.9911, 0.9716, 0.9692, 0.9976, 0.9801, 0.9737, 0.9750, 1.0032, 0.9712,\n",
       "                      0.9831, 0.9793, 1.0119, 0.9947, 0.9525, 0.9689, 1.0086, 0.9671, 0.9862,\n",
       "                      0.9723, 0.9898, 0.9515, 0.9780, 0.9625, 0.9707, 0.9851, 0.9711, 0.9946,\n",
       "                      0.9929, 1.0127, 0.9705, 0.9535, 0.9593, 0.9769, 0.9911, 0.9627, 0.9748,\n",
       "                      0.9724, 0.9391, 0.9803, 0.9876, 0.9843, 0.9748, 0.9582, 0.9636, 0.9737,\n",
       "                      0.9705, 0.9908, 0.9860, 0.9873, 0.9901, 0.9624, 0.9739, 0.9752, 0.9613,\n",
       "                      0.9775, 0.9644, 0.9877, 0.9880, 0.9751, 0.9752, 0.9599, 0.9629, 0.9751,\n",
       "                      0.9859, 0.9705, 0.9769, 0.9848, 0.9831, 0.9677, 1.0146, 0.9704, 0.9786,\n",
       "                      0.9771, 0.9810, 0.9668, 0.9568, 0.9419, 0.9776, 0.9674, 0.9866, 0.9767,\n",
       "                      0.9543, 0.9812, 1.0107, 0.9792, 0.9727, 0.9707, 0.9655, 0.9763, 0.9820,\n",
       "                      0.9982, 0.9833, 0.9660, 1.0028, 0.9630, 0.9713, 1.0131, 0.9784, 0.9664,\n",
       "                      0.9688, 0.9602, 0.9605, 0.9668, 0.9759, 0.9633, 0.9736, 0.9751, 0.9571,\n",
       "                      0.9551, 0.9673, 0.9850, 0.9753, 0.9827, 0.9796, 0.9681, 0.9709, 0.9784,\n",
       "                      0.9611, 0.9603, 0.9895, 0.9809, 0.9890, 0.9777, 0.9484, 0.9913, 0.9686,\n",
       "                      1.0060, 0.9723], device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.4.edge_encoder.1.bias',\n",
       "              tensor([-2.5693e-02, -9.7445e-03, -1.3280e-02, -1.4876e-02, -1.3010e-02,\n",
       "                      -2.8902e-02, -1.5408e-02, -1.3348e-02, -7.5672e-03,  1.6497e-03,\n",
       "                      -7.8495e-03, -9.1716e-03, -2.0961e-02, -2.2757e-02, -2.0028e-02,\n",
       "                      -1.7987e-02, -7.9770e-03, -1.8736e-03, -5.3145e-03, -3.8504e-03,\n",
       "                      -1.5113e-02, -2.7974e-02,  2.6333e-03, -8.1461e-03, -1.9291e-02,\n",
       "                      -1.5892e-03,  1.6622e-04, -1.8932e-02, -1.3259e-02, -2.7374e-02,\n",
       "                      -1.4522e-02, -1.6898e-02, -8.0646e-03, -1.0664e-02, -1.0739e-02,\n",
       "                      -1.7976e-03, -1.9121e-02, -1.7618e-02, -1.1595e-02, -8.5707e-03,\n",
       "                      -1.0648e-02, -1.1552e-02, -1.4868e-02, -9.6961e-03, -2.4517e-02,\n",
       "                      -7.4088e-03,  7.0666e-03, -1.7505e-02, -1.4665e-02, -2.4669e-02,\n",
       "                      -2.5899e-02, -3.7980e-02, -2.2516e-02, -3.0423e-03, -9.7302e-03,\n",
       "                      -2.5835e-02, -2.2611e-03, -4.0520e-03, -6.8373e-03, -1.9277e-02,\n",
       "                      -8.0628e-03, -1.8217e-02, -1.6750e-02, -1.5095e-02, -1.4788e-03,\n",
       "                      -3.7971e-02, -1.9556e-02,  1.5557e-04, -7.2736e-03, -3.9847e-03,\n",
       "                      -1.2300e-02, -1.9903e-02, -1.9171e-02, -9.9416e-03, -5.3805e-03,\n",
       "                       1.5913e-03, -7.6342e-03, -3.3007e-03, -6.2690e-03, -1.4096e-05,\n",
       "                      -1.5686e-02, -6.8913e-03, -1.7321e-02, -2.5634e-02, -1.4783e-02,\n",
       "                      -2.4108e-02, -1.3706e-02, -2.0894e-02, -2.0094e-02, -6.5898e-03,\n",
       "                      -1.2185e-02, -6.1023e-03, -2.7504e-02, -2.4717e-02, -2.5939e-02,\n",
       "                      -1.5674e-02, -5.1389e-03, -7.2659e-03,  4.9414e-03, -1.5022e-03,\n",
       "                      -1.3755e-02, -2.0142e-02, -2.5539e-02, -3.3021e-02, -1.7456e-02,\n",
       "                      -7.0987e-03, -1.8066e-02, -7.1374e-03, -9.0562e-03, -4.0189e-02,\n",
       "                      -4.1441e-03, -9.2944e-03, -8.8290e-03, -1.3431e-02, -1.1504e-02,\n",
       "                      -2.5691e-02, -1.5559e-02, -2.4027e-02, -1.8737e-02, -6.9398e-03,\n",
       "                      -1.3982e-02, -9.3979e-03, -2.2429e-02, -1.6925e-02, -1.1936e-02,\n",
       "                      -2.2714e-02, -8.0626e-03, -2.0102e-02, -1.1027e-02, -1.1894e-02,\n",
       "                      -2.9027e-02, -1.0246e-02, -2.0020e-02, -2.4571e-02,  1.9411e-03,\n",
       "                      -2.1970e-02, -1.8667e-02, -1.4658e-02, -3.9352e-03, -1.8957e-02,\n",
       "                      -9.4686e-03, -2.8255e-02,  5.2848e-04,  7.7191e-03, -1.7395e-02,\n",
       "                      -1.0582e-02, -1.7854e-02, -2.6494e-02, -3.3694e-02, -2.2807e-02,\n",
       "                      -2.3661e-02, -5.3341e-03, -7.3770e-03, -3.4522e-02, -2.7705e-02,\n",
       "                      -7.6568e-03, -5.1986e-03,  6.7720e-03, -2.3240e-02, -3.5141e-02,\n",
       "                      -1.3055e-02, -8.6289e-03, -2.5888e-02, -1.1771e-02, -1.2512e-02,\n",
       "                      -1.8411e-02, -3.3645e-02, -7.4316e-03, -1.2644e-02, -7.5547e-03,\n",
       "                      -1.6641e-02, -1.9724e-02, -2.6223e-02, -1.5339e-02, -6.3751e-03,\n",
       "                      -5.5682e-03, -2.3769e-02, -8.3162e-03, -7.2813e-03, -3.8014e-02,\n",
       "                      -2.6523e-02, -2.3696e-02, -9.4407e-03, -1.6965e-02, -1.8803e-02,\n",
       "                       4.4039e-03, -1.6914e-02, -1.6613e-02,  7.9222e-03, -2.1573e-02,\n",
       "                      -5.3399e-03, -1.7694e-02, -4.4106e-03, -3.1973e-03, -3.3638e-03,\n",
       "                      -3.0254e-02,  3.6135e-03, -1.7349e-02,  2.9815e-03, -8.8753e-03],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.4.edge_encoder.1.running_mean',\n",
       "              tensor([ 2.7008e-02,  1.6912e-03,  1.5797e-02, -6.7778e-02,  2.0418e-02,\n",
       "                      -1.1173e-02,  1.5179e-02,  2.4307e-02,  1.2653e-02,  4.6869e-03,\n",
       "                      -1.0762e-02, -1.9674e-03, -1.3291e-02,  3.0813e-02, -1.3610e-03,\n",
       "                       4.5526e-03,  2.5402e-02,  2.0468e-02,  1.6868e-02,  1.5769e-02,\n",
       "                      -3.7985e-03, -2.9739e-02,  3.6873e-02, -1.5693e-03, -2.0923e-02,\n",
       "                       4.5054e-02,  3.2104e-02, -3.1810e-03,  5.9307e-03, -2.4748e-03,\n",
       "                       2.8697e-02,  2.8321e-03,  4.0958e-02,  2.8253e-02,  3.6128e-02,\n",
       "                      -1.6234e-02,  1.5718e-02,  2.1499e-02,  3.2818e-02,  4.5780e-02,\n",
       "                       1.8265e-02, -2.2358e-02,  1.0330e-02, -8.1752e-03, -7.3849e-02,\n",
       "                      -7.7433e-02, -9.5062e-03,  5.6934e-02,  2.9798e-02, -5.6704e-02,\n",
       "                      -2.8998e-04,  3.8911e-02,  7.1862e-02,  2.8319e-02, -1.3835e-03,\n",
       "                       2.4380e-02,  4.7917e-02, -7.5812e-03,  4.3195e-02, -8.7772e-03,\n",
       "                       3.0336e-02, -2.1767e-02, -2.0313e-02, -5.7155e-02,  2.2238e-02,\n",
       "                      -1.7876e-02,  7.2475e-03,  5.9072e-02,  1.7254e-02,  3.5640e-02,\n",
       "                      -5.3690e-02,  3.1887e-02, -6.1408e-02,  1.1748e-02, -2.8399e-02,\n",
       "                       3.6311e-02,  3.8973e-02,  6.4906e-02,  7.8385e-03, -2.0935e-02,\n",
       "                      -5.8416e-02, -2.0047e-02, -3.1496e-02,  2.9189e-02, -3.4504e-02,\n",
       "                      -2.7514e-02,  6.8505e-02,  2.8062e-03,  1.8849e-05, -1.3774e-02,\n",
       "                       9.2343e-03,  3.7521e-02,  4.5121e-02,  1.4074e-02, -1.8121e-04,\n",
       "                      -4.0558e-02, -3.7644e-03,  1.6923e-02,  2.7104e-02, -1.5634e-02,\n",
       "                      -4.1377e-03,  9.3574e-03,  1.9628e-02,  5.6155e-02,  5.2343e-02,\n",
       "                       8.2967e-03, -3.7830e-03, -4.8709e-03, -8.8138e-03,  5.4959e-02,\n",
       "                       9.5033e-02, -8.7470e-03, -2.1711e-03, -2.7213e-02,  2.7870e-02,\n",
       "                      -6.4279e-02, -1.5909e-02, -4.3667e-02, -1.5132e-02, -9.5939e-03,\n",
       "                      -1.8963e-02, -6.7713e-03, -5.5545e-02, -1.0497e-02, -3.9040e-02,\n",
       "                      -4.8672e-03,  1.1762e-02, -1.5282e-02, -4.3349e-02, -5.3518e-02,\n",
       "                       4.6776e-03, -4.4651e-02, -4.5448e-02, -1.2307e-02,  1.7775e-02,\n",
       "                      -4.1911e-03,  2.1014e-02, -4.3004e-03,  2.7901e-02,  1.0977e-02,\n",
       "                      -7.3112e-03, -3.7840e-02, -1.7166e-03,  1.3762e-02, -2.5244e-02,\n",
       "                       1.1566e-02,  7.3994e-02, -4.3874e-03,  4.3512e-02, -4.0878e-02,\n",
       "                       1.8922e-03, -1.0121e-02, -2.9110e-02,  2.4583e-02, -4.8153e-02,\n",
       "                       2.5973e-02, -2.9922e-03, -2.0870e-02, -2.2877e-02, -1.4993e-03,\n",
       "                      -5.9943e-03, -7.2241e-03, -2.0146e-02,  1.2459e-02, -3.8290e-03,\n",
       "                      -2.0011e-02,  3.9809e-02,  1.3255e-02, -4.2352e-04,  1.7046e-02,\n",
       "                      -6.5159e-03,  1.2209e-02,  6.6373e-02, -1.1389e-02,  5.5789e-02,\n",
       "                       1.8531e-02, -1.1453e-02,  2.1218e-02,  1.8626e-02,  1.3585e-02,\n",
       "                      -3.0026e-02,  1.2386e-02, -9.9208e-03, -2.6795e-04, -8.1980e-03,\n",
       "                      -1.3025e-02, -1.7465e-02,  3.8352e-04, -2.6250e-02, -3.8193e-02,\n",
       "                       1.8636e-02, -7.6045e-03, -3.9300e-02,  1.3399e-03,  1.3233e-02,\n",
       "                       1.9639e-02, -1.1317e-02, -1.9422e-02, -3.2577e-02,  5.8234e-02],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.4.edge_encoder.1.running_var',\n",
       "              tensor([0.0007, 0.0011, 0.0017, 0.0010, 0.0004, 0.0005, 0.0011, 0.0008, 0.0008,\n",
       "                      0.0006, 0.0011, 0.0012, 0.0004, 0.0011, 0.0017, 0.0008, 0.0009, 0.0008,\n",
       "                      0.0008, 0.0017, 0.0010, 0.0005, 0.0005, 0.0005, 0.0007, 0.0009, 0.0004,\n",
       "                      0.0016, 0.0005, 0.0014, 0.0013, 0.0005, 0.0005, 0.0010, 0.0009, 0.0005,\n",
       "                      0.0009, 0.0014, 0.0012, 0.0007, 0.0004, 0.0008, 0.0005, 0.0008, 0.0010,\n",
       "                      0.0010, 0.0010, 0.0012, 0.0016, 0.0011, 0.0004, 0.0004, 0.0009, 0.0014,\n",
       "                      0.0009, 0.0013, 0.0004, 0.0005, 0.0009, 0.0005, 0.0003, 0.0009, 0.0005,\n",
       "                      0.0007, 0.0009, 0.0004, 0.0008, 0.0009, 0.0006, 0.0004, 0.0013, 0.0007,\n",
       "                      0.0007, 0.0006, 0.0007, 0.0004, 0.0007, 0.0007, 0.0007, 0.0003, 0.0020,\n",
       "                      0.0011, 0.0006, 0.0004, 0.0010, 0.0019, 0.0012, 0.0007, 0.0005, 0.0004,\n",
       "                      0.0005, 0.0009, 0.0012, 0.0007, 0.0007, 0.0014, 0.0015, 0.0009, 0.0009,\n",
       "                      0.0006, 0.0004, 0.0006, 0.0008, 0.0008, 0.0012, 0.0005, 0.0013, 0.0009,\n",
       "                      0.0006, 0.0015, 0.0007, 0.0006, 0.0007, 0.0010, 0.0010, 0.0010, 0.0005,\n",
       "                      0.0006, 0.0006, 0.0005, 0.0003, 0.0008, 0.0007, 0.0010, 0.0008, 0.0009,\n",
       "                      0.0008, 0.0012, 0.0011, 0.0014, 0.0014, 0.0012, 0.0019, 0.0012, 0.0016,\n",
       "                      0.0008, 0.0008, 0.0006, 0.0006, 0.0012, 0.0004, 0.0006, 0.0020, 0.0009,\n",
       "                      0.0004, 0.0004, 0.0010, 0.0010, 0.0006, 0.0004, 0.0008, 0.0006, 0.0010,\n",
       "                      0.0016, 0.0006, 0.0004, 0.0010, 0.0015, 0.0007, 0.0009, 0.0008, 0.0008,\n",
       "                      0.0005, 0.0006, 0.0010, 0.0003, 0.0010, 0.0007, 0.0005, 0.0007, 0.0007,\n",
       "                      0.0008, 0.0009, 0.0022, 0.0009, 0.0007, 0.0006, 0.0006, 0.0006, 0.0014,\n",
       "                      0.0004, 0.0004, 0.0003, 0.0004, 0.0008, 0.0010, 0.0010, 0.0010, 0.0016,\n",
       "                      0.0016, 0.0008, 0.0008, 0.0017, 0.0004, 0.0013, 0.0004, 0.0015, 0.0007,\n",
       "                      0.0011, 0.0009], device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.4.edge_encoder.1.num_batches_tracked',\n",
       "              tensor(318750, device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.4.edge_encoder.3.weight',\n",
       "              tensor([[-0.0193, -0.0094, -0.0241,  ...,  0.0122, -0.0301, -0.0028],\n",
       "                      [ 0.0069,  0.0188,  0.0111,  ..., -0.0008, -0.0141,  0.0301],\n",
       "                      [ 0.0371, -0.0236, -0.0005,  ..., -0.0178,  0.0145,  0.0044],\n",
       "                      ...,\n",
       "                      [ 0.0266,  0.0113,  0.0204,  ..., -0.0058,  0.0168, -0.0279],\n",
       "                      [ 0.0263, -0.0120,  0.0145,  ..., -0.0088,  0.0285, -0.0355],\n",
       "                      [ 0.0217,  0.0041,  0.0519,  ...,  0.0308, -0.0709, -0.0156]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.4.edge_encoder.3.bias',\n",
       "              tensor([-2.3653e-03, -5.7033e-03,  2.7150e-03,  1.7915e-03, -1.3082e-03,\n",
       "                      -3.1844e-04,  8.8534e-04, -5.2766e-03,  1.3499e-03,  4.7690e-03,\n",
       "                      -4.6336e-03,  1.4850e-03, -3.2236e-03,  3.7453e-03, -8.5289e-03,\n",
       "                       7.5043e-03,  5.8532e-03,  2.3962e-04, -5.7625e-04,  5.2903e-04,\n",
       "                      -1.7449e-03,  5.2435e-03,  2.9055e-03, -4.1971e-03, -5.6767e-03,\n",
       "                      -4.0691e-03, -1.4285e-03,  5.0252e-03, -1.9099e-03,  1.1951e-03,\n",
       "                       2.1446e-03, -2.3171e-03,  5.1971e-03,  1.3342e-03, -6.3974e-03,\n",
       "                       7.7394e-04, -5.0417e-03, -4.6538e-04,  8.4626e-03, -4.4000e-04,\n",
       "                      -7.0619e-04,  4.7418e-03, -5.4846e-03, -5.1588e-03, -7.3695e-03,\n",
       "                      -9.4579e-03,  4.9077e-03, -5.9823e-03,  1.0702e-03, -2.1661e-03,\n",
       "                       1.0390e-03,  1.1983e-03, -4.2399e-03, -1.2942e-03, -7.8520e-03,\n",
       "                      -3.5293e-03, -1.0280e-02,  3.5102e-04,  3.8343e-03, -1.2780e-03,\n",
       "                       4.5618e-04,  3.8666e-03,  1.8226e-03,  4.2149e-03, -7.9116e-03,\n",
       "                      -6.3569e-03,  7.4834e-04,  4.8660e-04, -3.4787e-03, -3.4874e-03,\n",
       "                      -2.9350e-03,  6.0196e-03,  2.0707e-03,  6.1710e-03, -2.5195e-04,\n",
       "                       2.7551e-03, -3.0170e-03, -3.2106e-03, -5.5723e-05,  5.0233e-03,\n",
       "                      -5.5378e-03, -8.5195e-03,  2.5666e-03, -1.8356e-03,  1.2716e-03,\n",
       "                      -1.2945e-03,  1.9425e-03,  8.8292e-04,  2.0636e-03,  1.4934e-03,\n",
       "                      -1.9848e-03,  9.8496e-03, -2.1664e-03,  1.9293e-03, -3.8735e-03,\n",
       "                      -5.7664e-03,  3.7731e-03, -2.0194e-03,  5.2783e-03,  3.5625e-03,\n",
       "                      -4.3390e-03, -4.5637e-03,  6.6010e-03,  3.1173e-03,  4.0452e-03,\n",
       "                      -2.6583e-03,  4.5262e-03, -1.5825e-03, -4.2482e-03, -3.4520e-03,\n",
       "                       2.3763e-03,  3.6228e-03,  1.7307e-03,  1.0506e-03,  4.2683e-03,\n",
       "                      -3.5708e-04, -2.0222e-03, -1.5319e-03,  4.2033e-03, -6.7279e-03,\n",
       "                       1.4046e-03,  2.9070e-03,  3.6665e-03,  1.5358e-03,  2.2912e-03,\n",
       "                       1.5417e-03, -5.5028e-03,  1.9160e-03, -3.6478e-03, -3.0722e-03,\n",
       "                      -6.0849e-04,  4.6370e-03,  1.5033e-03,  7.6505e-03,  1.1843e-03,\n",
       "                      -2.6880e-03, -7.3885e-04, -1.9909e-03, -4.8474e-03,  7.0672e-03,\n",
       "                       7.6360e-03, -5.4759e-03, -6.0674e-03, -1.4287e-03,  1.6351e-03,\n",
       "                       4.7338e-03, -4.7588e-03, -5.5839e-03,  1.8682e-03, -1.0032e-03,\n",
       "                      -1.1349e-04,  6.5163e-03,  7.6160e-04,  6.0492e-03,  2.1817e-03,\n",
       "                       5.5140e-04, -5.6854e-03,  2.1677e-04,  1.8623e-03,  1.7347e-03,\n",
       "                      -3.2468e-03,  2.5972e-03, -1.4406e-03, -4.4453e-03, -6.4311e-03,\n",
       "                      -3.7272e-03,  2.8988e-03, -3.4194e-03,  8.8222e-04,  3.5037e-03,\n",
       "                       4.3227e-04, -1.8212e-03,  1.9136e-03, -3.1052e-03, -5.8780e-03,\n",
       "                      -9.3809e-04,  2.1546e-03, -5.0847e-03, -5.3777e-03, -3.2735e-03,\n",
       "                       1.7199e-04, -1.1658e-03,  3.6198e-03,  4.1820e-03,  1.1943e-04,\n",
       "                      -1.7642e-03,  4.1916e-03,  8.8105e-04, -6.2575e-03,  6.1010e-03,\n",
       "                      -4.3334e-04,  1.6691e-03,  8.9472e-06,  5.3347e-03,  4.1516e-03,\n",
       "                       4.4639e-03,  4.7324e-03, -6.6560e-04, -5.5783e-03,  1.1676e-03],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.4.linear_key.weight',\n",
       "              tensor([[-0.0174, -0.0075, -0.0178,  ...,  0.0331,  0.0086,  0.0188],\n",
       "                      [-0.0261,  0.0199,  0.0184,  ...,  0.0088,  0.0205,  0.0070],\n",
       "                      [-0.0167, -0.0150, -0.0182,  ..., -0.0140, -0.0180,  0.0003],\n",
       "                      ...,\n",
       "                      [-0.0484,  0.0122,  0.0207,  ..., -0.0159,  0.0132, -0.0069],\n",
       "                      [ 0.0055,  0.0027,  0.0291,  ..., -0.0143,  0.0007, -0.0397],\n",
       "                      [ 0.0263, -0.0147,  0.0306,  ...,  0.0006, -0.0084,  0.0151]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.4.linear_key.bias',\n",
       "              tensor([-2.0361e-02, -1.3585e-02,  1.6256e-02, -1.9488e-02,  1.8675e-02,\n",
       "                       9.7456e-03, -2.1691e-03, -2.1546e-03, -1.7278e-02,  6.7567e-03,\n",
       "                      -2.3131e-03, -2.4437e-02, -3.5201e-02, -1.9527e-02,  1.7901e-02,\n",
       "                      -2.1086e-02,  1.8843e-02, -2.8507e-02,  3.1116e-02, -1.4423e-02,\n",
       "                      -4.4986e-02, -9.9926e-03, -1.0158e-02,  1.6467e-02,  1.8762e-02,\n",
       "                      -5.3391e-03, -1.4838e-02,  1.2698e-02, -2.9353e-02, -1.7169e-02,\n",
       "                       1.0275e-02,  3.0359e-02,  9.6568e-03, -3.1193e-02, -7.0709e-04,\n",
       "                      -2.0554e-02, -1.4149e-02, -1.8807e-02,  2.8204e-02,  8.2927e-03,\n",
       "                      -1.0176e-02, -3.4930e-03,  2.7666e-02,  7.9554e-03, -1.1180e-02,\n",
       "                      -1.0738e-02,  1.0681e-02, -1.1160e-02,  1.7261e-02,  3.0824e-03,\n",
       "                      -1.3169e-02, -2.4229e-03,  1.2116e-02, -2.4050e-03,  4.8218e-04,\n",
       "                       2.8070e-02,  3.0176e-03, -7.6056e-03,  2.1462e-03,  2.4011e-02,\n",
       "                      -8.7551e-03,  1.1112e-03,  8.2797e-03,  3.2275e-03, -8.5847e-03,\n",
       "                       2.7811e-02,  1.4373e-02, -3.9583e-03, -1.7444e-02,  5.3861e-03,\n",
       "                       1.0021e-03, -6.5996e-04,  9.4627e-03,  1.6703e-02, -9.3798e-03,\n",
       "                       1.3695e-02,  6.3828e-03,  6.1141e-03, -1.1883e-02, -2.4466e-02,\n",
       "                      -1.5600e-02, -8.4963e-05,  1.1245e-02, -9.5523e-03,  1.0915e-02,\n",
       "                       1.9887e-03,  1.1448e-03,  5.9110e-03,  1.2738e-02, -7.8768e-03,\n",
       "                       1.7390e-03, -1.0120e-02, -1.7310e-02,  6.8927e-03, -2.7884e-03,\n",
       "                      -1.2022e-04,  9.6144e-03, -1.1217e-03, -5.1758e-04,  7.8154e-03,\n",
       "                      -2.6472e-02,  1.0558e-02, -2.0036e-02,  8.2444e-03, -2.1908e-02,\n",
       "                      -1.0068e-02,  3.9347e-03, -1.2443e-02, -1.4185e-02, -1.5558e-02,\n",
       "                      -2.7794e-03, -7.3212e-04,  2.5161e-02,  1.1396e-02,  1.8585e-02,\n",
       "                       3.1850e-02,  3.5856e-03,  7.1022e-03, -1.3033e-02, -6.4599e-03,\n",
       "                      -5.1281e-04,  1.8632e-03, -1.3350e-02,  9.8378e-03,  1.3703e-02,\n",
       "                       2.4600e-02, -1.2608e-02, -9.4540e-03,  1.0820e-02,  6.8718e-03,\n",
       "                       2.7586e-02, -1.6604e-02, -1.0196e-02, -5.2672e-03,  3.9570e-04,\n",
       "                       4.7798e-03,  7.3857e-03,  1.2877e-02, -1.9195e-02, -2.7407e-02,\n",
       "                      -1.3817e-02,  6.8572e-03,  9.1689e-04,  1.2197e-02, -2.1288e-02,\n",
       "                      -5.9910e-03,  7.2908e-03, -7.3262e-03,  2.3270e-02,  6.1475e-03,\n",
       "                       3.1430e-03, -1.5719e-03, -8.6737e-03,  2.8269e-03,  5.8124e-03,\n",
       "                      -1.1925e-03,  6.0953e-03, -9.4999e-03, -2.5553e-03, -7.3679e-03,\n",
       "                      -1.8339e-02,  7.6487e-03, -2.9845e-03, -2.4019e-02,  4.9802e-03,\n",
       "                       3.6179e-03,  1.1267e-02,  1.0451e-04,  5.4782e-03, -4.0756e-02,\n",
       "                       1.1025e-02,  2.0049e-02,  1.1878e-02, -9.1809e-03, -1.9087e-02,\n",
       "                      -2.2857e-02,  1.8188e-03, -5.3641e-03, -2.9514e-02, -2.0174e-02,\n",
       "                      -1.7496e-02, -2.9632e-03,  4.9012e-03,  1.1587e-02, -1.3219e-02,\n",
       "                       1.0501e-02,  1.2119e-02,  1.4126e-02, -5.3790e-03, -1.8683e-03,\n",
       "                       1.8508e-03, -2.2378e-02, -3.9305e-02, -7.8273e-03,  1.7121e-02,\n",
       "                      -3.2266e-03, -1.1195e-02, -1.5430e-02, -1.0927e-02,  1.5571e-02],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.4.linear_msg.weight',\n",
       "              tensor([[-0.0041,  0.0235,  0.0409,  ..., -0.0254, -0.0332, -0.0167],\n",
       "                      [ 0.0129,  0.0383, -0.0074,  ...,  0.0034, -0.0177, -0.0132],\n",
       "                      [-0.0087,  0.0068, -0.0015,  ...,  0.0168,  0.0425, -0.0039],\n",
       "                      ...,\n",
       "                      [-0.0378,  0.0039, -0.0179,  ...,  0.0036, -0.0505,  0.0058],\n",
       "                      [ 0.0091,  0.0134,  0.0077,  ..., -0.0127,  0.0168, -0.0122],\n",
       "                      [ 0.0011, -0.0541, -0.0143,  ...,  0.0086,  0.0173,  0.0168]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.4.linear_msg.bias',\n",
       "              tensor([ 1.2442e-02,  4.8924e-03, -6.7801e-03, -2.8757e-02, -1.0203e-02,\n",
       "                       4.1644e-03, -1.0881e-02,  9.8595e-03,  1.2610e-02, -1.1174e-02,\n",
       "                      -2.6269e-03,  2.1854e-03,  5.8973e-03,  1.5072e-03, -1.6198e-02,\n",
       "                       5.4929e-03,  1.3514e-02, -5.4019e-03,  8.4693e-03, -5.9947e-03,\n",
       "                      -1.3583e-02, -1.0126e-02, -1.4251e-02,  4.9310e-03, -2.2384e-03,\n",
       "                      -2.0614e-04,  6.5417e-03, -3.1551e-03, -9.5498e-03, -1.0863e-02,\n",
       "                       6.6747e-03, -1.9492e-02, -1.5803e-02, -4.9199e-03, -1.3338e-02,\n",
       "                      -1.7072e-02,  1.5511e-03,  1.4419e-02, -5.2024e-03,  1.4456e-02,\n",
       "                       8.7422e-03,  2.2308e-02, -3.6750e-04,  5.9243e-03,  1.0451e-02,\n",
       "                       9.7118e-03, -1.3962e-02,  5.0843e-03,  5.7733e-03,  1.2407e-02,\n",
       "                       1.6830e-03, -7.5544e-03, -1.6936e-02,  4.6087e-03, -1.4313e-02,\n",
       "                      -1.6295e-03,  1.2602e-02,  3.0640e-03, -6.6388e-03,  5.0650e-03,\n",
       "                      -3.8087e-03,  5.7915e-03, -2.5066e-03,  9.4404e-03,  4.3008e-03,\n",
       "                       7.9756e-03,  9.1158e-03,  3.4974e-03,  9.3498e-03,  1.1780e-02,\n",
       "                      -1.7039e-03, -2.8936e-03,  8.5089e-03,  3.2079e-03, -9.6781e-03,\n",
       "                      -2.6276e-03,  3.2281e-03,  7.7788e-03, -1.3112e-02,  3.4701e-04,\n",
       "                       1.5125e-03,  5.2154e-03, -1.1769e-02,  1.4585e-03, -2.5928e-04,\n",
       "                      -8.5234e-03, -7.7187e-03, -1.6995e-03, -2.0239e-03,  2.6604e-03,\n",
       "                      -4.5600e-03, -8.2359e-03, -1.2275e-02,  9.0281e-03, -2.6951e-03,\n",
       "                       6.0572e-03,  1.5126e-03,  4.7947e-03,  5.3855e-03,  1.0448e-03,\n",
       "                       6.6057e-03,  2.1415e-03, -7.6484e-03, -1.4576e-02, -1.0022e-02,\n",
       "                      -5.5040e-03, -1.2196e-02,  3.2215e-03,  3.7692e-03,  2.4948e-03,\n",
       "                      -1.0413e-02, -1.4503e-02,  3.8385e-03, -7.4219e-03, -1.0020e-02,\n",
       "                      -1.3047e-02, -1.0260e-02, -6.5911e-03, -8.6348e-03,  1.4301e-02,\n",
       "                      -5.8031e-03,  5.6790e-03,  7.0032e-03, -1.1155e-02,  4.9011e-03,\n",
       "                       7.0283e-03,  7.7470e-03,  3.9127e-03,  1.0379e-02,  1.8425e-02,\n",
       "                       2.4067e-03, -2.6343e-03, -9.7246e-03,  1.1727e-02,  1.0557e-02,\n",
       "                      -1.2934e-02,  1.6646e-02, -4.7960e-03, -1.3211e-02,  1.0016e-02,\n",
       "                       1.6051e-03,  3.9610e-05, -2.0523e-02, -1.2591e-02, -8.2880e-03,\n",
       "                      -1.1374e-02, -1.1965e-03,  1.2223e-02,  1.0554e-02,  9.2184e-03,\n",
       "                      -1.1696e-02,  1.5214e-02, -9.2984e-03,  4.2283e-03, -1.3728e-02,\n",
       "                       1.4412e-02,  3.4406e-03, -1.2315e-02,  9.0081e-03,  9.5337e-03,\n",
       "                      -8.2127e-03,  7.4159e-03,  4.9165e-03, -8.3669e-03,  9.4977e-03,\n",
       "                       2.7518e-03, -1.5290e-02, -1.8555e-03, -8.0448e-03,  1.0223e-02,\n",
       "                      -1.7026e-02,  1.6674e-02, -7.7872e-03,  6.2059e-03, -1.2881e-02,\n",
       "                       6.6564e-03, -2.8725e-03,  7.3827e-04, -1.8740e-03, -1.2649e-02,\n",
       "                       3.6008e-03, -4.1453e-03,  5.4938e-03, -1.4690e-02,  1.2408e-02,\n",
       "                       5.5852e-05, -3.4460e-03,  1.5828e-02,  1.1501e-02, -8.7758e-03,\n",
       "                      -5.6332e-03, -2.1626e-03, -1.4659e-02, -2.8180e-04, -1.2896e-02,\n",
       "                      -9.6095e-04, -2.7637e-02,  8.1085e-03,  1.4464e-02, -6.3184e-03],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.4.linear_query.weight',\n",
       "              tensor([[-0.0046, -0.0097,  0.0040,  ...,  0.0188,  0.0484, -0.0526],\n",
       "                      [-0.0360, -0.0169,  0.0037,  ...,  0.0326, -0.0742,  0.0037],\n",
       "                      [ 0.0070, -0.0385,  0.0151,  ...,  0.0042,  0.0177,  0.0019],\n",
       "                      ...,\n",
       "                      [-0.0364, -0.0103, -0.0292,  ..., -0.0248, -0.0434, -0.0132],\n",
       "                      [-0.0111,  0.0103,  0.0170,  ..., -0.0106, -0.0581,  0.0430],\n",
       "                      [ 0.0042, -0.0129, -0.0043,  ..., -0.0099,  0.0152, -0.0169]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.4.linear_query.bias',\n",
       "              tensor([ 0.0074,  0.0010,  0.0765,  0.0100,  0.0526, -0.0535, -0.0513,  0.0762,\n",
       "                       0.0834,  0.0339,  0.0918,  0.0072,  0.0204,  0.0784,  0.0124, -0.0718,\n",
       "                      -0.0159, -0.0679, -0.0117, -0.0502,  0.0010,  0.0165,  0.0038, -0.0516,\n",
       "                      -0.0342, -0.0643,  0.0063, -0.0142, -0.0203,  0.0132, -0.0984,  0.0427,\n",
       "                       0.0051, -0.0405,  0.0460,  0.0083, -0.0198, -0.0063,  0.0062,  0.0171,\n",
       "                      -0.0055, -0.0190,  0.0157, -0.0001, -0.0126, -0.0609,  0.0243,  0.0203,\n",
       "                      -0.0311,  0.0468,  0.0333, -0.0130, -0.0205,  0.0114,  0.0210, -0.0251,\n",
       "                       0.0131, -0.0092,  0.0164, -0.0172,  0.0087, -0.0247, -0.0353, -0.0099,\n",
       "                      -0.0042, -0.0204,  0.0180,  0.0147,  0.0112, -0.0054, -0.0130,  0.0311,\n",
       "                      -0.0165, -0.0261, -0.0126, -0.0314,  0.0114, -0.0124,  0.0125, -0.0015,\n",
       "                       0.0345,  0.0039, -0.0125, -0.0191, -0.0109,  0.0054, -0.0012,  0.0142,\n",
       "                       0.0030,  0.0152,  0.0140,  0.0008,  0.0026, -0.0170,  0.0281, -0.0074,\n",
       "                       0.0267,  0.0201,  0.0096, -0.0160,  0.0375,  0.0261, -0.0112, -0.0456,\n",
       "                       0.0171, -0.0098, -0.0305, -0.0225,  0.0026, -0.0222, -0.0124,  0.0150,\n",
       "                      -0.0157,  0.0196,  0.0021,  0.0080, -0.0308, -0.0393,  0.0018,  0.0240,\n",
       "                      -0.0058, -0.0176,  0.0447,  0.0302,  0.0346,  0.0112, -0.0404,  0.0059,\n",
       "                      -0.0287, -0.0056,  0.0261,  0.0543, -0.0152, -0.0160,  0.0296,  0.0347,\n",
       "                       0.0167,  0.0339,  0.0412,  0.0344,  0.0316, -0.0309,  0.0696, -0.0322,\n",
       "                       0.0325, -0.0271, -0.0243, -0.0130, -0.0119,  0.0198,  0.0276, -0.0144,\n",
       "                       0.0286,  0.0036, -0.0108, -0.0189, -0.0044, -0.0044, -0.0128, -0.0121,\n",
       "                       0.0258,  0.0195, -0.0122,  0.0236,  0.0429, -0.0405,  0.0393,  0.0062,\n",
       "                      -0.0152,  0.0080,  0.0262,  0.0190, -0.0450, -0.0290,  0.0048, -0.0201,\n",
       "                       0.0107, -0.0135,  0.0355, -0.0357,  0.0425, -0.0210, -0.0307, -0.0401,\n",
       "                       0.0274,  0.0224,  0.0358,  0.0152,  0.0239,  0.0151,  0.0030, -0.0057,\n",
       "                       0.0288, -0.0051,  0.0076,  0.0328,  0.0034, -0.0147,  0.0136, -0.0136],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.4.mlp.0.weight',\n",
       "              tensor([[-0.0244,  0.0305, -0.0129,  ...,  0.0408, -0.0125, -0.0051],\n",
       "                      [ 0.0227, -0.0006, -0.0284,  ..., -0.0175,  0.0043,  0.0367],\n",
       "                      [ 0.0150,  0.0075,  0.0265,  ...,  0.0045,  0.0048,  0.0049],\n",
       "                      ...,\n",
       "                      [-0.0354, -0.0473,  0.0028,  ..., -0.0065, -0.0305, -0.0211],\n",
       "                      [-0.0204,  0.0090,  0.0053,  ...,  0.0068, -0.0061, -0.0120],\n",
       "                      [-0.0300, -0.0406,  0.0169,  ..., -0.0193,  0.0028, -0.0157]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.4.mlp.0.bias',\n",
       "              tensor([ 1.7723e-03, -8.0581e-03, -8.4324e-03,  3.8911e-03, -7.6187e-03,\n",
       "                      -1.1040e-03, -3.0838e-02, -1.8247e-02,  9.5199e-03, -2.4542e-02,\n",
       "                      -5.3477e-03, -6.5162e-04, -1.6652e-02,  2.0782e-02, -8.8935e-03,\n",
       "                       8.3297e-03, -7.8489e-03,  1.1371e-02, -2.9585e-03,  2.1292e-02,\n",
       "                       1.2796e-02,  1.1311e-02,  4.5516e-03,  8.9223e-03,  2.2118e-03,\n",
       "                      -1.8560e-02,  6.7927e-03,  1.3853e-02,  5.3808e-03,  1.5878e-02,\n",
       "                       1.5200e-02, -1.3353e-03, -9.4384e-03, -9.9985e-03, -1.0995e-02,\n",
       "                       9.2708e-05, -6.8756e-03, -2.4241e-02,  3.3530e-04,  6.8398e-03,\n",
       "                       1.9197e-02,  1.6381e-03,  7.7485e-03, -9.2184e-03,  9.4985e-03,\n",
       "                      -1.0998e-02, -1.0769e-02,  1.2858e-02, -6.2528e-03,  1.7754e-03,\n",
       "                       8.9856e-03,  5.2955e-03, -2.4900e-03,  2.6524e-02, -1.6341e-02,\n",
       "                      -9.1020e-03,  1.2982e-03,  6.5825e-03, -6.5489e-03,  4.1733e-03,\n",
       "                       1.3398e-02, -1.2815e-02,  1.6642e-02, -1.1174e-03, -1.5330e-03,\n",
       "                      -1.3162e-02,  2.3943e-03,  1.6264e-02,  7.1581e-03,  1.0813e-03,\n",
       "                      -1.0454e-02, -1.3002e-02,  1.7860e-02,  3.5738e-03, -1.0436e-02,\n",
       "                      -7.9428e-03, -3.2996e-03,  7.3987e-03, -5.1484e-03, -3.7118e-03,\n",
       "                      -3.5453e-03, -9.7824e-03, -1.3506e-02,  7.7681e-04, -1.0009e-02,\n",
       "                       8.5434e-03,  2.1498e-02, -8.0956e-03,  3.3482e-03,  2.4708e-03,\n",
       "                      -1.1433e-02,  1.0781e-04,  1.1791e-02, -1.3782e-03,  2.3815e-02,\n",
       "                       1.1653e-02, -9.2652e-03, -6.1863e-03, -1.7914e-03, -4.0729e-03,\n",
       "                       1.1394e-02, -6.9447e-03, -7.4795e-03, -9.6668e-03, -1.5188e-02,\n",
       "                      -1.2623e-02, -1.6171e-02,  8.2952e-03,  5.3782e-05,  5.9452e-03,\n",
       "                       2.7058e-03, -2.0280e-02, -7.3605e-03, -4.0344e-03,  3.4852e-03,\n",
       "                       1.9317e-02,  7.5723e-03,  5.0640e-03, -6.5346e-03,  1.2736e-02,\n",
       "                       6.7081e-03, -1.8434e-03, -6.8924e-03,  5.2425e-03,  5.4509e-03,\n",
       "                      -1.1523e-02, -5.4539e-03, -1.5934e-03,  3.5740e-03, -3.7478e-03,\n",
       "                      -6.3377e-03,  4.4551e-03,  2.2175e-03, -2.7778e-03, -3.1217e-03,\n",
       "                      -1.4234e-02,  1.5164e-02,  1.4276e-02,  2.6822e-03,  4.0435e-03,\n",
       "                      -7.4622e-03,  1.8131e-02, -1.2433e-02,  2.8663e-05, -9.6471e-03,\n",
       "                       1.0495e-02, -4.6454e-03, -1.0160e-02,  6.8711e-05, -6.3252e-03,\n",
       "                       1.1808e-02, -8.2546e-03,  2.1070e-02,  1.1196e-02,  7.8041e-03,\n",
       "                      -8.2639e-03, -8.6976e-03, -1.4557e-02,  9.5425e-03,  8.7781e-04,\n",
       "                      -5.4977e-03,  2.3918e-02, -7.6626e-03,  1.9184e-03, -1.5916e-02,\n",
       "                      -4.4888e-03,  2.0113e-03, -7.3335e-04, -8.6441e-04,  4.8871e-04,\n",
       "                      -7.7835e-03, -6.7740e-03, -7.6888e-03,  1.9638e-04, -2.2392e-02,\n",
       "                       1.4653e-02,  1.7290e-02,  1.0615e-02,  1.0641e-03,  1.3589e-02,\n",
       "                      -5.9152e-03, -2.4870e-03, -6.7936e-03,  2.5456e-04, -1.0163e-02,\n",
       "                       1.1128e-03, -1.6892e-02, -9.1984e-04,  1.5823e-02,  1.8909e-02,\n",
       "                       9.5387e-04,  2.1333e-03,  2.8511e-03,  2.8004e-03, -1.4528e-02,\n",
       "                      -1.7816e-02,  1.4489e-02,  7.7663e-03, -6.4066e-03, -1.2064e-02],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.4.mlp.1.weight',\n",
       "              tensor([0.9748, 1.0059, 0.9868, 0.9906, 1.0220, 0.9865, 0.9977, 0.9904, 0.9951,\n",
       "                      0.9989, 0.9815, 0.9899, 0.9821, 1.0025, 0.9967, 0.9892, 0.9921, 0.9737,\n",
       "                      0.9932, 0.9863, 0.9938, 0.9605, 0.9825, 1.0054, 0.9919, 0.9912, 1.0175,\n",
       "                      0.9658, 0.9979, 0.9857, 1.0050, 0.9859, 0.9880, 0.9776, 0.9995, 0.9847,\n",
       "                      0.9933, 0.9722, 0.9919, 0.9894, 0.9853, 0.9902, 0.9990, 0.9739, 0.9856,\n",
       "                      0.9982, 1.0022, 0.9980, 0.9996, 0.9925, 1.0035, 0.9864, 0.9997, 0.9899,\n",
       "                      0.9829, 0.9933, 0.9950, 0.9923, 0.9891, 0.9802, 0.9970, 0.9661, 0.9693,\n",
       "                      0.9751, 0.9950, 0.9892, 0.9815, 0.9809, 0.9953, 0.9863, 0.9792, 1.0047,\n",
       "                      1.0000, 0.9865, 0.9827, 0.9957, 0.9778, 0.9775, 0.9834, 0.9848, 1.0061,\n",
       "                      0.9824, 0.9954, 1.0073, 0.9932, 0.9702, 1.0210, 0.9820, 0.9926, 0.9905,\n",
       "                      0.9882, 0.9803, 0.9988, 0.9932, 0.9870, 1.0031, 0.9984, 1.0116, 1.0000,\n",
       "                      0.9864, 0.9659, 0.9827, 1.0054, 0.9861, 0.9823, 0.9919, 0.9873, 0.9983,\n",
       "                      0.9770, 0.9899, 0.9937, 0.9836, 1.0190, 0.9868, 1.0198, 1.0087, 0.9903,\n",
       "                      0.9900, 0.9917, 1.0179, 0.9911, 0.9943, 0.9808, 0.9900, 0.9978, 0.9840,\n",
       "                      0.9956, 0.9840, 0.9908, 0.9708, 1.0012, 0.9822, 1.0043, 0.9780, 0.9841,\n",
       "                      0.9727, 0.9846, 0.9860, 1.0030, 0.9860, 0.9914, 0.9861, 0.9880, 0.9881,\n",
       "                      0.9950, 0.9886, 0.9887, 0.9888, 0.9898, 0.9962, 1.0099, 1.0018, 0.9766,\n",
       "                      0.9870, 0.9788, 0.9805, 0.9786, 0.9920, 0.9867, 1.0068, 0.9903, 0.9757,\n",
       "                      0.9904, 1.0103, 0.9543, 1.0227, 0.9894, 0.9690, 0.9936, 0.9908, 0.9723,\n",
       "                      1.0150, 0.9728, 0.9832, 0.9876, 0.9943, 0.9778, 0.9939, 0.9977, 0.9842,\n",
       "                      0.9629, 1.0038, 0.9895, 0.9897, 0.9900, 0.9795, 0.9780, 0.9882, 1.0098,\n",
       "                      0.9751, 1.0073, 1.0116, 1.0021, 0.9931, 0.9779, 0.9905, 1.0282, 0.9880,\n",
       "                      0.9905, 0.9769], device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.4.mlp.1.bias',\n",
       "              tensor([ 9.1144e-03,  2.3036e-02,  2.5051e-02,  1.7860e-02,  4.6584e-02,\n",
       "                       1.0837e-02,  2.9614e-02,  6.1200e-02,  2.0035e-02,  4.1005e-02,\n",
       "                       4.4914e-02,  4.4072e-02, -4.3799e-05,  5.1718e-02,  7.7372e-03,\n",
       "                       5.0975e-02,  3.4104e-02, -5.8003e-03,  1.0667e-03,  6.8821e-03,\n",
       "                       3.2256e-02, -1.3321e-02, -6.7061e-03,  4.4515e-02, -4.9935e-03,\n",
       "                       3.9886e-02,  4.4992e-02,  2.4499e-02,  3.3165e-02,  3.7948e-02,\n",
       "                       3.7886e-02,  8.6660e-03,  3.5780e-02,  3.7567e-02,  2.6683e-02,\n",
       "                       1.0698e-02,  1.2588e-02,  2.1237e-02,  4.6880e-02,  4.9736e-02,\n",
       "                       2.9394e-02,  6.5428e-02,  2.4822e-02,  1.6440e-02,  1.4933e-02,\n",
       "                       5.0627e-02,  3.5569e-02,  2.3301e-02,  3.8033e-02,  4.0211e-02,\n",
       "                       3.0821e-02,  2.2420e-02,  5.7201e-02,  2.9452e-02,  1.8346e-02,\n",
       "                       3.3162e-02,  3.5542e-02,  3.5699e-03,  2.4598e-02,  3.9075e-02,\n",
       "                      -3.2049e-02, -8.0434e-03,  3.7551e-02,  1.6566e-02,  2.4491e-02,\n",
       "                      -1.9893e-02, -1.3724e-02,  2.4593e-02,  2.0270e-02,  6.2828e-02,\n",
       "                      -7.7718e-03,  1.4831e-02,  2.7815e-02,  3.9034e-02, -3.8826e-03,\n",
       "                       2.5541e-03, -3.3562e-03,  7.6241e-03,  1.5228e-02, -6.5595e-05,\n",
       "                       4.2414e-02,  2.0456e-02,  2.9060e-02,  2.9228e-02,  5.3783e-02,\n",
       "                      -5.9626e-03,  4.4118e-02,  2.8179e-02,  3.6203e-02,  4.6755e-02,\n",
       "                       3.4746e-02,  2.7119e-02,  2.5116e-02,  3.9205e-02,  5.3738e-02,\n",
       "                       3.2470e-02,  2.9157e-02,  3.9538e-02,  2.7400e-02,  1.2318e-02,\n",
       "                       1.8757e-02,  2.4371e-02, -1.8302e-02,  1.9274e-04,  4.8579e-02,\n",
       "                       3.0513e-03,  2.1456e-02,  1.7016e-02, -4.6695e-02,  4.0277e-02,\n",
       "                       3.0549e-02,  5.1475e-02,  3.2844e-02,  4.7479e-02,  4.5704e-02,\n",
       "                       3.5715e-02,  1.8459e-02,  3.9666e-02, -8.0942e-03,  2.5035e-02,\n",
       "                       3.3544e-02,  6.0938e-04, -1.8602e-03,  3.3142e-02,  4.6477e-02,\n",
       "                       2.7378e-02,  3.0696e-02,  4.4820e-02,  4.7289e-02, -2.8671e-02,\n",
       "                       4.0005e-02,  2.3096e-02,  5.0933e-02, -2.6024e-02,  3.8376e-02,\n",
       "                       4.1520e-02,  3.3534e-02,  2.6101e-02,  3.6449e-02,  3.3659e-02,\n",
       "                       7.3448e-03,  3.6479e-02,  4.7592e-02,  1.4866e-03,  4.8326e-02,\n",
       "                       4.7011e-02,  5.4118e-02,  1.9781e-02,  1.7012e-02,  4.8792e-02,\n",
       "                       3.8374e-02,  4.6182e-02, -5.1413e-03,  2.2638e-02,  2.2920e-02,\n",
       "                       1.5218e-03, -1.4581e-02,  3.3110e-02,  5.3986e-03,  3.0704e-02,\n",
       "                       2.2323e-02, -1.3037e-02, -2.1907e-03,  4.1294e-02,  9.8522e-03,\n",
       "                       4.7524e-02, -3.6157e-03, -8.8695e-04,  4.0165e-02,  3.0214e-02,\n",
       "                      -1.8135e-03, -1.2214e-02,  1.3240e-02,  1.6268e-02,  7.7919e-03,\n",
       "                       4.5434e-02,  2.9261e-02,  3.8585e-02,  5.7343e-02, -1.6358e-02,\n",
       "                      -1.3366e-02,  2.9236e-02,  3.6800e-02, -7.7143e-04, -3.8666e-02,\n",
       "                       3.5712e-02, -1.8820e-02,  3.5487e-02,  2.6146e-02,  2.7139e-02,\n",
       "                       5.8467e-02,  4.9917e-02,  2.1414e-02,  3.4388e-03,  2.9890e-02,\n",
       "                      -3.0237e-02,  3.2285e-03,  3.5778e-02,  1.8103e-03,  3.1428e-02],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.4.mlp.1.running_mean',\n",
       "              tensor([-0.4704,  0.1439, -0.5756, -0.9538, -1.3238,  0.6071, -1.1246, -2.3151,\n",
       "                      -0.2901, -1.6952,  0.3737, -1.5740,  2.1225,  0.0904,  0.0144, -2.3206,\n",
       "                      -1.1758,  1.4706, -1.9722,  2.4214, -1.3488,  2.1326, -0.3683, -1.9080,\n",
       "                      -0.6780, -1.3888, -1.4815, -0.2718, -1.9541, -0.8932, -2.0013, -1.6640,\n",
       "                      -0.8851, -0.1301, -0.5850, -1.1617, -1.0159, -1.4498, -1.5228, -2.1235,\n",
       "                      -0.9520, -2.2645, -0.8018,  0.2853,  0.1724, -3.1177, -0.9083, -0.1814,\n",
       "                      -1.3251, -1.2177, -1.8630, -0.8361, -1.5624, -0.7311, -1.3353, -1.0596,\n",
       "                       0.8768,  0.7143, -0.3542, -0.2062,  1.9061,  1.3504,  1.1250, -1.1094,\n",
       "                      -1.5470,  1.8960,  2.2640, -0.6072, -0.9374, -2.4442,  2.0916, -1.0602,\n",
       "                      -1.4889, -0.0894,  0.1269,  0.0428, -0.2788,  2.0339,  1.6138,  2.1878,\n",
       "                      -0.5444,  1.8535, -0.6408, -1.5707, -2.0088,  2.3007, -1.3821,  1.0888,\n",
       "                      -0.7927,  0.5722,  1.7719, -0.9994, -0.8480, -0.6958, -1.4512, -1.1176,\n",
       "                      -0.7695, -2.0758, -0.9757,  2.4927,  1.9409,  0.0225, -0.4559,  1.8387,\n",
       "                      -0.0271, -0.1564, -0.9407, -0.2957,  1.4932, -1.4896, -0.9964,  0.6032,\n",
       "                      -2.1913, -2.0698, -2.5471, -1.2780, -0.5511, -1.5638, -0.5770, -0.4726,\n",
       "                      -1.6748, -1.2667,  0.4771, -0.7031, -1.6362, -1.7247, -0.8176, -2.1795,\n",
       "                      -1.5265,  2.8345, -1.4912,  1.1319, -0.5410,  2.4697, -1.1564,  1.1106,\n",
       "                      -2.2175, -0.9262, -1.8355,  0.0135,  1.7986, -1.6795, -1.2308,  2.1179,\n",
       "                      -1.9221, -0.7297, -1.8696, -0.3779, -0.3793, -1.3039, -2.0817, -1.4192,\n",
       "                       0.8556, -0.3803,  0.0302,  0.7626,  2.3251, -0.7047,  1.7637, -1.0334,\n",
       "                      -1.4603,  2.5834,  0.1677, -1.8634, -3.7227, -2.0274, -1.0314, -0.5973,\n",
       "                      -1.5782,  0.8455, -0.4778, -0.6696,  2.1344, -0.1912,  2.2490,  1.2983,\n",
       "                       0.5600, -0.9783, -2.3109,  2.2546,  1.6433, -0.9423, -1.5223,  1.8917,\n",
       "                      -0.1671,  0.8546,  1.9776,  1.3216, -2.8552, -0.4215, -0.1540, -1.6873,\n",
       "                      -0.0943, -1.0286, -0.3902,  3.4064, -0.1886, -1.9594, -1.6942, -2.1144],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.4.mlp.1.running_var',\n",
       "              tensor([ 2.6265,  2.3953,  3.1615,  4.4254, 10.4687,  4.0983,  4.7825, 12.4127,\n",
       "                       3.8447,  9.0646,  2.7454,  5.9090,  8.0723,  6.1882,  2.3662,  9.2179,\n",
       "                       8.8872,  6.1261,  6.2550, 11.0235,  6.2006,  8.2412,  1.0746, 11.0937,\n",
       "                       3.2472,  4.3764, 10.5114,  6.0757,  7.4415,  4.6825, 11.3090,  6.0523,\n",
       "                       6.4619,  3.9657,  3.3328,  2.7106,  2.8356,  4.3206,  5.8920, 10.7993,\n",
       "                       5.4706,  8.9799,  1.8469,  3.1471,  4.1903, 20.0857,  5.0142,  3.3180,\n",
       "                       8.0434,  4.6777,  7.5208,  3.0434,  6.4238,  3.8849,  3.9639,  8.5117,\n",
       "                       7.6095,  4.8251,  3.7263,  2.3576,  7.7566,  5.4677,  5.3179,  4.3316,\n",
       "                       5.5102,  7.7869,  9.7740,  4.2848,  2.3964, 11.4945,  6.4344,  4.8472,\n",
       "                       9.6086,  3.1576,  4.7375,  6.5360,  4.2862,  7.6604,  6.4368,  9.5182,\n",
       "                       3.3015,  7.3941,  2.7510,  6.0976,  8.4066,  9.7497,  9.9356,  4.0898,\n",
       "                       4.2117,  5.9925,  8.0087,  5.6267,  3.2922,  2.1109,  5.2325,  4.4581,\n",
       "                       4.0080,  8.4052,  5.0727, 10.9550,  9.2362,  5.9725,  3.5535,  8.8939,\n",
       "                       2.8450,  2.9760,  5.5547,  2.7751,  4.2451,  6.1425,  3.8869,  4.2421,\n",
       "                      10.8928,  7.8134, 12.2599,  6.2793,  3.1658,  4.8814,  6.1802,  2.2854,\n",
       "                       5.0489,  4.1533,  5.7911,  5.3038,  7.2883,  5.6526,  5.1174,  8.8240,\n",
       "                       4.6686, 14.4173,  5.9908,  6.1411,  3.2739, 12.5399,  4.8538,  8.2288,\n",
       "                      10.4822,  5.7071,  5.9760,  3.1413,  6.7250,  5.1272,  3.4034,  8.0522,\n",
       "                       7.9516,  4.2757,  9.0109,  4.2508,  3.0696,  4.6845,  8.9174,  9.8298,\n",
       "                       2.7405,  3.9592,  4.6253,  3.0837, 10.2556,  3.7100, 11.7673,  4.0416,\n",
       "                       4.3553, 12.2904,  3.9919, 10.1785, 20.4027,  8.1441,  3.3032,  7.9648,\n",
       "                       4.7412,  4.4267,  1.7531,  4.0688, 10.4883,  3.3528, 10.7375,  8.3600,\n",
       "                       4.6241,  5.7216, 12.6800,  9.1414,  5.1478,  3.8733,  5.5500,  6.9363,\n",
       "                       3.0920,  4.6733,  8.4911,  5.9085, 17.3483,  2.1800,  8.0849, 11.1852,\n",
       "                       2.5341,  2.5084,  3.7282, 17.0970,  3.9878,  7.7971,  5.5913,  9.6299],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.4.mlp.1.num_batches_tracked',\n",
       "              tensor(63750, device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.4.mlp.3.weight',\n",
       "              tensor([[-0.0219, -0.0602,  0.0174,  ...,  0.0129, -0.0316,  0.0316],\n",
       "                      [-0.0068, -0.0086,  0.0086,  ..., -0.0123,  0.0238, -0.0158],\n",
       "                      [-0.0178, -0.0058,  0.0144,  ...,  0.0269,  0.0005,  0.0143],\n",
       "                      ...,\n",
       "                      [ 0.0166, -0.0270,  0.0032,  ..., -0.0029,  0.0021,  0.0430],\n",
       "                      [ 0.0093, -0.0320,  0.0152,  ...,  0.0206,  0.0231,  0.0411],\n",
       "                      [-0.0076,  0.0234,  0.0004,  ..., -0.0229,  0.0067, -0.0254]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.gnn_layers.4.mlp.3.bias',\n",
       "              tensor([ 0.0248,  0.0321,  0.0189,  0.0099,  0.0209,  0.0338,  0.0076,  0.0157,\n",
       "                      -0.0162,  0.0374,  0.0225, -0.0116,  0.0178,  0.0173,  0.0136,  0.0194,\n",
       "                       0.0186,  0.0134,  0.0450, -0.0176,  0.0178,  0.0063,  0.0324,  0.0170,\n",
       "                       0.0254,  0.0210, -0.0056, -0.0024, -0.0049,  0.0283,  0.0252,  0.0310,\n",
       "                       0.0127,  0.0384,  0.0178,  0.0045,  0.0270, -0.0063,  0.0262,  0.0337,\n",
       "                       0.0440,  0.0076,  0.0058,  0.0141, -0.0016,  0.0294,  0.0125,  0.0181,\n",
       "                       0.0312, -0.0110,  0.0376,  0.0136,  0.0129, -0.0057,  0.0208,  0.0206,\n",
       "                       0.0064,  0.0133,  0.0179,  0.0187,  0.0384,  0.0359,  0.0043,  0.0105,\n",
       "                       0.0322,  0.0347,  0.0121,  0.0045,  0.0247,  0.0202,  0.0173,  0.0302,\n",
       "                       0.0317,  0.0046,  0.0386, -0.0019,  0.0074,  0.0296,  0.0285,  0.0166,\n",
       "                       0.0134, -0.0043,  0.0216,  0.0252,  0.0044,  0.0165,  0.0212, -0.0045,\n",
       "                       0.0154, -0.0014,  0.0306,  0.0196,  0.0282,  0.0267,  0.0415, -0.0021,\n",
       "                       0.0220,  0.0334,  0.0380,  0.0325, -0.0121,  0.0053,  0.0047,  0.0173,\n",
       "                       0.0102,  0.0085,  0.0275, -0.0019,  0.0201,  0.0104,  0.0242,  0.0311,\n",
       "                       0.0102, -0.0218, -0.0082,  0.0166,  0.0232,  0.0123,  0.0246,  0.0204,\n",
       "                       0.0248,  0.0172,  0.0325,  0.0131,  0.0196,  0.0012,  0.0189, -0.0040,\n",
       "                       0.0059, -0.0077,  0.0125,  0.0204,  0.0333,  0.0276,  0.0260,  0.0040,\n",
       "                       0.0324,  0.0224,  0.0039,  0.0045, -0.0191,  0.0382,  0.0290,  0.0413,\n",
       "                       0.0057,  0.0218,  0.0238,  0.0241,  0.0399,  0.0187,  0.0316,  0.0246,\n",
       "                      -0.0132,  0.0250,  0.0125,  0.0278,  0.0274,  0.0202,  0.0237,  0.0197,\n",
       "                       0.0327, -0.0014,  0.0141,  0.0066,  0.0404,  0.0126,  0.0310,  0.0036,\n",
       "                       0.0301,  0.0328,  0.0081,  0.0218,  0.0139, -0.0130,  0.0027,  0.0342,\n",
       "                       0.0212, -0.0206,  0.0130,  0.0193,  0.0130,  0.0274,  0.0029,  0.0208,\n",
       "                       0.0165,  0.0085,  0.0216, -0.0105,  0.0175,  0.0019,  0.0103,  0.0042,\n",
       "                      -0.0215,  0.0011,  0.0198,  0.0113,  0.0415,  0.0464,  0.0372,  0.0139],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.Vh.weight',\n",
       "              tensor([[ 2.0592e-02, -2.3823e-02,  3.2955e-02,  ..., -5.4625e-03,\n",
       "                        1.4741e-02, -4.5238e-03],\n",
       "                      [-2.6099e-02,  2.2891e-02,  5.3131e-02,  ...,  4.5356e-02,\n",
       "                       -1.1540e-03, -2.5901e-03],\n",
       "                      [ 3.7625e-02,  1.5886e-02,  3.3226e-02,  ...,  2.5338e-02,\n",
       "                       -3.2735e-03,  1.1722e-02],\n",
       "                      ...,\n",
       "                      [-4.3598e-02, -3.2153e-03, -1.8577e-02,  ..., -9.1293e-03,\n",
       "                        2.5321e-02,  2.1771e-02],\n",
       "                      [ 1.3392e-02,  1.1763e-02,  2.1900e-02,  ...,  9.2063e-05,\n",
       "                       -6.6513e-03,  3.0935e-02],\n",
       "                      [ 1.4348e-02, -2.2150e-02,  7.8168e-03,  ...,  9.8906e-03,\n",
       "                        2.9652e-02, -2.2663e-03]], device='cuda:0')),\n",
       "             ('decoder.gnn.Vh.bias',\n",
       "              tensor([ 0.0307,  0.0101, -0.0029,  0.0112,  0.0042,  0.0037,  0.0071,  0.0183,\n",
       "                       0.0098,  0.0035,  0.0051,  0.0146,  0.0012,  0.0244,  0.0096, -0.0001,\n",
       "                       0.0293,  0.0026,  0.0080,  0.0062, -0.0037,  0.0104,  0.0169,  0.0186,\n",
       "                       0.0070,  0.0120,  0.0196,  0.0018,  0.0146,  0.0203,  0.0041,  0.0301,\n",
       "                       0.0302,  0.0037,  0.0054, -0.0025,  0.0044,  0.0025,  0.0198, -0.0018,\n",
       "                       0.0250,  0.0076,  0.0087,  0.0118, -0.0029,  0.0003,  0.0156,  0.0037,\n",
       "                       0.0050,  0.0077,  0.0232,  0.0183, -0.0022,  0.0184,  0.0046,  0.0245,\n",
       "                       0.0116,  0.0202,  0.0062,  0.0155,  0.0167,  0.0145,  0.0161,  0.0178,\n",
       "                       0.0124,  0.0164,  0.0255,  0.0281,  0.0231,  0.0167,  0.0065,  0.0129,\n",
       "                       0.0133,  0.0205,  0.0242,  0.0031,  0.0108, -0.0169,  0.0017,  0.0023,\n",
       "                       0.0221,  0.0234,  0.0059,  0.0146,  0.0047,  0.0166,  0.0212,  0.0007,\n",
       "                       0.0116,  0.0076,  0.0075,  0.0252,  0.0124,  0.0193,  0.0057,  0.0023,\n",
       "                       0.0032,  0.0178, -0.0005,  0.0170,  0.0083, -0.0012,  0.0096,  0.0055,\n",
       "                       0.0049, -0.0033,  0.0020,  0.0087,  0.0075,  0.0017,  0.0134,  0.0127,\n",
       "                       0.0125,  0.0137, -0.0016,  0.0054,  0.0168,  0.0137,  0.0159,  0.0215,\n",
       "                       0.0081,  0.0105,  0.0082,  0.0212,  0.0102,  0.0177, -0.0047,  0.0115,\n",
       "                       0.0042,  0.0075,  0.0161,  0.0126,  0.0102,  0.0214,  0.0143,  0.0118,\n",
       "                      -0.0163,  0.0002,  0.0097,  0.0065,  0.0092,  0.0253,  0.0146, -0.0013,\n",
       "                       0.0029, -0.0052,  0.0271,  0.0018,  0.0033, -0.0068,  0.0116,  0.0043,\n",
       "                       0.0042,  0.0123,  0.0143,  0.0060,  0.0094,  0.0264,  0.0092, -0.0006,\n",
       "                       0.0225,  0.0100,  0.0123,  0.0131,  0.0123,  0.0174,  0.0225,  0.0080,\n",
       "                       0.0027,  0.0020,  0.0176,  0.0149, -0.0027,  0.0225,  0.0234,  0.0145,\n",
       "                       0.0140,  0.0223,  0.0097,  0.0174,  0.0045,  0.0170,  0.0134,  0.0121,\n",
       "                      -0.0165,  0.0090,  0.0153,  0.0048,  0.0048,  0.0086,  0.0187,  0.0092,\n",
       "                      -0.0032,  0.0077,  0.0136,  0.0042,  0.0135, -0.0066, -0.0003,  0.0157],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.Vx.weight',\n",
       "              tensor([[-0.0057, -0.0202,  0.0017,  ...,  0.0064, -0.0478, -0.0082],\n",
       "                      [ 0.0082,  0.0013,  0.0364,  ...,  0.0260,  0.0173, -0.0087],\n",
       "                      [-0.0079,  0.0101, -0.0334,  ...,  0.0113, -0.0038,  0.0059],\n",
       "                      ...,\n",
       "                      [-0.0017,  0.0015, -0.0342,  ..., -0.0187,  0.0012, -0.0175],\n",
       "                      [-0.0177,  0.0345, -0.0263,  ..., -0.0382,  0.0057,  0.0386],\n",
       "                      [ 0.0257, -0.0437,  0.0090,  ...,  0.0549,  0.0189, -0.0430]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.gnn.Vx.bias',\n",
       "              tensor([ 0.0307,  0.0101, -0.0029,  0.0112,  0.0042,  0.0037,  0.0071,  0.0183,\n",
       "                       0.0098,  0.0035,  0.0051,  0.0146,  0.0012,  0.0244,  0.0096, -0.0001,\n",
       "                       0.0293,  0.0026,  0.0080,  0.0062, -0.0037,  0.0104,  0.0169,  0.0186,\n",
       "                       0.0070,  0.0120,  0.0196,  0.0018,  0.0146,  0.0203,  0.0041,  0.0301,\n",
       "                       0.0302,  0.0037,  0.0054, -0.0025,  0.0044,  0.0025,  0.0198, -0.0018,\n",
       "                       0.0250,  0.0076,  0.0087,  0.0118, -0.0029,  0.0003,  0.0156,  0.0037,\n",
       "                       0.0050,  0.0077,  0.0232,  0.0183, -0.0022,  0.0184,  0.0046,  0.0245,\n",
       "                       0.0116,  0.0202,  0.0062,  0.0155,  0.0167,  0.0145,  0.0161,  0.0178,\n",
       "                       0.0124,  0.0164,  0.0255,  0.0281,  0.0231,  0.0167,  0.0065,  0.0129,\n",
       "                       0.0133,  0.0205,  0.0242,  0.0031,  0.0108, -0.0169,  0.0017,  0.0023,\n",
       "                       0.0221,  0.0234,  0.0059,  0.0146,  0.0047,  0.0166,  0.0212,  0.0007,\n",
       "                       0.0116,  0.0076,  0.0075,  0.0252,  0.0124,  0.0193,  0.0057,  0.0023,\n",
       "                       0.0032,  0.0178, -0.0005,  0.0170,  0.0083, -0.0012,  0.0096,  0.0055,\n",
       "                       0.0049, -0.0033,  0.0020,  0.0087,  0.0075,  0.0017,  0.0134,  0.0127,\n",
       "                       0.0125,  0.0137, -0.0016,  0.0054,  0.0168,  0.0137,  0.0159,  0.0215,\n",
       "                       0.0081,  0.0105,  0.0082,  0.0212,  0.0102,  0.0177, -0.0047,  0.0115,\n",
       "                       0.0042,  0.0075,  0.0161,  0.0126,  0.0102,  0.0214,  0.0143,  0.0118,\n",
       "                      -0.0163,  0.0002,  0.0097,  0.0065,  0.0092,  0.0253,  0.0146, -0.0013,\n",
       "                       0.0029, -0.0052,  0.0271,  0.0018,  0.0033, -0.0068,  0.0116,  0.0043,\n",
       "                       0.0042,  0.0123,  0.0143,  0.0060,  0.0094,  0.0264,  0.0092, -0.0006,\n",
       "                       0.0225,  0.0100,  0.0123,  0.0131,  0.0123,  0.0174,  0.0225,  0.0080,\n",
       "                       0.0027,  0.0020,  0.0176,  0.0149, -0.0027,  0.0225,  0.0234,  0.0145,\n",
       "                       0.0140,  0.0223,  0.0097,  0.0174,  0.0045,  0.0170,  0.0134,  0.0121,\n",
       "                      -0.0165,  0.0090,  0.0153,  0.0048,  0.0048,  0.0086,  0.0187,  0.0092,\n",
       "                      -0.0032,  0.0077,  0.0136,  0.0042,  0.0135, -0.0066, -0.0003,  0.0157],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.pooler.w_qs.weight',\n",
       "              tensor([[ 0.0221,  0.0366,  0.0087,  ..., -0.0128, -0.0015,  0.0041],\n",
       "                      [-0.0193,  0.0071,  0.0523,  ..., -0.0419,  0.0009,  0.0035],\n",
       "                      [-0.0166,  0.0053,  0.0379,  ..., -0.0155, -0.0213,  0.0221],\n",
       "                      ...,\n",
       "                      [-0.0160,  0.0052, -0.0089,  ...,  0.0344,  0.0672, -0.0023],\n",
       "                      [ 0.0353, -0.0232,  0.0159,  ...,  0.0081, -0.0227,  0.0085],\n",
       "                      [-0.0218, -0.0007,  0.0091,  ...,  0.0102, -0.0093, -0.0087]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.pooler.w_qs.bias',\n",
       "              tensor([-0.0213,  0.0094,  0.0341,  0.0101,  0.0004, -0.0261, -0.0296,  0.0019,\n",
       "                      -0.0152, -0.0252, -0.0014,  0.0044,  0.0186,  0.0007, -0.0164, -0.0118,\n",
       "                      -0.0220,  0.0005,  0.0065, -0.0091,  0.0013, -0.0149,  0.0484, -0.0173,\n",
       "                      -0.0361,  0.0237, -0.0395,  0.0147,  0.0021, -0.0207,  0.0017, -0.0074,\n",
       "                       0.0102, -0.0121, -0.0097, -0.0065,  0.0297, -0.0330,  0.0206, -0.0032,\n",
       "                       0.0386, -0.0288,  0.0142, -0.0081, -0.0066, -0.0336,  0.0299,  0.0132,\n",
       "                       0.0174, -0.0016,  0.0265, -0.0155, -0.0002,  0.0220,  0.0359, -0.0174,\n",
       "                       0.0336,  0.0377, -0.0477, -0.0106,  0.0402,  0.0281, -0.0033, -0.0104,\n",
       "                       0.0234,  0.0302, -0.0031,  0.0309, -0.0247,  0.0060, -0.0015, -0.0037,\n",
       "                      -0.0242, -0.0216, -0.0060,  0.0108,  0.0119,  0.0242,  0.0016, -0.0021,\n",
       "                       0.0407, -0.0119,  0.0249, -0.0072,  0.0033, -0.0095,  0.0082, -0.0107,\n",
       "                      -0.0482, -0.0394, -0.0038,  0.0021,  0.0080, -0.0094,  0.0104, -0.0318,\n",
       "                       0.0375, -0.0181,  0.0284,  0.0226,  0.0052,  0.0276,  0.0018, -0.0155,\n",
       "                      -0.0181, -0.0312, -0.0102,  0.0120, -0.0309,  0.0060, -0.0068,  0.0154,\n",
       "                      -0.0118,  0.0246,  0.0139, -0.0205,  0.0057, -0.0133,  0.0240,  0.0003,\n",
       "                       0.0033,  0.0106,  0.0221, -0.0175,  0.0081, -0.0023,  0.0046,  0.0219,\n",
       "                      -0.0352,  0.0164,  0.0037,  0.0301,  0.0017,  0.0133,  0.0218, -0.0022,\n",
       "                      -0.0036, -0.0091,  0.0087,  0.0100,  0.0309, -0.0252, -0.0254,  0.0274,\n",
       "                       0.0249, -0.0251,  0.0056,  0.0008,  0.0239, -0.0082, -0.0051,  0.0095,\n",
       "                      -0.0001,  0.0003,  0.0069, -0.0352,  0.0301,  0.0221,  0.0019, -0.0280,\n",
       "                       0.0070,  0.0082,  0.0222,  0.0227, -0.0110, -0.0211, -0.0061, -0.0349,\n",
       "                      -0.0100,  0.0044,  0.0162, -0.0122,  0.0016,  0.0067,  0.0072,  0.0037,\n",
       "                      -0.0070,  0.0111, -0.0300,  0.0050, -0.0010,  0.0017,  0.0218,  0.0111,\n",
       "                      -0.0142, -0.0064,  0.0066, -0.0108, -0.0221,  0.0002, -0.0061,  0.0009,\n",
       "                      -0.0322,  0.0191, -0.0091,  0.0010, -0.0282,  0.0119, -0.0055,  0.0169],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.pooler.w_ks.weight',\n",
       "              tensor([[ 0.0079,  0.0384,  0.0091,  ...,  0.0086,  0.0039,  0.0255],\n",
       "                      [-0.0711,  0.0020, -0.0033,  ..., -0.0250,  0.0143,  0.0367],\n",
       "                      [-0.0043, -0.0111, -0.0333,  ..., -0.0174, -0.0448, -0.0213],\n",
       "                      ...,\n",
       "                      [-0.0518,  0.0154,  0.0149,  ..., -0.0309,  0.0058, -0.0205],\n",
       "                      [-0.0143,  0.0291, -0.0414,  ...,  0.0062,  0.0209, -0.0316],\n",
       "                      [-0.0257, -0.0189,  0.0011,  ..., -0.0054,  0.0052,  0.0146]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.pooler.w_ks.bias',\n",
       "              tensor([-1.9664e-02,  1.7479e-02,  5.2928e-03,  9.6509e-03,  1.0743e-02,\n",
       "                      -2.7423e-03, -1.5878e-02, -1.6436e-02, -3.6621e-02, -5.1174e-03,\n",
       "                       1.4945e-02,  1.8737e-02,  6.8475e-03,  3.5718e-02, -2.1124e-02,\n",
       "                      -9.5675e-03,  6.9860e-03, -1.2971e-02,  1.4654e-02, -3.8565e-02,\n",
       "                       7.8800e-04,  3.4210e-03, -1.7265e-03, -1.4978e-02,  2.8272e-02,\n",
       "                       1.1322e-02, -1.7928e-02,  5.6820e-03,  5.3999e-03, -8.2937e-03,\n",
       "                      -1.4712e-04, -1.5900e-03,  9.4883e-03,  6.6784e-03, -6.2532e-03,\n",
       "                       1.2846e-02,  7.2549e-03, -1.8513e-02,  7.2822e-03, -4.7121e-02,\n",
       "                       5.2682e-03, -1.9938e-02,  7.5845e-03, -1.1435e-02, -3.5611e-02,\n",
       "                      -3.7717e-03, -6.8872e-03,  3.8281e-03, -4.1188e-03,  8.8976e-03,\n",
       "                       5.7601e-03, -3.9799e-04,  1.4714e-02, -9.4127e-03, -6.4002e-03,\n",
       "                      -1.4528e-02,  4.8491e-02,  1.9781e-02, -9.5523e-03, -6.1105e-04,\n",
       "                      -1.3485e-03,  1.4100e-03,  8.6614e-03,  1.3366e-02, -2.7513e-04,\n",
       "                      -8.2332e-04, -1.5373e-02,  9.9849e-03,  5.6509e-03,  7.4003e-03,\n",
       "                      -3.4258e-03,  5.2728e-03,  1.3238e-02, -1.0042e-05, -1.4742e-02,\n",
       "                      -3.8617e-03,  3.7665e-02,  5.9734e-03, -1.1515e-03, -3.4238e-02,\n",
       "                      -1.1436e-02,  1.4635e-02,  1.6605e-02, -1.0365e-02,  1.8738e-02,\n",
       "                      -2.0084e-03, -3.1932e-02,  2.6127e-03,  8.9033e-03, -1.9522e-02,\n",
       "                       3.4640e-02, -2.0440e-02, -7.9607e-03, -5.4781e-03,  1.7056e-02,\n",
       "                      -1.1164e-02,  7.9136e-03,  5.4821e-03,  2.4587e-03,  1.2098e-02,\n",
       "                       8.6946e-03,  2.0298e-02,  1.5115e-02, -1.9044e-03,  1.8861e-03,\n",
       "                      -9.8950e-03, -2.0724e-02, -1.3893e-03,  8.1729e-03, -2.5186e-04,\n",
       "                       3.1287e-03,  4.5192e-03, -6.9016e-04,  2.1956e-02,  8.7605e-03,\n",
       "                      -2.2504e-03,  1.8298e-02, -2.2341e-02,  5.5835e-03, -2.4234e-03,\n",
       "                       4.2521e-03,  8.8197e-03,  2.6943e-02, -1.0409e-02, -5.2599e-03,\n",
       "                       6.0183e-03,  6.8180e-04,  1.7468e-02, -2.4718e-02,  1.2513e-02,\n",
       "                      -1.0106e-03,  1.5881e-02, -3.3562e-03,  1.0636e-02,  1.7606e-02,\n",
       "                      -2.3189e-03,  9.9795e-03,  1.0741e-02,  1.9087e-02,  3.0245e-03,\n",
       "                       2.3470e-02, -1.9124e-02, -2.0035e-02,  8.5978e-03,  3.5819e-03,\n",
       "                      -1.0993e-03, -1.5789e-03,  3.7089e-04,  1.5847e-03, -4.2344e-03,\n",
       "                      -9.3803e-03, -2.8323e-03, -1.6243e-03, -1.8687e-02,  1.2605e-02,\n",
       "                      -6.4970e-03,  1.4118e-02,  2.0684e-02,  2.2582e-02, -5.5743e-03,\n",
       "                      -3.0696e-04,  2.1501e-02,  8.3338e-03,  1.5549e-03, -5.6198e-04,\n",
       "                       5.7049e-03, -1.0853e-03, -1.7157e-02, -8.0673e-05,  2.0039e-02,\n",
       "                       9.6533e-03, -1.6486e-02, -1.4573e-03, -2.0078e-02,  2.6200e-04,\n",
       "                       2.2603e-03,  1.1083e-03,  7.7040e-03, -1.7498e-02,  5.0111e-03,\n",
       "                      -1.0049e-02,  3.1715e-03,  1.5583e-02,  4.8026e-03, -1.0210e-02,\n",
       "                      -7.8279e-03, -1.3173e-02,  2.1026e-03, -1.4846e-02, -2.4753e-03,\n",
       "                       1.4841e-04,  1.2020e-02, -1.3507e-03,  2.1637e-02, -1.2646e-02,\n",
       "                       2.7922e-02, -1.7643e-02, -1.1698e-03, -1.1762e-02,  1.3403e-02],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.pooler.w_vs.weight',\n",
       "              tensor([[ 0.0528, -0.0178,  0.0046,  ..., -0.0175, -0.0197, -0.0136],\n",
       "                      [-0.0015,  0.0090,  0.0217,  ..., -0.0002,  0.0126,  0.0190],\n",
       "                      [-0.0033,  0.0003,  0.0397,  ...,  0.0122, -0.0019, -0.0052],\n",
       "                      ...,\n",
       "                      [ 0.0047,  0.0137,  0.0007,  ..., -0.0215,  0.0176, -0.0488],\n",
       "                      [-0.0037,  0.0391, -0.0354,  ..., -0.0267,  0.0535,  0.0073],\n",
       "                      [-0.0144,  0.0094,  0.0158,  ...,  0.0235, -0.0247,  0.0060]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.pooler.w_vs.bias',\n",
       "              tensor([-1.4504e-04,  1.7025e-03, -8.5591e-04,  8.4043e-03, -6.3569e-03,\n",
       "                       5.7008e-03,  1.8634e-03, -5.8425e-03, -2.8923e-03,  5.8822e-03,\n",
       "                       9.3323e-03,  5.6292e-03,  5.6848e-04, -7.4868e-03, -1.8633e-02,\n",
       "                      -2.1228e-02,  1.4955e-03, -4.1497e-03,  1.3225e-02,  7.4926e-03,\n",
       "                      -1.2036e-02, -1.1458e-02, -1.4202e-02, -5.3754e-03, -4.2175e-03,\n",
       "                      -1.2016e-03, -2.6656e-03, -5.4835e-03,  6.9702e-03, -6.7281e-03,\n",
       "                      -3.0543e-02,  3.5690e-03,  4.6939e-03,  1.3834e-02,  3.3755e-04,\n",
       "                      -3.5269e-03, -6.6742e-03,  5.8014e-03,  7.8975e-03, -2.8101e-03,\n",
       "                       5.4092e-03,  4.4680e-03, -2.7645e-02,  2.0798e-03, -2.2563e-03,\n",
       "                      -1.6441e-03,  1.0718e-02,  6.0132e-03, -1.7017e-02, -1.2712e-03,\n",
       "                      -7.5271e-03, -1.7181e-03, -4.0349e-03, -1.8836e-03, -1.5459e-03,\n",
       "                       1.8250e-03,  2.2274e-03,  4.1021e-03, -3.4261e-03, -1.6093e-02,\n",
       "                      -1.0155e-03,  1.0049e-02, -2.7185e-03, -1.1158e-02, -1.6999e-02,\n",
       "                       4.0282e-03,  1.1986e-02,  5.7665e-03, -1.1235e-02,  2.6585e-02,\n",
       "                      -1.2759e-02, -5.6945e-03, -4.2574e-04, -4.8654e-03,  3.4534e-03,\n",
       "                      -1.6053e-02,  7.1331e-03,  4.7426e-03,  1.6950e-03, -1.8264e-02,\n",
       "                       1.0236e-02,  1.2899e-02, -7.4479e-03,  3.7305e-03, -1.4385e-02,\n",
       "                      -1.2487e-02,  8.9648e-03, -9.5717e-03, -3.2726e-03,  1.5158e-02,\n",
       "                      -4.6572e-03, -5.2325e-03,  1.1334e-02, -1.5465e-02,  2.0992e-03,\n",
       "                      -3.4045e-03,  1.2270e-02, -1.2159e-02, -5.9814e-03, -1.2645e-02,\n",
       "                      -6.9660e-03,  2.0114e-03,  6.9886e-03, -4.4433e-03, -1.4196e-02,\n",
       "                       4.0298e-04,  7.7373e-03, -6.6523e-04,  2.2869e-02, -5.9456e-03,\n",
       "                      -3.3398e-03,  1.6669e-02, -9.1825e-03, -4.9488e-03,  9.2270e-03,\n",
       "                      -5.9997e-03, -4.5469e-03, -1.1728e-03,  4.9569e-03, -5.9868e-03,\n",
       "                       1.4031e-03,  1.4683e-02,  2.7520e-03, -3.8295e-03, -4.6931e-03,\n",
       "                       1.7838e-02, -8.8332e-03,  8.7202e-03,  8.9118e-03,  1.8928e-02,\n",
       "                      -8.1677e-03,  1.1778e-03, -4.7602e-03, -1.7902e-02, -7.2256e-04,\n",
       "                       1.1453e-02, -5.7434e-03,  6.9815e-03,  3.1859e-04, -6.2239e-03,\n",
       "                      -5.4810e-04,  9.1531e-04,  4.5137e-03, -1.8574e-03, -6.1261e-03,\n",
       "                      -1.6914e-05, -1.8939e-04,  1.1845e-02,  3.4999e-03,  5.2336e-03,\n",
       "                      -5.3663e-03, -7.4145e-03, -5.4144e-03, -6.1006e-04,  4.7093e-03,\n",
       "                      -4.1778e-03, -4.7151e-03, -1.5464e-03,  4.7098e-03,  6.6070e-03,\n",
       "                      -6.2587e-03, -1.1099e-02,  6.9957e-04,  1.3100e-02,  3.1013e-03,\n",
       "                      -2.5731e-03, -6.4687e-04,  6.4057e-03, -3.7085e-03,  9.9097e-03,\n",
       "                       2.0033e-02, -1.8866e-03, -5.3962e-03,  5.8916e-03,  6.1145e-03,\n",
       "                       1.1642e-04,  3.6246e-03, -7.8148e-03, -3.4589e-03,  6.2773e-03,\n",
       "                       7.2706e-03, -5.2979e-03, -6.7265e-04, -8.9096e-03, -4.0736e-03,\n",
       "                      -4.9350e-03, -6.8013e-03,  5.4620e-03, -1.3328e-02,  4.6304e-03,\n",
       "                       9.5784e-03,  6.5432e-03, -6.2536e-03, -1.4449e-03,  5.7473e-04,\n",
       "                      -1.2056e-02,  1.9061e-03,  1.7261e-02,  1.9932e-02, -5.7366e-03],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.fc.layers.0-Linear.weight',\n",
       "              tensor([[-0.0015, -0.0259, -0.0048,  ...,  0.0115,  0.0152, -0.0272]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder.fc.layers.0-Linear.bias',\n",
       "              tensor([-0.0115], device='cuda:0'))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a58d7c0b-c01e-419c-8863-73f604d81078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(att_head_num=2, batch_size=64, cuda=True, dataset='csqa', debug=False, decoder_lr=0.001, dev_adj='data/csqa/graph/dev.graph.adj.pk', dev_statements='data/csqa/statement/dev.statement.jsonl', drop_partial_batch=False, dropoutf=0.2, dropoutg=0.2, dropouti=0.2, encoder='FacebookAI/roberta-large', encoder_layer=-1, encoder_lr=1e-05, ent_emb=['tzw'], ent_emb_paths=['data/cpnet/tzw.ent.npy'], eval_batch_size=2, fc_dim=200, fc_layer_num=0, fill_partial_batch=False, fp16=True, freeze_ent_emb=True, gnn_dim=200, inhouse=True, inhouse_train_qids='data/csqa/inhouse_split_qids.txt', init_range=0.02, k=5, load_model_path=None, log_interval=10, loss='cross_entropy', lr_schedule='fixed', max_epochs_before_stop=10, max_grad_norm=1.0, max_node_num=200, max_seq_len=100, mini_batch_size=2, mode='train', n_epochs=15, num_relation=38, optim='radam', refreeze_epoch=10000, save_dir='saved_models/csqa/enc-FacebookAI/roberta-large__k5__gnndim200__bs64__seed0__20240320_173213', save_model=True, seed=0, simple=False, subsample=1.0, test_adj='data/csqa/graph/test.graph.adj.pk', test_statements='data/csqa/statement/test.statement.jsonl', train_adj='data/csqa/graph/train.graph.adj.pk', train_statements='data/csqa/statement/train.statement.jsonl', unfreeze_epoch=4, use_cache=True, warmup_steps=150, weight_decay=0.01)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a58418a4-4547-4bc9-a300-8a981b94f2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load this mf\n",
    "qa_gnn.load_state_dict(checkpoint[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284bf579-8099-405b-b7cc-0625c3917032",
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.load_model_path:\n",
    "            print (f'loading and initializing model from {args.load_model_path}')\n",
    "            model_state_dict, old_args = torch.load(args.load_model_path, map_location=torch.device('cpu'))\n",
    "            model.load_state_dict(model_state_dict)\n",
    "\n",
    "        model.encoder.to(device0)\n",
    "        model.decoder.to(device1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbb7de5a-0d2b-4346-8302-5e1875b26581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'args',\n",
       " 'batch_size',\n",
       " 'dev',\n",
       " 'dev_adj_data',\n",
       " 'dev_decoder_data',\n",
       " 'dev_encoder_data',\n",
       " 'dev_labels',\n",
       " 'dev_qids',\n",
       " 'dev_size',\n",
       " 'device0',\n",
       " 'device1',\n",
       " 'eval_batch_size',\n",
       " 'inhouse_test_indexes',\n",
       " 'inhouse_train_indexes',\n",
       " 'is_inhouse',\n",
       " 'num_choice',\n",
       " 'test',\n",
       " 'test_adj_data',\n",
       " 'test_decoder_data',\n",
       " 'test_encoder_data',\n",
       " 'test_labels',\n",
       " 'test_qids',\n",
       " 'test_size',\n",
       " 'train',\n",
       " 'train_adj_data',\n",
       " 'train_decoder_data',\n",
       " 'train_encoder_data',\n",
       " 'train_eval',\n",
       " 'train_labels',\n",
       " 'train_qids',\n",
       " 'train_size']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a9e0b57-2970-4f7a-aa1a-ac37637afdab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9839,\n",
       " 25610,\n",
       " 25610,\n",
       " 47942,\n",
       " 1910,\n",
       " 131,\n",
       " 4779,\n",
       " 506,\n",
       " 1910,\n",
       " 131,\n",
       " 26029,\n",
       " 18735,\n",
       " 26029,\n",
       " 506,\n",
       " 267,\n",
       " 506,\n",
       " 298,\n",
       " 36807,\n",
       " 1368,\n",
       " 4132,\n",
       " 4132,\n",
       " 20280]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"FacebookAI/roberta-large\")\n",
    "tokenizer.encode(\"yo yo yo dfja;ldfja;dj akdjfjfhdf hiiii hi\", add_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "53915d46-21b3-4050-afcc-81ed66b47d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce175ea8a278478596495ff72fd908ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/7.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.25M/1.25M [00:00<00:00, 3.97MB/s]\n",
      "Downloading data: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 160k/160k [00:00<00:00, 255kB/s]\n",
      "Downloading data: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 151k/151k [00:00<00:00, 668kB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a01fe3c26af46ff8cfac69e841e1ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/9741 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf9c215678e64871b8166b8cc7932056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1221 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31be992f1b0740a4a6007be36491b131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1140 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'question', 'question_concept', 'choices', 'answerKey'],\n",
       "        num_rows: 9741\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'question', 'question_concept', 'choices', 'answerKey'],\n",
       "        num_rows: 1221\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'question', 'question_concept', 'choices', 'answerKey'],\n",
       "        num_rows: 1140\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "csqa = load_dataset(\"tau/commonsense_qa\")\n",
    "csqa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "b4e282fb-bf29-47c5-9ad4-fd75539ef897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csqa[\"train\"][\"question\"].index('Bill is stuck in marsh when a man comes up to him peaking Cajun, where is he?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "53479b45-02b9-4c56-8f07-2eb841986649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change?',\n",
       " 'Sammy wanted to go to where the people were.  Where might he go?',\n",
       " 'To locate a choker not located in a jewelry box or boutique where would you go?',\n",
       " 'Google Maps and other highway and street GPS services have replaced what?',\n",
       " 'The fox walked from the city into the forest, what was it looking for?',\n",
       " 'What home entertainment equipment requires cable?',\n",
       " 'The only baggage the woman checked was a drawstring bag, where was she heading with it?',\n",
       " 'The forgotten leftovers had gotten quite old, he found it covered in mold in the back of his what?',\n",
       " 'What do people use to absorb extra ink from a fountain pen?',\n",
       " 'Where is a business restaurant likely to be located?',\n",
       " 'Where do you put your grapes just before checking out?',\n",
       " 'Before getting a divorce, what did the wife feel who was doing all the work?',\n",
       " 'Johnny sat on a bench and relaxed after doing a lot of work on his hobby.  Where is he?',\n",
       " \"James was cooling off two quickly.  He would die if he didn't find some way to stop what?\",\n",
       " 'Of all the rooms in a house it was his favorite, the aromas always drew him to the what?',\n",
       " 'Bill is stuck in marsh when a man comes up to him peaking Cajun, where is he?',\n",
       " 'What is it called when you slowly cook using a grill?',\n",
       " 'What type of person typically contracts illness?',\n",
       " 'Where would you expect to find a pizzeria while shopping?',\n",
       " 'When eating everything on the tasting menu, what does one tend to feel?',\n",
       " 'What does playing soccer for a long time lead to?',\n",
       " 'Which entrance would you use if you do not want to use the back entrance?',\n",
       " 'You can share files with someone if you have a connection to a what?',\n",
       " 'The accelerator was controller via a hand throttle, and the foot pedals controlled the steering in the small what?',\n",
       " 'Sean was lying about the body, but he was very scared.  He constantly worried about what?',\n",
       " 'The drug kingpin told his man to run errands, this was code to go to all the dealers to do what they had?',\n",
       " \"Though he could've kept going his body appreciated the rest, it had been constantly what during the day?\",\n",
       " 'Too many people want exotic snakes.  The demand is driving what to carry them?',\n",
       " 'Joe suffered many consequences from stabbing a stranger to death.   Among them, the family of the victim did something to him. What was that?',\n",
       " 'To prevent any glare during the big football game he made sure to clean the dust of his what?',\n",
       " 'I have something in my head I want to share, what ways can I do that?',\n",
       " 'He wanted a house that was gated off from other places, where should he start looking?',\n",
       " 'Where in Southern Europe would you find many canals?',\n",
       " 'What would a camper need to do before he or she can start cooking food?',\n",
       " 'What could happen to a paper if you leave it outside even if it does not move?',\n",
       " \"Mark's semen was very thick, but after his vasectomy it was also what?\",\n",
       " 'What is a great place to lay in the sun?',\n",
       " 'Where would you find a seafood restaurant in the east coast of North America?',\n",
       " 'The president is the leader of what institution?',\n",
       " 'Sitting to close while watching TV can cause what sort of pain?',\n",
       " 'Where is a bald eagle safe?',\n",
       " \"The game promised it was free, but the child's parents soon found themselves doing what for microtransactions?\",\n",
       " 'What kind of driving leads to accidents?',\n",
       " 'What is eating too much dinner likely to result in?',\n",
       " 'What is a person chatting with friends likely hoping to accomplish?',\n",
       " \"Jame's bare feet were burned as he walked, because the sunshine had made the surface hot.  Where might he have been?\",\n",
       " 'A fox was thirsty searching for water during the drought, where was he?',\n",
       " 'What might be the result of a season of successful skiing?',\n",
       " 'The sensor would just the distance then set off an alarm, the installation expert explained it was called a what kind of sensor?',\n",
       " 'The man was eating lunch, but rushed when he looked at his watch, why did he rush?',\n",
       " 'The evacuation became mandatory, so what came on the TV?',\n",
       " 'The person gave a good hands on what to show how to do the work?',\n",
       " 'Where would you see some people doing jumping jacks?',\n",
       " 'The body guard was good at his duties, he made the person who hired him what?',\n",
       " \"Learning languages is difficult.  Even in a full immersion environment you're likely to make mistakes, mistakes will cause misinterpretation, which will be uncomfortable, which will cause what?,\",\n",
       " 'Jim enjoyed killing people, but he did it too often and the cops found out.  What might the cops do to him?',\n",
       " 'Where is there usually a fiddle playing?',\n",
       " 'What is the only was to recover from exhaustion?',\n",
       " 'What would you do if you want to be able to earn money?',\n",
       " 'What is a grumpy person likely to have?',\n",
       " 'What do drugs do?',\n",
       " 'A beaver can destroy a machines functionality if they build their dam in this?',\n",
       " 'They decided to hash things out over drinks, after enough booze they were able to get close on a few things and what?',\n",
       " 'Where could a fungus grow and not be disturbed by sunlight?',\n",
       " 'Can you name a good reason for attending school?',\n",
       " 'What state south of Kentucky and north of Alabama will you find people playing the fiddle?',\n",
       " 'Though she made the cut years ago, its figurative scars would never what?',\n",
       " 'What does sex often make happen in people?',\n",
       " 'Where would you see people in uniform playing with a ball?',\n",
       " 'What kind of place could have a seafood restaurant?',\n",
       " 'Who was the head of the branch yelling at?',\n",
       " 'He made another call, he did this all day hoping people would what well to his offer?',\n",
       " 'She needs to visit a bookshop after buying the latest fashion, where should she look?',\n",
       " 'Where could you see an advertisement while reading news?',\n",
       " 'What is required to be good at playing tennis?',\n",
       " 'What state is the John Davis  Lodge toll road found in?',\n",
       " 'The man went to clown college, he had always want to run away with the what?',\n",
       " 'Jamie wanted to reduce her waist size, but all of her efforts failed miserably.  She continued to do what?',\n",
       " \"James felt himself losing consciousness.  He was frightened.  He didn't want this.  He was scared of what?\",\n",
       " 'If someone is aloof and self-important, what is their experience when meeting people?',\n",
       " \"He was receiving workman's compensation, he had tripped over a metal rod while building where?\",\n",
       " 'John and James spent most of their time communicating with each other on their project.  The time required to communicate slowed their what?',\n",
       " 'When you play around with your dog they will have?',\n",
       " \"Where would a person keep a book while it's being read?\",\n",
       " 'The student needed to  get some new pencils, where did he go?',\n",
       " 'She loved buying products, she was driven by her what to shop more than any practical needs?',\n",
       " 'How does getting paid feel?',\n",
       " 'The fat man refused to accept what was possible, he complained that he what the simplest activities?',\n",
       " 'Where can meat last a long time?',\n",
       " 'What group of musicians will include someone playing the cello?',\n",
       " 'Where do bees congregate with red flowerS?',\n",
       " 'What is someone who gets angry after getting drunk likely to participate in?',\n",
       " 'The teacher told all the students that listening was key, it was the main way they would gain what?',\n",
       " 'Stanley had a dream that was very vivid and scary. He had trouble telling it from what?',\n",
       " \"The city's community garden was demolished for yet another what?\",\n",
       " 'WHat do cats get into when they are ripping things apart?',\n",
       " 'What is a good result of losing weight?',\n",
       " 'A person lived in my what?',\n",
       " 'The skin was cut while chopping onions, where was this skin likely cut?',\n",
       " 'What might you feel after doing housework for hours?',\n",
       " 'The accountant used a calculator regularly, he kept one at home and one at the what?',\n",
       " 'At the end of your meal what will a waiter do?',\n",
       " \"If you aren't glad, unhappy or gloomy, what illness may you have?\",\n",
       " 'You can hear testimony of how spirituality changes lives when you do what?',\n",
       " 'It was a great rest, she had never felt this much what in the morning?',\n",
       " 'Which region has the most famous temple?',\n",
       " 'Where would you find a bee gathering pollen?',\n",
       " 'Where would you put a folding chair if you do not plan to use it and you do not have any large doors in your house?',\n",
       " \"If you're speaking to a lawyer about getting a divorce, what relationship status are you trying to end?\",\n",
       " 'How do geese normally get from place to place?',\n",
       " 'John was punching and punching at the wall but succeeded only in bloodying his knuckles. This was bad.  He would be unable to hold his tools if he injured what?',\n",
       " 'Though it stayed strictly indoors, the small dog felt like it had all the space in the world in the what?',\n",
       " \"WHat leads to someone's death when they are very depressed?\",\n",
       " 'She was sick and staying in bed the day of the event, unfortunately this meant she was what?',\n",
       " 'Where would a lizard surprise a person?',\n",
       " \"They were getting together for the big game, he wasn't hosting but made sure to bring pretty of food with him over to where?\",\n",
       " 'Who is likely yo have a caring heart?',\n",
       " \"I'm looking for alcohol and fried foods, any suggestions?\",\n",
       " 'If I had a jar which was likely to spoil if left out, where would I want to put it?',\n",
       " 'Sam went to Paris where he ordered a blowfish at a sushi place.  Where was Sam?',\n",
       " 'What will happen to skin pinched in something?',\n",
       " \"Sally lost her kite because she wasn't careful.  She thought that there was more string on the spool, but it slipped out of her fingers when she reached the what?.\",\n",
       " 'The man uses grooming before a job interview, what is he trying to portray?',\n",
       " 'Where would there be many people sitting in chair and listening to religious speech?',\n",
       " 'Where is a tabby cat likely to be happiest?',\n",
       " 'East coast areas such as Florida are found where?',\n",
       " 'To learn must have the right book, to work efficiently what must one have?',\n",
       " 'What is a mobile launching platform found in the ocean?',\n",
       " \"There weren't potatoes but actually a snake in his what?\",\n",
       " 'What could listening to music cause you to be?',\n",
       " 'If you want to make a big splash in a river with a rock, from where should you throw it?',\n",
       " 'What is committing perjury likely to lead to?',\n",
       " 'The new play was the go to performance of the year, all the crowds would stand and what?',\n",
       " '\"There are 10 apples on an apple tree.  Three fall off.  Now there are X apples.\"  What is this an example of?',\n",
       " 'Where are people likely to find food?',\n",
       " 'What might a kid do with his friend before going to play?',\n",
       " 'What is a person who is well educated?',\n",
       " 'Ben was an alcoholic and was in an accident.  Because of his mistake, he spent 8 years somewhere. Where was he?',\n",
       " 'Where do you buy tickets at a ticket booth for games/',\n",
       " 'A soccer field that is not contained in a building would be where?',\n",
       " 'Letters are sometimes delivered by hand through one of these.',\n",
       " \"John came to see Sam and Sam kicked him out.  Sam didn't like company.  He prefered what?\",\n",
       " 'If somebody likes temperatures cool, they might have more than one electric fan where?',\n",
       " 'Sky diving scared him, once they jumped out of the plane he began losing consciousness while what?',\n",
       " 'The president had to make a decision regarding the hate attack on his country, what did he do?',\n",
       " \"What's it called when you have seen something through an eyepiece?\",\n",
       " 'He had done a great job with the scary decorations, they were completely what?',\n",
       " 'If you did well on the test, you might get an A as a what?',\n",
       " \"If you tell you boss your suffering from boredom they'll likely tell you to get back to what?\",\n",
       " 'What is a good result of jogging?',\n",
       " 'What is done to wood to attach something to it?',\n",
       " 'Where is a fox likely to be caught?',\n",
       " 'Where do you put a new dining table?',\n",
       " \"Sometimes fighting inflation isn't even what, because it is so negligible?\",\n",
       " 'What is likely to have more than one level in a city?',\n",
       " 'Where is likely to have a lot of fire extinguishers?',\n",
       " 'Where would someone learn to play an upright piano?',\n",
       " 'What is necessary for learning by yourself?',\n",
       " 'John and Jane were a couple.  They were dating for a while and wanted to be together for even longer. For this reason, they did what?',\n",
       " 'What emotion does getting paid lead to?',\n",
       " 'Who is likely going in to a market?',\n",
       " 'What is a characteristic of thin glass?',\n",
       " 'What do you get for not moving your car during the required time?',\n",
       " \"Bob's feet hurt from running barefoot on the hot pavement.  I lost his shoes, didn't know where they landed, and had to run from the corner store to his home.  About where did he run?\",\n",
       " 'Where would you be able to hear a bassoon played in an unpleasing fashion?',\n",
       " 'John loved competing because he was very competitive.  He liked being about to divide people into what categories?',\n",
       " 'The game was on sale.  I got it then because it was usually what?',\n",
       " 'What could a massive building be if it is not constructed well?',\n",
       " 'Where could a printer be used by thousands of people?',\n",
       " 'What could prevent someone from buying chistmas presents?',\n",
       " 'What is the hope of playing sports without competition?',\n",
       " 'They moved out of the city to have a master bedroom, what kind of home did they seek?',\n",
       " 'What could you add a line to?',\n",
       " 'Joe bought a ficus.  He thought it would look good in what part of his home?',\n",
       " \"Sarah wanted to by a new rug.  Ink spilled onto her old one.  Really, she didn't know what that thing had an inkwell in the first place.  What piece of furniture might have been on her run?\",\n",
       " 'When people discover something new while chatting with friends, why are they likely to continue talking?',\n",
       " \"How can one's views change after learning about science?\",\n",
       " 'Traveling underwater has many dangers, such as low visibility causing what?',\n",
       " 'Where are people likely to stand at an intersection?',\n",
       " 'Janet knew she was dying from her injuries because she could feel herself doing what?',\n",
       " 'An expressway can suffer from traffic, this traffic gets worse the closer you get to any what?',\n",
       " 'Where are there more telephone booths?',\n",
       " 'John moved away from his family.  He was a bit upset that he had to do it, but he needed the job.  Still, he would have preferred it if the job were what?',\n",
       " \"James complained that Alexa's electric guitar was too loud and he couldn't get any work done at home,  so she decided that she should get an acoustic guitar.  Where might she look for one?\",\n",
       " 'What can someone feeling happiness fall into?',\n",
       " 'How might a person address someone who is leaving?',\n",
       " 'What does a chef do when working in the evening?',\n",
       " 'What would happen to a person if his or her money is stolen?',\n",
       " 'The people in class were instructed to brainstorm ideas, how would they use their minds for this?',\n",
       " 'Someone lacking immortality will one day be?',\n",
       " 'After his mother saw his report card he knew he was going to be doing housework, what could have prevented this?',\n",
       " \"Glass that hasn't been treated to be extra strong is what?\",\n",
       " \"If you've thrown a rod you've done damage to what?\",\n",
       " 'What enables most people to transport themselves?',\n",
       " 'What do people in the same family often share?',\n",
       " 'What is an area with no grass where I can get things to sell at a roadside stand?',\n",
       " 'Where do kids find fish in their backyards?',\n",
       " 'Where must one wear a white shoe?',\n",
       " 'James chose to not to print the cards, because he wanted to be more personal. What type of cards did he choose, instead?',\n",
       " 'They checked the weather one more time during the flight, they were on their way to paradise and wanted it to what?',\n",
       " 'What are you hoping to achieve when talking to someone?',\n",
       " 'What place of work might you find a hairpin?',\n",
       " 'What can go on a football field?',\n",
       " 'What has a master of their craft done about that craft?',\n",
       " 'If your watching television and accomplish nothing what have you done?',\n",
       " 'He was in a cabin in the woods, through the window he saw a fox where?',\n",
       " 'The hippy wanted peace with all humans, he had strong what for them all?',\n",
       " 'He was a very sharp engineer, but when it came to the details his calculations could were often what?',\n",
       " 'In the middle of the day what will someone do because of being hungry?',\n",
       " 'John enjoyed his time visiting the museum.  He wanted to spend more time there, so that he could study the exhibits more.   He was a very academic person and loved doing what?',\n",
       " 'What will telling many people about an embarrassing situation lead to?',\n",
       " 'The electric motor powered many important things, including one if almost every house. Name this item?',\n",
       " 'Where can peanut butter be stored?',\n",
       " 'Where would you play a board game with your family?',\n",
       " 'James needed a garage because he spent a lot of money on what?',\n",
       " 'If I am a person, I have a unique ability to do what?',\n",
       " 'Two friends wanted to spend a quiet evening together, what did they go see?',\n",
       " 'If an animal is tired, what is it likely to do?',\n",
       " 'Where would you sit in a chair to watch four-legged animals complete?',\n",
       " 'If you were looking for a lemur where would you find it?',\n",
       " 'John ran out of pencils.  Where did  he go to get more?',\n",
       " 'When would you be able to see your reflection in a piece of wood?',\n",
       " 'What emotion do people expressing themselves show when they trip in front of a crowd and break their leg?',\n",
       " 'He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what?',\n",
       " 'When you plant a garden you can harvest what to eat?',\n",
       " 'Where is basketball court likely to be outdoors?',\n",
       " 'What could a balalaika be needed for?',\n",
       " 'What type of home is most likely to have an attic filled with historical items?',\n",
       " \"Jackson is a popular city name, but the one with a governor's office is where?\",\n",
       " 'Where is microphone boom likely to be used to record an album?',\n",
       " 'What is the worst outcome of an injury?',\n",
       " 'How is someone who loves their TV likely to feel about their remote?',\n",
       " 'The man wanted to take a bus, but all the chars were full of people doing what?',\n",
       " 'Bob thought that his Pokemon cards were common and worthless, but he was wrong about them. They were really what?',\n",
       " 'A wife asks a husband to stop being married to her, what is he likely to feel even with friends?',\n",
       " 'The camper looked up at the vast night sky, it left him feeling mighty what?',\n",
       " 'Though nearby, an apple from an apple tree where would be an imported product to the USA?',\n",
       " 'The old man was retired and liked the simple things, he would do crossword puzzle every morning simply just to do what?',\n",
       " 'What would you change the learning process to be if someone does not like learning?',\n",
       " 'To properly instruct children attending school you would need a great deal of what?',\n",
       " \"If done correctly grooming pet's nails generally does not cause this?\",\n",
       " 'The man was cleaning clothes for his date, what was he looking to achieve?',\n",
       " 'The person was looking up airline and hotel prices, what was he looking to do?',\n",
       " 'The person put on lotion, what did they want?',\n",
       " \"Eating breakfast in bed can make you feel what, assuming that you don't spill anything?\",\n",
       " 'What would an adult man do to get ready for work?',\n",
       " 'The woman picked from an apple tree while surrounded by other trees, where was she?',\n",
       " 'Mom is tidying a house, where would she put the loose dictionary?',\n",
       " 'The judge did not take this part of the job lightly, the man was guilty but it was his passing sentence that condemned the man to what?',\n",
       " \"Simon bought a cow because he wanted to put it to work.   He didn't want any meat for it.  Where might Simon be taking the cow?\",\n",
       " 'What would children do if they are bored?',\n",
       " 'Behind what small door are canned goods usually kept in?',\n",
       " 'While laid up in the hospital she tried remembering good times, like that massage on vacation that brought great what?',\n",
       " 'If I want to maximize my number of potential customers, where should I build a new department store?',\n",
       " 'Where is a good place to get a ball?',\n",
       " 'What common chemical reaction is often used as a heat source?',\n",
       " 'Where could you put a dollar that would make it hard to get out without breaking?',\n",
       " \"I'm at a restaurant ans want a glass of milk, how do I find out if they serve that?\",\n",
       " 'What could contain no more than around 100 people?',\n",
       " 'John joined the army because he wanted to see the world.  When the fighting started, he only saw what sort of things?',\n",
       " 'where do children play a game?',\n",
       " 'What could happen after driving car that does not involve pain?',\n",
       " 'In what place could you find air that has been breathed by only a few people recently?',\n",
       " 'what happens to a company when it is bankrupt?',\n",
       " \"Blood isn't usually spilled during what sport that doesn't allow the use of hands?\",\n",
       " 'The dog ran to the front window and barked, this is because of a presence at the what?',\n",
       " 'Where would you find a sign with some people lined up next to it?',\n",
       " 'Sometimes it felt like being able to pay bills was the only reason he was actively what?',\n",
       " 'John just made first violin.  This is  is a position on what?',\n",
       " 'Where can someone keep a digital file?',\n",
       " 'What appliance uses water and soap?',\n",
       " 'I am looking to buy honey right from an apiary, where should I go?',\n",
       " 'Where would someone likely bring an attache case?',\n",
       " 'i like to examine different things,why do books the chapters on the back',\n",
       " 'The whole family was playing cards, they were full of joy and what?',\n",
       " 'Jimmy wanted a beer but his wife was an alcoholic on probation.  Where might he go?',\n",
       " 'What country has with the capital of Amsterdam has a Fortis bank?',\n",
       " 'What building has a ot of glue bottles?',\n",
       " 'The king was to meet an ambassador, where would the meet?',\n",
       " 'Where do kids play with a ball that is concrete?',\n",
       " 'Diving off a cliff for a cartoon character often ends in comedic what?',\n",
       " \"Jimmy didn't like going to the party.  It seemed like the guys there did nothing but what?\",\n",
       " 'Where does a person need to get when they have more kids?',\n",
       " 'Where would a special ficus be found?',\n",
       " \"James is apply for a job that he really wants. He knows that it will be a good fit and he has experience, but he doesn't have all the qualifications that they're asking for, so he's worried about what?\",\n",
       " 'What is a sign that you might not be living soon?',\n",
       " 'Riding bike through rough terrain can be dangerous, one could find themselves what?',\n",
       " 'What would a document be if it is not obtuse?',\n",
       " 'For convenience some customers want things straight to the doorstep and use what?',\n",
       " 'What is a great, but non-specific, overall benefit of exercise?',\n",
       " 'Where does a spoon go on one side of a plate?',\n",
       " 'Where is a note likely to indicate a melody?',\n",
       " 'what can years of playing tennis lead to?',\n",
       " 'Where would you be going if using a parking lot near a roller coaster?',\n",
       " 'What does a virus primarily do to a person?',\n",
       " \"Where would you go if you didn't feel like baking a cake yourself?\",\n",
       " 'Where are floors kept clean for holy purposes?',\n",
       " 'Where will a bullet projectile be found during a war?',\n",
       " 'What is a place that might not always have a queen?',\n",
       " 'What do you need to be to learn hard concepts?',\n",
       " 'Many addicts turn to exercise to deal with their addictions, this is because it is a healthy way to do what?',\n",
       " \"A night owl is what you'd head at sunset and you'd hear a what at sunrise?\",\n",
       " 'What place is not interesting to children?',\n",
       " 'What do rich people like in terms of bagels?',\n",
       " 'A shop will give you what for your purchases?',\n",
       " 'Where is small knight likely to be found?',\n",
       " 'How can you get in shape if there is no land nearby?',\n",
       " 'What might a person receive from their boss if they do a poor job?',\n",
       " 'The cabinets were imported from the south. John bought they because he knew that they would look good.  Where might they be installed?',\n",
       " 'What might two people competing get into?',\n",
       " 'What are ai machines known for doing?',\n",
       " 'Bob and Boris were standing in a queue at the grocery store.  They were standing in place.  The line was fast, but the children in front of them were loud.   They were what?',\n",
       " 'A blowfish lives free. He lives on his own. Where does he live?',\n",
       " 'Where is a paper notice likely to be left on a house?',\n",
       " 'People are purposefully harming others, what trait are they exhibiting?',\n",
       " 'The child pounded his mitt in excitement while enjoying his first game in the bleachers where?',\n",
       " 'After eating a dinner of uncooked chicken, what was felt by the poor man?',\n",
       " 'The obsessive man was always washing hands, he had even done it so much once that it caused a what?',\n",
       " 'The person is laying on the beach, why would he do that?',\n",
       " \"The spoiled child's playroom was massive, but only one of many rooms in the what?\",\n",
       " \"There's a lot to reproducing, but it begins and end with new life by giving what?\",\n",
       " 'Where is known to always have snow?',\n",
       " 'What does someone want when having fun with their friends and trying to fit in?',\n",
       " 'The parents thought their children should learn teamwork, what were they signed up for?',\n",
       " 'If a human is sleepy what can they do to feel more alert?',\n",
       " 'What is a place that could have hundreds of sporting goods store?',\n",
       " \"The little girl was raised selfish, she didn't even care when she was doing what?\",\n",
       " 'People want to explore space, so what should they use to do it?',\n",
       " 'Where might I find unusual varieties of roses?',\n",
       " 'Where would you put a light?',\n",
       " 'What can happen to you when eating hamburger from someone that you do not know that does not happen when you usually eat a hamburger?',\n",
       " \"When he touched the exposed wire he shouldn't have found it surprising that he got what?\",\n",
       " 'If one sees a fox and is standing in a landlocked, southern state, where is this person?',\n",
       " 'The priest pushed for more orthodox behavior, what kind of behavior was he trying to stop?',\n",
       " 'When they got out of the car in the mountains he felt like he was breathing fresh air for the first time, he began to do what to enjoy it more?',\n",
       " \"The cow would come outside even after the storm had passed, it wouldn't leave the what?\",\n",
       " 'Where would you get a contraceptive if you do not have one?',\n",
       " 'Where would a Martian find the Indian Ocean?',\n",
       " 'Where would a ficus plant brighten up a room?',\n",
       " 'The turkey needed to be kept from spoiling, what is useful in this situation?',\n",
       " 'Sam found a giant hole in the plain.  What might this hole be called?',\n",
       " 'If I have to keep track of how much oxygen there is, where am I?',\n",
       " 'The other passengers on the bus were quite loud, so he put on his headphones to relax and what?',\n",
       " 'The person knew the police were after him, so what did he do?',\n",
       " 'After going for run you have a sense of what?',\n",
       " 'If you are fiddling through a music book when you should be playing, you probably dont have?',\n",
       " 'In the movie a fragile man is causing accidents, his hope is to find a person opposite of him who is what?',\n",
       " 'Where would you get a bass clarinet to take home?',\n",
       " 'What will you need to do to decide whether to be seeing artifacts?',\n",
       " \"Mary wasn't familiar with James, so she wasn't comfortable speaking with him. How might she come off?\",\n",
       " 'It was a vast complex, the launch pad was just one part of what?',\n",
       " 'An electronics store had things damaged from the rain, where should these things be stored?',\n",
       " 'A lonely man committed suicide, why would he do that?',\n",
       " 'What might someone want to be if he or she is thick?',\n",
       " 'He wore the wrong shoes while walking all day, now he has what on his heels and toes?',\n",
       " 'What would release energy, but not mainly in your muscles?',\n",
       " 'If I am suffering from boredom, and I want to do something with a dictionary, what would help?',\n",
       " 'What is made out of only one piece?',\n",
       " 'When he was a small child he called the giraffe mascot a cow, it was a fond memory of the now defunct what?',\n",
       " 'He had a hard time finding the room on his schedule, it was on the second floor and he got lost in the very large what?',\n",
       " \"Whether it's popped, grilled, or canned people like to what?\",\n",
       " 'What happens to the conscience of someone who has been caught committing a murder?',\n",
       " 'Having a car in the city seemed to be more trouble than it was worth, the man still had to walk to and from the what after commuting?',\n",
       " 'What is likely to be the goal of telling many people about a new organization?',\n",
       " 'Where can the legs of a stool be built?',\n",
       " 'How might people perceive someone they are scared of?',\n",
       " 'Where would a ticket help you to get to a different country?',\n",
       " 'What happens when someone is playing too aggressively?',\n",
       " 'What are students trying to do?',\n",
       " 'Where do farmers keep toothpicks?',\n",
       " 'The detective had to analyse all the clues, every little thing at the scene he had to what?',\n",
       " 'A person with brown skin may share that skin with whom?',\n",
       " 'If I screw a chain ring onto something, what am I fixing?',\n",
       " \"Where would you put a dictionary while you're using it?\",\n",
       " 'A common saying, Sam thought, was to go forth, also this.',\n",
       " \"Someone who is awake is likely to know what's going on because they are this?\",\n",
       " 'Where would you find some swords in your house?',\n",
       " 'Bill did not abandon the fight, but did what to the enemy?',\n",
       " 'A shower is an expected amenity when you reserve a what?',\n",
       " 'What do humans do when in a race?',\n",
       " 'The garage had light sensors and automatic doors, what kind of house was it?',\n",
       " 'Where would you find people gathered near liquid in a workplace?',\n",
       " 'Where can you store you tent and keep it on your person?',\n",
       " 'What happens to people playing games?',\n",
       " \"Billy went away because his parents were fighting and he didn't want to stay where?\",\n",
       " 'Where could you find a fox hunting when not in a forest?',\n",
       " \"Lindy was a senior.  He lived with his children because he didn't want to go where?\",\n",
       " 'What could be happening near you if the ground is getting wet?',\n",
       " 'Where do most people keep magazines?',\n",
       " 'What cuisine is joked about eating small dogs?',\n",
       " 'Why might a person go to get counseling?',\n",
       " 'A water spout was seen in the ocean off the coast of what?',\n",
       " 'How can buildings like the Empire State building be described?',\n",
       " 'The rowdy frat boys shouted they would have fun and do what tonight?',\n",
       " 'What might someone do who is having fun?',\n",
       " 'what is the goal of going jogging?',\n",
       " \"John was stuck in his house.  He couldn't get out the door.  He was very frightened when the smoke detectors went off, but luckily it was a false alarm.  Why might he be stuck?\",\n",
       " 'The master control for the Tardis is where in the main room?',\n",
       " 'The old barn was beyond repair, they had to destroy it before they could what a new one?',\n",
       " 'Where would one find a shopping bag for packing groceries?',\n",
       " 'The lady was getting worked up about the article explaining the uptick in accidents in their area, but her husband was dismissive of it stating that accidents what?',\n",
       " 'There was a show on television about a ranger who loved flowers, but the next day it was about a gardener who also loved flowers.  It was a what?',\n",
       " 'They wanted to eat at home but the cupboards were barren, so they had to go what?',\n",
       " 'How does a flea locomote?',\n",
       " 'Where are you likely to find a professional prostitute?',\n",
       " 'If I have a vintage, decorative light source in my possession, what is it likely to be?',\n",
       " 'What would you do if you have curiosity about something but cannot leave your house?',\n",
       " \"Sam was against Allison's decision.  Joe was the opposite.  What was Joe, regarding that decision?\",\n",
       " 'Why would you not want to be working with wood?',\n",
       " 'He was good at traditional science but excelled at social science, his favorite subject was what?',\n",
       " 'A gentleman is very wealthy and flaunts it, where does he likely live?',\n",
       " 'Where could you find a bookstore?',\n",
       " 'John had a lot of respect for Jill, but not many other people did.  She faced a lot of what?',\n",
       " \"If you have trouble beginning work you're suffering from what?\",\n",
       " 'Why is waiting for the doctor difficult for people who need to do work?',\n",
       " \"If you aren't experiencing curiosity and want to ensure viewing enjoyment, what may you watch?\",\n",
       " 'The gambler had been winning a lot, he wisely decided to what?',\n",
       " 'What is a lover likely to want to do with their partner?',\n",
       " 'Where would you get a bag after someone fills it with clothes?',\n",
       " 'The sample needed to be pure, but the lab assistant got it what?',\n",
       " 'What treatment might an old time doctor have tried to accomplish with leeches?',\n",
       " 'What does a person looking for new things in life do?',\n",
       " 'Where would you put a handle if you want to bring it with you?',\n",
       " 'What do you need to have before buying products?',\n",
       " 'They were competing in basketball, the goal was to what?',\n",
       " 'What often happens after a long day of traveling?',\n",
       " 'while luck plays a big role, every person who is great at something has focus and what to it?',\n",
       " 'What happens when humans are exposed to noises?',\n",
       " 'What are you hoping to do when listening to an expert speak?',\n",
       " 'Where is a likely place to view an old copy machine?',\n",
       " 'What chore might a child have to do after breakfast, before getting on the bus?',\n",
       " 'A large container was a dime a dozen, there were hundreds of rows of them in the giant what?',\n",
       " 'The snake was a cottonmouth.  It was an American, from where?',\n",
       " 'What would you put furniture on top of?',\n",
       " 'Where can someone view a county highway as a line?',\n",
       " 'Which effect of stress could cause death if not treated immediately?',\n",
       " 'A person takes a seat to watch a movie, where is he?',\n",
       " 'You can read a magazine where while waiting for your transportation on rails to arrive?',\n",
       " 'The farmer chose plants he could make bird feed from and use of again the next year, he only planted what?',\n",
       " 'Where might you have cake with your ice cream?',\n",
       " 'James lived in the top of a tall tower.  He could see clouds when he looked out his window.  Where might he live?',\n",
       " 'The policemen wanted to clear the scene of the accident, so what did they do to traffic?',\n",
       " \"If you're betting with a shark, where are you likely playing?\",\n",
       " 'If one sees a fox and is standing in a coastal, gulf state, where is this person?',\n",
       " 'A person writes a check to a clerk, where does the clerk put them?',\n",
       " 'Where would you find performers on a platform in public?',\n",
       " 'He was looking for the holiday decorations and found an old box of clothes up where?',\n",
       " 'Where might a yard be tiny?',\n",
       " 'What is love when everyone keeps feeling it?',\n",
       " 'A balloon or two is a staple at a what?',\n",
       " 'HOw do you carry potatos home?',\n",
       " 'Where are you likely to find a paper program?',\n",
       " 'Billy bounced the ball off the wall.  There was a target on the wall for him to bounce against.  Where might he be?',\n",
       " 'How can an artist commemorate a horse forever.',\n",
       " 'Where do almost all people live?',\n",
       " 'What is a living thing with a lip?',\n",
       " 'what do you do before going to party?',\n",
       " 'The color yellow is associated with the opposite of the characteristic, what is it?',\n",
       " 'What is another term for instituting civil action?',\n",
       " 'If they were celebrating the occasion, how could the occasion be described?',\n",
       " 'The delivery man was delivering a whole crate of shampoo, they went through a lot of it at the what?',\n",
       " 'The man needed balls of cotton, where should he look?',\n",
       " 'Where would I put a rosebush if I did not have any containers to store it in?',\n",
       " 'Where could you find some large pieces of paper that are not for sale?',\n",
       " \"James didn't know what to do.  He felt that he'd ruin his relationship with Jen if he took it further, and he didn't want to do that.  At the same time,  He fight that pushing farther might do what to something good?\",\n",
       " 'What is important in a car when you are driving fast and come to a light?',\n",
       " 'Bob needs a level to hang a shelf but cant find one in his home. Where would he go to get one?',\n",
       " 'Why would professionals playing sports not be able to compete?',\n",
       " 'A musician is most likely to perform a concerto for clarinet with what type of group?',\n",
       " \"When a newborn's eyes open for the first time it will be the first time the ever?\",\n",
       " 'Where in a town would you put your shed?',\n",
       " \"James's bouncing rubber balls were at rest, and so he could sleep.  He would get up in the morning, and then put them in what state again?\",\n",
       " 'What would you normally expect a cat to say?',\n",
       " 'Where do people find bills with bread?',\n",
       " \"If you're traveling along a highway what item made of paper can you use to find your way?\",\n",
       " 'When I was home, I was comfortable.  But I had a crippling fear of going where?',\n",
       " 'Where will a native lemur be found?',\n",
       " 'Where can you eat fruit on a red bridge?',\n",
       " 'Where in your entrance hall can you keep you head wear?',\n",
       " \"John's RV needs electricity so that he can cook lunch.  Where would he go to plug in?\",\n",
       " 'Turkey is a nation in what part of the world?',\n",
       " 'What makes people happy when it is surprising and unexpected?',\n",
       " 'If I wanted to see a lizard in its natural habitat but I do not speak Spanish, where would I go?',\n",
       " 'What is not a safe way to transport jewelry on vacation?',\n",
       " 'Johnny and bill fought over money.  Johnny wanted it to be over.  What might he choose to do?',\n",
       " 'The man took 3 hours every morning for grooming, what is the likely result with his job?',\n",
       " 'Sarah opened his chest and found a second heart.  Her patient might not be what?',\n",
       " 'They launch a surprise attack, this ended the what?',\n",
       " 'What European country is famous for its potato industry?',\n",
       " 'Dancing for a long time will lead you to become what?',\n",
       " 'Where do most people keep their curling iron stored?',\n",
       " 'The shore was now a tourist attraction with nearby little shops, but at one time this what was home to a bustling fishing industry?',\n",
       " \"What is likely to happen to someone's speech after becoming inebriated?\",\n",
       " 'What gets rid of a mundane routine?',\n",
       " 'What does a master carpenter use to put holes in objects?',\n",
       " 'When someone falls from a mountain it will lead them to?',\n",
       " 'Why is this person not listening to music?',\n",
       " \"David hurt all over. He was tired, he was shaking, and he was in pain.  He hadn't gotten what he needed in a long time.  He was suffering from what?\",\n",
       " 'Where is a good place to buy moistener?',\n",
       " 'There was a saucepan used only for marinara, where was it kept?',\n",
       " 'If people are vegetarian, what do they do more of?',\n",
       " 'The movie had many a song and dance, it was a what?',\n",
       " 'Danny was having fun singing in front of his class.   He has a lot of what?',\n",
       " 'Where is a system of electronic devices likely to be used in school?',\n",
       " 'What do humans do when they want to reproduce?',\n",
       " 'After the guilty verdict in the killing the judge gave a speech, he told the murderer he was pure what?',\n",
       " 'Changing society using a violent conflict is know as a what?',\n",
       " 'After new coke was discontinued what formula was used?',\n",
       " 'Where is a monkey likely to be found in the rainforest?',\n",
       " 'The billionaire donated a large sum to his former college, this allowed them to construct a new science what?',\n",
       " 'What do humans take in while breathing?',\n",
       " \"Someone who doesn't care about about someone else and wishes them to fail has what feeling towards them?\",\n",
       " 'What does reckless driving lead to on a person?',\n",
       " 'Many containers full of goods are unloaded where after their long sea journey',\n",
       " 'Where is a lion likely to live?',\n",
       " 'My favorite type of entertainment are rollercoasters and ferris wheels, where should I go?',\n",
       " 'Where is a ferret getting lots of attention likely to be found?',\n",
       " \"An attempt to confirm an applicant's reference would fail if the reference does what?\",\n",
       " 'Everybody raised a drink and cheered, they were doing what?',\n",
       " 'What is someone watching a person who is playing guitar doing?',\n",
       " \"The animals weren't good at swimming, so it was hard for them to do what?\",\n",
       " 'Where is a microphone boom likely to be covering a stock market event?',\n",
       " 'John is getting something important.  What does this make him feel?',\n",
       " 'James thought that giving the AI a secular upbringing would be the better choice.  He felt that the alternative might have results that were too what?',\n",
       " \"The new kitten hadn't gotten used to what it was allowed to climb on in most rooms, so the owned kept the bedroom door what?\",\n",
       " 'What happens to cats every day?',\n",
       " 'He got a job dancing and waving an advertisement, he got to be outside instead of stuck inside the what?',\n",
       " 'What could you do if you want to listen to music?',\n",
       " 'Where do you keep a teakettle?',\n",
       " 'Where are seats most likely bleachers?',\n",
       " \"Where does someone lay with their leg elevated when it's broken?\",\n",
       " 'What does a chicken do in a joke?',\n",
       " 'The disease was spreading fast, so what were researchers desperately seeking?',\n",
       " 'Where are you if your reading magazines while waiting for a vehicle on rails?',\n",
       " 'Dry and cracked heels are found on?',\n",
       " 'One way to relieve your hunger if you live near the coast is to do what?',\n",
       " 'He needed to check an electrical connection in the house, where did he look?',\n",
       " 'If an actor is said to be on the “silver screen\" where would you see them perform?',\n",
       " 'He had an index card he had to return, so where did he put it after finding the book he needed?',\n",
       " 'The shelf was showing signs of instability, what should the carpenter fix to avoid any issues?',\n",
       " 'Jan went to the auditorium and listened to the speech. Where might he be?',\n",
       " \"What's the nickname of the monster the beauty loved?\",\n",
       " \"Where do I put my coffee mug after it's dry?\",\n",
       " 'Where are all participants likely to need sports equipment?',\n",
       " 'We were having a canned food drive and I needed to pick up some contributions, where did I go?',\n",
       " 'Where is a telephone booth likely to be red?',\n",
       " 'John is a human who is in a wheelchair due to an accident.  Where would he go to get to the third floor of his apartment building?',\n",
       " 'The mother finished wrapping the very last gift, she then placed it under the what?',\n",
       " 'The wheel was loose, and threatened to fall off when they were what?',\n",
       " 'What is someone unintentionally hurting someone else but unable to stop likely to feel?',\n",
       " 'One might find theirs open, with the letters that had been delivered stolen.',\n",
       " 'The man was playfully wrestling with a woman he was enamored with, what was the physiological result?',\n",
       " 'The teams were evenly matched when competing against one another, what did spectators want to find out?',\n",
       " 'Sally was a senior in the House.  What might she be a member of?',\n",
       " 'Where are a lot of offices in New York?',\n",
       " 'The small cabin was not available, so they were upgraded to what?',\n",
       " \"Johnny was looking for blowfish in places that weren't near America.  Where would he look?\",\n",
       " \"John lives in Texas. If he takes the highway South and doesn't stop, where will he end up next?\",\n",
       " 'He would finally see idea become reality, never in a million years did he what that this would happen?',\n",
       " 'A projector displayed people on the huge screen while the audience laughed.  What might they be watching?',\n",
       " 'Nowadays people have smart ones, but at one time it was cutting edge to have a tiny calculator on your what?',\n",
       " 'What happens when you take a shower after going for a run?',\n",
       " 'What is a negative effect to someone other than a spouse when two spouses are getting divorced?',\n",
       " 'What business has a tower to transmit signals?',\n",
       " 'Where do you go to meet a friend who lives close to you?',\n",
       " 'No matter the background of the person, they should all be given what in applying for the job?',\n",
       " 'James looked for a pencil sharpener.  Where might he look first?',\n",
       " 'The crab was scuttling but strained when he moved, what was impeding him?',\n",
       " 'What is a place where you usually store dishes but not books?',\n",
       " 'What happens to the next appointment when a grooming takes longer than expected?',\n",
       " 'James is very interested in other planets.  He loved the idea of going to mars, and reads books about it all the time.   He dreams of being on what?',\n",
       " 'What would you put in a container?',\n",
       " 'Parents often yell in times of chaos, what are they trying to do?',\n",
       " 'Where would you stand in a line and need a coat if it is cold?',\n",
       " 'James was looking for a place to buy bitcoins.  He searched and found a large menu of what?',\n",
       " 'What is illegal to do when you play cards at a casino?',\n",
       " 'What could there be in a beauty salon?',\n",
       " 'where do you typically find a trash can in the city?',\n",
       " 'Where can you store a small notepad on your person?',\n",
       " 'At a state fair judging pigs requires careful what?',\n",
       " 'What feeling might propel one to instituting civil action?',\n",
       " 'John loves animals and he hates animal abuse.  Because of this, john is very careful about the places he goes.  Where might he avoid going?',\n",
       " 'Reading a newspaper gives you a what about local current events?',\n",
       " 'The lady was doing a one man show of her tell story, when the show began she did what?',\n",
       " 'Where can you buy a fishing rod?',\n",
       " 'What would you tell ali to do if he bumps into you when you are walking?',\n",
       " \"I'm watching tv because there is nothing else to do, what do I expect to get from this?\",\n",
       " 'Where would you store a shopping bag if all the seats in your vehicle are full?',\n",
       " 'What city in the middle east is known for a temple?',\n",
       " 'What do people do to pass time before they can use electronics when fly in airplane?',\n",
       " 'After attending school for twelve years what do you do?',\n",
       " 'When you are expressing yourself by yelling after getting a bruise, what are you feeling?',\n",
       " 'The helm is not something you wear on your head. Rather, it moves the masts on what?',\n",
       " 'Where is a good place to sore a wind instrument in you home?',\n",
       " 'To what part of your home is your morning paper delivered?',\n",
       " 'What do people who are speech therapists do?',\n",
       " \"John hated mosquitoes.  It wasn't the bloodsucking that he disliked, it was that the insects made what?\",\n",
       " 'She curled up under a blanket to get warm, this made her what on the couch as they started movie?',\n",
       " \"He found the blowfish off the coast of the Carolina's, it was where?\",\n",
       " 'He had been doing favors for everybody at work, it was frustrating not getting any what for it?',\n",
       " 'The family was playing cards, what would be a reason for this?',\n",
       " 'What does moving cars entail?',\n",
       " 'What area is likely to contain a large village?',\n",
       " 'What did the business require of everyone walking into their store?',\n",
       " 'The woman experienced great joy, but despite that this was a what?',\n",
       " 'Where would you find a binder containing homework assignments?',\n",
       " 'Shane was supposed to speak at his fathers funeral.  He was a clown, and acted very ridiculous.  This cheerfulness turned off people who expected the funeral to be what?',\n",
       " \"The college kids weren't known for their apartment decor choices, they used a folding chair inside their what?\",\n",
       " 'The department store is located in the Northwest USA.  Where might it be?',\n",
       " 'If you see blinking lights in the air at night, what are you usually looking at?',\n",
       " 'When a monkey is taken away from their home they are often brought to this place where people wear white coats.',\n",
       " 'What could you put a table in if you want the table to be in your house?',\n",
       " 'John is studying animals.   What is one of the many things he has to watch them doing?',\n",
       " 'Sarah thought that she had been home all evening.  That meant that the only time to leave was when?',\n",
       " 'Where did the person have to walk downstairs to get the tool?',\n",
       " 'James was cooking s stew in his apartment kitchen.  Where might he look for a potato.',\n",
       " 'What do only some types of police do?',\n",
       " 'The child really wanted to teach his grandpa to read, he thought it was wrong that he had spent his whole life what?',\n",
       " 'Where do people traditionally get information about the world?',\n",
       " 'The sun was out and the temperature changing rapidly, it was really beginning to what?',\n",
       " \"She'd sooner just spray herself with water than the what she didn't like the smell of?\",\n",
       " 'What would a person expect if they are competent in their school work?',\n",
       " \"Lizards need the sun's heat to regulate their body temperature, this is why you'll see them still on what?\",\n",
       " 'Where did his wife ask him to look first when he complained of missing deodorant?',\n",
       " 'What would a person do if he or she wanted to get good grades?',\n",
       " \"There weren't enough chairs for everyone.  What might have to be delayed?\",\n",
       " 'Where does a shadow usually appear?',\n",
       " 'When we are thankful for getting something what do we do?',\n",
       " 'What can happen in your mind while sleeping?',\n",
       " 'What preposition do you use if you want to combine two words?',\n",
       " 'George ruined the surprise.  How did he do so?',\n",
       " 'Some might say that if you want to do something that results in changing society then you need to start from within, to do this what would you be doing?',\n",
       " \"If I take my heifer out East, where's a place we might end up?\",\n",
       " 'Where in your home would you store birth control pills near your toothpaste?',\n",
       " 'Where do fish spend the majority of their time?',\n",
       " 'What would form on your feet, if you were jogging all day?',\n",
       " 'Water is an important ingredient in what sugary beverage?',\n",
       " 'Where should you find a school in?',\n",
       " 'She a deep love for all her friends, every Friday she had an open invitation for them as she loved to host and what?',\n",
       " 'What were southern institutions where slaves do the labor called?',\n",
       " 'What divider stores papers for work or school?',\n",
       " 'Where is a notebook often purchased?',\n",
       " 'The circus monkey waived a white surrender flag, the conductor joked the monkey must work in the what?',\n",
       " \"If you're afraid of spiders what should you avoid owning?\",\n",
       " 'Where would one find a captive monkey?',\n",
       " 'If you are driving too fast on an icy road you are being what?',\n",
       " 'Who said ignorance was not an excuse for the crime?',\n",
       " 'A yard is made up of what?',\n",
       " 'If someone is outgoing what are they likely to seek?',\n",
       " \"What has happened to a person's money after he or she has used the last of it?\",\n",
       " 'Where is the strategic gold reserve in the U.S.?',\n",
       " 'What is a parents primary duty?',\n",
       " 'What sport is the audience the loudest at?',\n",
       " 'Where can you find a place to eat and places to buy items of many different kinds?',\n",
       " \"If electrical equipment won't power on, what connection should be checked?\",\n",
       " 'If children get confused walking home where may they go?',\n",
       " \"A government seeks what over it's people?\",\n",
       " 'If I recieve a letter from a friend over seas, why might I read it?',\n",
       " 'Where above your kitchen sink could you store canned food?',\n",
       " 'The graveyard was important to build, where should it be built?',\n",
       " 'The people wanted to take the scenic route, they chose the highway that cut through the what?',\n",
       " 'Where would you see a performer at a gathering of you friends?',\n",
       " 'Where is a road known as a motorway?',\n",
       " 'What is the opposite of hosting a crowd?',\n",
       " \"You are seeking to provide yourself what when you're applying for a job?\",\n",
       " 'He called bull when his friend said a bull can be what?',\n",
       " 'How might compassionate thoughful be described as being?',\n",
       " 'What could fighting inflation cause if it is not successful?',\n",
       " 'They took a break from all the rides to have lunch, while eating hamburger they talked about how they were going to what on the next ride?',\n",
       " 'James drove his niece to her father.  Where did he drive?',\n",
       " 'The teachers needed to get their classrooms ready for the school year.  What is one thing they might do?',\n",
       " 'We do not have rest, so how are we feeling?',\n",
       " 'Where can you purchase food and eat it at tables?',\n",
       " 'What could you buy in a bookstore?',\n",
       " 'If you socialize by having trivial conversations it is called what?',\n",
       " 'The kids had been having fun all day, there was now a what?',\n",
       " 'Sarah took poison by accident She found it in the cabinet and. thought that it was what?',\n",
       " 'Some stores trick women to buy products, the sales make it seem like if you buy more you what?',\n",
       " 'If a person is seeing new things, what do they most often feel?',\n",
       " 'A strong laxative will help you keep what kind of bowel movements?',\n",
       " 'Where would there be a connection to go to another place?',\n",
       " 'What does god want people to do for money?',\n",
       " 'What part of the body are lips on?',\n",
       " 'Where would you carry a pen as you go through your day?',\n",
       " 'What white meat goes well with potatos?',\n",
       " 'What is the result of instituting civil action?',\n",
       " 'If you hit someone while driving what could happen to that person?',\n",
       " 'Why do people engage in chatting with friends in class?',\n",
       " 'Where would a human expect to find manufacturing operations?',\n",
       " \"The man didn't like getting out of bed and stepping on the cold tile, so where did he put carpeting?\",\n",
       " \"You'd add pepper and salt to what liquid meal if it's bland?\",\n",
       " 'How can you get the attention of a person across the room?',\n",
       " 'Where can you get a stray small dog?',\n",
       " 'What is something that you feel when you go to the opera?',\n",
       " 'What do people want to do when they love a place that they are going on vacation in?',\n",
       " 'A shark swam in the background aquarium as the card players sat emotionless, what were they playing?',\n",
       " 'Where can someone purchase a contraceptive device without a prescription?',\n",
       " 'Where would you find a desk normally occupied by a young person?',\n",
       " 'Where can you buy socks and jeans?',\n",
       " 'Where did the compassionate farmer allow the heifer to reside during her last days?',\n",
       " 'Where would people be looking at some things which can move, but are not moving?',\n",
       " \"People celebrate by going places and riding rides.  What's one obvious place people might go to celebrate?\",\n",
       " 'The shark was migrating between continents, where did biologists find it?',\n",
       " \"Lilly owns the only kosher deli in the area.  She isn't in a heavily populated area.  Where might she live?\",\n",
       " 'Where do  you park in the parking lot with shopping bags?',\n",
       " 'Stopping being married to one another was a costly task, the lawyers and their what were astronomical?',\n",
       " 'What does one chop us a grape for?',\n",
       " 'What is a place that could have tens of thousands of fiddle?',\n",
       " 'James used the cannon to shoot at something while seeking lunch. It was overkill.  What did he shoot at?',\n",
       " 'What will happen if you are successful when committing suicide?',\n",
       " 'James was a student who had a report that is due tomorrow.  Where might he spend most of his time today?',\n",
       " 'Where could you find many theater?',\n",
       " \"His running escape didn't last long once he tripped, perhaps he should've thought to what?\",\n",
       " 'A school is most likely to be located in what sort of zone?',\n",
       " 'James went to the best steakhouse outside of the South.  Where is James?',\n",
       " 'If I wanted to thank someone for saying I have done a good job, what would I do?',\n",
       " 'The window of the Honda was hit from the inside, not the outside. Where was most of the the broken glass found?',\n",
       " 'What happens to people when they do not have enough food?',\n",
       " 'Utensils are used during what evening activity?',\n",
       " 'Where can you learn about operations with numbers?',\n",
       " 'What creatures performing pollination are loved my millions?',\n",
       " 'What is a common sign that someone is lying?',\n",
       " 'The friends loved competing against one another, it was a good way to work their what?',\n",
       " 'james loved the stars.  In the wilderness, they lit up what?',\n",
       " 'Deciding to watch tv or play with your cell phone might be a routine but they provide no help in being able to do what?',\n",
       " 'Everybody has a little bit of creativity, but only a few lucky ones get to do what for a living?',\n",
       " 'What type of water transportation is human powered?',\n",
       " 'What could someone be doing while performing that cannot be enjoyed by deaf people?',\n",
       " \"If you're standing in line and the line isn't moving what might you feel?\",\n",
       " \"Bob is in a dressing room.  He's putting on waterproof trunks and goggles.  What sort of facility is he most likely visiting?\",\n",
       " 'What do customers do in a store?',\n",
       " 'There are many cubicles in the office, they all have computers for employees to what?',\n",
       " 'If I wanted to store dirt in my home, where could I put it?',\n",
       " 'He was selling all his collector items even the rare plate, he had bought a lot at the what for the weekend?',\n",
       " 'What is a fast but expensive way to send small cargo?',\n",
       " 'The star had 4 rocky planets and 4 gaseous planets orbiting it, what was it part of',\n",
       " 'I need a person to milk a cow would a volunteer do this?',\n",
       " 'Food must be freeze dried before it is taken on what vehicle?',\n",
       " 'What is a useful activity when experiencing loneliness?',\n",
       " 'His day at the office was nearing an end, he went to the start menu on his computer to do what?',\n",
       " 'If a person wants to buy a radio, where are they likely to go?',\n",
       " 'What does someone chatting with friends do when they hear a joke?',\n",
       " 'Where might someone find old clothing?',\n",
       " \"If something is obtuse, what couldn't it be?\",\n",
       " 'Learning usually leads to greater what?',\n",
       " 'The artist knew that this was the peak of his fandom, so he decided it was time for cashing in by doing what?',\n",
       " \"Sam didn't like the people he met while traveling.  What might he do to get away from them?\",\n",
       " 'The children saw superman fly overhead, what did they exclaim as a result?',\n",
       " 'Illegitimate designer handbags will not have a certificate of what?',\n",
       " 'What state shaped like a glove has a lot of farmland?',\n",
       " 'What office furniture stores paper files?',\n",
       " 'Where should an excavation never take place?',\n",
       " 'Where can I find a steakhouse with a view of corn fields?',\n",
       " 'If you harm property after starting a fire where are you likely to end up?',\n",
       " 'Having your marijuana in bags help keep it what?',\n",
       " 'What kind of place could have thousands of statue?',\n",
       " 'Everybody seemed to have a horse not just the regular gamblers, which event always brings out the biggest crowds to the sport?',\n",
       " 'A person is alone in the woods and wounded, what should he do?',\n",
       " 'Why would a company be going public?',\n",
       " 'The human looked down longingly as he sat in the orbiting space station, what did he miss?',\n",
       " 'How can a person end up stopping standing in  puddle?',\n",
       " 'What  might john order at an indian resturant on top of the space needle?',\n",
       " 'What eastern state is home to a mountain?',\n",
       " 'Sam left his muddy shoes in the entryway.  Where might he be?',\n",
       " 'What would a person do if he or she just woke up?',\n",
       " \"He curled up and tried to fall on his shoulder so his arm or what wouldn't take the hit?\",\n",
       " 'If I need deodorant, where do I go to but some?',\n",
       " 'Why might a person take a vacation?',\n",
       " 'What are people playing when they want to take the lead with small papers?',\n",
       " 'Where can you buy a hairbrush along with bandages?',\n",
       " 'Who sits at the center table at a receeption?',\n",
       " 'The clothing was extremely expensive compared to other places, where was it likely purchased?',\n",
       " 'What do you fill with ink to print?',\n",
       " 'Where would a restaurant put a candle?',\n",
       " 'What is KFC who serves chicken?',\n",
       " \"John didn't enjoy procreating.  He had a hangup.  He didn't like to be what?\",\n",
       " 'Where does a marmoset not usually go?',\n",
       " 'What is a child likely to do while going to play?',\n",
       " 'What prevents someone from getting sleep at night?',\n",
       " 'Reaching advantage position in a competitin puts me in what position as compared to others?',\n",
       " 'I wanted  a side chair for people to visit me while I worked, where did I have it put?',\n",
       " 'where do you store wine?',\n",
       " 'John spent too much money buying products for his swollen testicles.  He did so because he was feeling what?',\n",
       " \"People always talked childlike to him, even though his disability was physical and didn't affect his what?\",\n",
       " 'What is the biggest speech in the capital?',\n",
       " 'A person with children might have a lot of plastic things in what place?',\n",
       " 'What do people look for when competing against someone?',\n",
       " \"The swimming pool couln't be refilled due to drought regulations, where was it located?\",\n",
       " 'What is a person likely to feel when they are abandoned by everyone after they stop being married to someone else?',\n",
       " 'A bride and groom are taking care of proposals, what is the likely ceremony?',\n",
       " 'Three quarters of what are covered by the ocean?',\n",
       " 'Why would a person be approached by a lot of people?',\n",
       " 'She had a knack for entertaining, everybody told he she had a what?',\n",
       " 'Where would someone be likely to store a double edge razor?',\n",
       " 'When people want to watch a new move, the often go see it at the?',\n",
       " 'What might a satisfied person do?',\n",
       " 'Dave put his beer where he could get to it, but it would be off the floor.  Where did he put it?',\n",
       " 'Eating breakfast with a large family leads to a pile of what in the sink?',\n",
       " 'Where would you buy a ticket to sit in a room with a lot of chairs facing the same direction?',\n",
       " \"If I wanted to store my chess pawn when I wasn't using it, what would be a good place for that?\",\n",
       " \"If you're known to buy presents for others often you would be called what?\",\n",
       " \"There aren't many anemone in what glove-shaped state?\",\n",
       " 'The keys were black and white, what were they attached to?',\n",
       " \"They don't get grades or sit at desks, but crowds of fish do what?\",\n",
       " 'What kind of people will someone who is in charge of project look for?',\n",
       " 'Where you have finished a conversation with a person what do you say?',\n",
       " 'What do you need to run after ball?',\n",
       " 'Where could you find some airplanes that are not being used?',\n",
       " 'She was processing the wool, she kept her leg bouncing to operate the what?',\n",
       " 'Where would you put a computer other than a desk?',\n",
       " 'Where do you buy treats for kids over a counter?',\n",
       " 'Long term consumption of beer can lead to all sorts of problems, it can be quite what?',\n",
       " 'When going to sleep what noise does a human make?',\n",
       " 'The boy was too nervous to dance, so what was he doing progressively at the ball?',\n",
       " 'Where could you find a laundry room that is only used by staff?',\n",
       " 'Where does a beaver leave?',\n",
       " 'What is the opposite of a village?',\n",
       " 'What does someone living life fully feel?',\n",
       " \"The artist didn't use many colors to capture the view, he was famous for his very plain what?\",\n",
       " 'When you experience boredom, what can you do on television?',\n",
       " 'It had a beach with shallow water, while not the ocean this was a hot spot all the locals enjoyed on the what?',\n",
       " 'What would happen to you if you are not good at playing violin?',\n",
       " 'Wanting to avoid the cabbage spoiling, where did he put it?',\n",
       " 'If people listen, they can understand each other better.  If they understand each other, they can do what?',\n",
       " 'What place would a person go to look at zebras?',\n",
       " 'Where might a human sit for extended periods over a bowl of water?',\n",
       " 'The window across the street was broken and John felt guilty. He never meant to damage what?',\n",
       " 'If I have a forgiving attitude toward someone, what do they receive?',\n",
       " 'I was shopping at a car dealership, what did a salesman do?',\n",
       " 'The fact the two sides were able to even reach tentative agreement was a feat to what?',\n",
       " 'The police man was waving flares, what did he do with the impatient car?',\n",
       " 'Where do you watch garbage?',\n",
       " 'In what place could you find air that has been breathed by many people recently?',\n",
       " 'What business uses lots of potatoes?',\n",
       " 'What does a judge do when someone is convicted of a crime?',\n",
       " 'Where do security guards usually drive around in golf carts and protect young adults?',\n",
       " 'The man needed flooring, where was he looking to install it?',\n",
       " 'Where can you find pamphlets regarding diseases and ailments?',\n",
       " 'What would humans do when their legs are tired?',\n",
       " 'What planet is the atlantic ocean part of?',\n",
       " \"Mark wanted to know the truth, because he didn't want to continue existing in what?\",\n",
       " 'What animal produces milk?',\n",
       " \"Where is disease often spread but shouldn't be?\",\n",
       " 'A beaver builds structures to block what sort of feature?',\n",
       " 'What would someone wear to protect themselves from a cannon?',\n",
       " 'Society cannot exist without numbers.   They only rise up in what sort of spaces?',\n",
       " 'Where is a snake likely to reside?',\n",
       " \"John couldn't find a place to stay, and he didn't want to waste money.  He picked a place that was inexpensive and offered few luxuries.  Where might he be staying?\",\n",
       " 'Where does someone not happy to take their car?',\n",
       " \"Bill bought an upright piano but didn't have anywhere to put it because he lived where?\",\n",
       " 'Where would you hear a viola along side many other string and brass instruments?',\n",
       " 'Traders work on the floor of the stock what?',\n",
       " 'To gain her trust the real estate agent was very polite, delightful and all around what?',\n",
       " 'What could you find at a bus station that can help you?',\n",
       " 'Where are small grapes used?',\n",
       " 'Rumors of roving bands of monsters killing people could lead to what?',\n",
       " 'Remembering past successe is likely to cause what?',\n",
       " 'What would you use if you wanted to make some columns of numbers?',\n",
       " 'A person notices popcorn, cotton candy on the grass, where is he likely?',\n",
       " 'What happens when people are waiting for something?',\n",
       " 'What corner areas have lots of windows?',\n",
       " 'What would a person do to help someone that is not able to speak coherently?',\n",
       " 'In war, your primary method is combat, but your goal is to do what?',\n",
       " 'What would something be if you do not need it?',\n",
       " 'A person would carry a large netted drawstring bag to what sort of place?',\n",
       " 'The investigator considered the gun evidence, where did he send it?',\n",
       " 'Where would you read a passage but not write it?',\n",
       " 'Where could you find an armchair that is used by only a few people?',\n",
       " 'My house is very dry, with little water in the air. What tool should I use to fix this?',\n",
       " 'What do all rooms facing outside have?',\n",
       " 'What do all humans have on the side of their head?',\n",
       " 'Where is one likely to hear a harpsichord?',\n",
       " 'She had been applying for job for weeks with no call back, she knew she was qualified, so what did she feel?',\n",
       " 'What usually happens to people who are models?',\n",
       " 'What has highly criticized security?',\n",
       " 'How often are secular parties held?',\n",
       " 'Why would I want to be exercising?',\n",
       " 'Why would someone be wet after being full of fear?',\n",
       " 'A person is putting on makeup, what is their likely goal?',\n",
       " 'What will happen to your knowledge with more learning?',\n",
       " 'The wind tore off the shingles, what was the wind like?',\n",
       " 'Dan outfitted his house to run on the oldest heat source on Earth. What is the oldest heat source on Earth?',\n",
       " 'Where is a horse likely to live?',\n",
       " 'Why does she sing so much?',\n",
       " \"Ice fishing can be done surprisingly far out most winters on what greatest of the Michigan's greats?\",\n",
       " \"Though he was an adult he still stereotypical slept on a sofa bed in his parent's what\",\n",
       " 'James kept a clipboard where he could easily find  it.  Where might he keep it?',\n",
       " 'The mother was worried about all the spills, so she bought a rug for under the what?',\n",
       " 'If there is a stale smell in the air coming from the kitchen, what should one check for the source of the smell?',\n",
       " 'What would cause someone to use invitro for reproducing?',\n",
       " \"Why shouldn't you walk barefooted after the rain?\",\n",
       " 'What will all the differences equal?',\n",
       " 'What would be considered a success when attempting procreation?',\n",
       " 'The janitor got his pail out of where?',\n",
       " 'The doctor recommended washing hands, what was being promoted?',\n",
       " \"The cloth's are not yet placed where they belong, where should we put them?\",\n",
       " 'Where is one likely to purchase listening vinyl?',\n",
       " 'Sally took her medicine and experienced strong side effects.  What did doctors say about the side effects?',\n",
       " 'What is a student about to do if they are sitting in front of a number of black and white keys?',\n",
       " 'The robot shockingly began to read book after book, it had apparently done what?',\n",
       " 'What is the purpose of the cabin in an airplane?',\n",
       " 'You can buy a pen here.',\n",
       " 'What should the bean bag chair sit on?',\n",
       " 'This city in Northern Norway is filled within things to do like Polar Nights half marathons and located in the middle of the Northern lights oval, which city is it?',\n",
       " 'Where can you buy a binder?',\n",
       " 'James was delayed for a couple of hours because he had a connection.  Where might his connection be?',\n",
       " 'Where would you find isopropol alcohol and safety glasses?',\n",
       " 'The man tried to run, but he could not. He could that he could only move by doing what?',\n",
       " 'Collections of atoms called molecules make up everything you can hold in your what?',\n",
       " 'What is the opposite of foolhardy?',\n",
       " 'Where can you get in shape and drink at a juice bar?',\n",
       " 'What is an way for people to meet with each other?',\n",
       " 'What do horses do to get energy?',\n",
       " 'Where would you see some people standing on a line near a road?',\n",
       " \"The museum made an odd choice for the koala display, they put the stuffed creature in what area where you'd usually find a panda?\",\n",
       " 'What does exercising immediately lead to?',\n",
       " 'There are a lot of ways to relax, for this person it is simply opening one up and what?',\n",
       " 'If a person does something to hurt someone else, they might do what?',\n",
       " 'Where was the apple tree said to contain something forbidden?',\n",
       " 'There is a lot of sugar in what food that fits in your hand?',\n",
       " 'Where do you wait in a reception area for a meeting?',\n",
       " 'She was bad at dancing, so what basic skill did the instructor teach her?',\n",
       " \"Billy's mother tripped over a stuffed animal.  She yelled at him not to leave his things where?\",\n",
       " 'A student wants to hear what the professor is saying, what does he do?',\n",
       " 'How would someone feel after going for run?',\n",
       " 'If a student was about to graduate, they would no longer be attending what?',\n",
       " 'What are adult people usually expected to do?',\n",
       " 'Where would you dispose of a broken icebox?',\n",
       " 'Mary was a bad girl, but she was always open about that.  People liked her because she was what?',\n",
       " 'Where may I view sharks in a clear tunnel?',\n",
       " 'Dan said that getting in line was the best choice because it would lead to what?',\n",
       " 'Where could you find a theater which only has unpaid actors?',\n",
       " 'The competition was to see who would be the last one the drop the object, the hard part was you had to have your arm extended straight out while what the object?',\n",
       " 'Why would someone confess to committing murder?',\n",
       " \"Which long saga will we be watching on tonight's program?\",\n",
       " 'She wanted to make a quilt of velvet, where should she look?',\n",
       " 'What is a convenient place for a bus station?',\n",
       " \"The crowd wasn't that big.  It can better be described as what?\",\n",
       " \"Where would you put silverware once they've dried, but you're not ready to use them.\",\n",
       " 'After bringing eggs home from the store in what are they held?',\n",
       " 'Where would you put an account book if you are leaving and do not need to bring it with you?',\n",
       " \"If clothes have developed a smell and can't be washed what should you do with them?\",\n",
       " 'What do you feel from playing football?',\n",
       " 'The wood became fossilized, what did the paleontologists call it when they found ti?',\n",
       " 'What is a place that someone can go buy a teddy bear?',\n",
       " 'What might the inability to learn cause?',\n",
       " 'Who does the government help with schools?',\n",
       " 'A small dog is lost in New England, where would it likely be found?',\n",
       " 'What do you do to hold loose papers together?',\n",
       " 'People were talking on the corner, who were they talking with?',\n",
       " \"He finally found someone as ugly as him, knowing he wouldn't be the one sticking out was what?\",\n",
       " 'The band enjoyed their success and fans, they loved to what at the start of every concert?',\n",
       " 'During the brainstorming session there was a lot of talking and what?',\n",
       " 'Where could you find multiple ruler that are owned by different people?',\n",
       " 'Why is grooming often recommended to greasy teens?',\n",
       " 'We want to try some new barbecue sauces, where should we buy some?',\n",
       " 'Where can you see a mammoth in NYC?',\n",
       " 'Where could you put some olives to prevent them from getting nearby food wet?',\n",
       " 'When having food at a formal place, what do you usually do?',\n",
       " 'What body of water is typically shallow water?',\n",
       " 'How do you indicate that you agree wtih someone?',\n",
       " 'James wanted to stop competing.  What might he have been feeling?',\n",
       " \"Always wash your hands before eating, you don't want to get germs onto food and inside your what?\",\n",
       " 'The explorers found a central passage, much to their delight it led straight to the ancient buried what?',\n",
       " 'Along what feature will you find a rosebush?',\n",
       " 'A man was driving himself to the airport, where did he put his luggage?',\n",
       " 'What is someone likely to feel after receiving a gift that is not common?',\n",
       " \"The banjo finds it's history in the Caribbean, but it's probably most famous where?\",\n",
       " 'The print was extremely small, as he was reading letter after letter he began to suffer eye what?',\n",
       " 'If I am forgiving, what hidden force may be activated in my life?',\n",
       " 'When playing baseball they keep track of mistakes, this stat is called what?',\n",
       " 'What does someone need to do to begin creating art?',\n",
       " 'If I have a reception with many people attending, where should I be sure to hold it?',\n",
       " \"What should you do if your pens aren't work?\",\n",
       " 'Who designs a building?',\n",
       " 'Where is a bay always found?',\n",
       " 'What past time are people engaged in when they are traveling along liquid?',\n",
       " 'Where can you find a movie theater along with other stores in one placE?',\n",
       " 'The man on the street corner was showing off a wristwatch, he was trying to what it for drug money?',\n",
       " 'The man needed to buy flooring, where was he looking for it?',\n",
       " 'Bill was awaking, what was happening to him physiologically?',\n",
       " 'Why might someone want to be buying beer?',\n",
       " 'What kind of radio does someone use to reach base?',\n",
       " 'The person turned the oven on and put a pizza in, what happened one hour later?',\n",
       " \"You weren't suppose to touch the wild animals, they could what?\",\n",
       " 'Danny hated helping people.  It always brought what?',\n",
       " \"A person who wants to make more at their job but can't will often need to find a what?\",\n",
       " 'What could happen to you after you see some beautiful clouds above you?',\n",
       " 'As a human in a large northeastern city, where can you see animals?',\n",
       " 'What is something you do  in a bank?',\n",
       " 'Where would you find fungus growing on something made from milk?',\n",
       " 'When a snake prefers warm, sunny weather, where would it likely want to live?',\n",
       " 'The jar was plastic, just like most of the stuff in the kitchen.  John preferred glass, and wished he was somewhere else.  Where does he want to be?',\n",
       " 'When she went to examine the thing, what was she considering doing with it?',\n",
       " \"Where would you find a metal rod in most people's preferred method of transportation?\",\n",
       " \"The man set the cup on the table.  It didn't matter.   He didn't heave anything to put it on, and he lacked the what to balance it?\",\n",
       " 'Where do you buy a glass of wine?',\n",
       " \"If a human wants to enjoy another human's company, where might they go?\",\n",
       " 'It was breakfast time.  Brad ordered eggs, toast, and something to drink. What might he drink?',\n",
       " 'You might head to the locker room after getting a green drink here.',\n",
       " ...]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csqa[\"train\"][\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "de8b0b23-a880-47c6-aa9e-ab95dbca8565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e6766a66f8d326bf00fbf628a0e4ef24'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csqa[\"train\"][15][\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "c7d072f9-5a5f-47d0-9a04-af050152e0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def remove_non_alphanumeric(text):\n",
    "  \"\"\"\n",
    "  Removes all non-alphanumeric characters from a string.\n",
    "\n",
    "  Args:\n",
    "    text: The string to process.\n",
    "\n",
    "  Returns:\n",
    "    The string with all non-alphanumeric characters removed.\n",
    "  \"\"\"\n",
    "\n",
    "  # Use a regular expression to match all non-alphanumeric characters\n",
    "  pattern = r'\\W+'\n",
    "\n",
    "  # Replace all matches with an empty string\n",
    "  return re.sub(pattern, '', text)\n",
    "\n",
    "\n",
    "# CommonSenseQA Question ID\n",
    "\n",
    "# dataset is either train, dev, or test from csqa huggingface\n",
    "# return None if not found\n",
    "def question_to_qid_from_data(question: str, dataset) -> str:\n",
    "    try:\n",
    "        q_index: int = dataset[\"question\"].index(question)\n",
    "        qid = dataset[q_index][\"id\"]\n",
    "\n",
    "        return qid\n",
    "    except:  # question not found\n",
    "        # Try a more accurate method of search\n",
    "        # remove whitespace and special characters\n",
    "        question_bare: str = remove_non_alphanumeric(question)\n",
    "        #print(f\"question_bare: {question_bare}\")\n",
    "        questions: List[str] = dataset[\"question\"]\n",
    "        for (i, q) in enumerate(questions):\n",
    "            q_bare: str = remove_non_alphanumeric(q)\n",
    "            #print(f\"  q_bare: {q_bare}\")\n",
    "            if q_bare == question_bare:\n",
    "                qid = dataset[i][\"id\"]\n",
    "                return qid\n",
    "\n",
    "        # Ok the question for sure is not found\n",
    "        return None\n",
    "\n",
    "\n",
    "def question_to_qid(question: str):\n",
    "    qid = question_to_qid_from_data(question, csqa[\"train\"])\n",
    "\n",
    "    if qid is not None:\n",
    "        return qid\n",
    "\n",
    "    qid = question_to_qid_from_data(question, csqa[\"validation\"])\n",
    "\n",
    "    if qid is not None:\n",
    "        return qid\n",
    "\n",
    "    qid = question_to_qid_from_data(question, csqa[\"test\"])\n",
    "\n",
    "    if qid is not None:\n",
    "        return qid\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "# dataset is either train, dev, or test\n",
    "# return None if not found\n",
    "def qid_to_input_from_dataset(qid, dataset):\n",
    "    def index_preserve_dims(data_elem, index: int):\n",
    "        if type(data_elem) is list:\n",
    "            return [data_elem[index]]\n",
    "        else:  # torch tensor\n",
    "            return data_elem[index].unsqueeze(0)\n",
    "        \n",
    "    \n",
    "    for qids, labels, *input_data in dataset:\n",
    "        #batch_size: int = len(qids)\n",
    "        try:\n",
    "            index: int = qids.index(qid)\n",
    "\n",
    "            label_index: int = labels[index]\n",
    "            input_data_from_qid = [index_preserve_dims(input_data_element, index) for input_data_element in input_data]\n",
    "\n",
    "            return (label_index, input_data_from_qid)\n",
    "        except:  # not in the list\n",
    "            continue\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def qid_to_input(qid):\n",
    "    input_ = qid_to_input_from_dataset(qid, dataset.train())\n",
    "\n",
    "    if input_ is not None:\n",
    "        return input_\n",
    "\n",
    "    input_ = qid_to_input_from_dataset(qid, dataset.dev())\n",
    "\n",
    "    if input_ is not None:\n",
    "        return input_\n",
    "\n",
    "    input_ = qid_to_input_from_dataset(qid, dataset.test())\n",
    "\n",
    "    if input_ is not None:\n",
    "        return input_\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def question_to_input(question: str):\n",
    "    qid = question_to_qid(question)\n",
    "    return qid_to_input(qid)  # returns a tuple (label_idx, input_data_from_qid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "7a5adb06-5f9d-4848-a8ac-193f7e0f5cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor(2, device='cuda:0'), [tensor([[[    0, 42489, 11991,    16,  1202,     4,  1437,  1648,    11,    10,\n",
      "            455, 35239,  1737,    47,   214,   533,     7,   146,  6160,     6,\n",
      "           6160,    40,  1303, 36939,  1258,     6,    61,    40,    28,  9800,\n",
      "              6,    61,    40,  1303,    99, 33647,     2,     2,   357,  4358,\n",
      "              2,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [    0, 42489, 11991,    16,  1202,     4,  1437,  1648,    11,    10,\n",
      "            455, 35239,  1737,    47,   214,   533,     7,   146,  6160,     6,\n",
      "           6160,    40,  1303, 36939,  1258,     6,    61,    40,    28,  9800,\n",
      "              6,    61,    40,  1303,    99, 33647,     2,     2,    81, 22710,\n",
      "              2,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [    0, 42489, 11991,    16,  1202,     4,  1437,  1648,    11,    10,\n",
      "            455, 35239,  1737,    47,   214,   533,     7,   146,  6160,     6,\n",
      "           6160,    40,  1303, 36939,  1258,     6,    61,    40,    28,  9800,\n",
      "              6,    61,    40,  1303,    99, 33647,     2,     2,  8413,     2,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [    0, 42489, 11991,    16,  1202,     4,  1437,  1648,    11,    10,\n",
      "            455, 35239,  1737,    47,   214,   533,     7,   146,  6160,     6,\n",
      "           6160,    40,  1303, 36939,  1258,     6,    61,    40,    28,  9800,\n",
      "              6,    61,    40,  1303,    99, 33647,     2,     2, 37721,  1033,\n",
      "              2,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
      "         [    0, 42489, 11991,    16,  1202,     4,  1437,  1648,    11,    10,\n",
      "            455, 35239,  1737,    47,   214,   533,     7,   146,  6160,     6,\n",
      "           6160,    40,  1303, 36939,  1258,     6,    61,    40,    28,  9800,\n",
      "              6,    61,    40,  1303,    99, 33647,     2,     2, 20816,     2,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0]]],\n",
      "       device='cuda:0'), tensor([[[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0]]], device='cuda:0'), tensor([[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "          0, 0, 0, 0, 0, 0, 0, 0]]], device='cuda:0'), tensor([[[ True, False, False, False, False, False, False, False, False, False,\n",
      "          False, False, False, False, False, False, False, False, False, False,\n",
      "          False, False, False, False, False, False, False, False, False, False,\n",
      "          False, False, False, False, False, False,  True,  True, False, False,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True, False, False, False, False, False, False, False, False, False,\n",
      "          False, False, False, False, False, False, False, False, False, False,\n",
      "          False, False, False, False, False, False, False, False, False, False,\n",
      "          False, False, False, False, False, False,  True,  True, False, False,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True, False, False, False, False, False, False, False, False, False,\n",
      "          False, False, False, False, False, False, False, False, False, False,\n",
      "          False, False, False, False, False, False, False, False, False, False,\n",
      "          False, False, False, False, False, False,  True,  True, False,  True,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True, False, False, False, False, False, False, False, False, False,\n",
      "          False, False, False, False, False, False, False, False, False, False,\n",
      "          False, False, False, False, False, False, False, False, False, False,\n",
      "          False, False, False, False, False, False,  True,  True, False, False,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n",
      "         [ True, False, False, False, False, False, False, False, False, False,\n",
      "          False, False, False, False, False, False, False, False, False, False,\n",
      "          False, False, False, False, False, False, False, False, False, False,\n",
      "          False, False, False, False, False, False,  True,  True, False,  True,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
      "           True,  True,  True,  True,  True,  True,  True,  True,  True,  True]]],\n",
      "       device='cuda:0'), tensor([[[     0,   1949,   3002,   3613,   5153,   6398,  10012,  10016,\n",
      "           10989,  40875,  43569,  51091,  55260,  66455,  76968,  79597,\n",
      "          141027, 308991,   1857,   3660,  60249, 105909,   9700,  60933,\n",
      "          313240,  19868, 180197,  44524,  54774, 503462,  54297, 279285,\n",
      "           81463,  66022,  53400, 157021, 422102,  54383, 569340,  60224,\n",
      "          725179, 431162,  44504,   1832,  58927,  60288,  31586,   1006,\n",
      "           70460, 364114,  66266,  13439, 194540,  58449, 519689,  60245,\n",
      "           64668,  48691,  37969, 368297,   3079,  58452, 257446,  12383,\n",
      "          560713,  22091,  60445,  54479,  10390,  60857,   2457,   6303,\n",
      "           62175,  12973,  31218,  65491,  10995,  57321,  14307,   8790,\n",
      "          725185,  11066,   6009, 322604,  65584,   1833, 198089,   1004,\n",
      "             290,  54540, 581836,  54476,  55768,  10996,  65938,   2572,\n",
      "          225749,  40113,  57507,  66140,  21126,  55789, 128842,   5355,\n",
      "           37846,  26571,   9857, 672626,   6562,   8042,  37664,   7686,\n",
      "           44560,   3211, 487510,  59219,   1427,  10018,   7321,  54491,\n",
      "           65936,  13092,  13436,   9723,  10015,   5338,  74455,   1328,\n",
      "           36026,  20442, 256220,  29067,  13679, 108014,   6423,   2814,\n",
      "          228328,  15156,  62747,  30634,  10241,  63954,  63767,   4813,\n",
      "            7619,   9854,   3320, 149151,   7250,  50021,   3332,   3611,\n",
      "            1002,  13434,   2847,   3327,  26019,  10811, 239812, 560710,\n",
      "             296,   2019,  10245,  14238,  13957,   3734,   9093, 122341,\n",
      "            4780,   6754,    198,   9439,   6720,   7635,  16173,   8381,\n",
      "           11210,  15099,  56268,  55250, 157867,  24425,  19307,  62190,\n",
      "            2453,  22676,   2868,   8403,  12695,  57310,   4267, 386455,\n",
      "           14352,  65981,   5855, 628784,   8541,  14462,  64373,  62815],\n",
      "         [     0,   1949,   3002,   3613,   5153,   6398,  10012,  10016,\n",
      "           10989,  40875,  43569,  51091,  55260,  66455,  76968,  79597,\n",
      "          141027, 308991, 612985,   9700, 503462, 180197,  54774, 279285,\n",
      "          313240, 569340,  53400,  44524, 364114, 157021,  19868,  58927,\n",
      "           58452,  54297, 725179,  64668, 194540, 519689,  31586,  13439,\n",
      "           66022, 581836,   8790, 422102,  44504,  11066,  70460, 431162,\n",
      "           22091,  62175,  48691,  54479,  60445,  57321, 560713,  15156,\n",
      "          257446,  37969,  10995,   2457, 725185,   3079,  66266,  65938,\n",
      "           60857,   3211, 368297,  54383,  10390,   6303,  65584,  55768,\n",
      "            1006,  54476,   1004,  60224,  12383, 128842,  26571,  57507,\n",
      "           54540,   1002,   2572,  13092,  13434,  21126,    296,  37846,\n",
      "             290, 228328,   7686,   6009,  12973,   7321,  10996,  31218,\n",
      "           13436,  55789,  29067,  59219,  44560, 225749,  30634,  54491,\n",
      "            1833,  65936, 322604,   5338,   1328,  37664,  15099,  10018,\n",
      "            3327,   8381,  20442,  10015,  66140,   9857,   2814,   4813,\n",
      "            6423,   7619,   9854,   6754,   3332, 239812,   2847, 487510,\n",
      "           74455,  13679,  22676,  62747,  63954, 149151,   3734,   3611,\n",
      "            9439,  62190,  45601,  10811,  13957,  26019,   1697,  24425,\n",
      "           65981,  57310,   2453,   2019,   8042,   7635,  10241,   8541,\n",
      "          560710,    443,   8403,  55250,   2939,  48825, 157867,   7250,\n",
      "            4267,    307,   2868,  54310,    198,  63767,   5855, 386455,\n",
      "          213639,   3610,  12739,   5280,  13560,  14352,   4300,   2443,\n",
      "          148673,   7599, 386552,   5535,  19307,    568,   5556,    391,\n",
      "            3918,   9948,  23833,  73835,  62815, 114428,  16935,    425,\n",
      "          628784,   2412,  26242, 483503,   5699,  18327,   3296,   7676],\n",
      "         [     0,   1949,   3002,   3613,   5153,   6398,  10012,  10016,\n",
      "           10989,  36784,  40875,  43569,  51091,  55260,  66455,  76968,\n",
      "           79597, 141027, 308991,  22078,   9700, 503462, 313240, 279285,\n",
      "          180197, 569340,  54774,  65929,  54297, 422102,  44524,  56474,\n",
      "          364114,  66022,  31586,  65346,  53400,   8790, 157021,  48691,\n",
      "           54500, 519689, 194540, 725179,  19868,  58466, 560713,  62175,\n",
      "           13439,  60245, 431162,  70460,  44504,  58452,  58927,  22091,\n",
      "           12383,  37969,  54479,  64668,    907,   3079,  57507, 257446,\n",
      "            2457,  10995,  61470,  65938,  57321, 368297,  65584,  54383,\n",
      "           60224,   3211,  66266,   1004,   6303,   6009,  55871,  55768,\n",
      "           54476,   6423,  26571, 128842, 581836,  10390, 239812,    290,\n",
      "           60445,   2572,  60857, 725185,  12973,  37846,  54540,  31218,\n",
      "            1006,  21126,  59219,  13434,  15156,  11066,  44560,  37664,\n",
      "           13092,   4813, 225749,   9854,  10015,   1002,   1833,  66140,\n",
      "           54491,   9857,   6754,  64399,   7321,  65936,  10018,  29067,\n",
      "           62747,   7619, 322604,  10996,   2847,  20442,  13679,   7686,\n",
      "           62190,   1328,   8381, 228328,   3332,   8042,   3327,  55789,\n",
      "           30634,   7635,  63954,   5338,  15099, 487510,   3611,   2453,\n",
      "           74455,   2814,  13436,  57310,   1697,   3734,    296,   8541,\n",
      "          149151,   9439,  10811,  45601,  65981,  13957,    198,  63767,\n",
      "            2019,  10241,  55250, 560710,   8403,  48825,   7250, 157867,\n",
      "            2868,  12739,  22676,  54310,  26019,    568,  24425,   3610,\n",
      "           32627, 386455, 628784,   2939,   5855,  14352,    307,   5556,\n",
      "           13560,   4267,   9948,   7381,   2443,  19307,    443,    425,\n",
      "            5280,   4300,    391,  62815,  73835,  16935,   2412, 213639],\n",
      "         [     0,   1949,   3002,   3613,   5153,   6398,  10012,  10016,\n",
      "           10989,  40875,  43569,  51091,  55260,  60618,  66455,  76968,\n",
      "           79597, 141027, 308991,  10995,  43574,   1309, 157570, 716657,\n",
      "           54774,  58927,   9700, 157509, 581836, 313240, 422102,  58452,\n",
      "           13439,  64668,  70460,  53400, 503462,  57321, 431162,  60245,\n",
      "          569340,  44524, 194540, 257446,  22091,  19868, 157021,  54479,\n",
      "            3324,  54297,  48691, 519689, 385464, 364114,  31586,  60445,\n",
      "          725179, 180197, 560713,  44504,  62175,  26571, 128842, 279285,\n",
      "          322604,  66022,  66266,  60857,  54383,  37969,  12383, 368297,\n",
      "           65584,  60224,    290,  54540,  54476,   8790,   2457,  55768,\n",
      "           10996,   6303,  57507,  21126,   3079,  65938,  11066,  12973,\n",
      "          725185,  54491,  37664,  10390,  66140,  59219,   1004,   1006,\n",
      "            8042,  31218,  37846,   7321,  10018,   9857,   7686,  44560,\n",
      "          225749,  29067,  15576,   3211,  13092,  65936, 487510,   2572,\n",
      "           62190,  10015,  20442,  13434, 486544,  62747,   1328, 239812,\n",
      "            1833,   3332,   2814,   6423,   2847,   9854, 228328,  30634,\n",
      "            3327,   3734,   6009,  74455, 122341,   7619,  13679,  63954,\n",
      "           10811, 628784,   6754, 560710,   5338,  19307,  63767,  55789,\n",
      "          149151,   1002,   8381,  62815,  15099,  36026,   2453,  22676,\n",
      "           57310,  24425,    198,   4813,  15156,  13436,  13957,    296,\n",
      "           45601,  10245,  10241,   9439,  55250, 386455,   2019,  54310,\n",
      "            7635,  26019,  65981,   8403,   1697,   3611,   2868,   4267,\n",
      "            8541,    568,   5855,   2443,   3610,   9948,   2939,  12739,\n",
      "            7250,  13560,  16935,    307,   5280,   4300,    391,   5556,\n",
      "            2412,   7599,  26242, 157867, 386552,    443,  48825,   5699],\n",
      "         [     0,   1949,   3002,   3613,   5153,   6398,  10012,  10016,\n",
      "           10989,  32184,  33315,  40875,  43569,  51091,  55260,  66455,\n",
      "           76968,  79597, 141027, 308991,  40233,  54290,  34665,  54297,\n",
      "           64788, 503462, 313240,  54774, 279285,   9700,  56474,  66022,\n",
      "          569340, 180197,  13439,  65346,  44524, 725179,  58466,  61460,\n",
      "           60245, 194540, 560713,  58452, 157021,  31586,  56350,  22091,\n",
      "           48691,  53400,  12383, 364114,  62175,  54365,  64668,  65049,\n",
      "            2457,  64552,  58927,  54383,  55666,   8790, 431162, 519689,\n",
      "           65938,  19868,  54479,  57507,  70460,  66266,  37969,  57321,\n",
      "           11066,  44504,  51148,  10390,  60445,  60972,  55768,  54476,\n",
      "           60857,   2572,  54447,  60224,  12973,  65584, 128842,  59219,\n",
      "          368297,   1006,   9854,  31218,  64625,  21126, 422102,   6423,\n",
      "           63783,  26571,   7619,    290,   3211,  37846,  13092,   1833,\n",
      "           54540,  13434,   2847,  44560,   1328,  27015,  10015,   9857,\n",
      "          257446,  15156,  66140,   3079,   1004,  29067,  37664,  62190,\n",
      "          581836,   7686,   6009,   7635,  65936,   7321,  62747,   8381,\n",
      "           10995,   1002,   6303,  54491,  10018, 239812, 725185,  13679,\n",
      "            2814,  30634,  10996,   3332,  74455,   3327,  15099,   8042,\n",
      "            3611, 228328,  63954,   5338,  63767,   6754,  65981,   2019,\n",
      "            1697,  13957, 560710,   3734, 149151,  10811, 322604,   8403,\n",
      "           20442,  55250,  10245,  10241,  54310,  13436,    198,   8541,\n",
      "            4813,  45601,  22676,  24425,  57310,   4267,   2443, 628784,\n",
      "           19307, 386455,   9439, 487510,  26019,   7250,   9948,   2453,\n",
      "           13560,   2412,  12739,  55789,   5855,   2868,  23833,    576,\n",
      "            4300,  26242,  62815,  14947,  56155,   5556,   5535,  48825]]],\n",
      "       device='cuda:0'), tensor([[[3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
      "         [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
      "         [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
      "         [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2],\n",
      "         [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "          2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]]], device='cuda:0'), tensor([[[[-0.3418],\n",
      "          [-0.9313],\n",
      "          [-0.7732],\n",
      "          [-0.6398],\n",
      "          [-0.5665],\n",
      "          [-0.8247],\n",
      "          [-0.6646],\n",
      "          [-0.6579],\n",
      "          [-0.7615],\n",
      "          [-0.5715],\n",
      "          [-0.6317],\n",
      "          [-0.5875],\n",
      "          [-0.6212],\n",
      "          [-0.8102],\n",
      "          [-0.7411],\n",
      "          [-0.7553],\n",
      "          [-0.6632],\n",
      "          [-0.5721],\n",
      "          [-0.7333],\n",
      "          [-0.5897],\n",
      "          [-0.5313],\n",
      "          [-0.4728],\n",
      "          [-0.5068],\n",
      "          [-0.5182],\n",
      "          [-0.5261],\n",
      "          [-0.5282],\n",
      "          [-0.5286],\n",
      "          [-0.5365],\n",
      "          [-0.5391],\n",
      "          [-0.5396],\n",
      "          [-0.5437],\n",
      "          [-0.5438],\n",
      "          [-0.5450],\n",
      "          [-0.5474],\n",
      "          [-0.5491],\n",
      "          [-0.5499],\n",
      "          [-0.5540],\n",
      "          [-0.5552],\n",
      "          [-0.5584],\n",
      "          [-0.5595],\n",
      "          [-0.5618],\n",
      "          [-0.5661],\n",
      "          [-0.5667],\n",
      "          [-0.5696],\n",
      "          [-0.5701],\n",
      "          [-0.5715],\n",
      "          [-0.5735],\n",
      "          [-0.5741],\n",
      "          [-0.5763],\n",
      "          [-0.5819],\n",
      "          [-0.5833],\n",
      "          [-0.5855],\n",
      "          [-0.5878],\n",
      "          [-0.5884],\n",
      "          [-0.5896],\n",
      "          [-0.5911],\n",
      "          [-0.5913],\n",
      "          [-0.5971],\n",
      "          [-0.5981],\n",
      "          [-0.6003],\n",
      "          [-0.6022],\n",
      "          [-0.6024],\n",
      "          [-0.6036],\n",
      "          [-0.6064],\n",
      "          [-0.6095],\n",
      "          [-0.6129],\n",
      "          [-0.6143],\n",
      "          [-0.6203],\n",
      "          [-0.6253],\n",
      "          [-0.6295],\n",
      "          [-0.6297],\n",
      "          [-0.6301],\n",
      "          [-0.6311],\n",
      "          [-0.6319],\n",
      "          [-0.6319],\n",
      "          [-0.6331],\n",
      "          [-0.6381],\n",
      "          [-0.6422],\n",
      "          [-0.6429],\n",
      "          [-0.6448],\n",
      "          [-0.6461],\n",
      "          [-0.6466],\n",
      "          [-0.6474],\n",
      "          [-0.6517],\n",
      "          [-0.6521],\n",
      "          [-0.6521],\n",
      "          [-0.6557],\n",
      "          [-0.6564],\n",
      "          [-0.6578],\n",
      "          [-0.6588],\n",
      "          [-0.6597],\n",
      "          [-0.6624],\n",
      "          [-0.6631],\n",
      "          [-0.6648],\n",
      "          [-0.6650],\n",
      "          [-0.6704],\n",
      "          [-0.6762],\n",
      "          [-0.6801],\n",
      "          [-0.6824],\n",
      "          [-0.6824],\n",
      "          [-0.6829],\n",
      "          [-0.6846],\n",
      "          [-0.6861],\n",
      "          [-0.6892],\n",
      "          [-0.6936],\n",
      "          [-0.6952],\n",
      "          [-0.6962],\n",
      "          [-0.6971],\n",
      "          [-0.7000],\n",
      "          [-0.7070],\n",
      "          [-0.7080],\n",
      "          [-0.7084],\n",
      "          [-0.7101],\n",
      "          [-0.7201],\n",
      "          [-0.7202],\n",
      "          [-0.7259],\n",
      "          [-0.7262],\n",
      "          [-0.7376],\n",
      "          [-0.7378],\n",
      "          [-0.7380],\n",
      "          [-0.7405],\n",
      "          [-0.7487],\n",
      "          [-0.7505],\n",
      "          [-0.7517],\n",
      "          [-0.7586],\n",
      "          [-0.7615],\n",
      "          [-0.7655],\n",
      "          [-0.7663],\n",
      "          [-0.7666],\n",
      "          [-0.7726],\n",
      "          [-0.7744],\n",
      "          [-0.7783],\n",
      "          [-0.7795],\n",
      "          [-0.7800],\n",
      "          [-0.7877],\n",
      "          [-0.7912],\n",
      "          [-0.7931],\n",
      "          [-0.7937],\n",
      "          [-0.7996],\n",
      "          [-0.8000],\n",
      "          [-0.8017],\n",
      "          [-0.8028],\n",
      "          [-0.8069],\n",
      "          [-0.8078],\n",
      "          [-0.8087],\n",
      "          [-0.8096],\n",
      "          [-0.8108],\n",
      "          [-0.8114],\n",
      "          [-0.8117],\n",
      "          [-0.8260],\n",
      "          [-0.8265],\n",
      "          [-0.8297],\n",
      "          [-0.8314],\n",
      "          [-0.8326],\n",
      "          [-0.8330],\n",
      "          [-0.8331],\n",
      "          [-0.8335],\n",
      "          [-0.8373],\n",
      "          [-0.8374],\n",
      "          [-0.8390],\n",
      "          [-0.8394],\n",
      "          [-0.8449],\n",
      "          [-0.8470],\n",
      "          [-0.8494],\n",
      "          [-0.8507],\n",
      "          [-0.8578],\n",
      "          [-0.8610],\n",
      "          [-0.8623],\n",
      "          [-0.8629],\n",
      "          [-0.8637],\n",
      "          [-0.8649],\n",
      "          [-0.8668],\n",
      "          [-0.8673],\n",
      "          [-0.8680],\n",
      "          [-0.8689],\n",
      "          [-0.8690],\n",
      "          [-0.8720],\n",
      "          [-0.8725],\n",
      "          [-0.8730],\n",
      "          [-0.8731],\n",
      "          [-0.8743],\n",
      "          [-0.8764],\n",
      "          [-0.8780],\n",
      "          [-0.8796],\n",
      "          [-0.8798],\n",
      "          [-0.8824],\n",
      "          [-0.8857],\n",
      "          [-0.8881],\n",
      "          [-0.8896],\n",
      "          [-0.8899],\n",
      "          [-0.8912],\n",
      "          [-0.8918],\n",
      "          [-0.8923],\n",
      "          [-0.8929],\n",
      "          [-0.8931],\n",
      "          [-0.8933],\n",
      "          [-0.8992],\n",
      "          [-0.8995],\n",
      "          [-0.8998],\n",
      "          [-0.9023]],\n",
      "\n",
      "         [[-0.2459],\n",
      "          [-0.8096],\n",
      "          [-0.5847],\n",
      "          [-0.5079],\n",
      "          [-0.4753],\n",
      "          [-0.6300],\n",
      "          [-0.5596],\n",
      "          [-0.5408],\n",
      "          [-0.5721],\n",
      "          [-0.4789],\n",
      "          [-0.5277],\n",
      "          [-0.4965],\n",
      "          [-0.5362],\n",
      "          [-0.6950],\n",
      "          [-0.5550],\n",
      "          [-0.5645],\n",
      "          [-0.5905],\n",
      "          [-0.4706],\n",
      "          [-0.4247],\n",
      "          [-0.3075],\n",
      "          [-0.3938],\n",
      "          [-0.4098],\n",
      "          [-0.4170],\n",
      "          [-0.4211],\n",
      "          [-0.4259],\n",
      "          [-0.4408],\n",
      "          [-0.4409],\n",
      "          [-0.4427],\n",
      "          [-0.4431],\n",
      "          [-0.4512],\n",
      "          [-0.4522],\n",
      "          [-0.4530],\n",
      "          [-0.4576],\n",
      "          [-0.4581],\n",
      "          [-0.4594],\n",
      "          [-0.4634],\n",
      "          [-0.4680],\n",
      "          [-0.4687],\n",
      "          [-0.4688],\n",
      "          [-0.4706],\n",
      "          [-0.4719],\n",
      "          [-0.4739],\n",
      "          [-0.4744],\n",
      "          [-0.4778],\n",
      "          [-0.4784],\n",
      "          [-0.4796],\n",
      "          [-0.4815],\n",
      "          [-0.4827],\n",
      "          [-0.4834],\n",
      "          [-0.4853],\n",
      "          [-0.4895],\n",
      "          [-0.4938],\n",
      "          [-0.4941],\n",
      "          [-0.4965],\n",
      "          [-0.4967],\n",
      "          [-0.4976],\n",
      "          [-0.5012],\n",
      "          [-0.5030],\n",
      "          [-0.5067],\n",
      "          [-0.5072],\n",
      "          [-0.5082],\n",
      "          [-0.5157],\n",
      "          [-0.5168],\n",
      "          [-0.5173],\n",
      "          [-0.5200],\n",
      "          [-0.5227],\n",
      "          [-0.5252],\n",
      "          [-0.5255],\n",
      "          [-0.5269],\n",
      "          [-0.5272],\n",
      "          [-0.5286],\n",
      "          [-0.5293],\n",
      "          [-0.5301],\n",
      "          [-0.5301],\n",
      "          [-0.5321],\n",
      "          [-0.5332],\n",
      "          [-0.5343],\n",
      "          [-0.5356],\n",
      "          [-0.5368],\n",
      "          [-0.5378],\n",
      "          [-0.5400],\n",
      "          [-0.5413],\n",
      "          [-0.5431],\n",
      "          [-0.5461],\n",
      "          [-0.5476],\n",
      "          [-0.5480],\n",
      "          [-0.5483],\n",
      "          [-0.5537],\n",
      "          [-0.5539],\n",
      "          [-0.5553],\n",
      "          [-0.5563],\n",
      "          [-0.5606],\n",
      "          [-0.5695],\n",
      "          [-0.5737],\n",
      "          [-0.5761],\n",
      "          [-0.5766],\n",
      "          [-0.5776],\n",
      "          [-0.5838],\n",
      "          [-0.5915],\n",
      "          [-0.5916],\n",
      "          [-0.5921],\n",
      "          [-0.5925],\n",
      "          [-0.5952],\n",
      "          [-0.5953],\n",
      "          [-0.5993],\n",
      "          [-0.6029],\n",
      "          [-0.6089],\n",
      "          [-0.6134],\n",
      "          [-0.6165],\n",
      "          [-0.6165],\n",
      "          [-0.6167],\n",
      "          [-0.6205],\n",
      "          [-0.6219],\n",
      "          [-0.6238],\n",
      "          [-0.6255],\n",
      "          [-0.6256],\n",
      "          [-0.6277],\n",
      "          [-0.6300],\n",
      "          [-0.6367],\n",
      "          [-0.6374],\n",
      "          [-0.6380],\n",
      "          [-0.6518],\n",
      "          [-0.6547],\n",
      "          [-0.6565],\n",
      "          [-0.6593],\n",
      "          [-0.6619],\n",
      "          [-0.6622],\n",
      "          [-0.6667],\n",
      "          [-0.6667],\n",
      "          [-0.6710],\n",
      "          [-0.6780],\n",
      "          [-0.6868],\n",
      "          [-0.6902],\n",
      "          [-0.7009],\n",
      "          [-0.7010],\n",
      "          [-0.7080],\n",
      "          [-0.7097],\n",
      "          [-0.7114],\n",
      "          [-0.7150],\n",
      "          [-0.7150],\n",
      "          [-0.7232],\n",
      "          [-0.7249],\n",
      "          [-0.7275],\n",
      "          [-0.7316],\n",
      "          [-0.7345],\n",
      "          [-0.7390],\n",
      "          [-0.7412],\n",
      "          [-0.7418],\n",
      "          [-0.7467],\n",
      "          [-0.7470],\n",
      "          [-0.7476],\n",
      "          [-0.7480],\n",
      "          [-0.7500],\n",
      "          [-0.7512],\n",
      "          [-0.7514],\n",
      "          [-0.7517],\n",
      "          [-0.7544],\n",
      "          [-0.7544],\n",
      "          [-0.7579],\n",
      "          [-0.7580],\n",
      "          [-0.7589],\n",
      "          [-0.7609],\n",
      "          [-0.7610],\n",
      "          [-0.7610],\n",
      "          [-0.7620],\n",
      "          [-0.7632],\n",
      "          [-0.7734],\n",
      "          [-0.7762],\n",
      "          [-0.7785],\n",
      "          [-0.7811],\n",
      "          [-0.7820],\n",
      "          [-0.7843],\n",
      "          [-0.7844],\n",
      "          [-0.7863],\n",
      "          [-0.7882],\n",
      "          [-0.7882],\n",
      "          [-0.7887],\n",
      "          [-0.7924],\n",
      "          [-0.7930],\n",
      "          [-0.7992],\n",
      "          [-0.8000],\n",
      "          [-0.8011],\n",
      "          [-0.8013],\n",
      "          [-0.8014],\n",
      "          [-0.8031],\n",
      "          [-0.8033],\n",
      "          [-0.8067],\n",
      "          [-0.8074],\n",
      "          [-0.8077],\n",
      "          [-0.8086],\n",
      "          [-0.8097],\n",
      "          [-0.8098],\n",
      "          [-0.8124],\n",
      "          [-0.8146],\n",
      "          [-0.8184],\n",
      "          [-0.8188],\n",
      "          [-0.8363],\n",
      "          [-0.8463],\n",
      "          [-0.8486],\n",
      "          [-0.8589]],\n",
      "\n",
      "         [[-0.3242],\n",
      "          [-0.8898],\n",
      "          [-0.6041],\n",
      "          [-0.5732],\n",
      "          [-0.5445],\n",
      "          [-0.6970],\n",
      "          [-0.6351],\n",
      "          [-0.5865],\n",
      "          [-0.6662],\n",
      "          [-0.4900],\n",
      "          [-0.5455],\n",
      "          [-0.5725],\n",
      "          [-0.5535],\n",
      "          [-0.5717],\n",
      "          [-0.8069],\n",
      "          [-0.6293],\n",
      "          [-0.6602],\n",
      "          [-0.6547],\n",
      "          [-0.5228],\n",
      "          [-0.5001],\n",
      "          [-0.3088],\n",
      "          [-0.4713],\n",
      "          [-0.4806],\n",
      "          [-0.4917],\n",
      "          [-0.4963],\n",
      "          [-0.4974],\n",
      "          [-0.4994],\n",
      "          [-0.5006],\n",
      "          [-0.5041],\n",
      "          [-0.5149],\n",
      "          [-0.5158],\n",
      "          [-0.5169],\n",
      "          [-0.5202],\n",
      "          [-0.5226],\n",
      "          [-0.5233],\n",
      "          [-0.5233],\n",
      "          [-0.5249],\n",
      "          [-0.5255],\n",
      "          [-0.5277],\n",
      "          [-0.5279],\n",
      "          [-0.5286],\n",
      "          [-0.5293],\n",
      "          [-0.5296],\n",
      "          [-0.5327],\n",
      "          [-0.5327],\n",
      "          [-0.5339],\n",
      "          [-0.5346],\n",
      "          [-0.5349],\n",
      "          [-0.5354],\n",
      "          [-0.5360],\n",
      "          [-0.5372],\n",
      "          [-0.5384],\n",
      "          [-0.5440],\n",
      "          [-0.5440],\n",
      "          [-0.5469],\n",
      "          [-0.5541],\n",
      "          [-0.5545],\n",
      "          [-0.5547],\n",
      "          [-0.5555],\n",
      "          [-0.5565],\n",
      "          [-0.5591],\n",
      "          [-0.5609],\n",
      "          [-0.5652],\n",
      "          [-0.5659],\n",
      "          [-0.5677],\n",
      "          [-0.5717],\n",
      "          [-0.5744],\n",
      "          [-0.5811],\n",
      "          [-0.5834],\n",
      "          [-0.5852],\n",
      "          [-0.5882],\n",
      "          [-0.5897],\n",
      "          [-0.5908],\n",
      "          [-0.5908],\n",
      "          [-0.5926],\n",
      "          [-0.5944],\n",
      "          [-0.5961],\n",
      "          [-0.5976],\n",
      "          [-0.5996],\n",
      "          [-0.6006],\n",
      "          [-0.6012],\n",
      "          [-0.6020],\n",
      "          [-0.6066],\n",
      "          [-0.6076],\n",
      "          [-0.6085],\n",
      "          [-0.6091],\n",
      "          [-0.6100],\n",
      "          [-0.6109],\n",
      "          [-0.6132],\n",
      "          [-0.6143],\n",
      "          [-0.6149],\n",
      "          [-0.6162],\n",
      "          [-0.6175],\n",
      "          [-0.6187],\n",
      "          [-0.6211],\n",
      "          [-0.6212],\n",
      "          [-0.6243],\n",
      "          [-0.6248],\n",
      "          [-0.6262],\n",
      "          [-0.6275],\n",
      "          [-0.6349],\n",
      "          [-0.6393],\n",
      "          [-0.6396],\n",
      "          [-0.6410],\n",
      "          [-0.6436],\n",
      "          [-0.6513],\n",
      "          [-0.6537],\n",
      "          [-0.6547],\n",
      "          [-0.6549],\n",
      "          [-0.6572],\n",
      "          [-0.6574],\n",
      "          [-0.6623],\n",
      "          [-0.6646],\n",
      "          [-0.6660],\n",
      "          [-0.6702],\n",
      "          [-0.6759],\n",
      "          [-0.6778],\n",
      "          [-0.6847],\n",
      "          [-0.6861],\n",
      "          [-0.6874],\n",
      "          [-0.6893],\n",
      "          [-0.6907],\n",
      "          [-0.6912],\n",
      "          [-0.6916],\n",
      "          [-0.6921],\n",
      "          [-0.6948],\n",
      "          [-0.6991],\n",
      "          [-0.7026],\n",
      "          [-0.7075],\n",
      "          [-0.7081],\n",
      "          [-0.7097],\n",
      "          [-0.7114],\n",
      "          [-0.7199],\n",
      "          [-0.7231],\n",
      "          [-0.7274],\n",
      "          [-0.7373],\n",
      "          [-0.7393],\n",
      "          [-0.7402],\n",
      "          [-0.7445],\n",
      "          [-0.7513],\n",
      "          [-0.7544],\n",
      "          [-0.7560],\n",
      "          [-0.7649],\n",
      "          [-0.7755],\n",
      "          [-0.7765],\n",
      "          [-0.7796],\n",
      "          [-0.7796],\n",
      "          [-0.7822],\n",
      "          [-0.7826],\n",
      "          [-0.7868],\n",
      "          [-0.7876],\n",
      "          [-0.7883],\n",
      "          [-0.7888],\n",
      "          [-0.7941],\n",
      "          [-0.7944],\n",
      "          [-0.8089],\n",
      "          [-0.8126],\n",
      "          [-0.8143],\n",
      "          [-0.8175],\n",
      "          [-0.8183],\n",
      "          [-0.8197],\n",
      "          [-0.8285],\n",
      "          [-0.8302],\n",
      "          [-0.8310],\n",
      "          [-0.8333],\n",
      "          [-0.8356],\n",
      "          [-0.8397],\n",
      "          [-0.8427],\n",
      "          [-0.8432],\n",
      "          [-0.8451],\n",
      "          [-0.8457],\n",
      "          [-0.8537],\n",
      "          [-0.8537],\n",
      "          [-0.8544],\n",
      "          [-0.8546],\n",
      "          [-0.8556],\n",
      "          [-0.8588],\n",
      "          [-0.8594],\n",
      "          [-0.8603],\n",
      "          [-0.8642],\n",
      "          [-0.8669],\n",
      "          [-0.8755],\n",
      "          [-0.8797],\n",
      "          [-0.8801],\n",
      "          [-0.8828],\n",
      "          [-0.8843],\n",
      "          [-0.8854],\n",
      "          [-0.8871],\n",
      "          [-0.8873],\n",
      "          [-0.8888],\n",
      "          [-0.8889],\n",
      "          [-0.8922],\n",
      "          [-0.8982],\n",
      "          [-0.8998],\n",
      "          [-0.9001],\n",
      "          [-0.9017],\n",
      "          [-0.9027],\n",
      "          [-0.9053],\n",
      "          [-0.9054],\n",
      "          [-0.9064]],\n",
      "\n",
      "         [[-0.3678],\n",
      "          [-0.9017],\n",
      "          [-0.5615],\n",
      "          [-0.5792],\n",
      "          [-0.5282],\n",
      "          [-0.6998],\n",
      "          [-0.6500],\n",
      "          [-0.6204],\n",
      "          [-0.7572],\n",
      "          [-0.5747],\n",
      "          [-0.5755],\n",
      "          [-0.5663],\n",
      "          [-0.5977],\n",
      "          [-0.4929],\n",
      "          [-0.8129],\n",
      "          [-0.6349],\n",
      "          [-0.6322],\n",
      "          [-0.6732],\n",
      "          [-0.5043],\n",
      "          [-0.4929],\n",
      "          [-0.4769],\n",
      "          [-0.4859],\n",
      "          [-0.5042],\n",
      "          [-0.5117],\n",
      "          [-0.5149],\n",
      "          [-0.5186],\n",
      "          [-0.5193],\n",
      "          [-0.5201],\n",
      "          [-0.5249],\n",
      "          [-0.5303],\n",
      "          [-0.5306],\n",
      "          [-0.5330],\n",
      "          [-0.5338],\n",
      "          [-0.5364],\n",
      "          [-0.5366],\n",
      "          [-0.5376],\n",
      "          [-0.5381],\n",
      "          [-0.5404],\n",
      "          [-0.5426],\n",
      "          [-0.5434],\n",
      "          [-0.5444],\n",
      "          [-0.5449],\n",
      "          [-0.5460],\n",
      "          [-0.5463],\n",
      "          [-0.5482],\n",
      "          [-0.5483],\n",
      "          [-0.5487],\n",
      "          [-0.5505],\n",
      "          [-0.5517],\n",
      "          [-0.5528],\n",
      "          [-0.5576],\n",
      "          [-0.5581],\n",
      "          [-0.5584],\n",
      "          [-0.5597],\n",
      "          [-0.5599],\n",
      "          [-0.5648],\n",
      "          [-0.5662],\n",
      "          [-0.5676],\n",
      "          [-0.5708],\n",
      "          [-0.5716],\n",
      "          [-0.5747],\n",
      "          [-0.5758],\n",
      "          [-0.5761],\n",
      "          [-0.5765],\n",
      "          [-0.5768],\n",
      "          [-0.5772],\n",
      "          [-0.5785],\n",
      "          [-0.5822],\n",
      "          [-0.5834],\n",
      "          [-0.5891],\n",
      "          [-0.5900],\n",
      "          [-0.5960],\n",
      "          [-0.5995],\n",
      "          [-0.6025],\n",
      "          [-0.6074],\n",
      "          [-0.6097],\n",
      "          [-0.6100],\n",
      "          [-0.6132],\n",
      "          [-0.6162],\n",
      "          [-0.6195],\n",
      "          [-0.6230],\n",
      "          [-0.6232],\n",
      "          [-0.6274],\n",
      "          [-0.6283],\n",
      "          [-0.6293],\n",
      "          [-0.6293],\n",
      "          [-0.6314],\n",
      "          [-0.6316],\n",
      "          [-0.6360],\n",
      "          [-0.6379],\n",
      "          [-0.6408],\n",
      "          [-0.6422],\n",
      "          [-0.6508],\n",
      "          [-0.6524],\n",
      "          [-0.6525],\n",
      "          [-0.6537],\n",
      "          [-0.6564],\n",
      "          [-0.6566],\n",
      "          [-0.6626],\n",
      "          [-0.6632],\n",
      "          [-0.6772],\n",
      "          [-0.6790],\n",
      "          [-0.6869],\n",
      "          [-0.6873],\n",
      "          [-0.6912],\n",
      "          [-0.6945],\n",
      "          [-0.7007],\n",
      "          [-0.7016],\n",
      "          [-0.7024],\n",
      "          [-0.7035],\n",
      "          [-0.7050],\n",
      "          [-0.7091],\n",
      "          [-0.7118],\n",
      "          [-0.7136],\n",
      "          [-0.7185],\n",
      "          [-0.7193],\n",
      "          [-0.7301],\n",
      "          [-0.7309],\n",
      "          [-0.7365],\n",
      "          [-0.7372],\n",
      "          [-0.7377],\n",
      "          [-0.7389],\n",
      "          [-0.7442],\n",
      "          [-0.7451],\n",
      "          [-0.7467],\n",
      "          [-0.7653],\n",
      "          [-0.7682],\n",
      "          [-0.7691],\n",
      "          [-0.7719],\n",
      "          [-0.7751],\n",
      "          [-0.7779],\n",
      "          [-0.7785],\n",
      "          [-0.7799],\n",
      "          [-0.7830],\n",
      "          [-0.7838],\n",
      "          [-0.7921],\n",
      "          [-0.8005],\n",
      "          [-0.8069],\n",
      "          [-0.8097],\n",
      "          [-0.8125],\n",
      "          [-0.8175],\n",
      "          [-0.8187],\n",
      "          [-0.8218],\n",
      "          [-0.8220],\n",
      "          [-0.8236],\n",
      "          [-0.8238],\n",
      "          [-0.8264],\n",
      "          [-0.8291],\n",
      "          [-0.8294],\n",
      "          [-0.8304],\n",
      "          [-0.8308],\n",
      "          [-0.8336],\n",
      "          [-0.8338],\n",
      "          [-0.8359],\n",
      "          [-0.8378],\n",
      "          [-0.8381],\n",
      "          [-0.8388],\n",
      "          [-0.8419],\n",
      "          [-0.8425],\n",
      "          [-0.8457],\n",
      "          [-0.8468],\n",
      "          [-0.8510],\n",
      "          [-0.8537],\n",
      "          [-0.8577],\n",
      "          [-0.8595],\n",
      "          [-0.8603],\n",
      "          [-0.8632],\n",
      "          [-0.8632],\n",
      "          [-0.8640],\n",
      "          [-0.8668],\n",
      "          [-0.8670],\n",
      "          [-0.8677],\n",
      "          [-0.8710],\n",
      "          [-0.8737],\n",
      "          [-0.8755],\n",
      "          [-0.8757],\n",
      "          [-0.8761],\n",
      "          [-0.8786],\n",
      "          [-0.8861],\n",
      "          [-0.8922],\n",
      "          [-0.8966],\n",
      "          [-0.8977],\n",
      "          [-0.9032],\n",
      "          [-0.9033],\n",
      "          [-0.9062],\n",
      "          [-0.9063],\n",
      "          [-0.9070],\n",
      "          [-0.9076],\n",
      "          [-0.9084],\n",
      "          [-0.9089],\n",
      "          [-0.9114],\n",
      "          [-0.9124],\n",
      "          [-0.9137],\n",
      "          [-0.9146],\n",
      "          [-0.9169],\n",
      "          [-0.9171],\n",
      "          [-0.9201],\n",
      "          [-0.9257],\n",
      "          [-0.9260],\n",
      "          [-0.9260]],\n",
      "\n",
      "         [[-0.2921],\n",
      "          [-0.8879],\n",
      "          [-0.6451],\n",
      "          [-0.6261],\n",
      "          [-0.5817],\n",
      "          [-0.6606],\n",
      "          [-0.6323],\n",
      "          [-0.6306],\n",
      "          [-0.7063],\n",
      "          [-0.4835],\n",
      "          [-0.4726],\n",
      "          [-0.5758],\n",
      "          [-0.6730],\n",
      "          [-0.5641],\n",
      "          [-0.5953],\n",
      "          [-0.8452],\n",
      "          [-0.6313],\n",
      "          [-0.6499],\n",
      "          [-0.6922],\n",
      "          [-0.6058],\n",
      "          [-0.5112],\n",
      "          [-0.5084],\n",
      "          [-0.4763],\n",
      "          [-0.4819],\n",
      "          [-0.4830],\n",
      "          [-0.4893],\n",
      "          [-0.4894],\n",
      "          [-0.4917],\n",
      "          [-0.4951],\n",
      "          [-0.4962],\n",
      "          [-0.5126],\n",
      "          [-0.5131],\n",
      "          [-0.5132],\n",
      "          [-0.5144],\n",
      "          [-0.5172],\n",
      "          [-0.5209],\n",
      "          [-0.5248],\n",
      "          [-0.5320],\n",
      "          [-0.5377],\n",
      "          [-0.5400],\n",
      "          [-0.5425],\n",
      "          [-0.5430],\n",
      "          [-0.5450],\n",
      "          [-0.5489],\n",
      "          [-0.5493],\n",
      "          [-0.5501],\n",
      "          [-0.5537],\n",
      "          [-0.5542],\n",
      "          [-0.5557],\n",
      "          [-0.5591],\n",
      "          [-0.5596],\n",
      "          [-0.5599],\n",
      "          [-0.5633],\n",
      "          [-0.5666],\n",
      "          [-0.5679],\n",
      "          [-0.5681],\n",
      "          [-0.5710],\n",
      "          [-0.5717],\n",
      "          [-0.5723],\n",
      "          [-0.5734],\n",
      "          [-0.5776],\n",
      "          [-0.5796],\n",
      "          [-0.5815],\n",
      "          [-0.5823],\n",
      "          [-0.5832],\n",
      "          [-0.5850],\n",
      "          [-0.5885],\n",
      "          [-0.5897],\n",
      "          [-0.5897],\n",
      "          [-0.5898],\n",
      "          [-0.5899],\n",
      "          [-0.5932],\n",
      "          [-0.5937],\n",
      "          [-0.5946],\n",
      "          [-0.5970],\n",
      "          [-0.5994],\n",
      "          [-0.6045],\n",
      "          [-0.6065],\n",
      "          [-0.6066],\n",
      "          [-0.6110],\n",
      "          [-0.6127],\n",
      "          [-0.6142],\n",
      "          [-0.6176],\n",
      "          [-0.6182],\n",
      "          [-0.6194],\n",
      "          [-0.6199],\n",
      "          [-0.6206],\n",
      "          [-0.6249],\n",
      "          [-0.6263],\n",
      "          [-0.6295],\n",
      "          [-0.6297],\n",
      "          [-0.6301],\n",
      "          [-0.6324],\n",
      "          [-0.6338],\n",
      "          [-0.6345],\n",
      "          [-0.6363],\n",
      "          [-0.6413],\n",
      "          [-0.6417],\n",
      "          [-0.6421],\n",
      "          [-0.6430],\n",
      "          [-0.6433],\n",
      "          [-0.6469],\n",
      "          [-0.6478],\n",
      "          [-0.6511],\n",
      "          [-0.6568],\n",
      "          [-0.6571],\n",
      "          [-0.6573],\n",
      "          [-0.6588],\n",
      "          [-0.6598],\n",
      "          [-0.6608],\n",
      "          [-0.6611],\n",
      "          [-0.6630],\n",
      "          [-0.6633],\n",
      "          [-0.6698],\n",
      "          [-0.6710],\n",
      "          [-0.6719],\n",
      "          [-0.6728],\n",
      "          [-0.6769],\n",
      "          [-0.6797],\n",
      "          [-0.6817],\n",
      "          [-0.6821],\n",
      "          [-0.6882],\n",
      "          [-0.6884],\n",
      "          [-0.6924],\n",
      "          [-0.6937],\n",
      "          [-0.6947],\n",
      "          [-0.6977],\n",
      "          [-0.6989],\n",
      "          [-0.7013],\n",
      "          [-0.7032],\n",
      "          [-0.7070],\n",
      "          [-0.7077],\n",
      "          [-0.7093],\n",
      "          [-0.7109],\n",
      "          [-0.7144],\n",
      "          [-0.7223],\n",
      "          [-0.7283],\n",
      "          [-0.7285],\n",
      "          [-0.7355],\n",
      "          [-0.7380],\n",
      "          [-0.7404],\n",
      "          [-0.7415],\n",
      "          [-0.7426],\n",
      "          [-0.7470],\n",
      "          [-0.7616],\n",
      "          [-0.7673],\n",
      "          [-0.7727],\n",
      "          [-0.7851],\n",
      "          [-0.7909],\n",
      "          [-0.7936],\n",
      "          [-0.8001],\n",
      "          [-0.8046],\n",
      "          [-0.8060],\n",
      "          [-0.8091],\n",
      "          [-0.8106],\n",
      "          [-0.8126],\n",
      "          [-0.8152],\n",
      "          [-0.8166],\n",
      "          [-0.8206],\n",
      "          [-0.8232],\n",
      "          [-0.8242],\n",
      "          [-0.8311],\n",
      "          [-0.8321],\n",
      "          [-0.8339],\n",
      "          [-0.8340],\n",
      "          [-0.8370],\n",
      "          [-0.8424],\n",
      "          [-0.8431],\n",
      "          [-0.8434],\n",
      "          [-0.8441],\n",
      "          [-0.8536],\n",
      "          [-0.8540],\n",
      "          [-0.8550],\n",
      "          [-0.8551],\n",
      "          [-0.8581],\n",
      "          [-0.8595],\n",
      "          [-0.8608],\n",
      "          [-0.8637],\n",
      "          [-0.8643],\n",
      "          [-0.8648],\n",
      "          [-0.8649],\n",
      "          [-0.8672],\n",
      "          [-0.8685],\n",
      "          [-0.8705],\n",
      "          [-0.8735],\n",
      "          [-0.8736],\n",
      "          [-0.8739],\n",
      "          [-0.8779],\n",
      "          [-0.8784],\n",
      "          [-0.8786],\n",
      "          [-0.8803],\n",
      "          [-0.8803],\n",
      "          [-0.8828],\n",
      "          [-0.8832],\n",
      "          [-0.8847],\n",
      "          [-0.8854],\n",
      "          [-0.8878],\n",
      "          [-0.8882],\n",
      "          [-0.8891],\n",
      "          [-0.8938]]]], device='cuda:0'), tensor([[200, 200, 200, 200, 200]], device='cuda:0'), [[tensor([[  3,   7,   8,  ...,  18,  19,  20],\n",
      "        [151, 117, 152,  ...,   0,   0,   0]], device='cuda:0'), tensor([[  3,   7,   8,  ...,  16,  17,  18],\n",
      "        [135, 111,  81,  ...,   0,   0,   0]], device='cuda:0'), tensor([[  3,   7,   8,  ...,  17,  18,  19],\n",
      "        [142, 118, 109,  ...,   0,   0,   0]], device='cuda:0'), tensor([[  3,   7,   8,  ...,  18,  19,  20],\n",
      "        [173, 100, 145,  ...,   0,   0,   0]], device='cuda:0'), tensor([[  3,   7,   8,  ...,  19,  20,  21],\n",
      "        [144, 132, 129,  ...,   0,   0,   0]], device='cuda:0')]], [[tensor([ 2,  2,  2,  ..., 20, 20, 20], device='cuda:0'), tensor([ 2,  2,  2,  ..., 19, 19, 20], device='cuda:0'), tensor([ 2,  2,  2,  ..., 19, 19, 20], device='cuda:0'), tensor([ 2,  2,  2,  ..., 19, 20, 20], device='cuda:0'), tensor([ 2,  2,  2,  ..., 19, 20, 20], device='cuda:0')]]])\n"
     ]
    }
   ],
   "source": [
    "#print(question_to_input(\"Learning languages is difficult.  Even in a full immersion environment you're likely to make mistakes, mistakes will cause misinterpretation, which will be uncomfortable, which will cause what?,\"))\n",
    "print(question_to_input(\"Learning languages is difficult. Even in a full immersion environment you're likely to make mistakes, mistakes will cause misinterpretation, which will be uncomfortable, which will cause what?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "86d24e47-8a45-4e49-9ff9-a01e1a12a218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 100]), dtype=torch.int64, device=cuda:0\n",
      "torch.Size([1, 5, 100]), dtype=torch.int64, device=cuda:0\n",
      "torch.Size([1, 5, 100]), dtype=torch.int64, device=cuda:0\n",
      "torch.Size([1, 5, 100]), dtype=torch.bool, device=cuda:0\n",
      "torch.Size([1, 5, 200]), dtype=torch.int64, device=cuda:0\n",
      "torch.Size([1, 5, 200]), dtype=torch.int64, device=cuda:0\n",
      "torch.Size([1, 5, 200, 1]), dtype=torch.float32, device=cuda:0\n",
      "torch.Size([1, 5]), dtype=torch.int64, device=cuda:0\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "# Validate the previous\n",
    "\n",
    "from typing import List\n",
    "\n",
    "\n",
    "(label_idx, local_input_data) = question_to_input(\"Where does a person need to get when they have more kids?\")\n",
    "\n",
    "for i in range(len(local_input_data)):\n",
    "        try:\n",
    "            tensor: torch.Tensor = local_input_data[i]\n",
    "            print(f\"{tensor.shape}, dtype={tensor.dtype}, device={tensor.device}\")\n",
    "            #print(str(input_data[i].int())[:128])\n",
    "        except:\n",
    "            tensors: List = local_input_data[i]\n",
    "            #print(input_data[i])\n",
    "            #list_tensor = torch.tensor(input_data[i], device=device0)\n",
    "            #print(f\"{list_tensor.shape}, dtype={input_data[i].dtype}\")\n",
    "            \n",
    "            print(f\"{[len(tensors)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "6efd3b93-84a9-4399-999b-f72c810bc54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QAGNN(\n",
       "  (concept_emb): CustomizedEmbedding(\n",
       "    (emb): Embedding(799273, 1024)\n",
       "    (cpt_transform): Linear(in_features=1024, out_features=200, bias=True)\n",
       "    (activation): GELU()\n",
       "  )\n",
       "  (svec2nvec): Linear(in_features=1024, out_features=200, bias=True)\n",
       "  (activation): GELU()\n",
       "  (gnn): QAGNN_Message_Passing(\n",
       "    (emb_node_type): Linear(in_features=4, out_features=100, bias=True)\n",
       "    (emb_score): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (edge_encoder): Sequential(\n",
       "      (0): Linear(in_features=47, out_features=200, bias=True)\n",
       "      (1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=200, out_features=200, bias=True)\n",
       "    )\n",
       "    (gnn_layers): ModuleList(\n",
       "      (0-4): 5 x GATConvE()\n",
       "    )\n",
       "    (Vh): Linear(in_features=200, out_features=200, bias=True)\n",
       "    (Vx): Linear(in_features=200, out_features=200, bias=True)\n",
       "    (activation): GELU()\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (pooler): MultiheadAttPoolLayer(\n",
       "    (w_qs): Linear(in_features=1024, out_features=200, bias=True)\n",
       "    (w_ks): Linear(in_features=200, out_features=200, bias=True)\n",
       "    (w_vs): Linear(in_features=200, out_features=200, bias=True)\n",
       "    (attention): MatrixVectorScaledDotProductAttention(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (softmax): Softmax(dim=1)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (fc): MLP(\n",
       "    (layers): Sequential(\n",
       "      (0-Linear): Linear(in_features=1424, out_features=1, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (dropout_e): Dropout(p=0.2, inplace=False)\n",
       "  (dropout_fc): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_gnn.encoder.to(device0)\n",
    "qa_gnn.decoder.to(device1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "9a849f13-8146-4162-a439-bbef1a90e7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'actual_answer': 'E', 'prediction': 'E'}"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POSSIBLE_ANSWERS = ['A', 'B', 'C', 'D', 'E']\n",
    "\n",
    "# Make predictions\n",
    "# question: just the question, not the prompt given to LLMs\n",
    "def qa_gnn_predict(question: str, return_letter: bool = False):\n",
    "    result = {}\n",
    "    \n",
    "    (label_idx, input_data) = question_to_input(question)\n",
    "    \n",
    "    actual_answer: str = POSSIBLE_ANSWERS[label_idx]\n",
    "    result[\"actual_answer\"] = actual_answer\n",
    "    \n",
    "    # run inference\n",
    "    with torch.no_grad():\n",
    "        logits, _, concept_ids, node_type_ids, edge_index, edge_type = qa_gnn(*input_data, detail=True)\n",
    "        prediction = logits.argmax(1)  # [batch_size which should = 1,]\n",
    "        #print(predictions.shape)\n",
    "        #print(POSSIBLE_ANSWERS[predictions])\n",
    "\n",
    "        \n",
    "        if return_letter:\n",
    "            answer_choice = POSSIBLE_ANSWERS[prediction]\n",
    "            result[\"prediction\"] = answer_choice\n",
    "        else:\n",
    "            result[\"prediction\"] = prediction\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "qa_gnn_predict(\"Where does a person need to get when they have more kids?\", return_letter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "435a794c-1eaa-46a7-a15a-11c4b52b56e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'actual_answer': 'E', 'prediction': 'E'}"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_prompt = '''\n",
    "The hippy wanted peace with all humans, he had strong what for them all?\n",
    "  A.  \"names\"\n",
    "  B. \"words\"\n",
    "  C. \"naval\"\n",
    "  D. \"bladders\"\n",
    "  E. \"feelings\"\n",
    "'''[1:-1]\n",
    "\n",
    "qa_gnn_predict(\"The hippy wanted peace with all humans, he had strong what for them all?\", return_letter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbec2ba2-51c6-4d15-bf48-495e5cee689e",
   "metadata": {},
   "source": [
    "# Hierarchical Knowledge Graph Reasoning Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "b08832ee-67be-42b8-8630-b45094ade5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Answers</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Before getting a divorce, what did the wife fe...</td>\n",
       "      <td>{ \"label\": [ \"A\", \"B\", \"C\", \"D\", \"E\" ], \"text\"...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The sensor would just the distance then set of...</td>\n",
       "      <td>{ \"label\": [ \"A\", \"B\", \"C\", \"D\", \"E\" ], \"text\"...</td>\n",
       "      <td>D</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Learning languages is difficult. Even in a ful...</td>\n",
       "      <td>{ \"label\": [ \"A\", \"B\", \"C\", \"D\", \"E\" ], \"text\"...</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The sanctions against the school were a punish...</td>\n",
       "      <td>{ \"label\": [ \"A\", \"B\", \"C\", \"D\", \"E\" ], \"text\"...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To locate a choker not located in a jewelry bo...</td>\n",
       "      <td>{ \"label\": [ \"A\", \"B\", \"C\", \"D\", \"E\" ], \"text\"...</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  Before getting a divorce, what did the wife fe...   \n",
       "1  The sensor would just the distance then set of...   \n",
       "2  Learning languages is difficult. Even in a ful...   \n",
       "3  The sanctions against the school were a punish...   \n",
       "4  To locate a choker not located in a jewelry bo...   \n",
       "\n",
       "                                             Answers Answer  \n",
       "0  { \"label\": [ \"A\", \"B\", \"C\", \"D\", \"E\" ], \"text\"...      C  \n",
       "1  { \"label\": [ \"A\", \"B\", \"C\", \"D\", \"E\" ], \"text\"...      D  \n",
       "2  { \"label\": [ \"A\", \"B\", \"C\", \"D\", \"E\" ], \"text\"...      C  \n",
       "3  { \"label\": [ \"A\", \"B\", \"C\", \"D\", \"E\" ], \"text\"...      A  \n",
       "4  { \"label\": [ \"A\", \"B\", \"C\", \"D\", \"E\" ], \"text\"...      A  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 50 samples of hierarchical reasoning from CommonSenseQA\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"qagnn/data/CommonSenseQA_hierarchical_samples.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "3645a63c-5fbb-4384-8957-ae2d3eadcee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q': 'James thought that giving the AI a secular upbringing would be the better choice. He felt that the alternative might have results that were too what?',\n",
       " 'Possible Answers': [' \"eternal\"',\n",
       "  '\"religious\"',\n",
       "  '\"unpredictable\"',\n",
       "  '\"holy\"',\n",
       "  '\"monastic\" '],\n",
       " 'AnswerIndex': 2}"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List, Dict\n",
    "\n",
    "\n",
    "POSSIBLE_ANSWERS = [\"A\", \"B\", \"C\", \"D\", \"E\"]\n",
    "\n",
    "\n",
    "EXTRACTION_START_INDEX = len('{ \"label\": [ \"A\", \"B\", \"C\", \"D\", \"E\" ], \"text\": ')\n",
    "def extract_answers_list(answers_entry: str) -> List[str]:  # Get the representation of each of these answers\n",
    "  return answers_entry[EXTRACTION_START_INDEX:-2].strip('][').split(', ')\n",
    "\n",
    "\n",
    "def get_mcq(q_idx: int) -> Dict:\n",
    "  mcq = df.iloc[q_idx]\n",
    "\n",
    "  question: str = mcq[\"Question\"]\n",
    "  answers: List[str] = extract_answers_list(mcq[\"Answers\"])\n",
    "  real_answer: int = POSSIBLE_ANSWERS.index(mcq[\"Answer\"])\n",
    "\n",
    "  return {\"Q\": question, \"Possible Answers\": answers, \"AnswerIndex\": real_answer}\n",
    "\n",
    "\n",
    "def get_random_mcq() -> Dict:\n",
    "  return get_mcq(np.random.randint(0, len(df)))\n",
    "\n",
    "\n",
    "def mcq_to_prompt(mcq: Dict, include_answer: bool = True) -> str:\n",
    "  answer_options: List[str] = mcq[\"Possible Answers\"]\n",
    "\n",
    "  answer: str = \"\"\n",
    "  if include_answer:\n",
    "    answer = POSSIBLE_ANSWERS[mcq[\"AnswerIndex\"]]\n",
    "\n",
    "  return f\"\"\"\n",
    "  Question: {mcq[\"Q\"]}\n",
    "  A. {answer_options[0]}\n",
    "  B. {answer_options[1]}\n",
    "  C. {answer_options[2]}\n",
    "  D. {answer_options[3]}\n",
    "  E. {answer_options[4]}\n",
    "  Answer: {answer}\n",
    "  \"\"\"[1:-1]\n",
    "\n",
    "\n",
    "get_random_mcq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "2a53c496-cfce-41c2-bd74-44d2168d7846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_qa_gnn() -> pd.DataFrame:\n",
    "    eval_df: pd.DataFrame = pd.DataFrame(columns=[\"Question\", \"Possible Answers\", \"Real Answer\", \"Predicted Answer\"])\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        mcq: Dict = get_mcq(i)\n",
    "        question: str = mcq[\"Q\"]\n",
    "\n",
    "        print(question, end=\" \")\n",
    "        print(mcq[\"Possible Answers\"])\n",
    "        \n",
    "        eval_df.loc[i, \"Question\"] = question \n",
    "        eval_df.loc[i, \"Possible Answers\"] = str(mcq[\"Possible Answers\"])\n",
    "\n",
    "        result = qa_gnn_predict(question, return_letter=True)\n",
    "        prediction: str = result[\"prediction\"]\n",
    "        actual_answer: str = result[\"actual_answer\"]\n",
    "        \n",
    "        pred_is_correct: bool = (prediction == actual_answer)\n",
    "        print(f\"Answer: {prediction}; Real Answer: {actual_answer}\", end=\"\\n\\n\")\n",
    "        \n",
    "        eval_df.loc[i, \"Real Answer\"] = actual_answer\n",
    "        eval_df.loc[i, \"Predicted Answer\"] = prediction\n",
    "\n",
    "        eval_df.loc[i, \"Correct\"] = pred_is_correct\n",
    "\n",
    "    return eval_df\n",
    "\n",
    "\n",
    "def summary_eval_df(eval_df: pd.DataFrame, name: str, idx=0) -> pd.DataFrame:\n",
    "    summary_df: pd.DataFrame = pd.DataFrame(columns=[\"Correct\", \"Incorrect\", \"Accuracy\"])\n",
    "\n",
    "    summary_df.loc[idx, \"Model\"] = name\n",
    "    summary_df.loc[idx, \"Correct\"] = eval_df[\"Correct\"].value_counts()[True]\n",
    "    summary_df.loc[idx, \"Incorrect\"] = eval_df[\"Correct\"].value_counts()[False]\n",
    "    summary_df.loc[idx, \"Accuracy\"] = eval_df[\"Correct\"].sum() / len(eval_df)\n",
    "\n",
    "    return summary_df\n",
    "\n",
    "\n",
    "def full_eval_qa_gnn() -> Dict:\n",
    "    eval_df: pd.DataFrame = eval_qa_gnn()\n",
    "    summary_df: pd.DataFrame = summary_eval_df(eval_df, name=\"QA-GNN\")\n",
    "    \n",
    "    return {\"evaluation\": eval_df, \"summary\": summary_df}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "a7eeecbc-5cdb-4509-9127-f5c806887e8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QA-GNN Evaluation on Hierarchical Knowledge Graph Reasoning\n",
      "Before getting a divorce, what did the wife feel who was doing all the work? [' \"harder\"', '\"anguish\"', '\"bitterness\"', '\"tears\"', '\"sadness\" ']\n",
      "Answer: C; Real Answer: C\n",
      "\n",
      "The sensor would just the distance then set off an alarm, the installation expert explained it was called a what kind of sensor? [' \"near\"', '\"closeness\"', '\"here\"', '\"proximity\"', '\"this\" ']\n",
      "Answer: D; Real Answer: D\n",
      "\n",
      "Learning languages is difficult. Even in a full immersion environment you're likely to make mistakes, mistakes will cause misinterpretation, which will be uncomfortable, which will cause what? [' \"better communication\"', '\"overthinking\"', '\"frustration\"', '\"misunderstandings\"', '\"headaches\" ']\n",
      "Answer: C; Real Answer: C\n",
      "\n",
      "The sanctions against the school were a punishing blow, and they seemed to what the efforts the school had made to change? [' \"ignore\"', '\"enforce\"', '\"authoritarian\"', '\"yell at\"', '\"avoid\" ']\n",
      "Answer: A; Real Answer: A\n",
      "\n",
      "To locate a choker not located in a jewelry box or boutique where would you go? [' \"jewelry store\"', '\"neck\"', '\"jewlery box\"', '\"jewelry box\"', '\"boutique\" ']\n",
      "Answer: A; Real Answer: A\n",
      "\n",
      "The fox walked from the city into the forest, what was it looking for? [' \"pretty flowers.\"', '\"hen house\"', '\"natural habitat\"', '\"storybook\"', '\"dense forest\" ']\n",
      "Answer: C; Real Answer: C\n",
      "\n",
      "Joe suffered many consequences from stabbing a stranger to death. Among them, the family of the victim did something to him. What was that? [' \"knife wounds\"', '\"buy a gun\"', '\"bleeding\"', '\"jail time\"', '\"law suit\" ']\n",
      "Answer: E; Real Answer: E\n",
      "\n",
      "What could happen to a paper if you leave it outside even if it does not move? [' \"park\"', '\"make time for\"', '\"receive instructions\"', '\"take money\"', '\"leave work\" ']\n",
      "Answer: C; Real Answer: C\n",
      "\n",
      "The drug kingpin told his man to run errands, this was code to go to all the dealers to do what they had? [' \"park\"', '\"make time for\"', '\"receive instructions\"', '\"take money\"', '\"leave work\" ']\n",
      "Answer: D; Real Answer: D\n",
      "\n",
      "Too many people want exotic snakes. The demand is driving what to carry them? [' \"ditch\"', '\"shop\"', '\"north america\"', '\"pet shops\"', '\"outdoors\" ']\n",
      "Answer: D; Real Answer: D\n",
      "\n",
      "Where in Southern Europe would you find many canals? [' \"michigan\"', '\"new york\"', '\"amsterdam\"', '\"venice\"', '\"bridge\" ']\n",
      "Answer: C; Real Answer: D\n",
      "\n",
      "The game promised it was free, but the child's parents soon found themselves doing what for microtransactions? [' \"costly\"', '\"captive\"', '\"contained\"', '\"paying\"', '\"caught\" ']\n",
      "Answer: D; Real Answer: D\n",
      "\n",
      "The body guard was good at his duties, he made the person who hired him what? [' \"better job\"', '\"irritated\"', '\"feel safe\"', '\"save money\"', '\"headache\" ']\n",
      "Answer: C; Real Answer: C\n",
      "\n",
      "Learning languages is difficult. Even in a full immersion environment you're likely to make mistakes, mistakes will cause misinterpretation, which will be uncomfortable, which will cause what?, [' \"better communication\"', '\"overthinking\"', '\"frustration\"', '\"misunderstandings\"', '\"headaches\" ']\n",
      "Answer: C; Real Answer: C\n",
      "\n",
      "A beaver can destroy a machines functionality if they build their dam in this?\t [' \"strip club\"', '\"pocket\"', '\"millpond\"', '\"ontario\"', '\"lake or river\" ']\n",
      "Answer: E; Real Answer: C\n",
      "\n",
      "What state south of Kentucky and north of Alabama will you find people playing the fiddle? [' \"circus\"', '\"carnival\"', '\"surprise\"', '\"spoons\"', '\"party\" ']\n",
      "Answer: B; Real Answer: B\n",
      "\n",
      "The man went to clown college, he had always want to run away with the what? [' \"circus\"', '\"carnival\"', '\"surprise\"', '\"spoons\"', '\"party\" ']\n",
      "Answer: A; Real Answer: A\n",
      "\n",
      "John and James spent most of their time communicating with each other on their project. The time required to communicate slowed their what? [' \"static\"', '\"train of thought.\"', '\"progress\"', '\"transfer of information\"', '\"collaboration\" ']\n",
      "Answer: C; Real Answer: C\n",
      "\n",
      "The fat man refused to accept what was possible, he complained that he what the simplest activities? [' \"no go\"', '\"unlikely\"', '\"unable\"', '\"cant do\"', '\"impossibility\" ']\n",
      "Answer: C; Real Answer: D\n",
      "\n",
      "The accountant used a calculator regularly, he kept one at home and one at the what? [' \"desk drawer\"', '\"desktop\"', '\"office\"', '\"wristwatch\"', '\"city hall\" ']\n",
      "Answer: C; Real Answer: C\n",
      "\n",
      "WHat leads to someone's death when they are very depressed? [' \"suicide\"', '\"overdosing\"', '\"sadness\"', '\"murder\"', '\"cyanide\" ']\n",
      "Answer: A; Real Answer: A\n",
      "\n",
      "Sally lost her kite because she wasn't careful. She thought that there was more string on the spool, but it slipped out of her fingers when she reached the what?. [' \"child\\'s hand\"', '\"the last straw\"', '\"hobby shop\"', '\"end of line\"', '\"toy store\" ']\n",
      "Answer: D; Real Answer: D\n",
      "\n",
      "The man uses grooming before a job interview, what is he trying to portray? [' \"looking good\"', '\"beauty\"', '\"tardiness\"', '\"handsomeness\"', '\"neatness\" ']\n",
      "Answer: E; Real Answer: E\n",
      "\n",
      "If your watching television and accomplish nothing what have you done? [' \"getting fat\"', '\"get fat\"', '\"typing words\"', '\"falling asleep\"', '\"wasted time\" ']\n",
      "Answer: E; Real Answer: E\n",
      "\n",
      "The hippy wanted peace with all humans, he had strong what for them all? [' \"names\"', '\"words\"', '\"naval\"', '\"bladders\"', '\"feelings\" ']\n",
      "Answer: E; Real Answer: E\n",
      "\n",
      "John enjoyed his time visiting the museum. He wanted to spend more time there, so that he could study the exhibits more. He was a very academic person and loved doing what? [' \"tired feet\"', '\"gaining knowledge\"', '\"back pain\"', '\"being bored\"', '\"pondering\" ']\n",
      "Answer: B; Real Answer: B\n",
      "\n",
      "Where would you sit in a chair to watch four-legged animals complete? [' \"bookstore\"', '\"house\"', '\"race track\"', '\"friend\\'s house\"', '\"building\" ']\n",
      "Answer: C; Real Answer: C\n",
      "\n",
      "If I am a person, I have a unique ability to do what? [' \"cross street\"', '\"stand upright\"', '\"speak spanish\"', '\"speak chinese\"', '\"further education\" ']\n",
      "Answer: B; Real Answer: B\n",
      "\n",
      "He waited for his friend at the squash court, but he was worried his friend thought he meant the at the other end of the public what? [' \"country club\"', '\"rich person\\'s house\"', '\"pool\"', '\"park\"', '\"fitness center\" ']\n",
      "Answer: D; Real Answer: D\n",
      "\n",
      "Jackson is a popular city name, but the one with a governor's office is where? [' \"personal\"', '\"special\"', '\"shiny\"', '\"rare\"', '\"irregular\" ']\n",
      "Answer: C; Real Answer: E\n",
      "\n",
      "Bob thought that his Pokemon cards were common and worthless, but he was wrong about them. They were really what? [' \"personal\"', '\"special\"', '\"shiny\"', '\"rare\"', '\"irregular\" ']\n",
      "Answer: D; Real Answer: D\n",
      "\n",
      "A wife asks a husband to stop being married to her, what is he likely to feel even with friends? [' \"happiness\"', '\"pleasure\"', '\"happy\"', '\"grief\"', '\"isolation\" ']\n",
      "Answer: D; Real Answer: D\n",
      "\n",
      "Though nearby, an apple from an apple tree where would be an imported product to the USA? [' \"ohio\"', '\"washington state\"', '\"alaska\"', '\"canada\"', '\"flowers\" ']\n",
      "Answer: D; Real Answer: D\n",
      "\n",
      "What would you change the learning process to be if someone does not like learning? [' \"interesting\"', '\"fun\"', '\"joyful or painful\"', '\"very important\"', '\"free\" ']\n",
      "Answer: B; Real Answer: B\n",
      "\n",
      "The judge did not take this part of the job lightly, the man was guilty but it was his passing sentence that condemned the man to what? [' \"dream\"', '\"knowing\"', '\"depression\"', '\"pleasure\"', '\"nostalgia\" ']\n",
      "Answer: D; Real Answer: D\n",
      "\n",
      "While laid up in the hospital she tried remembering good times, like that massage on vacation that brought great what? [' \"dream\"', '\"knowing\"', '\"depression\"', '\"pleasure\"', '\"nostalgia\" ']\n",
      "Answer: D; Real Answer: D\n",
      "\n",
      "What could contain no more than around 100 people? [' \"apartment\"', '\"classroom\"', '\"buildings\"', '\"car\"', '\"audience\" ']\n",
      "Answer: B; Real Answer: B\n",
      "\n",
      "What could happen after driving car that does not involve pain? [' \"automobile accidents\"', '\"backache\"', '\"eye strain\"', '\"getting tired\"', '\"car crash\" ']\n",
      "Answer: D; Real Answer: D\n",
      "\n",
      "The dog ran to the front window and barked, this is because of a presence at the what? [' \"building\"', '\"friend\\'s house\"', '\"classroom\"', '\"window\"', '\"front door\" ']\n",
      "Answer: E; Real Answer: E\n",
      "\n",
      "Where does a person need to get when they have more kids? [' \"compliments\"', '\"understand themselves\"', '\"life partner\"', '\"second chances\"', '\"larger house\" ']\n",
      "Answer: E; Real Answer: E\n",
      "\n",
      "James is apply for a job that he really wants. He knows that it will be a good fit and he has experience, but he doesn't have all the qualifications that they're asking for, so he's worried about what? [' \"acceptance\"', '\"rejection\"', '\"hope\"', '\"less sleep\"', '\"employment\" ']\n",
      "Answer: B; Real Answer: B\n",
      "\n",
      "Many addicts turn to exercise to deal with their addictions, this is because it is a healthy way to do what? [' \"condition heart\"', '\"expend energy\"', '\"laugh\"', '\"stretch\"', '\"weigh\" ']\n",
      "Answer: B; Real Answer: B\n",
      "\n",
      "Bob and Boris were standing in a queue at the grocery store. They were standing in place. The line was fast, but the children in front of them were loud. They were what? [' \"use soap\"', '\"irritation\"', '\"cleanliness\"', '\"thinking\"', '\"wet towel\" ']\n",
      "Answer: B; Real Answer: B\n",
      "\n",
      "The obsessive man was always washing hands, he had even done it so much once that it caused a what? [' \"use soap\"', '\"irritation\"', '\"cleanliness\"', '\"thinking\"', '\"wet towel\" ']\n",
      "Answer: B; Real Answer: B\n",
      "\n",
      "There was a show on television about a ranger who loved flowers, but the next day it was about a gardener who also loved flowers. It was a what? [' \"countryside\"', '\"anthology\"', '\"dull read\"', '\"state park\"', '\"surface of earth\" ']\n",
      "Answer: B; Real Answer: B\n",
      "\n",
      "Where is a system of electronic devices likely to be used in school? [' \"nature\"', '\"toilet\"', '\"computer science\"', '\"computer store\"', '\"human body\" ']\n",
      "Answer: C; Real Answer: C\n",
      "\n",
      "An attempt to confirm an applicant's reference would fail if the reference does what? [' \"question\"', '\"dispute\"', '\"deny\"', '\"contradict\"', '\"refuse\" ']\n",
      "Answer: C; Real Answer: C\n",
      "\n",
      "James thought that giving the AI a secular upbringing would be the better choice. He felt that the alternative might have results that were too what? [' \"eternal\"', '\"religious\"', '\"unpredictable\"', '\"holy\"', '\"monastic\" ']\n",
      "Answer: C; Real Answer: C\n",
      "\n",
      "He had an index card he had to return, so where did he put it after finding the book he needed? [' \"inside the book\"', '\"oral report\"', '\"library\"', '\"fileing cabnet\"', '\"card catalogue\" ']\n",
      "Answer: E; Real Answer: E\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>0.918367</td>\n",
       "      <td>QA-GNN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Correct Incorrect  Accuracy   Model\n",
       "0      45         4  0.918367  QA-GNN"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"QA-GNN Evaluation on Hierarchical Knowledge Graph Reasoning\")\n",
    "eval_qagnn = full_eval_qa_gnn()\n",
    "\n",
    "eval_qagnn[\"summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "951724e5-a370-4b13-86d9-e8f6223d5978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QA-GNN</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>0.918367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model Correct Incorrect  Accuracy\n",
       "0  QA-GNN      45         4  0.918367"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_qagnn[\"summary\"] = eval_qagnn[\"summary\"].reindex(columns=[\"Model\", \"Correct\", \"Incorrect\", \"Accuracy\"])  # reorder\n",
    "eval_qagnn[\"summary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "8ef49a17-3920-4b7b-89c9-26714216feaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Possible Answers</th>\n",
       "      <th>Real Answer</th>\n",
       "      <th>Predicted Answer</th>\n",
       "      <th>Correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Before getting a divorce, what did the wife fe...</td>\n",
       "      <td>[' \"harder\"', '\"anguish\"', '\"bitterness\"', '\"t...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The sensor would just the distance then set of...</td>\n",
       "      <td>[' \"near\"', '\"closeness\"', '\"here\"', '\"proximi...</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Learning languages is difficult. Even in a ful...</td>\n",
       "      <td>[' \"better communication\"', '\"overthinking\"', ...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The sanctions against the school were a punish...</td>\n",
       "      <td>[' \"ignore\"', '\"enforce\"', '\"authoritarian\"', ...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>To locate a choker not located in a jewelry bo...</td>\n",
       "      <td>[' \"jewelry store\"', '\"neck\"', '\"jewlery box\"'...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The fox walked from the city into the forest, ...</td>\n",
       "      <td>[' \"pretty flowers.\"', '\"hen house\"', '\"natura...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Joe suffered many consequences from stabbing a...</td>\n",
       "      <td>[' \"knife wounds\"', '\"buy a gun\"', '\"bleeding\"...</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What could happen to a paper if you leave it o...</td>\n",
       "      <td>[' \"park\"', '\"make time for\"', '\"receive instr...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The drug kingpin told his man to run errands, ...</td>\n",
       "      <td>[' \"park\"', '\"make time for\"', '\"receive instr...</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Too many people want exotic snakes. The demand...</td>\n",
       "      <td>[' \"ditch\"', '\"shop\"', '\"north america\"', '\"pe...</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Where in Southern Europe would you find many c...</td>\n",
       "      <td>[' \"michigan\"', '\"new york\"', '\"amsterdam\"', '...</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The game promised it was free, but the child's...</td>\n",
       "      <td>[' \"costly\"', '\"captive\"', '\"contained\"', '\"pa...</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The body guard was good at his duties, he made...</td>\n",
       "      <td>[' \"better job\"', '\"irritated\"', '\"feel safe\"'...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Learning languages is difficult. Even in a ful...</td>\n",
       "      <td>[' \"better communication\"', '\"overthinking\"', ...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>A beaver can destroy a machines functionality ...</td>\n",
       "      <td>[' \"strip club\"', '\"pocket\"', '\"millpond\"', '\"...</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What state south of Kentucky and north of Alab...</td>\n",
       "      <td>[' \"circus\"', '\"carnival\"', '\"surprise\"', '\"sp...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The man went to clown college, he had always w...</td>\n",
       "      <td>[' \"circus\"', '\"carnival\"', '\"surprise\"', '\"sp...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>John and James spent most of their time commun...</td>\n",
       "      <td>[' \"static\"', '\"train of thought.\"', '\"progres...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The fat man refused to accept what was possibl...</td>\n",
       "      <td>[' \"no go\"', '\"unlikely\"', '\"unable\"', '\"cant ...</td>\n",
       "      <td>D</td>\n",
       "      <td>C</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The accountant used a calculator regularly, he...</td>\n",
       "      <td>[' \"desk drawer\"', '\"desktop\"', '\"office\"', '\"...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>WHat leads to someone's death when they are ve...</td>\n",
       "      <td>[' \"suicide\"', '\"overdosing\"', '\"sadness\"', '\"...</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Sally lost her kite because she wasn't careful...</td>\n",
       "      <td>[' \"child\\'s hand\"', '\"the last straw\"', '\"hob...</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>The man uses grooming before a job interview, ...</td>\n",
       "      <td>[' \"looking good\"', '\"beauty\"', '\"tardiness\"',...</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>If your watching television and accomplish not...</td>\n",
       "      <td>[' \"getting fat\"', '\"get fat\"', '\"typing words...</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>The hippy wanted peace with all humans, he had...</td>\n",
       "      <td>[' \"names\"', '\"words\"', '\"naval\"', '\"bladders\"...</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>John enjoyed his time visiting the museum. He ...</td>\n",
       "      <td>[' \"tired feet\"', '\"gaining knowledge\"', '\"bac...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Where would you sit in a chair to watch four-l...</td>\n",
       "      <td>[' \"bookstore\"', '\"house\"', '\"race track\"', '\"...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>If I am a person, I have a unique ability to d...</td>\n",
       "      <td>[' \"cross street\"', '\"stand upright\"', '\"speak...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>He waited for his friend at the squash court, ...</td>\n",
       "      <td>[' \"country club\"', '\"rich person\\'s house\"', ...</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Jackson is a popular city name, but the one wi...</td>\n",
       "      <td>[' \"personal\"', '\"special\"', '\"shiny\"', '\"rare...</td>\n",
       "      <td>E</td>\n",
       "      <td>C</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Bob thought that his Pokemon cards were common...</td>\n",
       "      <td>[' \"personal\"', '\"special\"', '\"shiny\"', '\"rare...</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>A wife asks a husband to stop being married to...</td>\n",
       "      <td>[' \"happiness\"', '\"pleasure\"', '\"happy\"', '\"gr...</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Though nearby, an apple from an apple tree whe...</td>\n",
       "      <td>[' \"ohio\"', '\"washington state\"', '\"alaska\"', ...</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>What would you change the learning process to ...</td>\n",
       "      <td>[' \"interesting\"', '\"fun\"', '\"joyful or painfu...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>The judge did not take this part of the job li...</td>\n",
       "      <td>[' \"dream\"', '\"knowing\"', '\"depression\"', '\"pl...</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>While laid up in the hospital she tried rememb...</td>\n",
       "      <td>[' \"dream\"', '\"knowing\"', '\"depression\"', '\"pl...</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>What could contain no more than around 100 peo...</td>\n",
       "      <td>[' \"apartment\"', '\"classroom\"', '\"buildings\"',...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>What could happen after driving car that does ...</td>\n",
       "      <td>[' \"automobile accidents\"', '\"backache\"', '\"ey...</td>\n",
       "      <td>D</td>\n",
       "      <td>D</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>The dog ran to the front window and barked, th...</td>\n",
       "      <td>[' \"building\"', '\"friend\\'s house\"', '\"classro...</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Where does a person need to get when they have...</td>\n",
       "      <td>[' \"compliments\"', '\"understand themselves\"', ...</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>James is apply for a job that he really wants....</td>\n",
       "      <td>[' \"acceptance\"', '\"rejection\"', '\"hope\"', '\"l...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Many addicts turn to exercise to deal with the...</td>\n",
       "      <td>[' \"condition heart\"', '\"expend energy\"', '\"la...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Bob and Boris were standing in a queue at the ...</td>\n",
       "      <td>[' \"use soap\"', '\"irritation\"', '\"cleanliness\"...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>The obsessive man was always washing hands, he...</td>\n",
       "      <td>[' \"use soap\"', '\"irritation\"', '\"cleanliness\"...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>There was a show on television about a ranger ...</td>\n",
       "      <td>[' \"countryside\"', '\"anthology\"', '\"dull read\"...</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Where is a system of electronic devices likely...</td>\n",
       "      <td>[' \"nature\"', '\"toilet\"', '\"computer science\"'...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>An attempt to confirm an applicant's reference...</td>\n",
       "      <td>[' \"question\"', '\"dispute\"', '\"deny\"', '\"contr...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>James thought that giving the AI a secular upb...</td>\n",
       "      <td>[' \"eternal\"', '\"religious\"', '\"unpredictable\"...</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>He had an index card he had to return, so wher...</td>\n",
       "      <td>[' \"inside the book\"', '\"oral report\"', '\"libr...</td>\n",
       "      <td>E</td>\n",
       "      <td>E</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Question  \\\n",
       "0   Before getting a divorce, what did the wife fe...   \n",
       "1   The sensor would just the distance then set of...   \n",
       "2   Learning languages is difficult. Even in a ful...   \n",
       "3   The sanctions against the school were a punish...   \n",
       "4   To locate a choker not located in a jewelry bo...   \n",
       "5   The fox walked from the city into the forest, ...   \n",
       "6   Joe suffered many consequences from stabbing a...   \n",
       "7   What could happen to a paper if you leave it o...   \n",
       "8   The drug kingpin told his man to run errands, ...   \n",
       "9   Too many people want exotic snakes. The demand...   \n",
       "10  Where in Southern Europe would you find many c...   \n",
       "11  The game promised it was free, but the child's...   \n",
       "12  The body guard was good at his duties, he made...   \n",
       "13  Learning languages is difficult. Even in a ful...   \n",
       "14  A beaver can destroy a machines functionality ...   \n",
       "15  What state south of Kentucky and north of Alab...   \n",
       "16  The man went to clown college, he had always w...   \n",
       "17  John and James spent most of their time commun...   \n",
       "18  The fat man refused to accept what was possibl...   \n",
       "19  The accountant used a calculator regularly, he...   \n",
       "20  WHat leads to someone's death when they are ve...   \n",
       "21  Sally lost her kite because she wasn't careful...   \n",
       "22  The man uses grooming before a job interview, ...   \n",
       "23  If your watching television and accomplish not...   \n",
       "24  The hippy wanted peace with all humans, he had...   \n",
       "25  John enjoyed his time visiting the museum. He ...   \n",
       "26  Where would you sit in a chair to watch four-l...   \n",
       "27  If I am a person, I have a unique ability to d...   \n",
       "28  He waited for his friend at the squash court, ...   \n",
       "29  Jackson is a popular city name, but the one wi...   \n",
       "30  Bob thought that his Pokemon cards were common...   \n",
       "31  A wife asks a husband to stop being married to...   \n",
       "32  Though nearby, an apple from an apple tree whe...   \n",
       "33  What would you change the learning process to ...   \n",
       "34  The judge did not take this part of the job li...   \n",
       "35  While laid up in the hospital she tried rememb...   \n",
       "36  What could contain no more than around 100 peo...   \n",
       "37  What could happen after driving car that does ...   \n",
       "38  The dog ran to the front window and barked, th...   \n",
       "39  Where does a person need to get when they have...   \n",
       "40  James is apply for a job that he really wants....   \n",
       "41  Many addicts turn to exercise to deal with the...   \n",
       "42  Bob and Boris were standing in a queue at the ...   \n",
       "43  The obsessive man was always washing hands, he...   \n",
       "44  There was a show on television about a ranger ...   \n",
       "45  Where is a system of electronic devices likely...   \n",
       "46  An attempt to confirm an applicant's reference...   \n",
       "47  James thought that giving the AI a secular upb...   \n",
       "48  He had an index card he had to return, so wher...   \n",
       "\n",
       "                                     Possible Answers Real Answer  \\\n",
       "0   [' \"harder\"', '\"anguish\"', '\"bitterness\"', '\"t...           C   \n",
       "1   [' \"near\"', '\"closeness\"', '\"here\"', '\"proximi...           D   \n",
       "2   [' \"better communication\"', '\"overthinking\"', ...           C   \n",
       "3   [' \"ignore\"', '\"enforce\"', '\"authoritarian\"', ...           A   \n",
       "4   [' \"jewelry store\"', '\"neck\"', '\"jewlery box\"'...           A   \n",
       "5   [' \"pretty flowers.\"', '\"hen house\"', '\"natura...           C   \n",
       "6   [' \"knife wounds\"', '\"buy a gun\"', '\"bleeding\"...           E   \n",
       "7   [' \"park\"', '\"make time for\"', '\"receive instr...           C   \n",
       "8   [' \"park\"', '\"make time for\"', '\"receive instr...           D   \n",
       "9   [' \"ditch\"', '\"shop\"', '\"north america\"', '\"pe...           D   \n",
       "10  [' \"michigan\"', '\"new york\"', '\"amsterdam\"', '...           D   \n",
       "11  [' \"costly\"', '\"captive\"', '\"contained\"', '\"pa...           D   \n",
       "12  [' \"better job\"', '\"irritated\"', '\"feel safe\"'...           C   \n",
       "13  [' \"better communication\"', '\"overthinking\"', ...           C   \n",
       "14  [' \"strip club\"', '\"pocket\"', '\"millpond\"', '\"...           C   \n",
       "15  [' \"circus\"', '\"carnival\"', '\"surprise\"', '\"sp...           B   \n",
       "16  [' \"circus\"', '\"carnival\"', '\"surprise\"', '\"sp...           A   \n",
       "17  [' \"static\"', '\"train of thought.\"', '\"progres...           C   \n",
       "18  [' \"no go\"', '\"unlikely\"', '\"unable\"', '\"cant ...           D   \n",
       "19  [' \"desk drawer\"', '\"desktop\"', '\"office\"', '\"...           C   \n",
       "20  [' \"suicide\"', '\"overdosing\"', '\"sadness\"', '\"...           A   \n",
       "21  [' \"child\\'s hand\"', '\"the last straw\"', '\"hob...           D   \n",
       "22  [' \"looking good\"', '\"beauty\"', '\"tardiness\"',...           E   \n",
       "23  [' \"getting fat\"', '\"get fat\"', '\"typing words...           E   \n",
       "24  [' \"names\"', '\"words\"', '\"naval\"', '\"bladders\"...           E   \n",
       "25  [' \"tired feet\"', '\"gaining knowledge\"', '\"bac...           B   \n",
       "26  [' \"bookstore\"', '\"house\"', '\"race track\"', '\"...           C   \n",
       "27  [' \"cross street\"', '\"stand upright\"', '\"speak...           B   \n",
       "28  [' \"country club\"', '\"rich person\\'s house\"', ...           D   \n",
       "29  [' \"personal\"', '\"special\"', '\"shiny\"', '\"rare...           E   \n",
       "30  [' \"personal\"', '\"special\"', '\"shiny\"', '\"rare...           D   \n",
       "31  [' \"happiness\"', '\"pleasure\"', '\"happy\"', '\"gr...           D   \n",
       "32  [' \"ohio\"', '\"washington state\"', '\"alaska\"', ...           D   \n",
       "33  [' \"interesting\"', '\"fun\"', '\"joyful or painfu...           B   \n",
       "34  [' \"dream\"', '\"knowing\"', '\"depression\"', '\"pl...           D   \n",
       "35  [' \"dream\"', '\"knowing\"', '\"depression\"', '\"pl...           D   \n",
       "36  [' \"apartment\"', '\"classroom\"', '\"buildings\"',...           B   \n",
       "37  [' \"automobile accidents\"', '\"backache\"', '\"ey...           D   \n",
       "38  [' \"building\"', '\"friend\\'s house\"', '\"classro...           E   \n",
       "39  [' \"compliments\"', '\"understand themselves\"', ...           E   \n",
       "40  [' \"acceptance\"', '\"rejection\"', '\"hope\"', '\"l...           B   \n",
       "41  [' \"condition heart\"', '\"expend energy\"', '\"la...           B   \n",
       "42  [' \"use soap\"', '\"irritation\"', '\"cleanliness\"...           B   \n",
       "43  [' \"use soap\"', '\"irritation\"', '\"cleanliness\"...           B   \n",
       "44  [' \"countryside\"', '\"anthology\"', '\"dull read\"...           B   \n",
       "45  [' \"nature\"', '\"toilet\"', '\"computer science\"'...           C   \n",
       "46  [' \"question\"', '\"dispute\"', '\"deny\"', '\"contr...           C   \n",
       "47  [' \"eternal\"', '\"religious\"', '\"unpredictable\"...           C   \n",
       "48  [' \"inside the book\"', '\"oral report\"', '\"libr...           E   \n",
       "\n",
       "   Predicted Answer Correct  \n",
       "0                 C    True  \n",
       "1                 D    True  \n",
       "2                 C    True  \n",
       "3                 A    True  \n",
       "4                 A    True  \n",
       "5                 C    True  \n",
       "6                 E    True  \n",
       "7                 C    True  \n",
       "8                 D    True  \n",
       "9                 D    True  \n",
       "10                C   False  \n",
       "11                D    True  \n",
       "12                C    True  \n",
       "13                C    True  \n",
       "14                E   False  \n",
       "15                B    True  \n",
       "16                A    True  \n",
       "17                C    True  \n",
       "18                C   False  \n",
       "19                C    True  \n",
       "20                A    True  \n",
       "21                D    True  \n",
       "22                E    True  \n",
       "23                E    True  \n",
       "24                E    True  \n",
       "25                B    True  \n",
       "26                C    True  \n",
       "27                B    True  \n",
       "28                D    True  \n",
       "29                C   False  \n",
       "30                D    True  \n",
       "31                D    True  \n",
       "32                D    True  \n",
       "33                B    True  \n",
       "34                D    True  \n",
       "35                D    True  \n",
       "36                B    True  \n",
       "37                D    True  \n",
       "38                E    True  \n",
       "39                E    True  \n",
       "40                B    True  \n",
       "41                B    True  \n",
       "42                B    True  \n",
       "43                B    True  \n",
       "44                B    True  \n",
       "45                C    True  \n",
       "46                C    True  \n",
       "47                C    True  \n",
       "48                E    True  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_qagnn[\"evaluation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "0505bb67-bff6-4fca-aade-2138dcc62278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gemma-7b-it</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Llama-2-7b-chat-hf</td>\n",
       "      <td>17</td>\n",
       "      <td>32</td>\n",
       "      <td>0.346939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>37</td>\n",
       "      <td>12</td>\n",
       "      <td>0.755102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Falcon-7b-instruct</td>\n",
       "      <td>13</td>\n",
       "      <td>36</td>\n",
       "      <td>0.265306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model  Correct  Incorrect  Accuracy\n",
       "0               Gemma-7b-it       21         28  0.428571\n",
       "1        Llama-2-7b-chat-hf       17         32  0.346939\n",
       "2  Mistral-7B-Instruct-v0.2       37         12  0.755102\n",
       "3        Falcon-7b-instruct       13         36  0.265306"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the LLM stats\n",
    "# from https://drive.google.com/file/d/1HIFetTdjmL539WO3KCnk2jNNEgYU2dOb/view?usp=sharing\n",
    "llm_summaries_df = pd.read_csv(\"qagnn/data/llm_data/llm_summaries_df.csv\")\n",
    "\n",
    "falcon_eval_df = pd.read_csv(\"qagnn/data/llm_data/Falcon-7b-instruct_eval_df.csv\")\n",
    "gemma_eval_df = pd.read_csv(\"qagnn/data/llm_data/Gemma-7b-it_eval_df.csv\")\n",
    "llama2_eval_df = pd.read_csv(\"qagnn/data/llm_data/Llama-2-7b-chat-hf_eval_df.csv\")\n",
    "mistral_eval_df = pd.read_csv(\"qagnn/data/llm_data/Mistral-7B-Instruct-v0.2_eval_df.csv\")\n",
    "\n",
    "llm_summaries_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6542da3a-880f-47c0-88a9-3bc033228b20",
   "metadata": {},
   "source": [
    "# Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "daed843c-780a-457f-88a7-1099c53b6ca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QA-GNN</td>\n",
       "      <td>45</td>\n",
       "      <td>4</td>\n",
       "      <td>0.918367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gemma-7b-it</td>\n",
       "      <td>21</td>\n",
       "      <td>28</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Llama-2-7b-chat-hf</td>\n",
       "      <td>17</td>\n",
       "      <td>32</td>\n",
       "      <td>0.346939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mistral-7B-Instruct-v0.2</td>\n",
       "      <td>37</td>\n",
       "      <td>12</td>\n",
       "      <td>0.755102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Falcon-7b-instruct</td>\n",
       "      <td>13</td>\n",
       "      <td>36</td>\n",
       "      <td>0.265306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model Correct Incorrect  Accuracy\n",
       "0                    QA-GNN      45         4  0.918367\n",
       "0               Gemma-7b-it      21        28  0.428571\n",
       "1        Llama-2-7b-chat-hf      17        32  0.346939\n",
       "2  Mistral-7B-Instruct-v0.2      37        12  0.755102\n",
       "3        Falcon-7b-instruct      13        36  0.265306"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_qagnn_summary: pd.DataFrame = eval_qagnn[\"summary\"]\n",
    "eval_qagnn_evaluation: pd.DataFrame = eval_qagnn[\"evaluation\"]\n",
    "\n",
    "summaries_df: pd.DataFrame = pd.concat([eval_qagnn_summary, llm_summaries_df])\n",
    "summaries_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "5f86d62b-92b7-487a-b2ac-af0097c945b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export this\n",
    "summaries_df.to_csv(\"qagnn/data/summaries_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030853bc-625a-46ed-8dd9-2e89e27b2871",
   "metadata": {},
   "source": [
    "# Stray Experimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "05adafe5-deef-42f1-b6bc-e7ca61c6dfa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 5, 100]), dtype=torch.int64\n",
      "torch.Size([64, 5, 100]), dtype=torch.int64\n",
      "torch.Size([64, 5, 100]), dtype=torch.int64\n",
      "torch.Size([64, 5, 100]), dtype=torch.bool\n",
      "torch.Size([64, 5, 200]), dtype=torch.int64\n",
      "torch.Size([64, 5, 200]), dtype=torch.int64\n",
      "torch.Size([64, 5, 200, 1]), dtype=torch.float32\n",
      "torch.Size([64, 5]), dtype=torch.int64\n",
      "[64]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "[64]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n",
      "   <class 'list'> [5]\n"
     ]
    }
   ],
   "source": [
    "# This cell was used for tons of experimentation for reverse engineering\n",
    "\n",
    "from typing import List\n",
    "\n",
    "\n",
    "POSSIBLE_ANSWERS = ['A', 'B', 'C', 'D', 'E']\n",
    "\n",
    "i = 0\n",
    "stop = 1\n",
    "\n",
    "# data: qids, labels, *input_data (len == 10)\n",
    "# iterate batch-by-batch\n",
    "for qids, labels, *input_data in dataset.train():\n",
    "    # FINDINGS\n",
    "    batch_size: int = len(qids)\n",
    "    # qids == question_ids???\n",
    "    mcq_labels: List[int] = list(labels)  # they will go up to 4\n",
    "    mcq_answers: List[str] = [POSSIBLE_ANSWERS[mcq_label] for mcq_label in mcq_labels]\n",
    "    num_choice: int = 5\n",
    "    #d_sent: int = 100\n",
    "    #n_node: int = 200\n",
    "    \n",
    "    #print(qids)\n",
    "    #print(mcq_answers)\n",
    "    #print(type(input_data))\n",
    "    #print(type(input_data[-1]))\n",
    "    #print(input_data[7][0].unsqueeze(0).shape)\n",
    "    #print(f\"batch_size: {batch_size}\")\n",
    "    # input_data: list; len == 10\n",
    "    \n",
    "    # [0:4]: sent_vecs (batch_size, num_choice, d_sent)  -> (batch_size * num_choice, d_sent)\n",
    "    \n",
    "    # [4]: concept_ids (batch_size, num_choice, n_node)  -> (batch_size * num_choice, n_node)\n",
    "    # [5]: node_type_ids (batch_size, num_choice, n_node) -> (batch_size * num_choice, n_node)\n",
    "    # [6]: ???\n",
    "    # [7]: adj_lengths (batch_size, num_choice)          -> (batch_size * num_choice, )\n",
    "    \n",
    "    # [8]: edge_index_orig\n",
    "    # [9]: edge_type_orig\n",
    "    \n",
    "    # tests\n",
    "    #print(input_data[0].dtype)\n",
    "    #entity = torch.tensor([input_data[0].int(), input_data[1].int(), input_data[2].int(), input_data[3].int()], device=device0)\n",
    "    \n",
    "    for i in range(len(input_data)):\n",
    "        try:\n",
    "            print(f\"{input_data[i].shape}, dtype={input_data[i].dtype}\")\n",
    "            #print(str(input_data[i].int())[:128])\n",
    "        except:\n",
    "            #print(input_data[i])\n",
    "            #list_tensor = torch.tensor(input_data[i], device=device0)\n",
    "            #print(f\"{list_tensor.shape}, dtype={input_data[i].dtype}\")\n",
    "            tensors: List = input_data[i]\n",
    "            print(f\"{[len(tensors)]}\")\n",
    "            for tensor in tensors:\n",
    "                try:\n",
    "                    print(f\"   {tensor.shape}, dtype={tensor.dtype}\")\n",
    "                    #print(str(input_data[i].int())[:128])\n",
    "                except:\n",
    "                    #print(input_data[i])\n",
    "                    #list_tensor = torch.tensor(input_data[i], device=device0)\n",
    "                    #print(f\"{list_tensor.shape}, dtype={input_data[i].dtype}\")\n",
    "                    print(f\"   {type(tensor)}\", end=\" \")\n",
    "                    print(f\"{[len(tensor)]}\")\n",
    "            \n",
    "    #print(entity.shape)  # [64, 5, 100]\n",
    "    #print(entity)\n",
    "    #print(qids)\n",
    "    #print(labels)\n",
    "    \n",
    "    #print(len(qids))\n",
    "    #print(input_data[6])\n",
    "    \n",
    "    #print(len(entity))\n",
    "    #print(type(entity))\n",
    "\n",
    "    #print(tokenizer.decode(entity, skip_special_tokens=True))\n",
    "    \n",
    "    i += 1\n",
    "    if i >= stop:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
