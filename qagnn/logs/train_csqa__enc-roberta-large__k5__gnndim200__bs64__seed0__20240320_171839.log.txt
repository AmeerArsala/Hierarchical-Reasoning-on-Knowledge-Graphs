CREATION
pid: 1387547
conda env: hierarchical_reasoning_kg
screen: 

gpu: 0,1

Namespace(att_head_num=2, batch_size=64, cuda=True, dataset='csqa', debug=False, decoder_lr=0.001, dev_adj='data/csqa/graph/dev.graph.adj.pk', dev_statements='data/csqa/statement/dev.statement.jsonl', drop_partial_batch=False, dropoutf=0.2, dropoutg=0.2, dropouti=0.2, encoder='roberta-large', encoder_layer=-1, encoder_lr=1e-05, ent_emb=['tzw'], ent_emb_paths=['data/cpnet/tzw.ent.npy'], eval_batch_size=2, fc_dim=200, fc_layer_num=0, fill_partial_batch=False, fp16=True, freeze_ent_emb=True, gnn_dim=200, inhouse=True, inhouse_train_qids='data/csqa/inhouse_split_qids.txt', init_range=0.02, k=5, load_model_path=None, log_interval=10, loss='cross_entropy', lr_schedule='fixed', max_epochs_before_stop=10, max_grad_norm=1.0, max_node_num=200, max_seq_len=100, mini_batch_size=2, mode='train', n_epochs=15, num_relation=38, optim='radam', refreeze_epoch=10000, save_dir='saved_models/csqa/enc-roberta-large__k5__gnndim200__bs64__seed0__20240320_171839', save_model=True, seed=0, simple=False, subsample=1.0, test_adj='data/csqa/graph/test.graph.adj.pk', test_statements='data/csqa/statement/test.statement.jsonl', train_adj='data/csqa/graph/train.graph.adj.pk', train_statements='data/csqa/statement/train.statement.jsonl', unfreeze_epoch=4, use_cache=True, warmup_steps=150, weight_decay=0.01)
| num_concepts: 799273 |
dict_items([('openai-community/openai-gpt', 'gpt'), ('google-bert/bert-base-uncased', 'bert'), ('google-bert/bert-large-uncased', 'bert'), ('google-bert/bert-base-cased', 'bert'), ('google-bert/bert-large-cased', 'bert'), ('google-bert/bert-base-multilingual-uncased', 'bert'), ('google-bert/bert-base-multilingual-cased', 'bert'), ('google-bert/bert-base-chinese', 'bert'), ('google-bert/bert-base-german-cased', 'bert'), ('google-bert/bert-large-uncased-whole-word-masking', 'bert'), ('google-bert/bert-large-cased-whole-word-masking', 'bert'), ('google-bert/bert-large-uncased-whole-word-masking-finetuned-squad', 'bert'), ('google-bert/bert-large-cased-whole-word-masking-finetuned-squad', 'bert'), ('google-bert/bert-base-cased-finetuned-mrpc', 'bert'), ('google-bert/bert-base-german-dbmdz-cased', 'bert'), ('google-bert/bert-base-german-dbmdz-uncased', 'bert'), ('cl-tohoku/bert-base-japanese', 'bert'), ('cl-tohoku/bert-base-japanese-whole-word-masking', 'bert'), ('cl-tohoku/bert-base-japanese-char', 'bert'), ('cl-tohoku/bert-base-japanese-char-whole-word-masking', 'bert'), ('TurkuNLP/bert-base-finnish-cased-v1', 'bert'), ('TurkuNLP/bert-base-finnish-uncased-v1', 'bert'), ('wietsedv/bert-base-dutch-cased', 'bert'), ('xlnet/xlnet-base-cased', 'xlnet'), ('xlnet/xlnet-large-cased', 'xlnet'), ('FacebookAI/roberta-base', 'roberta'), ('FacebookAI/roberta-large', 'roberta'), ('FacebookAI/roberta-large-mnli', 'roberta'), ('distilbert/distilroberta-base', 'roberta'), ('openai-community/roberta-base-openai-detector', 'roberta'), ('openai-community/roberta-large-openai-detector', 'roberta'), ('lstm', 'lstm'), ('albert/albert-base-v1', 'albert'), ('albert/albert-large-v1', 'albert'), ('albert/albert-xlarge-v1', 'albert'), ('albert/albert-xxlarge-v1', 'albert'), ('albert/albert-base-v2', 'albert'), ('albert/albert-large-v2', 'albert'), ('albert/albert-xlarge-v2', 'albert'), ('albert/albert-xxlarge-v2', 'albert'), ('cambridgeltl/SapBERT-from-PubMedBERT-fulltext', 'bert')])
